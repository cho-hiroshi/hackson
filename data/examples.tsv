google-0x0g-2018-badge	About ##	This is the electronic badge distributed at 0x0G, Google's annual event atDEF CON/Black Hat
google-0x0g-2018-badge	About ##	 This badge features a PIC microcontroller driving a ring ofLEDs with communication over infrared.Included are circuit design files and firmware source
google-0x0g-2018-badge	About ##	 Both are licensed underthe Apache 2 license.This is not an officially supported Google product
google-0x0g-2018-badge	About ##	 This is a one-time release,do not expect updates even if it turns out we have bugs.
google-0x0g-2018-badge	Authors ##	If you have any questions about the badge, feel free to contact one of the
google-AppSpeedIndex	1  Build the "BoundingBox" helper app.	sdk/tools/android update project --name BoundingBox -p 
google-AppSpeedIndex	1  Build the "BoundingBox" helper app.	--target android-19ant clean debugant debug install
google-AppSpeedIndex	2  Build the "bitmap" python module:	g++ bitmaptools.cc -o bitmaptools
google-AppUpdateTrackerLib	UpdateTracker Android Library project	Project Goal ------- Right click on .aar file and select 'Save Link as...' Also in **build.gradle*PingAdwordsUtil.recordRefererOnDeepLinkCall ..
google-AppUpdateTrackerLib	UpdateTracker Android Library project	PingAdwordsUtil.onResumePingIfAppUpdate ..
google-AppUpdateTrackerLib	UpdateTracker Android Library project	 Upon app update ad-click, if a deeplink is fired then DeepLinkTrackerActivity can be called
google-AppUpdateTrackerLib	UpdateTracker Android Library project	Later when PingAdwordsUtil.onResumePingIfAppUpdate .
google-AppUpdateTrackerLib	UpdateTracker Android Library project	 will be invoked, the referer will be used for adwords attribution
google-AppUpdateTrackerLib	Copyright Notice	Copyright  C  2013-2015 Google Inc., authors, and contributors  see the AUTHORSfile 
google-AppUpdateTrackerLib	Copyright Notice	 Licensed under the  Apache 2.0 license  see the LICENSE file 
google-AppUpdateTrackerLib	Copyright Notice	 **This is not an official Google product.**
google-BrokenType	BrokenType	BrokenType is a set of tools designed to test the robustness and security of font rasterization software, especially codebases prone to memory corruption issues  written in C/C++ and similar languages 
google-BrokenType	BrokenType	It consists of three components:The programs and scripts were successfully used in 2015-2017 to discover and report  20  vulnerabilities in the font rasterization code present in the Windows kernel  win32k.sys and atmfd.dll drivers , and further  19  security flaws in the user-mode Microsoft Uniscribe library
google-BrokenType	BrokenType	The fuzzing efforts were discussed in the following Google Project Zero blog posts:
google-BrokenType	Disclaimer	This is not an official Google product.
google-CSP-Validator	CSP Validator	! image This is a  Sublime Text 2  plugin that checks yourJavaScript, HTML and CSS for potential  Content Security Policy  issues
google-CSP-Validator	CSP Validator	If you're new to Content Security Policythere is, in fact,  an HTML5 Rocks article for that Right now the plugin checks for:Right now you need to clone this repo into your packages folder typically ~/Library/Application Support/Sublime Text 2/Packages .to be added to Package Control._
google-CSP-Validator	Usage	Just code away and all being well you will receive warnings as the plugin findsthem
google-CSP-Validator	Usage	If for any reason you want to disable the warnings you can use *Ctrl + Option + Shift + C
google-CallBuilder	CallBuilder	Make a builder by defining one function
google-CallBuilder	CallBuilder	  _beta_: be ready for breaking API changes builder class
google-CallBuilder	CallBuilder	Builders are great when you have a constructor or method withmany parameters
google-CallBuilder	CallBuilder	They are even helpful when you have two or more arguments ofthe same type, since the order is easy to mix up.Builders are usually hard to write
google-CallBuilder	CallBuilder	You will probably need around 4 lines forevery field, and if it's an inner class, it makes the file long and cumbersometo navigate
google-CallBuilder	CallBuilder	This discourages many people from writing builders, and thosepeople give up and learn to live with brittle, and hard-to-read code
google-CallBuilder	CallBuilder	If youwant to add multiple setters for a field  common for lists that may have add andaddAll , your builder will quickly become a chore to write and a burden toCallBuilder changes that
google-CallBuilder	CallBuilder	To use it, you can simply write the method orconstructor as you normally would, but add the @CallBuilder annotation:that are of a certain type
google-CallBuilder	CallBuilder	This can make the API more natural and look morelike a manually-written builder:
google-CausalImpact	An R package for causal inference using Bayesian structural time-series models	This R package implements an approach to estimating the causal effect of adesigned intervention on a time series
google-CausalImpact	An R package for causal inference using Bayesian structural time-series models	For example, how many additional dailyclicks were generated by an advertising campaign? Answering a question like thiscan be difficult when a randomized experiment is not available
google-CausalImpact	An R package for causal inference using Bayesian structural time-series models	The package aimsto address this difficulty using a structural Bayesian time-series model toestimate how the response metric might have evolved after the intervention ifthe intervention had not occurred.As with all approaches to causal inference on non-experimental data, validconclusions require strong assumptions
google-CausalImpact	An R package for causal inference using Bayesian structural time-series models	The CausalImpact package, in particular,assumes that the outcome time series can be explained in terms of a set ofcontrol time series that were themselves not affected by the intervention.Furthermore, the relation between treated series and control series is assumedto be stable during the post-intervention period
google-CausalImpact	An R package for causal inference using Bayesian structural time-series models	Understanding and checkingthese assumptions for any given application is critical for obtaining valid
google-CausalImpact	Installation	 Video tutorial  Documentation and examples 
google-Chrome.Docs	Chrome.Docs	Draft documentation for developer features in the Chrome beta, canary, and dev channels.This repo contains drafts for content that will be moved to MDN when particular versions of Chrome reach stable
google-Chrome.Docs	Chrome.Docs	Because it is drafts, don't assume that it is authoratative or complete
google-Chrome.Docs	Chrome.Docs	It's organized with separate directories correspoonding to certain lables on  chromestatus.com The current directories are:Chrome.Docs is an open source project and we welcome your contributions!Before submitting a pull request, please review  CONTRIBUTING.md  CONTRIBUTING.md and make sure that there is an issue filed describing the fix or new content.If you don't complete these steps, we won't be able to accept your pull request, sorry.
google-DirectXShaderCompiler	DirectX Shader Compiler	 ! Build status  The DirectX Shader Compiler project includes a compiler and related tools used to compile High-Level Shader Language  HLSL  programs into DirectX Intermediate Language  DXIL  representation
google-DirectXShaderCompiler	DirectX Shader Compiler	Applications that make use of DirectX for graphics, games, and computation can use it to generate shader programs.For more information, see the  Wiki 
google-DirectXShaderCompiler	Features and Goals	The starting point of the project is a fork of the  LLVM  and  Clang  projects, modified to accept HLSL and emit a validated container that can be consumed by GPU drivers.At the moment, the DirectX HLSL Compiler provides the following components:The goal of the project is to allow the broader community of shader developers to contribute to the language and representation of shader programs, maintaining the principles of compatibility and supportability for the platform
google-DirectXShaderCompiler	Features and Goals	It's currently in active development across two axes: language evolution  with no impact to DXIL representation , and surfacing hardware capabilities  with impact to DXIL, and thus requiring coordination with GPU implementations .
google-DirectXShaderCompiler	SPIR-V CodeGen	As an example of community contribution, this project can also target the  SPIR-V  intermediate representation
google-DirectXShaderCompiler	SPIR-V CodeGen	Please see the  doc  docs/SPIR-V.rst  for how HLSL features are mapped to SPIR-V, and the  wiki  page for how to build, use, and contribute to the SPIR-V CodeGen.
google-DirectXShaderCompiler	Building Sources	Note: Instead of building manually, you can download the artifacts built by Appveyor for the latest master branch at  here Before you build, you will need to have some additional software installed
google-DirectXShaderCompiler	Building Sources	This is the most straightforward pathTests are built using the TAEF framework
google-DirectXShaderCompiler	Building Sources	Unless you have the Windows Driver Kit installed, you should run the script at utils\hct\hctgettaef.py from your build environment before you start building to download and unzip it as an external dependency
google-DirectXShaderCompiler	Building Sources	You should only need to do this once.To build, run this command on the HLSL Console.You can also clean, build and run tests with this command.To see a list of additional commands available, run hcthelp
google-DirectXShaderCompiler	Running Tests	To run tests, open the HLSL Console and run this command after a successful build.Some tests will run shaders and verify their behavior
google-DirectXShaderCompiler	Running Tests	These tests also involve a driver that can run these execute these shaders
google-DirectXShaderCompiler	Running Tests	See the next section on how this should be currently set up.
google-DirectXShaderCompiler	Running Shaders	To run shaders compiled as DXIL, you will need support from the operating system as well as from the driver for your graphics adapter
google-DirectXShaderCompiler	Running Shaders	Windows 10 Creators Update is the first version to support DXIL shaders
google-DirectXShaderCompiler	Running Shaders	See the  Wiki  for information on using experimental support or the software adapter.
google-DirectXShaderCompiler	Hardware Support	Hardware GPU support for DXIL is provided by the following vendors:
google-DirectXShaderCompiler	NVIDIA	NVIDIA's r396 drivers  r397.64 and later  provide release mode support for DXIL1.1 and Shader Model 6.1 on Win10 1709 and later, and experimental mode supportfor DXIL 1.2 and Shader Model 6.2 on Win10 1803 and later
google-DirectXShaderCompiler	NVIDIA	These drivers alsosupport DXR in experimental mode.Drivers can be downloaded from  geforce.com 
google-DirectXShaderCompiler	AMD	AMD’s driver  Radeon Software Adrenalin Edition 18.4.1 or later  provides release mode support for DXIL 1.1 and Shader Model 6.Drivers can be downloaded from  AMD's download site 
google-DirectXShaderCompiler	Intel	Intel's 15.60 drivers  15.60.0.4849 and later  support release mode for DXIL 1.0 and Shader Model 6.0 as well asrelease mode for DXIL 1.1 and Shader Model 6.1  View Instancing support only .Drivers can be downloaded from the following link  Intel Graphics Drivers Direct access to 15.60 driver  latest as of of this update  is provided below: Installer  Release Notes related to DXIL 
google-DirectXShaderCompiler	Making Changes	To make contributions, see the  CONTRIBUTING.md  CONTRIBUTING.md  file in this project.
google-DirectXShaderCompiler	Documentation	You can find documentation for this project in the docs directory
google-DirectXShaderCompiler	Documentation	These contain the original LLVM documentation files, as well as two new files worth nothing:DirectX Shader Compiler is distributed under the terms of the University of Illinois Open Source License.See  LICENSE.txt  LICENSE.TXT  and  ThirdPartyNotices.txt  ThirdPartyNotices.txt  for details.
google-DirectXShaderCompiler	Code of Conduct	This project has adopted the  Microsoft Open Source Code of Conduct  For more information see the  Code of Conduct FAQ  or contact  opencode@microsoft.com  mailto:opencode@microsoft.com  with any additional questions or comments.
google-EXEgesis	Goal	Google's EXEgesis project aims to improve code generation in compilers, via: Providing machine-readable lists of instructions for  hardware Inferring latencies and Providing tools for debugging the performance of code based on this data.For a high-level overview of our efforts, see the slides  for a tech talk about EXEgesis  July 2017 .
google-EXEgesis	Details	This repository provides a set of  tools  exegesis/tools/README.md  forextracting data about instructions and latencies from canonical sources andconverting them into machine-readable form
google-EXEgesis	Details	Some require parsing PDF files;others are more straightforward.When latencies and µOps scheduling are not available in the documentation, weauto generate benchmarks to measure them.The output data is available in the form of a  ProtocolBuffer  message  exegesis/proto/microarchitecture.proto .It includes:
google-EXEgesis	What's Next	how to submit a patch.
google-EarlGrey	EarlGrey	 ! Apache License   ! CC-BY 4.0 License     ! Carthage compatible   ! CocoaPods   ! Gem Version  EarlGrey is a native iOS UI automation test framework that enables you to writeclear, concise tests.With the EarlGrey framework, you have access to enhanced synchronizationfeatures
google-EarlGrey	EarlGrey	EarlGrey automatically synchronizes with the UI, network requests,and various queues; but still allows you to manually implement customizedtimings, if needed.EarlGrey’s synchronization features help to ensure that the UI is in a steadystate before actions are performed
google-EarlGrey	EarlGrey	This greatly increases test stability andmakes tests highly repeatable.EarlGrey works in conjunction with the XCTest framework and integrates withXcode’s Test Navigator so you can run tests directly from Xcode or the commandline  using xcodebuild .
google-EarlGrey	Getting Started	The EarlGrey documentation for users is located in the EarlGrey/docs  folder.To get started, review the EarlGrey features, check for backward compatibility,and then install/run EarlGrey with your test target
google-EarlGrey	Getting Started	After everything isconfigured, take a look at the EarlGrey API and start writing your own tests.If you need help, several resources are available
google-EarlGrey	Getting Started	First check the  FAQ If you have more questions after reading the FAQ, see  Known Issues You can bring more specific issues to our attention by asking them on stackoverflow.com  using the  #earlgrey tag You can also start new discussions with us on our  Google group or request to join our  slack channel To prioritize and improve EarlGrey, the framework collects usage data anduploads it to Google Analytics
google-EarlGrey	Getting Started	More specifically, the framework collects the**MD5 hash*information allows us to measure the volume of usage
google-EarlGrey	Getting Started	For more detailedinformation about our analytics collection, please peruse the GREYAnalytics.m file which contains the implementation details
google-EarlGrey	Getting Started	If they wish, users can chooseto opt out by disabling the Analytics config setting in their test’sIn Objective-C:Please make sure you’ve followed the guidelines in CONTRIBUTING.md  before making any contributions.
google-EarlGrey	Setup an EarlGrey Project	using  **setup-earlgrey.sh**   After the script completes successfully, open EarlGrey.xcodeproj and ensure that allthe targets build
google-EarlGrey	Setup an EarlGrey Project	 You can now use EarlGrey.xcodeproj to make changes to the framework.
google-EarlGrey	Unit Tests	To add unit tests for EarlGrey, use Tests/UnitTests
google-EarlGrey	Unit Tests	To run all unit tests, select the **UnitTests*
google-EarlGrey	Functional Tests	To add functional tests for EarlGrey, use the FunctionalTests.xcodeproj locatedat Tests/FunctionalTests
google-EarlGrey	Functional Tests	To run all functional tests, select the **FunctionalTests*
google-ExoPlayer	ExoPlayer #	ExoPlayer is an application level media player for Android
google-ExoPlayer	ExoPlayer #	It provides analternative to Android’s MediaPlayer API for playing audio and video bothlocally and over the Internet
google-ExoPlayer	ExoPlayer #	ExoPlayer supports features not currentlysupported by Android’s MediaPlayer API, including DASH and SmoothStreamingadaptive playbacks
google-ExoPlayer	ExoPlayer #	Unlike the MediaPlayer API, ExoPlayer is easy to customizeand extend, and can be updated through Play Store application updates.
google-ExoPlayer	Documentation ##	 developer guide :  class reference :  release notes :  developer blog : 
google-ExoPlayer	Using ExoPlayer ##	ExoPlayer modules can be obtained from JCenter
google-ExoPlayer	Using ExoPlayer ##	It's also possible to clone therepository and depend on the modules locally.
google-ExoPlayer	From JCenter ###	The easiest way to get started using ExoPlayer is to add it as a gradledependency
google-ExoPlayer	From JCenter ###	You need to make sure you have the JCenter and Google repositoriesincluded in the build.gradle file in the root of your project:following will add a dependency to the full library:the library modules that you actually need
google-ExoPlayer	From JCenter ###	For example the following will adddependencies on the Core, DASH and UI library modules, as might be required foran app that plays DASH content:library is equivalent to adding dependencies on all of the library modulesdepend on external libraries to provide additional functionality
google-ExoPlayer	From JCenter ###	Someextensions are available from JCenter, whereas others must be built manually.Browse the  extensions directory    and their individual READMEs for details.More information on the library and extension modules that are available fromJCenter can be found on  Bintray   
google-ExoPlayer	From JCenter ###	extensions directory :  Bintray : 
google-ExoPlayer	Locally ###	Cloning the repository and depending on the modules locally is required whenusing some ExoPlayer extension modules
google-ExoPlayer	Locally ###	It's also a suitable approach if youwant to make local changes to ExoPlayer, or if you want to use a developmentFirst, clone the repository into a local directory and checkout the desireddepend on them as you would on any other local module, for example:
google-ExoPlayer	Using Android Studio ####	To develop ExoPlayer using Android Studio, simply open the ExoPlayer project inthe root directory of the repository.
google-FluidNet	Limitations of the current system	While this codebase is relatively self-contained and full-featured, **it is not a "ready-to-ship" fluid simluator**
google-FluidNet	Limitations of the current system	Rather it is a proof of concept and research platform only
google-FluidNet	Limitations of the current system	If you are interested in integrating our network into an existing system feel free to reach out  tompson@google.com  and we will do our best to answer your questions.The entire simulation loop is not optimized; however it is fast enough for real-time applications, where good GPU resources are available  i.e
google-FluidNet	Limitations of the current system	NVidia 1080 or Titan .**BOUNDARY HANDLING**Our example boundary condition code is very rudimentary
google-FluidNet	Limitations of the current system	However, we support the same cell types as Manta  in-flow, empty, occupied, etc , so more complicated boundary conditions can be created
google-FluidNet	Limitations of the current system	One potential limitation is that the setWallBcs codepath assumes zero velocity occupiers  like Manta does 
google-FluidNet	Limitations of the current system	However, it would be an easy extension to allows internal occupied voxels to have non-zero velocity.We do not have a real-time 3D fluid render
google-FluidNet	Limitations of the current system	We use an offline render instead
google-FluidNet	Limitations of the current system	For our 2D "renderer", we simply display the RGB density field to screen and visualize the velocity vectors
google-FluidNet	Limitations of the current system	It is very rudimentary
google-FluidNet	Limitations of the current system	Incorporating an open-source 3D fluid render is future work.The only external forces that are supported are vorticity confinement and buoyancy
google-FluidNet	Limitations of the current system	Viscosity and gravity are not supported  but could be added easily .**UNIT TESTING**We have unit tests  including FD gradient checks  for all custom torch modules
google-FluidNet	Limitations of the current system	The two main test scripts we do have are:
google-GL-Shader-Validator	GL Shader Validator	! image This is a  Sublime Text 2 / 3  plugin that passes GLSL / ESSL to ANGLE'spreprocessor / compiler for validation.Any errors that ANGLE finds are routed back to Sublime and the tokens inthe shader are highlighted for your convenience and debugging joy.To see the details of the error check the status message in the bottom left of theSublime view.
google-GL-Shader-Validator	Installation	**You can, and probably should, install GL Shader Validator via  Package Control If you would like to install it manually, clone this repo into your packages folder typically ~/Library/Application Support/Sublime Text 2/Packages .
google-GL-Shader-Validator	Usage	Assuming that you have a  GLSL / ESSL syntax highlighter  installed in Sublime, all you should need to dois install the plugin and your shader code will be validated as expected.It's worth saying that ANGLE expects vertex shaders to have the filesuffix .vert and fragment shaders .frag
google-GL-Shader-Validator	Usage	If you do not name your fileswith that suffix ANGLE  and therefore the plugin  will not be ableto validate your shaders
google-GL-Shader-Validator	Usage	Sadness will ensue.You can set the default specification to use in the settings:This can be overridden in a specific shader by adding comments:
google-GL-Shader-Validator	Permissions	This plugin requires use of a command line utility called essl_to_glsl, which is bundled with the plugin
google-GL-Shader-Validator	Permissions	By default,however, the utility will not have execute permissions
google-GL-Shader-Validator	Permissions	The plugin will attempt to enable those permissions automatically when it loads, butshould that fail you will receive the following error message:> GLShaderValidator: permission denied to use essl_to_glsl commandIn such instances you should enable execute permissions yourself:You can modify the settings file  GLShaderValidator.sublime-settings  insidethe plugin folder
google-GL-Shader-Validator	Permissions	You will find the documentation for the settings inthat file
google-GL-Shader-Validator	Permissions	There aren't many of those right now, but if you want more let usknow via the repo's Issues.
google-GOS-conventions	A convention for Objective-C libraries	The following convention defines a file system structure for a shared Objective-C library.
google-GOS-conventions	Style conventions	GOS libraries use clang-format to automatically clean up stylistic aspects of the source
google-GOS-conventions	Style conventions	Place acopy of  .clang-format  .clang-format  at the root of the library tree.There is a soft  aka: human-enforced  100 character line length limit.
google-GOS-conventions	Jazzy	Your .jazzy.yaml file should contain the following information:
google-GOS-conventions	Travis CI	Your .travis.yml file should contain the following information:for each example app.
google-GOS-conventions	Bootstrap script	The bootstrap script creates the skeletal directory structure for a GOS repo
google-GOS-conventions	Bootstrap script	This script must beprovided a library name and a path.Example usage:
google-GTMAppAuth	GTMAppAuth for iOS and macOS	GTMAppAuth enables you to use  AppAuth with the Google Toolbox for Mac  Google APIs Client Library for Objective-C For REST libraries by providing an implementation of GTMFetcherAuthorizationProtocolfor authorizing requests with AppAuth.GTMAppAuth is an alternative authorizer to GTMOAuthThe key differentiator isthe use of the user's default browser for the authorization, which is moresecure, more usable  the user's session can be reused  and follows modern OAuth best practices for native apps Compatibility methods for GTMOAuth2 are offered allowing you to migratefrom GTMOAuth2 to GTMAppAuth preserving previously serialized authorizations so users shouldn't need to re-authenticate .
google-GTMAppAuth	Setup	If you use  CocoaPods simply add:To your Podfile and run pod install.
google-GTMAppAuth	Configuration	To configure GTMAppAuth with the OAuth endpoints for Google, you can use theconvenience method:NSURL *authorizationEndpoint =NSURL *tokenEndpoint =OIDServiceConfiguration *configuration =// perform the auth request...Or through discovery:NSURL *issuer =  NSURL URLWithString:@"" ; OIDAuthorizationService discoverServiceConfigurationForIssuer:issuer  if  !configuration  {  }} ;
google-GTMAppAuth	Authorizing	First, you need to have a way for your UIApplicationDelegate to continue theauthorization flow session from the incoming redirect URI
google-GTMAppAuth	Authorizing	Typically you couldstore the in-progress OIDAuthorizationFlowSession instance in a property:property to store the authorization state:authStateByPresentingAuthorizationRequest method, the OAuth tokenexchange will be performed automatically, and everything will be protected withPKCE  if the server supports it .// builds authentication requestOIDAuthorizationRequest *request =// performs authentication requestself.appDelegate.currentAuthorizationFlow =  if  authState  {  } else {  }} ;
google-GTMAppAuth	Handling the Redirect	The authorization response URL is returned to the app via the platform-specificapplication delegate method, so you need to pipe this through to the currentauthorization session  created in the previous session .
google-GTMAppAuth	macOS Custom URI Scheme Redirect Example	  NSAppleEventManager *appleEventManager =   appleEventManager setEventHandler:self  NSString *URLString =   event paramDescriptorForKeyword:keyDirectObject  stringValue ;  NSURL *URL =  NSURL URLWithString:URLString ;   _currentAuthorizationFlow resumeAuthorizationFlowWithURL:URL ;
google-GTMAppAuth	iOS Custom URI Scheme Redirect Example	  // Sends the URL to the current authorization flow  if any  which will  // process it if it relates to an authorization response
google-GTMAppAuth	iOS Custom URI Scheme Redirect Example	 if   _currentAuthorizationFlow resumeAuthorizationFlowWithURL:url   {  }
google-GTMAppAuth	Making API Calls	The goal of GTMAppAuth is to enable you to authorize HTTP requests with freshtokens following the Session Fetcher pattern, which you can do like so:// Creates a GTMSessionFetcherService with the authorization.// Normally you would save this service object and re-use it for all REST API calls.GTMSessionFetcherService *fetcherService =   GTMSessionFetcherService alloc  init ;fetcherService.authorizer = self.authorization;// Creates a fetcher for the API call.NSURL *userinfoEndpoint =  NSURL URLWithString:@"" ;GTMSessionFetcher *fetcher =  fetcherService fetcherWithURL:userinfoEndpoint ; fetcher beginFetchWithCompletionHandler:^ NSData *data, NSError *error  {  // Checks for an error
google-GTMAppAuth	Making API Calls	 if  error  {  }  NSError *jsonError = nil;  id jsonDictionaryOrArray =  if  jsonError  {  }  NSLog @"Success: %@", jsonDictionaryOrArray ;} ;
google-GTMAppAuth	Serialization	The serialization format is different between GTMOAuth2 and GTMAppAuth, thoughwe have methods to help you migrate from one to the other without losing any
google-GTMAppAuth	GTMOAuth2-compatible Serialization	To assist the migration from GTMOAuth2 to GTMAppAuth, GTMOAuth2-compatibleserialization methods are provided in GTMOAuth2KeychainCompatibility.// Deserialize from KeychainGTMAppAuthFetcherAuthorization *auth =// Remove from Keychain GTMOAuth2KeychainCompatibility removeAuthFromKeychainForName:kKeychainItemName ;You can also serialize to GTMOAuth2 format, though this is discouraged  youshould serialize in GTMAppAuth format as described above .Try out one of the included samples Example-Mac and Example-iOS
google-GTMAppAuth	GTMOAuth2-compatible Serialization	In thefolder run pod install, then open the xcworkspace file.Be sure to follow the instructions in Example-iOS/README.md  Example-iOS/README.md  or Example-macOS/README.md  Example-macOS/README.md  to configure your own OAuthclient ID for use with the example.
google-GTMAppAuth	Authorization Method	GTMAppAuth uses the browser to present the authorization request, whileGTMOAuth2 uses an embedded web-view
google-GTMAppAuth	Authorization Method	Migrating to GTMAppAuth will require youto change how you authorize the user
google-GTMAppAuth	Authorization Method	Follow the instructions above to get theauthorization
google-GTMAppAuth	Authorization Method	 You can then create a GTMAppAuthFetcherAuthorization objectwith the initWithAuthState:authState initializer.Once you have the GTMAppAuthFetcherAuthorization you can continue to make RESTcalls as before.
google-GTMAppAuth	Error Handling	GTMAppAuth's error handling is also different
google-GTMAppAuth	Error Handling	There are no notifications,instead you need to inspect NSError in the callback
google-GTMAppAuth	Error Handling	If the error domain isOIDOAuthTokenErrorDomain, it indicates an authorization error, you shouldclear your authorization state and consider prompting the user to authorizeagain
google-GTMAppAuth	Error Handling	 Other errors are generally considered transient, meaning that you shouldretry the request after a delay.
google-GTMAppAuth	OAuth Client Registration	Typically, GTMOAuth2 clients are registered with Google as type "Other"
google-GTMAppAuth	OAuth Client Registration	This iscorrect for macOS, but on iOS clients should be registered with the type "iOS".If you're migrating an iOS client, in the *same project as your existing client*, register a new iOS client to be used with GTMAppAuth.
google-GTMAppAuth	Changing your Authorization Flows	Both GTMOAuth2 and GTMAppAuth support the id authorization
google-GTMAppAuth	Changing your Authorization Flows	 This allows you to switchthe authorization implementation under the hood to GTMAppAuth.Then, follow the instructions above to replace authorization request where you ask the user to grant access  with the GTMAppAuth approach
google-GTMAppAuth	Changing your Authorization Flows	If youcreated a new OAuth client, use that for these requests.
google-GTMAppAuth	Serialization & Migrating Existing Grants	GTMAppAuth has a new data format and APIs for serialization
google-GTMAppAuth	Serialization & Migrating Existing Grants	UnlikeGTMOAuth2, GTMAppAuth serializes the configuration and history of theauthorization, including the client id, and a record of the authorizationrequest that resulted in the authorization grant.The client ID used for GTMAppAuth is  different  #oauth-client-registration  tothe one used for GTMOAuthIn order to keep track of the different client idsused for new and old grants, it's recommended to migrate to the newserialization format, which will store that for you
google-GTMAppAuth	Serialization & Migrating Existing Grants	 GTMOAuth2-compatible serialization  #gtmoauth2-compatible-serialization  isalso offered, but not fully supported.Change how you serialize your authorization object using the new methodsusing the following example.For deserializing, we can preserve all existing grants  so users who authorizedyour app in GTMOAuth2 don't have to authorize it again 
google-GTMAppAuth	Serialization & Migrating Existing Grants	Remember that whendeserializing the *oldthe old client id and client secret  if those changed , and that when serializing to the *newOnce again, pay particular care to use the old details when deserializing theGTMOAuth2 keychain, and the new details for all other GTMAppAuth calls.Keychain migration example:// Attempt to deserialize from Keychain in GTMAppAuth format.id authorization =// If no data found in the new format, try to deserialize data from GTMOAuth2if  !authorization  {  // Tries to load the data serialized by GTMOAuth2 using old keychain name
google-GTMAppAuth	Serialization & Migrating Existing Grants	 // If you created a new client id, be sure to use the *previous  authorization =  if  authorization  {  }
google-GTXiLib	What is GTXiLib?	GTXiLib, Google Toolbox for Accessibility for the iOS platform or simply GTX-eyeis a framework for iOS accessibility testing
google-GTXiLib	What is GTXiLib?	GTXiLib has XCTest integration andcan be used with any XCTest based frameworks such as EarlGrey  GTXiLib enhances the value ofyour tests by installing "accessibility checks" on them, your existing testcases can double as accessibility tests with no other code change on your part.GTXiLib is able to accomplish this by hooking into the test tear down processand invoking the registered accessibility checks  such as check for presence ofaccessibility label  on all elements on the screen.
google-GTXiLib	Getting Started	To install GTXiLib on all the tests of a specific test class add the followingsnippet of code to it.// Include the GTXiLib umbrella header.
google-GTXiLib	#import 	// Note that that is +setUp not -setUp+  void setUp {   super setUp ;  NSArray *checksToBeInstalled = @    ;   GTXiLib installOnTestSuite: GTXTestSuite suiteWithAllTestsInClass:self Once installed, GTX will run all registered accessibility checks before testcase tearDown and fail the test if any accessibility checks fail
google-GTXiLib	#import 	With the abovesnippet of code your tests will now begin to catch issues where you have addedUI elements to your app but forgot to set accessibility labels on them.In the above snippet we have only installed checkForAXLabelPresent, but youcan also install multiple checks from GTXChecksCollection or include your owncustom checks as well:// Inside +setUp ...// Create a new check  for example that ensures that all AX label is not an image name id myNewCheck =  } ;// Create an array of checks to be installed.NSArray *checksToBeInstalled = @  ;// Install GTX on all tests in *this GTXiLib installOnTestSuite: GTXTestSuite suiteWithAllTestsInClass:self Note that GTX is being added to -setUp since GTX must only be installed once  for a given test run .To add GTXiLib to your project use the xcodeproj file in this project or cocoapods 
google-GTXiLib	Incremental Accessibility	GTXiLib APIs support a practical solution for improving accessibility of largeprojects which may not have included accessibility from the get go accessibility
google-GTXiLib	Incremental Accessibility	Adding GTXiLib to a project that is already halfway throughdevelopment may leads to several test failures and fixing them at once can betime consuming and tedious
google-GTXiLib	Incremental Accessibility	To solve this problem incrementally:+ Use above snippet to add GTXiLib to all test cases but fix errors in a small  subset of them
google-GTXiLib	Incremental Accessibility	 + Blacklist elements that you don't control using GTXiLib's blacklist APIs.+ Then use GTXTestSuite's suiteWithClass:andTests: method to  create a test suite with only the tests cases that have been fixed and add  GTXiLib only to that suite.Once the code is checked into your repo GTXiLib will catch any new failures inthose tests
google-GTXiLib	Incremental Accessibility	From this point:+ Every new test being added must be added it to the suite.+ Based on team priorities keep moving existing tests into the suite until all  methods are in the suite.If at any point all the tests of a test class are in the suite usesuiteWithAllTestsInClass: method instead of listing all the methods, this alsoensures that new methods added to the class are automatically underaccessibility checking.If GTXiLib is installed on every test in your project, usesuiteWithAllTestsFromAllClassesInheritedFromClass: to automatically addaccessibility checking to any test case added.
google-GTXiLib	Authoring your own checks	GTXiLib has APIs that allow for creation of your own accessibility checks  in factit does not have to be related to accessibility, for example i18n layout checksor even memory usage checks 
google-GTXiLib	Authoring your own checks	To create new checks use checkWithName:block: API and provide a unique name and block that evaluatesthe check and returns YES/NO for success/failure
google-GTXiLib	Authoring your own checks	Add the newly created checkto the array of checks being passed on to GTXiLib via the install API call.
google-GTXiLib	Dealing with GTXiLib Failures	When GTXiLib fails it has most likely found an accessibility bug and you must fixit
google-GTXiLib	Dealing with GTXiLib Failures	But due to various team priorities it may not be possible to do so rightaway in which case you have the following options at your disposal:+ Temporarily blacklist the test case by using  suiteWithAllTestsInClass:exceptTests:.+ Temporarily blacklist the offending element using element blacklist APIsBut if you believe GTXiLib has caught a bug that is not an accessibility issueplease let us know by  filing a bug or better  fix it for everyone.
google-GTXiLib	Integrating GTXiLib into custom test frameworks	If you are test *frameworkaccessibility checking into your test framework
google-GTXiLib	Integrating GTXiLib into custom test frameworks	GTXiLib's own XCTestintegration is also built using the APIs provided by GTXToolKit
google-GTXiLib	Integrating GTXiLib into custom test frameworks	UsingGTXToolKit for performing accessibility checks on a given element involves:Creating a GTXToolKit object.Associating a set of checks with it.Use it on the element to be checked.GTXToolKit *toolkit =   GTXToolKit alloc  init ;// Register one or more built in checks: toolkit registerCheck: GTXChecksCollection checkForAXLabelPresent  ; toolkit registerCheck: GTXChecksCollection checkForAXLabelNotPunctuated  ;// and/or add a couple of your own:id fooCustomCheck = } ; toolkit registerCheck:fooCustomCheck ;// Use the toolkit on an element.NSError *error;BOOL success =  toolkit checkElement:someElement error:&error ;if  !success  {  NSLog @"Element FAILED accessibility checks! Error: %@",} else {  NSLog @"Element PASSED accessibility checks!" ;GTXToolKit objects can also be applied on a tree of elements by just providingthe root element.Also, note that checkAllElementsFromRootElements: requires an *arrayelements, not a single element
google-GTXiLib	Integrating GTXiLib into custom test frameworks	The following snippet shows how to run thechecks on all elements on the screen:
google-GTXiLib	Analytics	To prioritize and improve GTXiLib, the framework collects usage data and uploadsit to Google Analytics
google-GTXiLib	Analytics	More specifically, the framework collects the MD5 hashof the test app's Bundle ID and pass/fail status of GTXiLib checks
google-GTXiLib	Analytics	Thisinformation allows us to measure the volume of usage
google-GTXiLib	Analytics	For more detailedinformation about our analytics collection, please peruse the GTXAnalytics.mfile which contains the implementation details
google-GTXiLib	Analytics	If they wish, users can chooseto opt out by disabling the Analytics by adding the following code snippet intest’s + void  setUp method:Please join us on  ios-accessibility Google group to discuss all things accessibility and also to keep a tap on allupdates to GTXiLib.
google-GTXiLib	Contributors	Please make sure you’ve followed the guidelines in CONTRIBUTING.md  ./CONTRIBUTING.md  before making any contributions.*Note: This is not an official Google product.*
google-GeoexperimentsResearch	R package GeoexperimentsResearch version 1.0.3	Copyright  C  2017 Google, Inc.License: Apache 2.0
google-GeoexperimentsResearch	Disclaimer	This is not an official Google product
google-GeoexperimentsResearch	Disclaimer	For research purposes only.
google-GeoexperimentsResearch	What is this R package for?	This R package  'GeoexperimentsResearch'  is an open-source implementation of the geoexperiment analysis methodology developed at Google  1, 2 .This package provides object classes and methods and functions for handling,verifying, and analyzing data from geo experiments
google-GeoexperimentsResearch	What is this R package for?	Version 1.0 implements thegeo experiment methodology presented in  1 , also called the geo-basedregression  GBR , and also the follow-up methodology 'time-based regression' TBR , introduced in  2 .
google-GeoexperimentsResearch	Documentation	See the vignette and the manual in this package  in the subdirectory inst/doc/in the source package .
google-GeoexperimentsResearch	References	 1  Vaver, J
google-GeoexperimentsResearch	References	and Koehler, J
google-GeoexperimentsResearch	References	 2011  2  Kerman, J., Wang, P
google-GeoexperimentsResearch	References	and Vaver, J
google-GeoexperimentsResearch	References	 2017 
google-Legilimency	A Memory Research Platform for iOS	Written and maintained by Gal Beniamini, Copyright 2017 Google Inc
google-Legilimency	A Memory Research Platform for iOS	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atThis is not an official Google product.
google-Legilimency	Usage	Legilimency is a memory exploration framework allowing navigation of the kernel'sdata structures from a python scripting environment
google-Legilimency	Usage	It connects to a server onthe target device implementing the Legilimency protocol  see "Protocol" , andissues subsequent memory access requests to the resident stub on the device.To use Legilimency, run an exploit stub on the target implementing the serverprotocol, then connect to the target using: python memshell.py Note that the provided implementation in memshell.py is left empty
google-Legilimency	Usage	After connecting tothe client you may fill in the code under "memshell.py" to utilise the provided classesand explore the kernel's memory.
google-Legilimency	Protocol	Legilimency uses a basic binary protocol to communicate with the server stub
google-Legilimency	Protocol	Alldata types used are encoded in little-endian byte order
google-Legilimency	Protocol	The protocol after a successfulTCP connection is made to the server
google-Legilimency	Protocol	Subsequently, the server sends a QWORD containingthe kernel's KASLR slide.After the connection is made, the client may issue requests to the server
google-Legilimency	Protocol	Each request isprefixed by a single byte representing the command code, followed by the request's contents.The following commands are supported:
google-LiquidFunPaint	Overview	LiquidFun Paint is a creative application created to demonstrate the use ofLiquidFun, an open source technology that provides developers with a liquidparticle system and physics simulation.You can find out more about LiquidFun at LiquidFun Paint lets users create with three drawing tools:flow, drip and slosh realistically.by fluids.the fluid.Start playing and see what you can create!
google-LiquidFunPaint	Releases	Releases of LiquidFun Paint are available for download from the Google Play Store   
google-LiquidFunPaint	Releases	The Play Store release is currently restricted to theUnited States.LiquidFun Paint source code is available for download from
google-LiquidFunPaint	Documentation	Please hop over to  for more details.Discuss LiquidFun Paint with other developers and users on the LiquidFun Paint Google Group   
google-LiquidFunPaint	Documentation	 File issues on the LiquidFun Paint Issues Tracker    or post your questions to stackoverflow.com    with a mention of **liquidfun paint**.
google-LiquidFunPaint	Tracking	The usage of LiquidFun Paint is not tracked
google-LiquidFunPaint	Tracking	However, the usage of the LiquidFun    library is tracked by default, though you can remove the trackingif you wish
google-LiquidFunPaint	Tracking	Please refer to the  LiquidFun Readme    for more details
google-LiquidFunPaint	Tracking	  LiquidFun Paint Google Group :   stackoverflow.com :   LiquidFun Readme : 
google-MAB	MAB	R package MAB is created toimplement strategies for stationary and non-stationary multi-armed bandit problems
google-MAB	MAB	Various widely-used strategies and their ensembles are included in this package.This package is designed to compare different strategies in multi-armed bandit problemsand help users to choose suitable strategies with suitable tuning parametersin different scenarios
google-MAB	MAB	This is not an official Google product.MAB depends on R package  emre  To install MAB package, download the package and run the following code in command line:R CMD INSTALL FILE.PATHAnother way is to install devtools package first and then run the following codein R:library devtools install_github "google/MAB" 
google-MOE-py	MOE-py	A system for synchronizing repositories
google-MOE-py	Installation	Please see the wiki pages for installation and setup instructions.
google-MOE-py	Project status	This is the project originally hosted at  writtenin python, to synchronize private and open-source repositories
google-MOE-py	Project status	 It is not under activedevelopment, though many stil find it usefulA related java-basedtool is under active  resumed  development at <>, which does not require an active server, but usesJSON files to store migrations and equivalencies.The python-based scrubber infrastructure is used by some installations of java-moe.
google-MOE-py	License	  Copyright 2011 Google, Inc
google-MOE-py	License	All Rights Reserved
google-MOE-py	License	 you may not use this file except in compliance with the License
google-MOE-py	License	 You may obtain a copy of the License at  distributed under the License is distributed on an "AS IS" BASIS,  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-MOE-py	License	 See the License for the specific language governing permissions and  limitations under the License.
google-MOE	Moe	*Make Open Easy* ! LICENSE   ! Travis CI   ! GitHub Issues   ! GitHub Pull Requests  
google-MOE	Introduction	MOE is a system for synchronizing, translating, and scrubbing source coderepositories
google-MOE	Introduction	 Often, a project needs to exist in two forms, typically becauseit is released in open-source, which may use a different build system, onlybe a subset of the wider project, etc
google-MOE	Introduction	 Maintaining code in two repositoriesis burdensome
google-MOE	Introduction	MOE allows users to:
google-MOE	Project Status	MOE was created around 2011, but has not had a lot of love
google-MOE	Project Status	Google teams thatmaintain open-source releases  guava, dagger, auto, etc
google-MOE	Project Status	 use it regularly,so we dusted it off to share fixes, improvements, and help folks who use itoutside of Google.The project is currently undergoing a fair bit of re-factoring and needs adocumentation update, which is forthcoming.
google-MOE	Building MOE	Install Apache Maven 3.1 if you don't already have it
google-MOE	Running MOE	Once you have the moe 
google-MOE	Contributing	Contributing to MOE is subject to the guidelines in the CONTRIBUTING.md file,which, in brief, requires that contributors sign the  Individual ContributorLicense Agreement  CLA   CLA 
google-MOE	Contributing	CLA :  Copyright 2011 Google, Inc
google-MOE	Contributing	All Rights Reserved
google-MOE	Contributing	 you may not use this file except in compliance with the License
google-MOE	Contributing	 You may obtain a copy of the License at  distributed under the License is distributed on an "AS IS" BASIS,  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-MOE	Contributing	 See the License for the specific language governing permissions and  limitations under the License.
google-OctoPrint-HeaterTimeout	OctoPrint-HeaterTimeout	OctoPrint Plugin that automatically shuts down heaters after a specified idle timeout.
google-OctoPrint-HeaterTimeout	Setup	Install via the bundled  Plugin Manager or manually using this URL:
google-OctoPrint-HeaterTimeout	Configuration	Configure via the OctoPrint settings UI.
google-OctoPrint-HeaterTimeout	Disclaimer	This is **not*
google-OctoPrint-LEDStripControl	OctoPrint-LEDStripControl	OctoPrint Plugin that intercepts M150 GCode commands and controls local GPIOs accordingly.Implements the M150 command syntax from the latest Marlin.
google-OctoPrint-LEDStripControl	Setup	Make sure that the OctoPrint user is in the gpio group via the following command.Install via the bundled  Plugin Manager or manually using this URL:
google-OctoPrint-LEDStripControl	Configuration	**NOTE: GPIO pins should be specified as physical number and not BCM number.**Configure the GPIO pins via the OctoPrint settings UI.
google-OctoPrint-LEDStripControl	Disclaimer	This is **not*
google-OctoPrint-TemperatureFailsafe	OctoPrint-TemperatureFailsafe	OctoPrint Plugin that executes shell commands on temperature violations
google-OctoPrint-TemperatureFailsafe	Setup	Install via the bundled  Plugin Manager or manually using this URL:
google-OctoPrint-TemperatureFailsafe	Configuration	Configure the thresholds and commands via the OctoPrint settings UI.! TemperatureFailsafe  temperaturefailsafe_settings.png?raw=true 
google-OctoPrint-TemperatureFailsafe	Disclaimer	This is **not*
google-PS3ControllerAutoSleep	PS3ControllerAutoSleep	Disconnects PS3 Bluetooth controller when Mac OS runs screen saver.Fixes a known problem: Mac OS can not sleep when PS3 Controller is connected via bluetooth.Known to work on English Mac OS X Mavericks and Yosemite.
google-PS3ControllerAutoSleep	Installation Instructions	Open _Security & Privacy_ in _System Preferences_Select _Accessibility_ and enable _PS3ControllerAutoSleep_ applicationOpen _Users & Groups_ in _System Preferences_Check your _Login Items_ and drag & drop _PS3ControolerAutoSleep_ application into this listUse _Hide_ checkbox to not to show this app in the DockOpen _Bluetooth_ in _System Preferences_Verify that Bluetooth is shown in menu barDon't forget to restart, or at least log out once
google-PS3ControllerAutoSleep	Known issue	I have not found a way to save an app as an editable file and make it stay open.I've created a wrapper app, which continues its execution:		end idle
google-REAPER	REAPER: Robust Epoch And Pitch EstimatoR	This is a speech processing system
google-REAPER	REAPER: Robust Epoch And Pitch EstimatoR	 The _reaper_ program uses theEpochTracker class to simultaneously estimate the location ofvoiced-speech "epochs" or glottal closure instants  GCI , voicingstate  voiced or unvoiced  and fundamental frequency  F0 or "pitch" .We define the local  instantaneous  F0 as the inverse of the timebetween successive GCI.This code was developed by David Talkin at Google
google-REAPER	REAPER: Robust Epoch And Pitch EstimatoR	This is not anofficial Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-REAPER	Downloading and Building _reaper_	_reaper_ will now be in convenient_place_for_repository/REAPER/build/reaperYou may want to add that path to your PATH environment variable ormove _reaper_ to your favorite bin repository.To compute F0  pitch  and pitchmark  GCI  tracks and write them out as ASCII files:reaper -i /tmp/bla.wav -f /tmp/bla.f0 -p /tmp/bla.pm -a
google-REAPER	Input Signals:	As written, the input stage expects 16-bit, signed integer samples.Any reasonable sample rate may be used, but rates below 16 kHz willintroduce increasingly coarse quantization of the results, and higherrates will incur quadratic increase in computational requirementswithout gaining much in output accuracy.While REAPER is fairly robust to recording quality, it is designed foruse with studio-quality speech signals, such as those recorded forconcatenation text-to-speech systems
google-REAPER	Input Signals:	 Phase distortion, such as thatintroduced by some close-talking microphones or by well-intendedrecording-studio filtering, including rumble removal, should beavoided, for best results
google-REAPER	Input Signals:	 A rumble filter is provided within REAPERas the recommended  default  high-pass pre-filtering option, and isimplemented as a symmetric FIR filter that introduces no phaseThe help text _ -h _ provided by the _reaper_ program describesvarious output options, including debug output of some of the featuresignals
google-REAPER	Input Signals:	 Of special interest is the residual waveform which may beused to check for the expected waveshape
google-REAPER	Input Signals:	  The residual has a_.resid_ filename extension
google-REAPER	Input Signals:	 During non-nasalized, open vocal tractvocalizations  such as /a/ , each period should show a somewhat noisyversion of the derivative of the idealized glottal flow
google-REAPER	Input Signals:	 If the computedresidual deviates radically from this ideal, the Hilbert transformoption _ -t _ might improve matters.
google-REAPER	The REAPER Algorithm:	The process can be broken down into the following phases:DC bias and low-frequency noise are removed by high-pass filtering,and the signal is converted to floating point
google-REAPER	The REAPER Algorithm:	 If the input is knownto have phase distortion that is impacting tracker performance, aHilbert transform, optionally done at this point, may improve
google-REAPER	Feature Extraction	The following feature signals are derived from the conditioned input:  interpolation of the filter coefficients
google-REAPER	Feature Extraction	 It is checked for the  expected polarity  negative impulses , and inverted, if necessary
google-REAPER	Feature Extraction	 by the peak energy in the utterance
google-REAPER	Feature Extraction	 local RMS
google-REAPER	Feature Extraction	 Peaks exceeding a threshold are selected as GCI candidates,  and then graded by a weighted combination of peak amplitude, skewness,  and sharpness
google-REAPER	Feature Extraction	Each of the resulting candidates is associated with the  other feature values that occur closest in time to the candidate
google-REAPER	Feature Extraction	 signal and its LP residual
google-REAPER	Feature Extraction	 The correlation reference window for  each GCI candidate impulse is centered on the inpulse, and  correlations are computed for all lags in the expected pitch period range.
google-REAPER	Lattice Generation	Each GCI candidate  pulse  is set into a lattice structure that linkspreceeding and following pulses that occur within minimum and maximumpitch period limits that are being considered for the utterance.These links establish all of the period hypotheses that will beconsidered for the pulse
google-REAPER	Lattice Generation	 Each hypothesis is scored on "local"evidence derived from the NCCF and peak quality measures
google-REAPER	Lattice Generation	 Each pulseis also assigned an unvoiced hypothesis, which is also given a scorebased on the available local evidence
google-REAPER	Lattice Generation	 The lattice is checked, andmodified, if necessary to ensure that each pulse has at least onevoiced and one unvoiced hypothesis preceeding and following it, tomaintain continuity for the dynamic programming to follow
google-REAPER	Lattice Generation	Note that the "scores" are used as costs during dynamic programming,so that low scores encourage selection of hypotheses
google-REAPER	Dynamic Programming	Starting at the last peak in the utterance, the lowest cost periodcandidate ending on that peak is found
google-REAPER	Dynamic Programming	 This is the starting pointfor backtracking
google-REAPER	Dynamic Programming	 The backpointers to the best preceeding periodcandidates are then followed backwards through the utterance
google-REAPER	Dynamic Programming	 As each"best candidate" is found, the time location of the terminal peak isrecorded, along with the F0 corresponding to the period, or 0.0 if thecandidate is unvoiced
google-REAPER	Dynamic Programming	 Instead of simply taking the inverse of theperiod between GCI estimates as F0, the system refers back to the NCCFfor that GCI, and takes the location of the NCCF maximum closest tothe GCI-based period as the actual period
google-REAPER	Dynamic Programming	 The output array of F0 andestimated GCI location is then time-reversed for final output.
google-RED	RED: version 1.0.0	Demonstration of the image restoration experiments conducted in Y
google-RED	RED: version 1.0.0	Romano, M
google-RED	RED: version 1.0.0	Elad, and P
google-RED	RED: version 1.0.0	Milanfar, " The Little Engine that Could: Regularization by Denoising  RED  ", SIAM Journal on Imaging Sciences, 10 4 , 1804–1844, 2017   arXiv  .! Examples  images/examples.png?raw=true The code was tested on Windows 7 and Windows 10, with Matlab R2016a.This is not an official Google product.
google-RED	Quick start	Clone or download this repository.Download a lightweight version of TNRD denoising fromDownload test images fromOpen Matlab and change the current folder to YOUR_LOCAL_PATH/RED  use "cd" function .In Matlab's command window run
google-RED	Third-party software components needed	The code uses an image denoising algorithm called TNRD, described in Yunjin Chen, and Thomas Pock, "Trainable Nonlinear Reaction Diffusion: A Flexible Framework for Fast and Effective Image Restoration", IEEE TPAMI The TNRD code is available in the authors websiteand downloaded fromNote1: For a fast execution, please enable "parfor" using Matlab command "matlabpool".Note2: The TNRD software contains mex files
google-RED	Third-party software components needed	If you encounter problems when running thedenoiser, try to download the TNRD code from the above dropbox link.Then, copy the files from the directory YOUR_LOCAL_PATH/TNRD-Codes/TestCodes denoising-deblocking-SR /GaussianDenoisingto YOUR_LOCAL_PATH/RED/tnrd_denoising directory.If you are using mex files for the first time, please run the following in Matlab'scommand window:For more details, please refer to Weisheng Dong, Lei Zhang, Guangming Shi, and Xin Li "Nonlocally Centralized Sparse Representation for Image Restoration", IEEE-TIP, The NCSR code is available in Also, to have a fair comparison, we use a similar degradation process as done in NCSR.Good luck!
google-Refaster	Refaster	This project has been subsumed into   Further development is being done there.
google-Safelight	Running the Server:	If all goes well, the console will output the following:***********************************Navigate to http:// hostname :6502 in your Chrome browser
google-Safelight	Running the Server:	 ! safelight_start  images/readmeImages/safelight_start.png "safelight_start"   Enjoy using Safelight!
google-Safelight	Cleaning dependencies and executables:	HOW TO USE SAFELIGHT
google-Safelight	Building:		"Function Name"	"Path to Generator"  paths may be absolute or relative to $SAFELIGHT_DIR 		e.g
google-Safelight	Building:	"generator/brighten_generator.cpp"	"Target"  at the moment Safelight only supports
google-Safelight	Running Halide Programs:	If you encounter:You might have downloaded an incompatible Halide binary distribution
google-Safelight	Running Halide Programs:	 This will download the correct halide binary distribution and point your HALIDE_DIR environment variable to it within your *~/.bashrc*.If you plan to use an already existing PNaCl Halide version, please double check your required environment variables and ensure they are all pointing to the right directories
google-Safelight	Running Halide Programs:	Then rerun:TESTING SAFELIGHT DEPENDENCIESSafelight comes with test packages for C++ visualizers packaged_call_runtime, rgba8_visualizer_generator, and transmogrify_rgba Follow the instructions below to run Google Tests on these dependencies.Download the two libraries from the links below and point these environment variables to them:A Successful Output:
google-TextNormalizationCoveringGrammars	Text normalization covering grammars	This repository provides covering grammars for English and Russian text normalization asdocumented in:  _Transactions of the Association for Computational Linguistics_ 4: 507-  Wu, K., Gorman, K., and Sproat, R
google-TextNormalizationCoveringGrammars	Text normalization covering grammars	 2016 
google-TextNormalizationCoveringGrammars	Text normalization covering grammars	Minimally supervised  written-to-spoken text normalization
google-TextNormalizationCoveringGrammars	Text normalization covering grammars	_arXiv_ 1609.If you use these grammars in a publication, we would appreciate if you cite these works.
google-TextNormalizationCoveringGrammars	Building	The grammars are written in  Thrax  thrax.opengrm.org  and compile into  OpenFst  openfst.org  FAR  FstARchive  files
google-TextNormalizationCoveringGrammars	Building	To compile, simply run make in the src/ directory.
google-TextNormalizationCoveringGrammars	License	See LICENSE.
google-TextNormalizationCoveringGrammars	Mandatory disclaimer	This is not an official Google product.
google-VRD	Visual Relations Detection	This repository contains tensorflow utility code for detectingvisual relations between objects in natural images.This is not an official Google product.
google-WebFundamentals	Web Fundamentals on DevSite	  Welcome to the new Web**Fundamentals**! An effort to showcase best practices and tools for modern Web Development.
google-WebFundamentals	What's changed?	If you have a high-bandwidth connection, I recommend starting with a fresh cloneof the repo.The new DevSite infrastructure simplifies the dependencies a lot
google-WebFundamentals	What's changed?	Ensureyou have a recent version of  Node  and the AppEngine SDK for Python already installed.Run npm install  needed for the build process 
google-WebFundamentals	Build the auto-generated files	Some files  contributors includes, some pages for updates, showcases, etc
google-WebFundamentals	Build the auto-generated files	 areautomatically generated
google-WebFundamentals	Build the auto-generated files	The first time you clone the repo and run npm install,this is done for you
google-WebFundamentals	Build the auto-generated files	However, when you add a case study, update, etc., you'llneed to re-build those files using:To view the site locally, just run:To update the Code Labs, you'll need the claat  tool andaccess to the original Doc files
google-WebFundamentals	Build the auto-generated files	This will likely only work for Googlers.Download the claat tool and place it in your tools directory.Run tools/update-codelabs.shCheck the latest changes into GitHub
google-WebFundamentals	Start the development server	Run npm start
google-WebFundamentals	Test your changes before submitting a PR	Please run your changes through npm test before submitting a PR
google-WebFundamentals	Test your changes before submitting a PR	The testlooks for things that may cause issues with DevSite and tries to keep ourcontent consistent
google-WebFundamentals	Test your changes before submitting a PR	It's part of the deployment process, so PRs will failif there are any errors! To run:
google-WikipediaHomographData	Homograph disambiguation data	This repository provides labeled data for training homograph disambiguationmodels, as described in:Gorman, K., Mazovetskiy, G., and Nikolaev, V
google-WikipediaHomographData	Homograph disambiguation data	 2018 
google-WikipediaHomographData	Homograph disambiguation data	Improving homographdisambiguation with machine learning
google-WikipediaHomographData	Homograph disambiguation data	In Proceedings of LREC, 1349-If you use this data in a publication, we would appreciate if you cite this
google-WikipediaHomographData	Annotation	Sentences were extracted from English Wikipedia articles
google-WikipediaHomographData	Annotation	Homograph wereinitially labeled for the most likely WORDID, a fourth senior annotator resolved the disagreements.There are now 162 unique homographs and roughly 100 examples per homograph.
google-WikipediaHomographData	Organization	The files in the directories data/train and data/eval are TSV files withthe following fields:These two files represent a suggested 90%/10% train/test split stratified byThe file data/wordids.tsv is a TSV file which maps from the WORDID fieldabove to information used by the annotator: -a short human-readable descriptionof the WORDID, and a transcription of the WORDID
google-WikipediaHomographData	Organization	Note that neither are intended to be authoritative; they are simply to help users distinguish betweenthe various WORDIDs for a homograph
google-WikipediaHomographData	Organization	The final two fields have someimpressionistic taxonomic information about the nature of the homography itselfintended for use during error analysis
google-WikipediaHomographData	Organization	The following fields are present:  distinct terms.
google-WikipediaHomographData	Authors	This data was collected by  Kyle Gorman  mailto:kbg@google.com , Vitaly Nikolaev  mailto:vitalyn@google.com , and Gleb Mazovetskiy  mailto:glebm@google.com , with help from a team of linguistsand annotators.
google-WikipediaHomographData	License	See LICENSE.
google-WikipediaHomographData	Contributing	See CONTRIBUTING.
google-WikipediaHomographData	Mandatory disclaimer	This is not an official Google product.
google-YetAnotherChatApp	Yet Another Chat App	This repo contains example code for a few workshops that introduces the FirebaseRealtime Database and Firestore.
google-abpackage	An R package for AB testing leveraging pre-period information	The abpackage implements PrePost, a Bayesian approach for theestimation of the treatment effect in A/B testing.When pre-period data are available, the method leverages the pre-period toget a more accurate estimate of the treatment effect.The abpackage assumes that the observations are Normally distributedboth in the pre-period and the post-period.Furthermore, the package assumes that the observations in treatment andcontrol groups are identically distributed in the pre-period.
google-abpackage	Installation	 Documentation and examples 
google-abpackage	Manuscript	 Percent Change Estimation in Large Scale Online Experiments 
google-abstreet	A/B Street	Development has moved to 
google-acai	Acai	      Acai makes it easy to write functional tests of your applicationwith JUnit4 and Guice.Acai makes it simple to:example it can help with writing tests which start your backend and frontendserver in a self-contained mode with their dependencies faked out and thenvalidates some key user scenarios with Webdriver to give you confidence yourcomplete system works correctly
google-acai	Acai	It can also be useful for tests which validatethe integration of a small set of components
google-acai	Acai	Note however that for smallerunit-tests we generally recommend you create the class under test manuallyrather than using Acai.
google-acai	Installation	Add a dependency on com.google.acai:acai in your build system to fetch Acaiautomatically from Maven Central
google-acai	Installation	For example, with Maven add the following toyour dependencies in pom.xml:|com.google.acai|acai|1.1| for dependency information for other build systems or to simply download the
google-acai	Using Acai to inject a test	The simplest test using Acai doesn't register any TestingService bindingsat all, it just uses Acai to inject a test with a module:@RunWith JUnit4.class public class SimpleTest {  @Rule public Acai acai = new Acai MyTestModule.class ;  public void checkSomethingWorks   {  }  }
google-acai	Using Acai to start services	The real power of Acai comes when your production server is configuredwith Guice and you create an alternate test module which configures your serverwith heavyweight dependencies like databases replaced with local in-memoryimplementations
google-acai	Using Acai to start services	You could then start this server once for all tests in thesuite  to avoid waiting for it to start between each test  and wipe thedatabase between tests  to cheaply isolate test-cases from one-another .The following example shows how this pattern would be used in tests:@RunWith JUnit4.class public class ExampleFunctionalTest {  @Rule public Acai acai = new Acai MyTestModule.class ;  public void checkSomethingWorks   {  }  }  }  }Note that when a module is passed to Acai in a rule any @BeforeSuitemethods are only executed once per suite even if the same module is used inmultiple Acai rules in multiple different test classes within that suite.This allows tests of the server to be structured into test classes according tothe functionality being tested.
google-acai	Test scoped bindings	Occasionally you may wish to have one instance of a class per test and injectthis instance in multiple places in the object graph
google-acai	Test scoped bindings	In this case Guice'sdefault instance scope will not do
google-acai	Test scoped bindings	Fortunately Acai provides a @TestScopedannotation which can be used to achieve exactly this.For example we may define a module for using Webdriver  a popular browserautomation tool  in our tests like so:class WebdriverModule extends AbstractModule {  private static final Duration MAX_WAIT = Duration.standardSeconds 5 ;  protected void configure   {  }  @TestScoped  WebDriver provideWebDriver   {  }  WebDriverWait provideWait WebDriver webDriver  {  }  }One important point to note when using TestingService instances are instantiated once for all tests outside of testscope
google-acai	Test scoped bindings	Therefore if you wish to access @TestScoped bindings in a @BeforeTestor @AfterTest method you should inject a Provider and call get on itwithin those methods as shown in the above example.Note that while @TestScoped works well for helpers injected only into tests such as the WebDriver instance in the above example  for fakes and otherobjects which are shared with the system under test it is usually simpler to usea single instance and reset its state with a TestingService
google-acai	Test scoped bindings	This techniqueavoids some of the limitations of @TestScoped such as the fact it can only beinjected on the test thread or child threads of the test and makes it possibleto inject the instance into objects whose lifetime is longer than that of anindividual test.
google-acai	Services which depend upon each other	If the services you need to start for tests must be started in a specific orderyou can express this using the @DependsOn annotation.For example:@RunWith JUnit4.class public class ExampleFrontendWebdriverTest {  @Rule public Acai acai = new Acai MyTestModule.class ;  public void checkSomethingWorks   {  }  }  private static class MyFrontendRunner implements TestingService {  }  }In the above example @DependsOn MyBackendRunner.class  which will cause Acai to start thebackend server before starting the frontend.
google-acai	API	As shown in the above examples Acai has a relatively small API surface.Firstly, and most importantly, there is the Acai rule class itselfwhich is used as a JUnit4 @Rule and is passed a module class to be used toconfigure the test.The module class passed to the TestingServiceModule to bind one or more TestingService implementations.The TestingService; Acai will find and run them all when appropriate.For more advanced use-cases where instance scope is not sufficient the@TestScoped annotation can be used to create one instance of a class per testFinally a TestingService implementation can be annotated @DependsOn tosignal its @BeforeSuite and @BeforeTest methods need to be run afterthose of another TestingService
google-acai	API	This provides a simple declarative mechanismto order service startup in tests.Refer to the examples above to see the API in action.
google-acai	Contributing	We'd love to accept your patches and contributions to this project
google-acai	Contributing	There are ajust a few small guidelines you need to follow
google-acai	Contributing	See the  CONTRIBUTING.md   file for more
google-acai	Disclaimer	This is not an official Google product.
google-access-bridge-explorer	Access Bridge Explorer	 Access Bridge Explorer  isa Windows application that allows exploring, as well as interacting with, theAccessibility tree of any Java applications that uses the Java Access Bridge to expose their accessibility features, for example Android Studio  and IntelliJ  Access Bridge Explorer provides features similar to the  Java Ferret and  Java Monkey sample applications that were distributed as part of the Java Access Bridge SDK when it was still distributed as a stand alone download
google-access-bridge-explorer	Access Bridge Explorer	Access Bridge Explorer  integratesboth set of features in a single application, is more stable and has been testedon recent versions of Windows  7, 8, 8.1 and 10  and offers a more modern andadvanced user interface
google-access-bridge-explorer	Access Bridge Explorer	Access Bridge Explorer consumes the same API that Windows screen readers supporting the Java Access Bridge  e.g
google-access-bridge-explorer	Access Bridge Explorer	 nvda  Jaws  consume.As such,  Access Bridge Explorer can be useful for validating accessibility support or identifying accessibilityissues of such Java applications without having to rely on a screen reader.**Note**:  Access Bridge Explorer should not considered a screen reader, as it is merely a debugging toolsuseful for developers of Java applications who want to validated/ensureholistic support for screen readers in their application.
google-access-bridge-explorer	Screenshot	! Access Bridge Explorer  /screenshots/AccessBridgeExplorer.png?raw=true "Access Bridge Explorer" 
google-access-bridge-explorer	Requirements	The  Access Bridge Explorer application requires  with earlier versions if the standalone Java Access Bridge SDK has been installed  see Access Bridge Explorer  is compatiblewith both the 32-bit and the 64-bit versions of Windows.
google-access-bridge-explorer	Installation	  menu item  or the "F5" key  to refresh the "Accessibility Tree" window
google-access-bridge-explorer	Installation	 Please make sure to install the Java Access Bridge, either the "x86" or "x64" version depending  on the Windows version  32-bit or 64-bit .
google-access-bridge-explorer	Contributing	 Access Bridge Explorer is written in C#, the source code can be compiled with Visual Studio 2015,or later, including Visual Studio 2015 Community For more details, see  CONTRIBUTING.md  /CONTRIBUTING.md .
google-access-bridge-explorer	Disclaimer	This is not an official Google product.
google-account-provisioning-for-google-apps	Account provisioning for Google Apps	Account provisioning for Google Apps is an open source API to:! self account provisioning demo  selfGif   | a script that creates accounts in bulk...! bulk account provisioning demo  bulkGif   |  or via a CSV input...! csv input  csv   | Usernames are generated automatically via configurable patterns
google-account-provisioning-for-google-apps	Account provisioning for Google Apps	Sample images are taken from the included demos
google-account-provisioning-for-google-apps	Account provisioning for Google Apps	Give them a try  here  #quick-start !This API can be installed as a RESTful service  to be invoked from almost any programming language and platform  or as a Java library.
google-account-provisioning-for-google-apps	Who should use it	Google Apps deployments where new usernames need to be created.Deployments that need to sync existing usernames can use  Google Apps Directory Sync   or  Google Apps School Directory Sync 
google-account-provisioning-for-google-apps	Quick start	*Ready? Try the demos!*This API needs Java, but don't worry you don't need to develop your client in Java
google-account-provisioning-for-google-apps	Quick start	You can use any language and platform you like  Python, JavaScript, PHP, C#, ObjectiveC, Go, etc
google-account-provisioning-for-google-apps	Quick start	 as long as it can do  REST  calls.> Included demos are built in JavaScript.
google-account-provisioning-for-google-apps	Check your Java version	In the terminal run:If you see: java version "1.7.X" or a newer version you are ready to go
google-account-provisioning-for-google-apps	Check your Java version	If not,  install Java 7 or a newer verion 
google-account-provisioning-for-google-apps	Set your Google Apps domain configuration	Follow the steps in the  Google Apps domain configuration guide  configGuide  to configure your domain to work with this API
google-account-provisioning-for-google-apps	Start the RESTful API service	 Move the config.properties and the p12 file  created in the previoius step  to the bin/ folder.
google-account-provisioning-for-google-apps	Open a demo	Awesome! You can now start getting usernames suggestions and creating Google Apps accounts in your domain.> See the Note below if you used a different port from 8080Open any of the index.html demos under the demos/ folder:Demo | Sampleself-provisioning-demoEach user selects and creates their own account | ! self account provisioning demo  selfGif bulk-provisioning-demoAll accounts are created in bulk | ! bulk account provisioning demo  bulkGif csv-provisioning-demoAll accounts are created in bulk from a CSV input | ! csv demo  csv to point to the right port
google-account-provisioning-for-google-apps	Open a demo	For example:! demo info  demoInfo > This screen will disappear after a couple of seconds.You can change these parameters in the config.properties file and use this screen to verify the current configuration
google-account-provisioning-for-google-apps	Open a demo	Follow the next step to see how.> A quick way of testing your server is by invoking the suggest method via the GET service 
google-account-provisioning-for-google-apps	Play with the configuration	Now that you have the demos up and running is a great time to learn how usernames are generated.Open the Now kill the Java process  Ctrl+C or Cmd+C  in the terminal and start the RESTful API service again   step 3  #3-start-the-restful-api-service  
google-account-provisioning-for-google-apps	Play with the configuration	This will load the new patterns configuration, which will result in different usernames being generated.Open the self-provisioning-demo\index.html demo and notice how the generated usernames are now different
google-account-provisioning-for-google-apps	Play with the configuration	They now follow the new patterns set in the config file
google-account-provisioning-for-google-apps	Play with the configuration	The  configuration section  #accountsusernamegenerationpatterns  explains how to patterns work.Next, you can try changing other accounts.UsernameGeneration properties
google-account-provisioning-for-google-apps	Play with the configuration	For example, updating the following properties:accounts.UsernameGeneration.numberOfSuggestions=5This will result in:This API is developed in Java and can be invoked from any language and platform that can do REST API calls
google-account-provisioning-for-google-apps	Play with the configuration	The username cache is an  H2  database, so you will see a usernames * .mv.db file when running the API.! use cases diagram  useCasesDiagram >  Only usernames are cached, no names or other user's data is ever stored
google-account-provisioning-for-google-apps	Play with the configuration	The  H2 Console Application  can be used to inspect the cache.The cache can be disabled with the  cachedUsernames  #accountsusernamegenerationcachedusernames  property
google-account-provisioning-for-google-apps	Play with the configuration	When disabled it will do Admin SDK API calls
google-account-provisioning-for-google-apps	Play with the configuration	When enabled, the cache will refresh periodically  see the  cacheExpirationHours  #accountsusernamegenerationcacheexpirationhours  property .
google-account-provisioning-for-google-apps	suggest method	 | REST API | Java API |**Method***Returns*
google-account-provisioning-for-google-apps	REST API	{"message":"User created successfully."}
google-account-provisioning-for-google-apps	Java API	String username = "carlos.alvarez";String firstname = "Carlos";String lastname = "Alvarez";String password = "12345678";ProvisioningApp provisioningApp = ProvisioningApp.getInstance  ;provisioningApp.initApp  ;UsernameManager usernameManager = provisioningApp.getUsernameManager  ;usernameManager.create username, firstname, lastname, password ;
google-account-provisioning-for-google-apps	select method	 | REST API | Java API |**Method***Returns*
google-account-provisioning-for-google-apps	create method	 | REST API | Java API |**Method***Returns*> Username and password fields must comply with the  Google Apps Name and password guidelines  
google-account-provisioning-for-google-apps	API limits	Account provisioning for Google Apps follows the same  AdminSDK Directory API limits   Each call to create, select and suggest consumes a different number of Directory API calls:The configuration is set in the config.properties file
google-account-provisioning-for-google-apps	API limits	Configuration properties are divided in four categories: Username generation properties  #username-generation-properties : use the property prefix accounts.UsernameGeneration
google-account-provisioning-for-google-apps	API limits	Google API properties  #google-api-properties : use the property prefix apis.GoogleAPIs
google-account-provisioning-for-google-apps	API limits	Cache location properties  #cache-location-properties : use the property prefix db.h2
google-account-provisioning-for-google-apps	API limits	SSL properties  #ssl-properties : use the property prefix security.ssl.
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cachedUsernames	**Description**: A username cache can be used to check if a username already exists
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cachedUsernames	This prevents reaching AdminSDK API calls/day limit
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cachedUsernames	If cachedUsernames is set to YES username availability will be checked against the cache
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cachedUsernames	If set to NO it will be checked against the Google Directory  using a Directory API call .**Possible values**: YES and NO
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cacheExpirationHours	**Description**: Defines the expiration time in hours of the usernames cache
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cacheExpirationHours	After expiration, the application refreshes the username cache
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.cacheExpirationHours	For reference, refreshing an account with 1 million users takes approximately 35 minutes.**Possible values**: Integers larger or equal to 1**Default**: 24
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.numberOfSuggestions	**Description**: The number of username suggestions to be returned for each call to suggest.**Possible values**: Integer between 1 and 10  inclusive **Default**: 3
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.suggestedUsernamesTimeout	**Description**: The amount of time  in seconds  that suggested usernames will remain locked  unavailable to another client .**Possible values**: Integer greater than **Default**: 120  2 minutes 
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	**Description**: A pattern is something that looks like  firstname  lastname 
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	This pattern indicates the API that we want to generate a username with *"the firstname followed by the lastname"*
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	Now, if that username happens to be taken the API will need another pattern
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	Therefore, a list of multiple patterns is recommended
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	For example:*So far so good?*Great
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	Now, say we want to generate a username with *"the nickname followed by the lastname"Well, nickname is a field that should be passed to the  suggest  #suggest-method  method
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	For example:Now say that for someone named *John SmithNow, say we have so many people named "John Smith" in a school district that we ran out of patterns
google-account-provisioning-for-google-apps	accounts.UsernameGeneration.patterns	We could then define a pattern that adds a number at the end of the username:
google-account-provisioning-for-google-apps	Adding separators to usernames	A common practice is to separate usernames with a period  
google-account-provisioning-for-google-apps	Adding separators to usernames	, an underscore  _  or a dash  - 
google-account-provisioning-for-google-apps	Adding separators to usernames	These separators can be added to patterns
google-account-provisioning-for-google-apps	Adding separators to usernames	Example:
google-account-provisioning-for-google-apps	Adding a string to a pattern	Same as the separators, it is possible to add a static string to username suggestions
google-account-provisioning-for-google-apps	Adding a string to a pattern	For example, the pattern:
google-account-provisioning-for-google-apps	What if the API runs out of patterns?	The following pattern is used as the last resort: C9_firstname  C9_lastname  #  Generated username | Used patterncarlos.alvarez |  firstname 
google-account-provisioning-for-google-apps	What if the API runs out of patterns?	lastname c.alvarez |  C1_firstname 
google-account-provisioning-for-google-apps	What if the API runs out of patterns?	lastname carlosalvarez_mx |  firstname  lastname _ region carlosalvarez_5A |  firstname  lastname _ group alvarez_nyc |  lastname _nyccarlosalvarez1 |  firstname  lastname  # carlosalvarez2 |  firstname  lastname  # carlosalvarez3 |  firstname  lastname  # ..
google-account-provisioning-for-google-apps	What if the API runs out of patterns?	|  firstname  lastname  # > **Notes:*
google-account-provisioning-for-google-apps	Google API properties	Follow the steps in the  Google Apps domain configuration guide  configGuide  to configure these properties.
google-account-provisioning-for-google-apps	apis.GoogleAPIs.domain	**Description**: The Google Apps domain
google-account-provisioning-for-google-apps	apis.GoogleAPIs.authUser	**Description**: Admin user who created the project in the Google Developer Console.
google-account-provisioning-for-google-apps	apis.GoogleAPIs.keyPath	**Description**: Path to the file that stores the Google private key
google-account-provisioning-for-google-apps	apis.GoogleAPIs.keyPath	Can be generated following the steps in: 
google-account-provisioning-for-google-apps	apis.GoogleAPIs.serviceAccountEmail	**Description**: Internal user for server side applications
google-account-provisioning-for-google-apps	apis.GoogleAPIs.serviceAccountEmail	Can be generated following the steps in:The following scope to the service account should be added: 
google-account-provisioning-for-google-apps	apis.GoogleAPIs.appName	**Description**: This value is the project name in the Google Developer Console
google-account-provisioning-for-google-apps	apis.GoogleAPIs.appName	Can be obtained following the steps in: 
google-account-provisioning-for-google-apps	db.h2.name	**Description**: The name of the H2 database .mv.db file.**Default**: usernames
google-account-provisioning-for-google-apps	db.h2.path	**Description**: The path where the H2 database  .mv.db file  will be created.**Default**: ./
google-account-provisioning-for-google-apps	security.ssl.useSSL	**Description**: Enables HTTPS support over SSL.**Possible values**: YES and NO**Default**: NO
google-account-provisioning-for-google-apps	security.ssl.keyStorePath	**Description**: The path where the KeyStore  
google-account-provisioning-for-google-apps	security.ssl.keyStorePassword	**Description**: The KeyStore password
google-account-provisioning-for-google-apps	security.ssl.keyStorePassword	Password provided when the jks file was generated.
google-account-provisioning-for-google-apps	security.ssl.keyManagerPassword	**Description**: Commonly the same as keyStorePassword
google-account-provisioning-for-google-apps	security.ssl.keyManagerPassword	Can be different if it is not a self-generated certificate.
google-account-provisioning-for-google-apps	Requirements	To generate a appsProvisioning-0.0.1.jar file under *./target*:**From bash**From the project's root folder, run:**From Eclipse* Run As > Maven build...
google-account-provisioning-for-google-apps	Feedback	If you have any questions or feedback, please let us know in the  forum  forum !
google-account-provisioning-for-google-apps	Impressions	This API logs the number of calls to suggest, create and select per Google Apps domain
google-account-provisioning-for-google-apps	Impressions	No other information is ever collected
google-account-provisioning-for-google-apps	Impressions	This helps us justify adding more resources and support to this API.
google-account-provisioning-for-google-apps	License	Account provisioning for Google Apps is licensed under Apache 2.Full license text is available in the  LICENSE  license  file.This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-account-provisioning-for-google-apps	Contributing	See  CONTRIBUTING  contributing .A good starting point to look at the Java code is contributing : api : #api--examples building : #building installing : #installing config : #configuration-properties customfields : #customfields csv :  useCasesDiagram :  tokens :  bulkGif :  selfGif :  demoInfo :  configGuide :  contributing :  license : 
google-acme	acme	A simple command line tool to manage TLS certificates with ACME-compliant CAs,which has no third party dependencies.If you're looking for a package to import in your program, golang.org/x/crypto/acmeor golang.org/x/crypto/acme/autocert is what you'll want instead.*This package is a work in progress and makes no API stability promises.*
google-acme	Usage	Quick install with go get -u github.com/google/acmeor download a pre-built binary from the releases page The release binaries have an additional command, acme version,which reports the release version.You need to have a user account, registered with the CA
google-acme	Usage	This is represented  by an RSA private key
google-acme	Usage	 Yours may vary
google-acme	Usage	Check with acme help reg
google-acme	Usage	 While some ACME CA may let you register without providing any contact info,  it is recommended to use one
google-acme	Usage	For instance a CA might need to notify  cert owners with an update.Agree with the ACME CA Terms of Service
google-acme	Usage	 the terms of the CA
google-acme	Usage	You can check the status of your account with:  provided as a link in "Terms: ..." field and agree by executing:Request a new certificate for your domain
google-acme	Usage	 and send a certificate request
google-acme	Usage	The location of the output files is ~/.config/acme,  but depends on your environment
google-acme	Usage	You can check this location with acme help cert
google-acme	Usage	 allowing for resolving authorization challenges  domain ownership proof 
google-acme	Usage	This typically  means the command should be executed on the same host the domain is served from.
google-acme	License	 c  Google, Licensed under  Apache-2  LICENSE  license.This is not an official Google product.
google-active-learning	Introduction	This is a python module for experimenting with different active learningalgorithms
google-active-learning	Introduction	There are a few key components to running active learningBelow I will go into each component in more detail.DISCLAIMER: This is not an official Google product.
google-active-learning	Setup	The dependencies are in  requirements.txt  requirements.txt 
google-active-learning	Setup	 Please make sure these packages areinstalled before running experiments
google-active-learning	Setup	 If GPU capable tensorflow is desired, please followinstructions  here It is highly suggested that you install all dependencies into a separate virtualenv foreasy package management.
google-active-learning	Getting benchmark datasets	By default the datasets are saved to --save_dir flag.Redownloading all the datasets will be very time consuming so please be patient.You can specify a subset of the data to download by passing in a comma separatedstring of datasets via the --datasets flag.
google-active-learning	Running experiments	There are a few key flags for run_experiment.py  run_experiment.py :preprocessing, introducing labeling noise, dataset subsampling, and using adifferent model to select than to score/evaluate.
google-active-learning	Available active learning methods	All named active learning methods are in sampling_methods/constants.py  sampling_methods/constants.py .You can also specify a mixture of active learning methods by following thepattern of mixture_of_samplers-margin-0.33-informative_diverse-0.33-uniform-0.34.Some supported sampling methods include:
google-active-learning	Adding new active learning methods	Implement either a base sampler that inherits from SamplingMethod  sampling_methods/sampling_def.py or a meta-sampler that calls base samplers which inherits from WrapperSamplingMethod  sampling_methods/wrapper_sampler_def.py .The only method that must be implemented by any sampler is select_batch_,which can have arbitrary named arguments
google-active-learning	Adding new active learning methods	The only restriction is that the namefor the same input must be consistent across all the samplers  i.e
google-active-learning	Adding new active learning methods	the indicesfor already selected examples all have the same name across samplers 
google-active-learning	Adding new active learning methods	Adding anew named argument that hasn't been used in other sampling methods will requirefeeding that into the select_batch call in run_experiment.py  run_experiment.py .After implementing your sampler, be sure to add it to constants.py  sampling_methods/constants.py so that it can be called from run_experiment.py  run_experiment.py .
google-active-learning	Available models	All available models are in the get_model method of utils/utils.py  utils/utils.py .Supported methods:
google-active-learning	Adding new models	New models must follow the scikit learn api and implement the following methods small_cnn.py  utils/small_cnn.py for an example.After implementing your new model, be sure to add it to get_model method of utils/utils.py  utils/utils.py .Currently models must be added on a one-off basis and not all scikit-learnclassifiers are supported due to the need for user input on whether and how totune the hyperparameters of the model
google-active-learning	Adding new models	However, it is very easy to add ascikit-learn model with hyperparameter search wrapped around as a supported
google-active-learning	Collecting results and charting	 utils/chart_data.py  utils/chart_data.py script handles processing of data and charting for a specified dataset andsource directory.
google-adapt-googleanalytics	adapt-googleanalytics	This is not an official Google product.This is a simple Adapt extension that implements Google Analytics upon post render of pageView, which is triggered when a page's view has rendered
google-adapt-googleanalytics	adapt-googleanalytics	 Be sure to include the Analytics library and Autotrack in core > js > scriptLoader.js.function setupRequireJS   {  requirejs.config {..
google-adapt-googleanalytics	adapt-googleanalytics	 analytics: '  autotrack: 'libraries/autotrack'Use Autotrack semantics in component-level .hbs files for tracking events such as mouseover and clicks.Video tracking is already available through the MediaElement library
google-adapt-googleanalytics	adapt-googleanalytics	Add "universalgoogleanalytics" to "features" for a given media component
google-adapt-googleanalytics	adapt-googleanalytics	Example:"features":    "universalgoogleanalytics"   
google-addlicense	addlicense	The program ensures source code files have copyright license headersby scanning directory patterns recursively.It modifies all source files in place and avoids adding a license headerto any file that already has one.
google-addlicense	usage	The pattern argument can be provided multiple times, and may also referto single files.
google-addlicense	license	Apache 2.0This is not an official Google product.
google-aff4	AFF4 -The Advanced Forensics File Format	The Advanced Forensics File Format 4  AFF4  is an open source format used for the storage of digital evidence andIt was originally designed and published in  1  and has since been standardised as the AFF4 Standard v1.0, which is available at  This project is a work in progress implementation, providing two library implementations, C/C++ and Python.
google-aff4	What is currently supported.	The focus of this implementation at present is reading images conforming with the AFF4 Standard v1.Canonical images are provided in the AFF4 Reference Images github project at Reading ZipFile style volumes.Reading AFF4 Image streams using the deflate or snappy compressor.Reading RDF metadata using Turtle  and in some instances YAML for backwards compatibility .
google-aff4	What is not yet supported.	The write support in the libraries is currently broken and being worked on
google-aff4	What is not yet supported.	Other aspects of the AFF4 that have not yet been implemented in this codebase include:Encrypted AFF4 volumes.Persistent data store.HTTP backed streams.Splitting an AFF4 Image across multiple volumes.Map streams.Support for signed statements or Bill of Materials.Logical file acquisition.
google-aff4	Notice	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-aff4	References	 1  "Extending the advanced forensic format to accommodate multiple data sources,logical evidence, arbitrary information and forensic workflow" M.I
google-aff4	References	Cohen,Simson Garfinkel and Bradley Schatz, digital investigation 6  2009  S57–S
google-agata	##agata	A simple UI layer over the components necessary to read hit logs for GAv4 onAndroid devices
google-agata	##agata	An **A**ndroid **GA*
google-agata	Dependencies	Apart from the npm dependencies listed in package.json, this app relies on adb  Android Debug Bridge .This can be installed either together with Android Studio or by installing the  SDK tools alone In short, we want:Once your dependencies are set up and this repo cloned, you may want to copy your adb binary into bin/adb at the project's root:This app can run in two environments.
google-ahdlc	aHDLC Data Frame Layer	This is not an officially supported Google productThis repository contains a micro controller friendly implimentation of adata framing layer, in C.
google-ahdlc	How to use this library	CMake and Bazel build files have been included for your convenience
google-ahdlc	How to use this library	Lib only  shell  cmake CMakeLists.txt  make unit_tests  ./src/unit_tests/unit_tests  See unit tests for example usage.
google-ahdlc	Source Code Headers	Every file containing source code must include copyright and licenseinformation
google-ahdlc	Source Code Headers	This includes any JS/CSS files that you might be serving out tobrowsers
google-ahdlc	Source Code Headers	 This is to help well-intentioned people avoid accidental copying thatdoesn't comply with the license
google-ahdlc	Source Code Headers	Apache header:
google-aiyprojects-deeplearn-tensorflow	NPM	For NPM use npm install deeplearn-tensorflow in your project folder.
google-aiyprojects-deeplearn-tensorflow	YARN	For YARN use yarn add deeplearn-tensorflow in your project folder.
google-aiyprojects-deeplearn-tensorflow	Other	Fork, clone, download the source on GitHub to get the latest version likegit clone .
google-aiyprojects-deeplearn-tensorflow	Basic Usage	import {NDArray, ...} from 'deeplearn';import {TensorflowLoader} from 'deeplearn-tensorflow';const tensorflowReader = new TensorflowLoader NDArray ;tensorflowReader.loadRemoteFiles 'data/model.ckpt-999' .then  vars  => {} ;
google-aiyprojects-deeplearn-tensorflow	Demo	For an demo implementation, please check  DEMO.md  DEMO.md .
google-aiyprojects-deeplearn-tensorflow	Disclaimer	This is not an official Google product.
google-aiyprojects-deeplearn-tensorflow	Author	 Markus Bordihn 
google-aiyprojects-deeplearn-tensorflow	License	Apache License, Version 2.0 - 
google-aiyprojects-raspbian	Overview	This repository contains an easy-to-use API for the  AIY Vision Kit  aiy-vision and  AIY Voice Kit  aiy-voice 
google-aiyprojects-raspbian	Overview	Have a look at  example code  aiy-github-examples to see how both kits can be used
google-aiyprojects-raspbian	Overview	Comprehensive documentation is at the AIY Projects Site  aiy-site .If you're using Raspbian instead of Google's provided image, read HACKING.md  for information on getting started.For returning users
google-aiyprojects-raspbian	Overview	The code for all AIY kits is in the master branch contains the original deprecated Voice Recognizer demo.
google-aiyprojects-raspbian	Support	If you're having trouble assembling your kit or running the demos, you can tryCheck  CONTRIBUTING.md  for details.If you've found a problem with the Assistant  for example, crashes in thelibrary or incorrect responses , you can try   HACKING.md : HACKING.md CONTRIBUTING.md : CONTRIBUTING.md aiy-site :  aiy-vision :  aiy-voice :  aiy-forums :  aiy-stack-overflow :  aiy-github-issues :  aiy-github-examples :  assistant-google-plus :  assistant-stack-overflow :  assistant-github-issues : 
google-alertmanager-irc-relay	Alertmanager IRC Relay	Alertmanager IRC Relay is a bot relaying  Prometheus  alerts to IRC.Alerts are received from Prometheus using Webhooks  and are relayed to an IRC channel.
google-alertmanager-irc-relay	Configuring and running the bot	To configure and run the bot you need to create a YAML configuration file andpass it to the service
google-alertmanager-irc-relay	Configuring and running the bot	Running the service without a configuration will usethe default test values and connect to a default IRC channel, which youprobably do not want to do.Example configuration:
google-alertmanager-irc-relay	this host/port.	http_host: localhosthttp_port: 8000
google-alertmanager-irc-relay	Note: SSL is enabled by default, use "irc_use_ssl: no" to disable.	irc_host: irc.example.comirc_port: 7000
google-alertmanager-irc-relay	Use this IRC nickname.	irc_nickname: myalertbot
google-alertmanager-irc-relay	Password used to identify with NickServ	irc_nickname_password: mynickserv_key
google-alertmanager-irc-relay	Use this IRC real name	irc_realname: myrealname
google-alertmanager-irc-relay	Note: By default a notice is sent for each alert in the webhook data.	notice_once_per_alert_group: no
google-alertmanager-irc-relay	The formatting is based on golang's text/template .	notice_template: "Alert {{ .Labels.alertname }} on {{ .Labels.instance }} is {{ .Status }}"
google-alertmanager-irc-relay	"Alert {{ .GroupLabels.alertname }} for {{ .GroupLabels.job }} is {{ .Status }}"	Running the bot  assuming *$GOPATH
google-alertmanager-irc-relay	Prometheus configuration	Prometheus can be configured following the official Webhooks  documentation
google-alertmanager-irc-relay	Prometheus configuration	The 
google-allocation-instrumenter	How to get it	The  latest release    is available from  Maven Central    as:In order to write your own allocation tracking code, you have to implement the Sampler interfaceand pass an instance of that to AllocationRecorder.addSampler  :You do this by instantiating a ConstructorInstrumenter.instrumentClass  : java.lang.instrument :  ASM :  latest release :  Maven Central :  Getting Started : 
google-amp-client-id-library	Google AMP Client ID Library	This Google AMP Client ID library provides a script that you can use to integrate the  Google AMP Client ID API  in your non-AMP pages for custom analytic systems  i.e., for in-house analytics tracking or for analytics vendors that are not  preconfigured for use with the API  The Google AMP Client ID API provides you with the ability to consistently track users across AMP and non-AMP pages.You can learn more about the API and how to customize your analytics systems in the  Google AMP Client ID API documentation 
google-amp-client-id-library	Usage	Choose one of the following options to integrate the Google AMP Client ID Library in your non-AMP pages:
google-amp-client-id-library	Option 1: Use the compiled binary served on Google CDN  preferred 	 Add the following  tag in your HTML  section: In your JavaScript code, wait for the library load, then call the getScopedCid method:
google-amp-client-id-library	Option 2: Copy the code into your own project	The recommended integration of the Google AMP Client ID library is to use binary that is served from CDN  option 1 ,  which saves you from any future version updates
google-amp-client-id-library	Option 2: Copy the code into your own project	However, if you prefer not to load the extra binary, you can compile the code into your own project.
google-amp-client-id-library	Methods	getScopedCid scope, apiKey, callback : Returns the scoped client ID.The  Google AMP Client ID library uses the AMP_TOKEN cookie to store information
google-amp-client-id-library	Methods	This cookie serves two purposes:To persist a security token that is received from the API server, which can be used to exchange CID values next time.To act as a lock so that no concurrent requests are being sent.
google-amp-client-id-library	Testing	To run tests on the Google AMP Client ID library, perform the following:
google-amp-pwa-demo	AMP+PWA Demo for Blog and News Sites	A simple, dependency-free blog that uses a Progressive Web App  PWA  to show  Accelerated Mobile Pages   AMP .__This is not an official Google product.__
google-amp-pwa-demo	Setup	This project requires  Node.js  and  NPM In the root of this repo, run npm install to download all dependencies, andthen npm start to start the server
google-amp-pwa-demo	Setup	You can visit the site at localhost:8080 Note that this is just a _demo site_
google-amp-pwa-demo	Setup	Some features  e.g
google-amp-pwa-demo	Setup	push notifications require a more complex backend that is not implemented here.
google-amp-pwa-demo	Implementation Details	Our site uses AMP and PWA to create a site that loads as fast as possible, whilestill allowing users to take advantage of some of the most recent web platformfeatures like push notifications and offline browsing.The front end consists of three main components:  AMP version .The first pageview will always be an AMP page
google-amp-pwa-demo	Implementation Details	If visitors are coming fromGoogle search results, this page will be loaded directly from the  Google AMPcache  In the background,the AMP page will install the service worker, which in turn will cache the appshell page and some other resources.Any further pageview will be intercepted by the service worker
google-amp-pwa-demo	Implementation Details	It returns theapp shell, rather than the requested page, and the app shell will then load theactual content using AJAX.While the content shown inside the app shell is still valid AMP, we can now usecustom JavaScript to add functionality that is not  yet  supported by AMP
google-amp-pwa-demo	Implementation Details	Notehowever that this functionality will not be available on the first pageview, orin browsers that don't support service workers
google-amp-pwa-demo	Implementation Details	The App Shell can also interceptlink clicks and use the web history API to create a "single page app".
google-amp-toolbox	AMP Toolbox	  A collection of AMP tools making it easier to publish and host AMP pages
google-amp-toolbox	AMP Toolbox	The following tools are part of this project:Please see  the CONTRIBUTING file  CONTRIBUTING.md  for information on contributing to the AMP Project.
google-amp-toolbox	License	AMP Toolbox is made by the  AMP Project  and is licensed under the  Apache License, Version 2.0  ./LICENSE .
google-amss	R package amss version 1.0.1	Copyright  C  2017 Google, Inc.License: Apache 2.0
google-amss	Disclaimer	This is not an official Google product
google-amss	Disclaimer	For research purposes only.
google-amss	What is this R package for?	This R package  amss  is an open-source implementation of the AggregateMarketing System Simulator developed at Google  1 .This package provides object classes, methods, and functions related tosimulated aggregate time series marketing data
google-amss	What is this R package for?	It provides functionality togenerate both simulated data and associated ground truth metrics
google-amss	What is this R package for?	Version 1.0implements the simulation framework presented in  1 .
google-amss	Documentation	See the vignette and the manual in this package  in the subdirectory inst/doc/in the source package .
google-amss	References	 1  Zhang, S
google-amss	References	and Vaver, J
google-amss	References	 2017 
google-amt-forensics	AMT Forensics for Linux	This README contains instructions on how to use the scripts in this repositoryto retrieve Intel AMT's Audit Log from a Linux machine without knowing theother pertinent information from Intel AMT via the ME Interface  MEI 
google-amt-forensics	AMT Forensics for Linux	TOC 
google-amt-forensics	Prerequisites	Linux machine with a provisioned AMTAMT yourself in 10 steps.Python & OpenWSMAN installedThe Local Manageability Service  LMS  for Linux needs to built and started:Download  lms-8.0.0-7.tar.gz Copy lms.patch from this repository into the unziped directory.Carry out the following commands:Note: On some machines, restarting lms and/or machine is required.If problems continue, re-try with **debugging*Once LMS is successfully running as per above, start a new shell:To login via  you canobtain password for the user **$$osAdmin*string to login.
google-amt-forensics	Info from all APIs	The getallinfo.sh script under the all_api_calls directory willattempt to gather info from all available AMT WSMAN APIs
google-amt-forensics	Info from all APIs	This can be usefulfor manual searching & inspiration during forensics.
google-amt-forensics	Disclaimer	This is not an official Google product.
google-androguard	Androguard	  
google-androguard	Features	Androguard is a full python tool to play with Android files.Androguard + tools: Anthony Desnos  desnos at t0t0.fr .DAD  DAD is A Decompiler : Geoffroy Gueguen  geoffroy dot gueguen at gmail dot com 
google-androguard	##Stable release	See the stable release here:All rights reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS-IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.All rights reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS-IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-android-arscblamer	ArscBlamer	ArscBlamer is a command-line tool that can parse an Android app's resources.arsc file and extract useful, actionable information about its contents.Features include:
google-android-arscblamer	Building	To use ArscBlamer with relative file paths, build the jar with:
google-android-arscblamer	-\-type=configs	Copyright 2016 Google Inc
google-android-arscblamer	-\-type=configs	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-android-arscblamer	Disclaimer	This is not an official Google product
google-android-classyshark	Introduction	Follow the shark on twitter  @ItsClassyshark ! alt text ClassyShark is a standalone binary inspection tool for Android developers
google-android-classyshark	Introduction	It can reliably browse any Android executable and show important info such as class interfaces and members, dex counts and dependencies
google-android-classyshark	Introduction	ClassyShark supports multiple formats including libraries  .dex, .aar, .so , executables  .apk, .jar, .class  and all Android binary XMLs: AndroidManifest, resources, layouts etc.
google-android-classyshark	Useful links	To run, grab the  latest JAR and run java -jar ClassyShark.jar.
google-android-classyshark	Export data in text format	Clone the repoOpen in your favorite IDE/editorBuild options:If you're running Arch Linux you can install the latest  prebuilt jar from the AUR 
google-android-classyshark	Dependencies	If you've found an error, please file an issue:submitting a pull request through GitHub.=======
google-android-cuttlefish	Virtual Device for Android host-side utilities	This repository holds source for Debian packages that prepare a hostto boot cuttlefish, an Android device that is designed to run on GoogleCompute Engine.
google-android-gradle-dsl	 Reference for latest plugin version 	 All versions   API Javadoc 
google-android-gradle-dsl	Android Gradle Plugin DSL Reference	This repository contains HTML documentation generated from Android Gradle Pluginsource code
google-android-gradle-dsl	Android Gradle Plugin DSL Reference	For instructions on how to check out the plugin source code, see the Building the Android Gradle Plugin If you find errors or missing parts, please  file a bug in the Android issuetracker or open an issue in this GitHub repo.
google-android-management-api-samples	Android Management API Samples	This repository contains Python notebooks for getting started with the Android Management API You can run the notebooks in  Google Colab using the following links:
google-android-transition-examples	Android Transition Examples	This repository holds various Android transition example projects.**This is not an officially supported Google product.**
google-android-transition-examples	Licence	 Apache License Version 2.0 
google-android-ui-toolkit-demos	Disclaimers	**This is not an official Google product.**
google-angle	ANGLE 	The goal of ANGLE is to allow users of multiple operating systems to seamlessly run WebGL and otherOpenGL ES content by translating OpenGL ES API calls to one of the hardware-supported APIs availablefor that platform
google-angle	ANGLE 	ANGLE currently provides translation from OpenGL ES 2.0 and 3.0 to desktopOpenGL, OpenGL ES, Direct3D 9, and Direct3D Support for translation from OpenGL ES to Vulkan isunderway, and future plans include compute shader support  ES 3.1  and MacOS support.
google-angle	Level of OpenGL ES support via backing renderers	|----------------|:-------------:|:----------------:|:--------------:|:-------------:|:-------------:|| OpenGL ES 2.0  || OpenGL ES 3.0  || OpenGL ES 3.1  |
google-angle	Platform support via backing renderers	|------------:|:--------------:|:--------------:|:-------------:|:-----------:|:-----------:|| Windows| Linux| Mac OS X| Chrome OS   || AndroidANGLE v1.0.772 was certified compliant by passing the ES 2.0.3 conformance tests in October ANGLE also provides an implementation of the EGL 1.4 specification.ANGLE is used as the default WebGL backend for both Google Chrome and Mozilla Firefox on Windowsplatforms
google-angle	Platform support via backing renderers	Chrome uses ANGLE for all graphics rendering on Windows, including the acceleratedCanvas2D implementation and the Native Client sandbox environment.Portions of the ANGLE shader compiler are used as a shader validator and translator by WebGLimplementations across multiple platforms
google-angle	Platform support via backing renderers	It is used on Mac OS X, Linux, and in mobile variants ofthe browsers
google-angle	Platform support via backing renderers	Having one shader validator helps to ensure that a consistent set of GLSL ES shadersare accepted across browsers and platforms
google-angle	Platform support via backing renderers	The shader translator can be used to translate shadersto other shading languages, and to optionally apply shader modifications to work around bugs orquirks in the native graphics drivers
google-angle	Platform support via backing renderers	The translator targets Desktop GLSL, Direct3D HLSL, and evenESSL for native GLES2 platforms.
google-angle	Sources	ANGLE repository is hosted by Chromium project and can be browsed online  or cloned with
google-angle	Building	View the  Dev setup instructions  doc/DevSetup.md 
google-angle	Building	For generating a Windows Store version of ANGLE view the  Windows Store instructions  doc/BuildingAngleForWindowsStore.md 
google-angular-a11y-workshop	AngularA11yWorkshop	This project was generated with  Angular CLI  version 6.0.
google-angular-a11y-workshop	About	A 4 hour deep dive interactive workshop to give developers the tools they need to make their Angular applications more inclusive and accessible to those with a wide variety of disabilities.
google-angular-a11y-workshop	Source Code Headers	Every file containing source code must include copyright and licenseinformation
google-angular-a11y-workshop	Source Code Headers	This includes any JS/CSS files that you might be serving out tobrowsers
google-angular-a11y-workshop	Source Code Headers	 This is to help well-intentioned people avoid accidental copying thatdoesn't comply with the license
google-angular-a11y-workshop	Source Code Headers	Apache header:
google-angular-a11y-workshop	Development server	Run ng serve for a dev server
google-angular-a11y-workshop	Development server	Navigate to 
google-angular-a11y-workshop	Development server	The app will automatically reload if you change any of the source files.
google-angular-a11y-workshop	Code scaffolding	Run ng generate component component-name to generate a new component
google-angular-a11y-workshop	Code scaffolding	You can also use ng generate directive|pipe|service|class|guard|interface|enum|module.
google-angular-a11y-workshop	Build	Run ng build to build the project
google-angular-a11y-workshop	Build	The build artifacts will be stored in the dist/ directory
google-angular-a11y-workshop	Build	Use the --prod flag for a production build.
google-angular-a11y-workshop	Running unit tests	Run ng test to execute the unit tests via  Karma 
google-angular-a11y-workshop	Running end-to-end tests	Run ng e2e to execute the end-to-end tests via  Protractor 
google-angular-a11y-workshop	Further help	To get more help on the Angular CLI use ng help or go check out the  Angular CLI README 
google-angular_cli	AngularDart CLI	 ! Pub Package    A command line interface for  AngularDart  webdev_angular .It can scaffold a skeleton AngularDart project, component, and test with page object  page_object .
google-angular_cli	Installation	To install:For example:
google-angular_cli	Generating AngularDart project	Command following will assume that you are in the root directory ofthe project.
google-angular_cli	Generating component	This command will generate component under folder lib/.You can use option -p to change the folder.
google-angular_cli	Generating test	and the other one is test file.Test generated is using  angular_test  pub_angular_test and  test  pub_test  package.Use command webdev_angular :  page_object :  pub_angular_test :  pub_test : 
google-anodyne	Anodyne: Type analysis of dynamic languages	NOTE: This is not an official Google product.Anodyne is an open-source experimental project to implement a type analysis toolfor commonly used manifestly-typed imperative programming languages.
google-anodyne	Building	Anodyne can be built with Bazel
google-anodyne	Building	There are some additional dependencies thatare not managed by Bazel that you must provide
google-anodyne	Building	They may be hardto these locations:
google-aperture_supervision	Aperture Supervision for Monocular Depth Estimation	 *Aperture Supervision for Monocular Depth Estimation*   Pratul P
google-aperture_supervision	Aperture Supervision for Monocular Depth Estimation	Srinivasan, Rahul Garg, Neal Wadhwa, Ren Ng, Jonathan T
google-aperture_supervision	Aperture Supervision for Monocular Depth Estimation	Barron  Computer Vision and Pattern Recognition, 2018Running this code requires the dataset from  Srinivasan 2017 This code is not quite the same as what was used in the paper, as the bilateral solver implementation used in the paper is not included in this open source release
google-aperture_supervision	Aperture Supervision for Monocular Depth Estimation	Comments in the code indicate where the solver used to be.
google-apis-client-generator	 limitations under the License.	Google APIs Code GeneratorAugust 20, 2013  documents
google-apis-client-generator	 limitations under the License.	It builds a rich  but language neutral  model of the API and  then invokes a language specific backend to emit the library
google-apis-client-generator	 limitations under the License.	The language  generators are template driven, so it is easy for a developer knowning  language X to write templates for code in X, without having to learn much  Python
google-apis-client-generator	 limitations under the License.	 and Dart
google-apis-client-generator	 limitations under the License.	 There may be multiple variations of each language
google-apis-client-generator	 limitations under the License.	For each,  the variant used by default  typically also named "default"  matches the  head of the respective base client libraries.Python 2.7 is required
google-apis-client-generator	 limitations under the License.	 Python3 is not supported.Everything can be installed quickly with easy_install or pip
google-apis-client-generator	 limitations under the License.	E.g.:The following dependencies will be installed:To run the library generator, use the "generate_library" script
google-apis-client-generator	 limitations under the License.	 This isnormally what you'd want to do
google-apis-client-generator	 limitations under the License.	 E.g.:To expand arbitrary templates, the "expand_templates" script is also available:  Jacob Smullyan  smulloni@google.com 
google-appengine-codiad	Codiad Managed VMs Docker Image	! Screenshot of Codiad running on MVMs  /codiad-screenshot.png?raw=true "Screenshot of Codiad running on MVMs" This repo defines a Docker Image that can be used to run Codiad on App Engine Managed VMs.
google-appengine-codiad	Codiad	The image is using a heavily customized version of Codiad  whichresides in codiad/third_party/codiad directory.
google-appengine-codiad	IDE Proxy	In order to run the IDE instances for developers in a cloud project, there is an IDE proxy runningon the managed VM which routes the requests to the individual Codiad containers for each developerbased on their email
google-appengine-codiad	IDE Proxy	The IDE proxy is written in nodejs
google-appengine-codiad	IDE Proxy	It is responsible for creating a Codiadcontainer for a user as soon as they connect to the IDE
google-appengine-codiad	IDE Proxy	Thereafter all of the request coming fromthat user will be forwarded to the respective container
google-appengine-codiad	IDE Proxy	The authentication is done throughappengine
google-appengine-codiad	IDE Proxy	Proxy code can be found under ide-proxy directory.
google-appengine-codiad	Building a dev image to test your changes to IDE	In order to do so, please see the README.md file in codiad directory.
google-appengine-codiad	Deploying to a Google Cloud project	Please see the instructions in ide-proxy directory.
google-appengine-codiad	How does it work?	The IDE is deployed as a Managed VM  MVM  module into a cloud project
google-appengine-codiad	How does it work?	This module is responsiblefor handling requests coming from different users of the IDE and dispatching them to the rightCodiad container
google-appengine-codiad	How does it work?	The general architecture of the system is as follows:routing requests to them based on user's email address which is registered with the cloud project.
google-appengine-codiad	Security	As can be seen in the above diagram, the authentication for each user is done by MVM
google-appengine-codiad	Security	Users areauthenticated with their cloud credential for the cloud project
google-appengine-codiad	Security	The IDE is accessed by all usersusing the same secure URL, e.g
google-appengine-codiad	Security	The Codiad containers are run by project's service account and not by user's credential
google-appengine-codiad	Security	No user'scredential is stored anywhere in the container by the system.Codiad containers for all users are run in the same machine and there is no security boundaryestablished for them
google-appengine-codiad	Security	Hence a user A's container could potentially access user B's container.
google-appengine-codiad	Running Codiad Locally	It is possible to run Codiad locally on a machine without using the IDE proxy and MVM hosting
google-appengine-codiad	Running Codiad Locally	Inorder to do so, see the README.md file in codiad directory.
google-appengine-phabricator	Phabricator-on-App-Engine Docker Image	This repo defines a Docker Image that can be used to run Phabricator on App Engine Managed VMs.
google-appengine-phabricator	Getting the code	Since Phabricator and its dependencies are fetched as git submodules, you have to include themwhen checking out the code:
google-appengine-phabricator	Installing	The source code includes a script named "install.sh", which deploys the image to a Managed VM.Assuming that you have your GCP project's name stored in the environment variable "PROJECT", runthe following:
google-appengine-phabricator	Phabricator version	The image is built using a fixed version of the source code for Phabricator and itsdependencies  libphutil and arcanist 
google-appengine-phabricator	Phabricator version	These versions are defined by the git submodulesunder the "third_party" directory named "arcanist", "libphutil", and "phabricator".
google-appengine-phabricator	Backups	This image automatically backs up the contents of the /var/repo directory to the project's defaultGoogle Cloud Storage bucket
google-appengine-phabricator	Backups	Backups are performed every 60 seconds, and on startup the imageautomatically tries to restore from the most recent backup  if one exists .Note that this means you will be billed by GCS for the storage of this backup
google-appengine-phabricator	Backups	To help minimizethis, the image automatically deletes the previous backup after generating a new one.
google-appengine-phabricator	Git/Phabricator mirror	This image includes a daemon which mirrors code reviews to and from git-notes That allows the Phabricator instance to integrate with the git-appraise command line tool  andmakes the use of the arcanist command line tool optional.Operations performed by the mirror daemon show up as the "git-mirror" bot, which is automatically
google-appengine-phabricator	Git authentication	This image includes a git credential helper that automatically authenticates access to Google Cloud Repositories  usingthe service account of the VM  hence the requirement for the projecthosting scope .
google-appengine-phabricator	Prerequisites	The built image requires an external MySQL instance, and must be run inside of a GCE VM withthe "" service account scope.There are four environment variables that must be passed to a Docker container running the image: "SQL_HOST": The IPv4 address of the MySQL instance "SQL_PASS": The root password for the MySQL instance "PHABRICATOR_BASE_URI": The URL of the Phabricator instance  for linking back to itself  "ALTERNATE_FILE_DOMAIN": A second URL for the Phabricator instance used for linking to untrusted user content
google-appengine-phabricator	Building a dev image to test your changes	The image is built using Make
google-appengine-phabricator	Building a dev image to test your changes	The default target builds a new Docker image andtags it with the name "google/phabricator-appengine":You can deploy this locally-built image to a test project using the "deploy" target:
google-appengine-phabricator	Building a testing or stable image	*Note that these two rules require permissions that are restricted to the core developer team.*The makefile also defines rules for creating a shared testing image, and uploading it to gcr.io.:..
google-appengine-phabricator	Building a testing or stable image	and one for labelling the current "testing" image as "latest"  which denotes our stable image :
google-appengine-phabricator	Updating the Phabricator version	This step should be taken with care.The git-phabricator-mirror tool included in this image calls into the conduit APIs provided byPhabricator
google-appengine-phabricator	Updating the Phabricator version	As such, any breaking changes to those APIs need to be preceded by correspondingupdates to the mirror's use of those APIs.This will result in pending changes that have to be committed  and pushed  which update thefixed versions for those submodules.
google-apps_script_tools	Apps Script Tools	This is not an official Google product
google-apps_script_tools	Apps Script Tools	It is not supported by the Dart team.This package is still in an experimental state.This package provides tools for using dart2js-compiled programs as Google AppsThe upload program uploads the resulting gs script to Google Drive.The main program makes the development process easier by automaticallyusing those two tools whenever the input JS file is changed.See also  clasp  for a similar tool that isn'tspecialized for Dart, but supports more operations.
google-apps_script_tools	Usage	The most common use case is to watch the output file of a dart2jscompilation and upload it as Google Apps script whenever it changes.This is accomplished with the main-script  aka apps_script_watch whenenabled through pub global activate .In its simplest form it just needs two arguments: the input file anda Google Drive destination
google-apps_script_tools	Usage	Every time the input file changes  and alsoinitially at startup  it converts the JS file into a validGoogle Apps script  prefixing it with a necessary preamble  and thenuploads it to Google drive at the given location
google-apps_script_tools	Usage	 This requires anOAuth authentication .Similar to /*Note that Google Apps script must be compiled with the --cps flag of
google-apps_script_tools	Gsify	The gsify executable converts a dart2js-compiled program into a validGoogle Apps script.It prefixes the necessary preamble and optionally add some stub functions,and /The input file must be the output of dart2js with the --cps flag.The following example adds the 
google-apps_script_tools	Upload	upload takes a valid Google Apps script and uploads it to Google Drive.If there exists already a Google Apps script at the provided destinationreplaces the content with the given input script
google-apps_script_tools	Upload	This only works if theexisting Google Apps script only contains one source file.The destination may be prefixed with folders  which must exist .This script uses Google APIs and thus requires an OAuth authenticationwhich is cached for future uses.
google-apps_script_tools	Run	run executes the uploaded script
google-apps_script_tools	Run	Scripts must be run in the sameGoogle Cloud project as the Google API that makes the invocation
google-apps_script_tools	Run	Thismeans that the request to run the script must use a clientId/Secret thatis provided by the user.See below  "Remote Script Execution"  for detailed instructions on how toset this up.
google-apps_script_tools	Stub Functions	Whenever the Google Apps Script service needs to call into the provided scriptit needs to statically see the target function
google-apps_script_tools	Stub Functions	That is, the providedJavaScript must contain a function with the given name
google-apps_script_tools	Stub Functions	For example,Spreadsheet Addons that want to add a menu entry must have a statically visibleonOpen function
google-apps_script_tools	Stub Functions	The output of dart2js avoids modifying the global environmentand the current JS interop functionality does not give any means to export aDart function
google-apps_script_tools	Stub Functions	To work around this limitation, one can use a stub function thatis then overwritten from within the Dart program.Concretely, running main or gsify with -s onOpen will add the followingJavaScript function to the generated .gs:it is invoked: dart@JS  library main;import 'package:js/js.dart';@JS  external set onOpen value ;void onOpenDart e  {  // Run on-open things like adding a menu.main   {  onOpen = allowInterop onOpenDart ;This  or a similar setup  must be done for any function that the Apps frameworkwants to use as an entry point
google-apps_script_tools	Stub Functions	This includes simple triggers  see the  menu entries,and callbacks from html services
google-apps_script_tools	Using the Script Editor	The easiest way to run a script is to upload it  using one of the providedtools , and then run a function from within the Script Editor.The Script Editor is not connected by default in Google Drive
google-apps_script_tools	Using the Script Editor	If theuploaded script doesn't open on double-click: go to "New" -> "More" -> "Connect more apps" and connect "Google Apps Script".The Editor allows to run  statically visible  functions directly.
google-apps_script_tools	Bound Scripts / Addons	Scripts that should be run on an opened document/spreadsheet are called"bound scripts" or "addons".The Script Editor has a convenient 'Test as add-on...' functionality whichopens a file with the script running as add-on.
google-apps_script_tools	As a Shared Library	Instead of using Script Editor's "Test as add-on...", one can also create abound script directly and then use the uploaded script as a shared library
google-apps_script_tools	As a Shared Library	Thisapproach has the advantage that the script will also be loaded when the documentis opened outside the editor
google-apps_script_tools	As a Shared Library	It also makes it possible for other users to usethe script without needing to publish it.Create a saved version of the script you want to use as a shared library
google-apps_script_tools	As a Shared Library	 File -> Manage versions .Create a bound script: "Tools" -> "Script Editor" from within a openfile  document, spreadsheet, ..
google-apps_script_tools	As a Shared Library	.Save the project and give it a name.Link the uploaded script as shared library: Resources -> Libraries -> Add a library
google-apps_script_tools	As a Shared Library	 Don't forget to enable the "Development mode"
google-apps_script_tools	As a Shared Library	This way uploads to the script are  immediately visible to you  but not other users .Once that's in place, one just needs to forward functions to the shared library.For example, the following bound script forwards the onOpen and hellofunctions from the bound script to the shared library  imported with theidentifier "dart" :possible to create menu entries that call immediately into the sharedlibrary
google-apps_script_tools	As a Shared Library	In this case, the function does not even need a stub.For development it's thus convenient to forward the prefix to Dart'sonOpen function:without needing to deal with forwarders or stub functions
google-apps_script_tools	As a Shared Library	dart@JS  external set onOpen value ;@JS  external set hello value ;void onOpenDart e,  String prefix   {  if  prefix == null  {  } else {  }  SpreadsheetAppvoid helloDart   {  SpreadsheetApp.getUi  .alert "Hello World" ;main   {  onOpen = allowInterop onOpenDart ;  hello = allowInterop helloDart ;
google-apps_script_tools	Using Google APIs	Google Apps script that have been uploaded to Google Drive can be invoked withGoogle API calls
google-apps_script_tools	Using Google APIs	The  Executing Functions using the Apps Script API Guide explains how to remotely execute a specified Apps Script function.Fundamentally, the call needs the following information:However, the scripts.run API has one important restriction: the scriptbeing called and the calling application must share a Cloud PlatformOne can either use the default one created for each script, or move thescript to a different project:The walk-through below details the necessary steps.
google-apps_script_tools	Walk-throughs	This section step-by-step instructions on common tasks.For all examples we assume a google-apps and js package:name: exampledescription: Example for Google Apps scripting in Dart.version: 0.0.1
google-apps_script_tools	#homepage: 	author:   sdk: '>=1.20.1  More -> Connect more appsSearch for Google Apps Script and connect it.In the editor select "create" in the listed functions and press run:! Image of selecting create  pics/select_create.png The first time the script is run it will ask for permissions, and thencreate a new Google Docs document.
google-apps_script_tools	Hello World Addon	In this section we create a script that is bound to a document.First create a new spreadsheet
google-apps_script_tools	Hello World Addon	Alternatively you can create a Google Docsdocument, but you would need to change a few lines below.Create the following bin/sheet.dart program: dart@JS  library hello_docs;import 'package:js/js.dart';import 'package:google_apps/spreadsheet.dart';@JS  external set sayHello value ;@JS  external set onOpen value ;void sayHelloDart   {  SpreadsheetApp.getUi  .alert "Hello world" ;void onOpenDart e  {  SpreadsheetAppmain List arguments  {  onOpen = allowInterop onOpenDart ;  sayHello = allowInterop sayHelloDart ;Compile it with dart2js:Upload it to Google Drive:Open the uploaded script in the Apps Script Editor
google-apps_script_tools	Hello World Addon	If a double-clickon the script doesn't work  "No preview available"  see the first example.In the editor run the application by testing it as an addon:! Image of testing as addon  pics/test_as_addon.png Note that the script will add an entry in the Add-ons menu
google-apps_script_tools	Hello World Addon	Ifthe script had been run as a bound script, it would add the menu directlyinto the main menu
google-apps_script_tools	Hello World Addon	We can achieve this effect by using the uploadedcode as a shared library.
google-apps_script_tools	Shared Library	Go back to the script editor from where we launched the add-on test.Save a new version: File -> Manage versionsFind the script-id
google-apps_script_tools	Shared Library	It's available in the URL, or in "File" -> "Project properties".Now go back to the spreadsheet where we want to run this script in.From within the spreadsheet open the Script editor  "Tools" -> "Script Editor" .Copy the following code into the editor  usually "Code.gs" :Go into "Resources" -> "Libraries".Add a new library, using the script-id we retrieved earlier.Use the latest version.Verify that the "Identifier" is correctly set to "hello"
google-apps_script_tools	Shared Library	 You can alsouse a different identifier, but then you need to update "Code.gs" .Enable "Development mode"
google-apps_script_tools	Shared Library	This way a new upload of the apps script isimmediately used
google-apps_script_tools	Shared Library	Note, however, that other users only see the selectedsaved version.Open the spreadsheet again  or reload it 
google-apps_script_tools	Shared Library	It should now add a new menuentry "from dart".
google-apps_script_tools	Remote Script Execution	Start by finishing the "Create Document" tutorial above
google-apps_script_tools	Remote Script Execution	You should nowhave a script "docs_create" in Google Drive.Open it with the Script Editor.First retrieve the project id and the necessary scopes for this project:Publish the script so that the Script's API can find it:"Publish" -> "Deploy as API executable".Now go to "Resources" -> "Cloud Platform project".In the opened window, the editor shows the project the script is currentlyassociated with
google-apps_script_tools	Remote Script Execution	Click on the link
google-apps_script_tools	Remote Script Execution	This brings you to the"Google Cloud Platform" page.In the "Getting Started" section click on"Enable APIs and get credentials like keys".Enable the Scripting API:Use those two strings as follows to run the script remotely from thecommand line:If there are multiple scopes, each of them must have its own "-s"parameter to the run script.If the script takes parameters, they can be added after the function name.
google-apps_script_tools	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-apps_script_tools	Features and bugs	tracker : 
google-arc-jazzy-linter	jazzy-linter	Use  jazzy  to lint your Objective-C and Swift documentationwith  Phabricator  arc command line tool.
google-arc-jazzy-linter	Features	Identify missing documentation for Objective-C and Swift APIs.
google-arc-jazzy-linter	Installation	Jazzy 0.6.0 or higher is required.Verify your version by running:
google-arc-jazzy-linter	Project-specific installation	You can add this repository as a git submodule
google-arc-jazzy-linter	Project-specific installation	Add a path to the submodule in your .arcconfiglike so:arcanist can load modules from an absolute path
google-arc-jazzy-linter	Project-specific installation	But it also searches for modules in a directoryup one level from itself.You can clone this repository to the same directory where arcanist and libphutil are located.In the end it will look like this:To use the linter you must register it in your .arclint file.of multiple parts then you may wish to create multiple .jazzy.yaml files
google-arc-jazzy-linter	Project-specific installation	Place the .jazzy.yamleither in the same directory as your source or in a parent directory.Example .jazzy.yaml for an Objective-C library:Licensed under the Apache 2.0 license
google-arc-jazzy-linter	Project-specific installation	See LICENSE for details.
google-arc-proselint	prose-lint for arc	prose-lint is a lint engine for use with  Phabricator  arc command line tool.It uses the open source  proselint  tool.
google-arc-proselint	Features	prose-lint generates advice messages.Example output:
google-arc-proselint	Install proselint	Read the  proselint installation guide  for more
google-arc-proselint	Project-specific	Add this repository as a git submodule.Your .arcconfig should list arc-proselint in the load configuration:
google-arc-proselint	Global	Clone this repository to the same directory where arcanist and libphutil are globally located.Your directory structure will look like so:Your .arcconfig should list arc-proselint in the load configuration  without a path :
google-arc-proselint	Usage	Create a .arclint file in the root of your project and add the following content:Feel free to change the include/exclude regexes to suit your project's needs.
google-arc-proselint	Configuration options	Checks can be ignored by configuring their severity:
google-arc-proselint	License	Licensed under the Apache 2.0 license
google-arc-proselint	License	See LICENSE for details.
google-arc-regex-line-length-linter	regex-line-length linter for arc	regex-line-length is a linter for use with  Phabricator  arc commandline tool
google-arc-regex-line-length-linter	regex-line-length linter for arc	This linter is able to identify lines that exceed a certain length while ignoring linesthat match a list of regexes.
google-arc-regex-line-length-linter	Project-specific	Add this repository as a git submodule.Your .arcconfig should list arc-regex-line-length-lint in the load configuration:
google-arc-regex-line-length-linter	Global	Clone this repository to the same directory where arcanist and libphutil are globally located.Your directory structure will look like so:Your .arcconfig should list arc-regex-line-length-lint in the load configuration  without apath :
google-arc-regex-line-length-linter	Usage	Create a .arclint file in the root of your project and add the following content:Feel free to change the include/exclude regexes to suit your project's needs.
google-arc-regex-line-length-linter	Configuration options	Line length can be configured by providing a max-line-length number:Lines can be ignored if they match a given list of regexes
google-arc-regex-line-length-linter	Configuration options	In the following example we ignore linesthat include a url.
google-arc-regex-line-length-linter	License	Licensed under the Apache 2.0 license
google-arc-regex-line-length-linter	License	See LICENSE for details.
google-arc-xcode-test-engine	xcode-test-engine for arc	xcode-test-engine is a test engine for use with  Phabricator  arccommand line tool.
google-arc-xcode-test-engine	Features	xcode-test-engine presently works well with projects that have asingle root workspace and a single unit test target.Supports arc unit:And arc unit --coverage:
google-arc-xcode-test-engine	Project-specific	Add this repository as a git submodule.Your .arcconfig should list xcode-test-engine in the load
google-arc-xcode-test-engine	Global	Clone this repository to the same directory where libphutil are globally located
google-arc-xcode-test-engine	Global	Your directory structure willlook like so:Your .arcconfig should list arc-xcode-test-engine in the loadconfiguration  without a path :
google-arc-xcode-test-engine	Usage	Create a .arcunit file in the root of your project and add the following content:Feel free to change the include/exclude regexes to suit your project's needs.Now modify your .arcconfig file by adding the following configuration:
google-arc-xcode-test-engine	Build configuration options	Any value provided to "build" will be passed along to xcodebuild as a flag.
google-arc-xcode-test-engine	Picking the coverage product	Provide the path to the product for which coverage should be calculated
google-arc-xcode-test-engine	Picking the coverage product	If building alibrary/framework this might be the framework binary product.
google-arc-xcode-test-engine	Pre-build commands	Some projects require a pre-build script that runs before the xcodebuild command.For example, CocoaPods projects may need to be re-generated.
google-arc-xcode-test-engine	Supporting multiple test engines	We support Arcanist's *multi test engineYour .arcconfig file will have something similar to the following configuration:Coverage will appear for affected source files in Side-by-Side mode as a colored bar.
google-arc-xcode-test-engine	License	Licensed under the Apache 2.0 license
google-arc-xcode-test-engine	License	See LICENSE for details.
google-argtail-check	argtail-check	Copyright 2017 Google Inc.This is not a Google product.Programatically adds check for trailing args that would otherwise be ignored.
google-arithmancer	Arithmancer	Arithmancer is a prediction market application
google-arithmancer	Arithmancer	Users can make trades on predictions, betting on how likely an event is to occur
google-arithmancer	Arithmancer	Each prediction is an individual market with a market maker system modeled on Robin Hanson's logarithmic market scoring rules.This was designed and tested as an internal corporate decision market
google-arithmancer	Arithmancer	Using outside of an organization as a general application will likely require additional features  ex
google-arithmancer	Arithmancer	ACLs, better form validation and security, etc
google-arithmancer	Arithmancer	.Note: This is not an official Google product.! Arithmancer  "Preview" ! Arithmancer Prediction 
google-arithmancer	Getting Started	pip install -r requirements.txt Download and install the Google Cloud SDK  and use dev_appserver.py to run a local server for development
google-arithmancer	Getting Started	Create your first prediction by going to "/predictions/create"
google-arithmancer	Prerequisites	This runs on App Engine and uses Google Cloud Datastore
google-arithmancer	Prerequisites	Google Cloud SDK is a prerequisite for development and deployment.
google-arithmancer	Running the tests	python runner.py app_test.py 
google-arithmancer	Contributing	Please read CONTRIBUTING.md for details on contributing.Features that would be desired/on the roadmap:This project is licensed under the Apache 2 License 
google-ashier	Ashier for Automating Terminal Interactions	Ashier is a program that serves the same purpose as expect  helping users script terminalinteractions
google-ashier	Ashier for Automating Terminal Interactions	 It is a computer assistant that watches the terminal screen overyour shoulder and interacts with the terminal using its own keyboard; someoneto answer the boring questions and enter the tedious commands for you
google-ashier	Ashier for Automating Terminal Interactions	 Unlikeexpect, Ashier supports multiple programming languages and provides a readabletemplate language for terminal output matching
google-ashier	Ashier for Automating Terminal Interactions	 These features make it easierto create and to maintain scripted terminal interactions.Ashier is not an official Google product.
google-ashier	Example: wargames	wargames is a program that asks you to play a game and then tells you thatthe only winning move is not to play
google-ashier	Example: wargames	 This example shows how you can makeAshier refuse wargames automatically.First, create a file ENTER.Then, enter the following command to run Ashier, which starts a new interactiveshell
google-ashier	Example: wargames	 The -c option points Ashier to the configuration file you justWhen you run /usr/games/wargames in this shell, Ashier automatically answers"no" to the "Would you like to play a game?" prompt.To stop Ashier, type exit in the interactive shell.
google-ashier	Example: ping	ping is a program that sends network packets to a remote host and reports theresponses
google-ashier	Example: ping	 It has a command line option to send a specific number of packets,but no option to continue sending packets until it receives, say, 10 responses.This example shows how you can implement that feature with Ashier.This wargames has a fixed prompt, but ping responses vary in reported packetsize, source, sequence number, Time-to-Live value, and latency
google-ashier	Example: ping	 So Ashierneeds to match only some parts of the template and ignore differences inothers
google-ashier	Example: ping	 Second, wargames takes only a fixed no response, but here Ashierneeds to react differently to ping responses: do nothing for the first 9, andpress Ctrl-C for the 10th
google-ashier	Example: ping	 In other words, Ashier needs to support dynamicbehavior through custom stateful logic.Ashier solves the first problem with variable markers, which appear on lines2-6 in the ping-output.ahr configuration file  shown below 
google-ashier	Example: ping	 Each variablemarker line starts with ?, followed by an optional sequence of SPACEcharacters, and then a sequence of 
google-ashier	Example: ping	dots
google-ashier	Example: ping	 The dots on each variable markerline marks the corresponding part of the template as a variable, which tellsAshier to ignore differences there when matching terminal output with thetemplate
google-ashier	Example: ping	 Each variable marker can also have a name, which appears after theAshier solves the second problem with a controller process
google-ashier	Example: ping	 When Ashierstarts, it in turn starts another program in the background
google-ashier	Example: ping	 That runningprogram is the controller process, which implements dynamic behavior forAshier
google-ashier	Example: ping	 Ashier talks to the controller process by sending messages to itsstandard input
google-ashier	Example: ping	 In return, the controller process may send data to standardoutput, which Ashier forwards verbatim to the terminal as keystrokes.Here, the last line of ping-output.ahr  above  tells Ashier to send a messageto the controller process  instead of typing into the terminal  when it matchesterminal output to the template
google-ashier	Example: ping	 The controller program ping-react.py  shownbelow  reads these messages and dynamically generates keystrokes
google-ashier	Example: ping	 Since Ashierstarts with a new interactive shell, the controller process first enters ashell command to run the ping program
google-ashier	Example: ping	 Then, it reads 10 Ashier messages each representing a ping response  from standard input and logs each messageto the output file
google-ashier	Example: ping	 After receiving all 10 messages, it sends the Ctrl-C keycombination to standard output, which terminates ping and drops the terminalback to the interactive shell
google-ashier	Example: ping	 Finally, it enters the exit command to quitthe interactive shell and stop Ashier.You can now enter the following command to run Ashier, which starts a newinteractive shell
google-ashier	Example: ping	 The -c option points Ashier to its configuration file,and the remaining arguments specify the controller program ping-react.py andits arguments.In the new shell, Ashier automatically runs ping with Ctrl-C and types exit to quit the new interactive shell.
google-asset-check	Asset Check	Check your assetlinks.json file for associations, ensuring you're configured correctly.*This is not an official Google product.*
google-asset-check	Install	Install the node dependencies and link the executable:
google-asset-check	Usage	If you've linked the package you can use:asset-check asset-check asset-check -u    # check a url with a specific useragentasset-check -d Or in your install directory:./run.js ./run.js ./run.js -d     # check a url with a specific useragent
google-asset-check	Examples	> asset-check -d assetlinks.jsoninstance 1 .target: is not exactly one from ,Errors validating schema› asset-check URL: 
google-asset-check	Tests	npm test
google-astc-codec	astc-codec	astc-codec is a software ASTC decoder implementation, which supports the ASTCLDR profile.Example usage:
google-astc-codec	#include 	// ...std::vector astc = LoadMyASTCData  ;const size_t width = 640;const size_t height = 480;std::vector result;result.resize width bool result = astc_codec::ASTCDecompressToRGBA 
google-astc-codec	Building	Install  Bazel  and then run:
google-astc-codec	Run Tests	See  CONTRIBUTING.md  CONTRIBUTING.md  for important contributing requirements.
google-astc-codec	License	astc-codec project is licensed under the Apache License Version 2.You canfind a copy of it in  LICENSE  LICENSE .This is not an officially supported Google product.
google-asylo-site	asylo-site	This repository contains the source code for the  asylo.dev  website.Please see the main Asylo  README file to learn about the overall Asylo project and how to get in touch with us.The website uses  Jekyll  templates Please make sure you arefamiliar with these before editing.To run the site locally with Docker, use the following command from the top level directory for this git repo e.g
google-asylo-site	asylo-site	pwd must be git clone  > In some cases the --incremental may not work properly and you might have to remove it.Alternatively, if you just want to develop locally w/o Docker/Kubernetes/Minikube, you can try installing Jekyll locally.You may need to install other prerequisites manually  which is where using the docker image shines 
google-asylo-site	asylo-site	Here's an example of doingso for Mac OS X:You should run scripts/linters.sh prior to checking in your changes.This will run 3 tests:Many thanks to  @geeknoid  for his help basing thiswebsite off the clean and elegant Istio.io 
google-asylo	Asylo 	Copyright 2018 Asylo authors
google-asylo	Documentation	The v0.2 documentation can be found at  asylo.dev Example code can be found in the  asylo/examples  asylo/examples  directory.This directory has a working Bazel workspace and example applications that canbe used as the start of your own project.
google-asylo	Support	There are several ways of getting support with Asylo:+   Join the  asylo-users +   Ask questions and find curated answers on
google-asylo	Build Environment in Docker  Recommended 	Asylo provides a custom Docker image that contains all required dependencies, aswell as Asylo's custom toolchain, which is required for compiling enclaveapplications for various enclave backends.inside the container image.See this guide for additional details on how to pull images from Google's Container Registry.
google-asylo	Examples	The following examples assume that the Asylo SDK was installed at ASYLO_SDK,which can be a directory of your choice
google-asylo	Examples	For example:
google-asylo	Running the hello_world example	To run the hello_world example, first use the following commands to grab the examples source code  and save it toany directory of your choice.simulated enclave backend:settings  #bazel-flags-and-workspace-settings  for an explanation of the flagsand workspace configuration used in this example.
google-asylo	Docker flags	In the above example, we use the following Docker flags:+   -it is used to allocate an interactive terminal in which the command is+   --rm is used to automatically delete the temporary container after the+   -v is used to map local files to paths inside the container.+   -w is used to set the working directory in the container so that bazel
google-asylo	Bazel flags and workspace settings	In the above example, we use the following Bazel flags:+   --config=enc-sim uses the Asylo toolchain to build the target for the+   --names="${NAMES}" is the argument passed to the //hello_world target.Note: The example project from  examples/  asylo/examples  also picks upadditional Bazel configuration from the tools/bazel.rc file in that directory.Remember to copy this file to a tools/ sub-directory in future Bazel projectsyou create so that you can make use of Asylo's toolchain configurations.
google-asylo	Running your own enclave application	You can follow the  steps above  #running-the-hello_world-example-1  to buildyour own enclave application instead
google-asylo	Running your own enclave application	You can use the examples code inMY_PROJECT as the start of your own project, or simply change MY_PROJECT topoint to your own Bazel project instead.
google-asylo	Running an interactive terminal	You can get an interactive terminal  instead of running a single command  byomitting the bazel run ..
google-asylo	Running an interactive terminal	part of the docker invocation
google-asylo	Running an interactive terminal	For instance, torun the hello_world example as above but in an interactive terminal, run:run Bazel as usual:To run our regression test suite, first clone the Asylo repository to adirectory of your choice.tests that run inside a simulated enclave environment
google-asylo	Running an interactive terminal	You can run it with thefollowing command:command
google-asylo	Running an interactive terminal	Note that in this command we also use -v to map the Asylo SDK sourcefiles to /opt/asylo/sdk.
google-asylo	Manual Installation	If you don't want to use the Asylo Docker image, you can manually install Asyloand its dependencies instead.See  INSTALL.md  INSTALL.md  for detailed installation steps.
google-asylo	Running the regression test suite	If you haven't already, use the following commands to clone the Asylo sourcecode repository and copy it to a directory of your choice.tests that run inside a simulated enclave environment
google-asylo	Running the regression test suite	You can run it with thefollowing command:This repository contains source code for the Asylo framework
google-asylo	Running the regression test suite	The v0.2 releaseof the framework supports C++11 applications and a Bazel build environment.The following packages contain source code that may be of particular interest tousers of the Asylo framework as well as those looking to contribute to Asylo+    asylo  asylo 
google-asylo	Disclaimer	This is not an officially supported Google product.
google-asymproj_edge_dnn	Learning Edge Representations via Low-Rank Asymmetric Projections	Implementation of  ACM CIKM 2017 paper _Learning Edge Representation via Low-Rank Asymmetric Projections_
google-asymproj_edge_dnn	Learning Edge Representations via Low-Rank Asymmetric Projections	As describedbelow, this repository includes:Code to process a graph  i.e
google-asymproj_edge_dnn	Learning Edge Representations via Low-Rank Asymmetric Projections	create training files .Code to train node embeddings and edge function, using our method, andDataset files, that are used in our paper.If you use this code, then you should:Note that this is **not*Consider citing our work, using the following bibtex:
google-asymproj_edge_dnn	Overview of files	  model on the test partition
google-asymproj_edge_dnn	Overview of files	 and  BioGrid  Nonetheless, we release our train/test  splits for others to replicate our results.
google-asymproj_edge_dnn	How to use	To use, you must first create dataset files using  create_dataset_arrays.py  ./create_dataset_arrays.py  , then train the nodeembeddings and the edge function using  deep_edge_trainer.py  ./deep_edge_trainer.py  
google-asymproj_edge_dnn	How to use	The following twosubsections explain how to use these two python scripts.
google-asymproj_edge_dnn	Create Trainer Files	The input to our method is an edge-list  readable by nx.read_edgelist In particular, assume that your file /path/to/graph.txt contains lines like:where n1 and n2 are node IDs, which can be strings or integers
google-asymproj_edge_dnn	Create Trainer Files	The lineindicates edge n1-n2  if graph is undirected  or n1->n2  if graph isdirected 
google-asymproj_edge_dnn	Create Trainer Files	Assume that the above graph.txt contains |E| lines
google-asymproj_edge_dnn	Create Trainer Files	You cangenerate dataset files by running:Which creates directory ~/asymproj/datasets/my_graph, writing files:train.pairs..txt.npy: Training pairs
google-asymproj_edge_dnn	Create Trainer Files	Sampled using random walks.
google-asymproj_edge_dnn	Pre-processed dataset files	If you are using pre-processed dataset files, with --only_simulate_walks to binary create_dataset_arrays.py
google-asymproj_edge_dnn	Pre-processed dataset files	For example, ifyou want to simulate walks for the PPI dataset  see  datasets  ./datasets/  ,then you can run the command:
google-asymproj_edge_dnn	Run Trainer Code	The training binary create_dataset_arrays.py
google-asymproj_edge_dnn	Run Trainer Code	During training, the trainer outputs the trainedmodel onto subdirectory dumps
google-asymproj_edge_dnn	Run Trainer Code	The name of the model files are automaticallycaptured from the hyper-parameters  e.g
google-asymproj_edge_dnn	Run Trainer Code	dimensions of embedding, dnn,projection 
google-asymproj_edge_dnn	Run Trainer Code	Setting flag --restore=0 will force to the trainer to start fromscratch
google-asymproj_edge_dnn	Run Trainer Code	Otherwise, if flag is ommitted, the trainer will continue training themodel from the last saved state.If you simulated walks on PPI, you can train a model with:The above command will print many lines like this:where Best=0.80/0.85 and cur=0.81/0.84, respectively, are the bestand current accuracies like test/train accuracies
google-asymproj_edge_dnn	Run Trainer Code	The Best is taken for_best train_
google-asymproj_edge_dnn	Run Trainer Code	We perform model selection at the training set
google-asymproj_edge_dnn	Run Trainer Code	In other words, weselect model parameters at peak train accuracy
google-asymproj_edge_dnn	Run Trainer Code	Please view the flags of deep_edge_trainer.py  ./deep_edge_trainer.py  to customize model
google-audio-sync-kit	Recording hardware	The instructions apply to any ALSA-compatible multi-channel audio recorder.The examples below use the Behringer U-Phono UFO202, a USB device withtwo input ports.The U-Phono is connected to a Linux system from where the recording commandswill be issued.
google-audio-sync-kit	Determining the ALSA device name	The first step is determining the name of the ALSA device corresponding tothe multi-channel recorder
google-audio-sync-kit	Determining the ALSA device name	Many systems have an embedded recording port e.g., the mic in most PCs , so it's important to determine the right device.The most straightforward way to identify the name is by running arecord -L; the additional entries will correspond to the card in question.For the U-Phono, the entries are those with CARD=CODEC,DEV=0:it provides the most direct path to the hardware and reduces the chancesof breaking the simultaneity of the recording.
google-audio-sync-kit	Recording command	Once the proper device name has been identified, the next step is actuallyrecording the audio
google-audio-sync-kit	Recording command	The following command line does it for the U-Phono:Since we're using the direct hardware device, it's mandatory to specifyparameters that are supported natively by the card
google-audio-sync-kit	Recording command	 In contrast, if--dump-hw-params switch:parameters in the audio file correspond to the arguments passed to arecord:Input FileSample RateDurationFile SizeBit RateSample Encoding: 16-bit Signed Integer PCM
google-audio-sync-kit	Splitting into mono files	Since the sync analyzer requires the audio signals to be in separatefiles, the following commands can be used to split the multichannelMeasuring sync from your programThe following steps were tested in Goobuntu 14.04, but should beapplicable to any Debian-based distribution.Create and start a virtualenv for the project.import audio_sync
google-audio-sync-kit	are given in audio_sync.DEFAULT_TEST_AUDIO_PROPERTIES.	latencies, dropouts  = audio_sync.AnalyzeAudios ref_wav_path, act_wav_path 
google-audio-sync-kit	Verify there are no dropouts and the latency is below the threshold.	assert    ==  x for x in latencies if x 1  >= LATENCY_THRESHOLD assert    == dropoutslatencies has the form   t0, latency0 ,  t1, latency1 , ..
google-audio-sync-kit	Verify there are no dropouts and the latency is below the threshold.	,where tx is the time, in seconds, from the start of the audioto a cliff in the reference audio and latencyx is the latency,in seconds, of the corresponding cliff in the actual signal.dropouts is a list of the form   s0, e0 ,  s1, e1 , ..
google-audio-sync-kit	Verify there are no dropouts and the latency is below the threshold.	with the start and the end of each dropout in the actual signal.How is latency measuredLatency measurements depend on the audio signals being made of pulsedsine waves of the following form:_simultaneously_, for example, using a multichannel audio card
google-audio-sync-kit	Verify there are no dropouts and the latency is below the threshold.	Notice that the requirement of simultaneity is a fundamental one;otherwise it's impossible to ensure that two corresponding datasamples had occurred at the same time
google-audio-sync-kit	Verify there are no dropouts and the latency is below the threshold.	By knowing the sampling frequency of the recordings the latencybetween the signals can be calculated by comparing the distancebetween two corresponding peaks in each audio signal using the formulaarbitrary media like a song:The first is that it allows to determine the sync of the audios asThe second is that since the audio is well characterized, it's
google-audio-sync-kit	Limitations	The algorithm can detect latencies in the rangeThe algorithm doesn't detect dropouts in the reference signal.Command line interfaceThe library also provides a command line interface  CLI  to analyzethe audios
google-audio-sync-kit	Limitations	This is useful for exploratory testing and experimentation.
google-audio-sync-kit	Requirements	The CLI depends on numpy  tested with 1.10.2, but other versions mayalso work .Running the program without parameters shows the available options.The most relevant ones are:  {  }      10:17:35 34:13 > +0839 ........
google-audio-sync-kit	Requirements	|  10:17:36 34:14 > +0929 ..........|  10:17:36 34:14 > +1111 ..........|*  10:17:37 34:15 > +0907 ..........|  10:17:37 34:15 > +1043 ..........|  10:17:37 34:15 > +0884 ........
google-audio-sync-kit	Requirements	|    specific latencies to occurances in the device log.Percentiles  secs :0%: 0.00000050%: 0.00000075%: 0.00000090%: 0.00400095%: 0.00700099%: 0.009400100%: 0.010000The latencies printed are the max absolute value of the delay, so a delayof -0.1 seconds would be displayed as 0.python ref.wav act.wav --print_percentilesPercentiles  secs :0%: 0.00000050%: 0.00000075%: 0.00000090%: 0.00000095%: 0.00000099%: 0.000000100%: 0.000000
google-audio-sync-kit	Example 2	For latencies, the first element on each sub-list is the time in secondsfrom the start of the recording and the second element is the latency measured.For dropouts, the first element on each sub-list is the start time of thedropout  in seconds from the start of the recording  and the second elementend time of the dropout.
google-audio-sync-kit	Example 3	.......
google-audio-sync-kit	Example 3	= Act more than 0.020 secs ahead of refo = Dropout
google-audio-sync-kit	Example 3	= 0.036 secsThe output shows a comparison over the time of the two audios:In the above example, the actual audio was behind at severalpoints
google-audio-sync-kit	Example 3	If the files are inverted = Act more than 0.020 secs ahead of refo = Dropout
google-audio-sync-kit	Example 3	= 0.035 secswe can see an expected reversal of the latencies.---------Unittests for all the modules can be run via the audio_sync/run_unittests
google-audion	Web Audio Inspector	Web Audio Inspector is a Chrome extension that adds a "Web Audio" panel to Developer Tools
google-audion	Web Audio Inspector	This panel visualizes the AudioNode graph generated by Web Audio API JavaScript
google-audion	Web Audio Inspector	Install the extension from its  Chrome Web Store page ! Web Audio Inspector The wiki details  how to use Web Audio Inspector 
google-audion	No Support for ES6 Classes at the Moment	This extension breaks ES6 classes that extend subclasses of AudioNode
google-audion	No Support for ES6 Classes at the Moment	See issue  #73  Web Audio Inspector's logic for overriding AudioNode constructors disallows classes from extending those constructors
google-audion	No Support for ES6 Classes at the Moment	We are trying to resolve this issue.
google-audion	Build Dependencies	We welcome contributions
google-audion	Build Dependencies	See the issues list, or suggest ideas
google-audion	Build Dependencies	For starters, we currently have some usability and visualization issues that need owners.Review CONTRIBUTING.md
google-audion	Build Dependencies	Note that Google requires contributors to sign a  Contributors License Agreement Set up  2-factor authentication for Github   as Google requires .Clone the repository with the git@ address
google-audion	Build Dependencies	The https address does not work with 2-factor authentication.
google-audion	Build and run	Run the following commands in the project root directory.
google-audion	Code Layout	This project uses the  Google Closure JavaScript library  and  Google's JavaScript style guide The extension comprises of several scripts
google-audion	Code Layout	Each script corresponds to a Closure entry point  JS file  within js/entry-points.Tests reside in the tests directory and use Closure's jsunit library
google-audion	Code Layout	Tests run in a web browser
google-audion	Code Layout	Each test has a _test.html file  which sets up DOM elements required by the test  and a _test.js file  which contains the bulk testing logic 
google-audion	Code Layout	To run all tests at once,Run npm install to update dependencies if you have not done so.Run gulp test to start a static server
google-audion	Code Layout	This command also uses your default browser  preferably  Google Chrome  to open a web page  pictured below  for running all tests at once.! Web Audio Inspector To run tests individually, you can use that UI as well, or you could visit the path to that test's _test.html file.
google-audit-normalmap	Normalmaps	Normal mapping is a technique to simulate surfaces with bumps of dents in 3Dcomputer graphics
google-audit-normalmap	Normalmaps	It works by storing additional per-pixel information formaterial textures: a single vector, indicating a normal protrudingperpendicularly from the surface.This information then can be used from a shader script using an equation like:from the light source
google-audit-normalmap	Normalmaps	Note: typically, normalmaps will be encoded in tangentspace, so for above formula, lightdirection needs to be computed in tangentspace first too
google-audit-normalmap	Normalmaps	As the normalmap contains information about surface steepness at each pixel,some consistency expectations can be made a normalmap corresponds to some heightmap, which essentially means thatintegrating the gradient  which is implied from the normal vectors  across anyclosed path must yield zero.Furthermore, commonly normalmaps contain height information in the alphachannel; this also should usually be consistent with the normal vectors.This tool verifies these consistency properties of normalmaps to aid withquality control of gaming artwork
google-audit-normalmap	Normalmaps	It supports both the common Direct3D andOpenGL Y axis conventions  a.k.a
google-audit-normalmap	Normalmaps	green channel inversion .
google-audit-normalmap	Usage	  this is also known as green channel inversion 
google-audit-normalmap	Usage	This matches most OpenGL based  game engines
google-audit-normalmap	Usage	By default, the y coordinate is interpreted according to the  usual convention of Direct3D based game engines
google-audit-normalmap	Usage	 engines.
google-audit-normalmap	Copyright	See the LICENSE file.
google-audit-normalmap	Contributing	See the CONTRIBUTING.md file.
google-audit-normalmap	Disclaimer	This is not an official Google product.
google-auth-library-swift	Auth Library for Swift	This project contains Swift packages that can be used to write command-linetools and cloud services that use OAuth to authenticate and authorize accessto remote services.Currently these packages support OAuth1 and OAuthThey are designed to work on OS X systems and on Linux systems that arerunning in the  Google Cloud browser and a local web server that is automatically run in thecommand-line client
google-auth-library-swift	Auth Library for Swift	Google Cloud Service Accounts 
google-auth-library-swift	Usage and Examples	 Sources/Examples  Sources/Examples  contains examples that illustrate OAuth1 and OAuth2 signin forvarious services
google-auth-library-swift	Usage and Examples	Each requires valid application credentials to run.See the various service providers for details.Services look for OAuth configuration information in "credentials" YAML filesthat are expected to be in $HOME/.credentials
google-auth-library-swift	Usage and Examples	Sample credentialsfiles are in  credentials  credentials and include client IDs, client secrets, and OAuth service URLs.When OAuth services require registered callback URLs, these should beset to  where SERVICE is specified in the corresponding credentials YAML file
google-auth-library-swift	Usage and Examples	The temporary web server runs locally on port 
google-auth-library-swift	Credits	This is work in progress toward great server-side Swift software
google-auth-library-swift	Credits	Please take carewhen using this in production projects: always refer to a tagged version and be aware that interfaces may change in future releases.
google-auth-library-swift	Contributing	We'd love to collaborate on this
google-auth-library-swift	Contributing	See  CONTRIBUTING.md  CONTRIBUTING.md  for details.
google-auth-library-swift	Copyright	Copyright 2017, Google Inc.
google-auth-library-swift	License	Released under the Apache 2.0 license.
google-auto	Auto	A collection of source code generators for  Java  java .
google-auto	Auto‽	 Java  java  is full of code that is mechanical, repetitive, typically untestedand sometimes the source of subtle bugs
google-auto	Auto‽	_Sounds like a job for robots!_The Auto subprojects are a collection of code generators that automate thosetypes of tasks
google-auto	Auto‽	They create the code you would have written, but withoutthe bugs.Save time
google-auto	Auto‽	 Save code
google-auto	Auto‽	 Save sanity.
google-auto	License	 AutoFactory :  AutoService :  AutoValue :  Common :  java :  value-type :  ServiceLoader : 
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	EVENT is refering to BR_INST_RETIRED:TAKEN if available
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	For somearchitectures, BR_INST_EXEC:TAKEN also works.--binary: BINARY with debug info
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	You need to make sure the binary name isthe same as the binary you run during profiling
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	Additionally, you will needto have debug info  i.e
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	line table  availabe in the binary
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	This means thatyou need to compile the binary with "-gmlt" or "-g1"
google-autofdo	perf record -c PERIOD -e EVENT -b -o perf.data -	For LLVM, you alse needto have -fdebug-info-for-profiling.For create_gcov:For create_llvm_prof:
google-automation-inspector	Automation Inspector	An inspection tool for Chrome Automation APIThe  Chrome Automation API is an experimental accessibility API that allows developers to access theautomation tree and events for the browser
google-automation-inspector	Automation Inspector	The tree resembles the DOM tree,but only exposes the semantic structure of a page
google-automation-inspector	Automation Inspector	It can be used toprogrammatically interact with a page by examining names, roles, and states,listening for events, and performing actions on nodes.One of Chrome Automation's main purposes is to enable the development ofassistive technologies written in JavaScript, for Chrome OS
google-automation-inspector	Automation Inspector	This is similar tohow MSAA, IA2 and  UIA are used on Windows, and AX Accessibility is used forOS X
google-automation-inspector	Automation Inspector	It can also be used by extensions, but because it is experimental, itis currently available only on the dev channel and to internal assistivetechnologies such as ChromeVox.Automation Inspector is used to exercise the Automation API, to inspect theentire Chrome OS desktop, or to inspect a specific browser tab.This tool is mainly useful for the following types of people:Chrome OS to the Dev Channel and then install Automation Inspector as an app  insert link here 
google-automation-inspector	Automation Inspector	install Google Chrome Canary  andthen install Automation Inspector as an extension  insert link here .
google-automation-inspector	Building	The first time you build, do an npm installThis will automatically run bower install for you.If you want to update the dependencies, use npm update && bower updateNext, type the following from the command line in the automation-inspector folder:grunt default watchto keep the build updated as source files change.
google-automation-inspector	Running from the local file system	Using developer mode from the Chrome extensions page at build/extension folder.
google-automation-inspector	Releasing	Update the version number via:grunt default compress to create app.zip and extension.zip for uploading to the Chrome web store in the build/package folder.
google-automation-inspector	Finding a node	The find field is very powerful, and can be used in a number of ways:This can be slow on complex pages, it it will cause the entire page to beloaded a bit at a time.Slow on complex pages  similiar to plain text search .to find a node matching a given selector
google-automation-inspector	Finding a node	This will currently return only thefirst item
google-automation-inspector	Finding a node	This method uses the Automation API's domQuerySelector method
google-automation-inspector	Finding a node	Forexample, use $ '#my-special-element'  to find the nearest automation node tothat element.similar to  FindParams However, this method accepts valid JSON syntax only
google-automation-inspector	Finding a node	You must provide stringsrather than constants
google-automation-inspector	Finding a node	For example, use { "state" : {"disabled": true }}rather than { state: { StateType.disabled: true }}.
google-autoparse	AutoParse	  Homepage  AuthorBob Aman  CopyrightCopyright © 2010 Google, Inc
google-autoparse	AutoParse	 LicenseApache 2.0
google-autoparse	Description	An implementation of the JSON Schema specification
google-autoparse	Description	Provides automatic parsingfor a given JSON Schema.
google-badwolf-drivers	BadWolf Drivers	    ! Go Report Card    ! GoDoc  by the Resource Description Framework  RDF  It presents a flexible storage abstraction, efficient query language, anddata-interchange model for representing a directed graph that accommodates thestorage and linking of arbitrary objects without the need for a rigid schema
google-badwolf-drivers	BadWolf Drivers	BadWolf  main repository contains theimplementation, but no persistent drivers
google-badwolf-drivers	BadWolf Drivers	This repository contains a collectionof driver implementations aim to provide, mainly, persistent storage 
google-badwolf-drivers	Bulding the command line tool	Assumming you have a fully working installation of GO, you just need to get the required packages and build the tool
google-badwolf-drivers	Bulding the command line tool	You can achieve this by typing the following commands:check that the new VOLATILEplease see the  original documentation  
google-badwolf-drivers	Testing the command line tool	You may always want to run all the test for both repos badwolf-drivers to make sure eveything is A-Ok
google-badwolf-drivers	Testing the command line tool	If the tests fail, you should consider not using the build tool since it may be tainted.
google-badwolf	BadWolf	    ! Go Report Card    ! GoDoc   BadWolf is a temporal graph store loosely modeled after the concepts introducedby the Resource Description Framework  RDF  It presents a flexible storage abstraction, efficient query language, anddata-interchange model for representing a directed graph that accommodates thestorage and linking of arbitrary objects without the need for a rigid schema.BadWolf began as a  triplestore but triples have been expanded to quads to allow simpler and flexible temporalreasoning
google-badwolf	BadWolf	Because BadWolf is designed for generalized relationship storage,most of the web-related idiosyncrasies of RDF are not used and have been toneddown or directly removed and focuses on its time reasoning aspects.In case you are curious about the name, BadWolf is named after the BadWolf entity    as it appearedin Dr
google-badwolf	BadWolf	Who series episode _"The Parting Of Ways"_ after Rose Tyler looked intothe Time Vortex itself
google-badwolf	BadWolf	The BadWolf entity scattered events in time as selfencode messages, creating a looped ontological paradox
google-badwolf	BadWolf	Hence, naming a temporalgraph store after the entity seemed appropriate.You can find more detail information on each of the components of BadWolf below:will be no guarantees on API stability till the first stable 1.0 release.You can reach us here or via @badwolf_project  on Twitter
google-badwolf	BadWolf	For more information, presentation, or to find other related projects that using BadWolf check the project website 
google-bamboo-soy	Bamboo Soy for IntelliJ 🏮🍣🏮	   ! GitHub license  The smartest Intellij plugin for the  Soy templating language ! output Adds syntax highlighting, autocompletion and static analysis for your closure template files.
google-bamboo-soy	Installation	Install the plugin directly from your IDE or the Jetbrains plugin repository 
google-bamboo-soy	Feature Summary	Bamboo Soy aims to provide super-fast, no-compromise language support for Soy in IntelliJ.unbalanced tags  things don’t break when you type .
google-bamboo-soy	Release notes	See the  release notes page  releasenotes.md .
google-bamboo-soy	Contributing	Small and large contributions welcome! For new features or substantial changes, please open an issuebeforehand so that it can be discussed.For all the details, see the  contributing page  CONTRIBUTING.md .
google-battery-historian	Battery Historian	Battery Historian is a tool to inspect battery related information and events on an Android device running Android 5.0 Lollipop  API level 21  and later, while the device was not plugged in
google-battery-historian	Battery Historian	It allows application developers to visualize system and application level events on a timeline with panning and zooming functionality, easily see various aggregated statistics since the device was last fully charged, and select an application and inspect the metrics that impact battery specific to the chosen application
google-battery-historian	Battery Historian	It also allows an A/B comparison of two bugreports, highlighting differences in key battery related metrics.
google-battery-historian	Using Docker	Install  Docker  <> .Run the Battery Historian image
google-battery-historian	Using Docker	Choose a port number and replace  withthat number in the commands below:For Windows:using
google-battery-historian	Using Docker	If, for example, the IP address is 123.456.78.90, Historian will beavailable at .For more information about the port forwarding, see the  Dockerdocumentation  <> .
google-battery-historian	Building from source code	Make sure you have at least Golang version 1.8.1:  through the "Advanced System Settings" option inside the "System" control panel.Next, install Git from <> if it's not already installed.Next, make sure Python 2.7  NOT Python 3!  is installed
google-battery-historian	Building from source code	See <>if it isn't, and ensure that python is added to your $PATH environment variable.Next, install Java from <>.Next, download the Battery Historian code and its dependencies:
google-battery-historian	Run Historian on your machine  make sure $PATH contains $GOBIN 	Remember, you must always run battery-historian from inside the $GOPATH/src/github.com/google/battery-historian directory:To take a bug report from your Android device, you will need to enable USB debugging under Settings > System > Developer Options
google-battery-historian	Run Historian on your machine  make sure $PATH contains $GOBIN 	On Android 4.2 and higher, the Developer options screen is hidden by default
google-battery-historian	Run Historian on your machine  make sure $PATH contains $GOBIN 	You can enable this by following the instructions  here  <> .To obtain a bug report from your development device running Android 7.0 andYou are all set now
google-battery-historian	Run Historian on your machine  make sure $PATH contains $GOBIN 	Run historian and visit <> andupload the bugreport.txt file to start analyzing.
google-battery-historian	Timeline:	! Timeline  /screenshots/timeline.png "Timeline Visualization" 
google-battery-historian	System stats:	! System  /screenshots/system.png "Aggregated System statistics since the device was last fully charged" 
google-battery-historian	App stats:	! App  /screenshots/app.png "Application specific statistics" 
google-battery-historian	Advanced	To reset aggregated battery stats and history:By default, Android does not record timestamps for application-specificuserspace wakelock transitions even though aggregate statistics are maintainedon a running basis
google-battery-historian	Advanced	If you want Historian to display detailed information abouteach individual wakelock on the timeline, you should enable full wakelockreporting using the following command before starting your experiment:in a few hours
google-battery-historian	Advanced	Use this option for short test runs  3-4 hrs .
google-battery-historian	Kernel trace analysis	To generate a trace file which logs kernel wakeup source and kernel wakelockFirst, connect the device to the desktop/laptop and enable kernel trace logging:
google-battery-historian	8MB to 10MB should be a decent size for 5-6 hours of logging.	Then, use the device for intended test case.Finally, extract the logs:
google-battery-historian	Take a bug report at this time.	Historian plots and relates events in real time  PST or UTC , whereas kerneltrace files logs events in jiffies  seconds since boot time 
google-battery-historian	Take a bug report at this time.	In order to relatethese events there is a script which approximates the jiffies to utc time
google-battery-historian	Take a bug report at this time.	Thescript reads the UTC times logged in the dmesg when the system suspends andresumes
google-battery-historian	Take a bug report at this time.	The scope of the script is limited to the amount of timestamps presentin the dmesg
google-battery-historian	Take a bug report at this time.	Since the script uses the dmesg log when the system suspends,there are different scripts for each device, with the only difference beingthe device-specific dmesg log it tries to find
google-battery-historian	Take a bug report at this time.	These scripts have beenintegrated into the Battery Historian tool itself.
google-battery-historian	Power monitor analysis	Lines in power monitor files should have one of the following formats, and theformat should be consistent throughout the entire file:To ensure the power monitor and bug report timelines are somewhat aligned,please reset the batterystats before running any power monitor logging:If using a Monsoon:Download the AOSP Monsoon Python script from <>
google-battery-historian	Modifying the proto files	If you want to modify the proto files  pb/\*/\*.proto , first download theadditional tools necessary:Install the standard C++ implementation of protocol buffers from <>Download the Go proto compiler:in your $PATH for the protocol compiler, protoc, to find it.Make your changes to the proto files.Finally, regenerate the compiled Go proto output files using regen_proto.sh.
google-battery-historian	License	Copyright 2016 Google, Inc.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atUnless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS, WITHOUTWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-battery-historian	License	 See theLicense for the specific language governing permissions and limitations underthe License.
google-bazel-common	Bazel Common Libraries	This repository contains assorted common functionality for Google's open-sourcelibraries that are built with  bazel 
google-bazel-common	Bazel Common Libraries	It is an experimental project and noneof the APIs/target names are fixed/guaranteed to remain
google-bazel-common	Bazel Common Libraries	You are welcome to useit and offer feedback at your own risk.This is not an official Google product
google-bazel-common	Bazel Common Libraries	bazel : 
google-bbcpu	BBSoftCPU	A Verilog HDL implementation of a breadboard TTL CPU design
google-bbcpu	BBSoftCPU	The design itself is based on theseries of educational  videos  1  by Ben Eater.Testing can be done on the Lattice iCE40 family of FPGAs
google-bbcpu	BBSoftCPU	The specific board used during development is:For anyone interested further information is available at:are used as a replacement.
google-bbcpu	Build environment	Ubuntu 16.04 or newer
google-bbcpu	Build environment	The toolchain and verilog simulator can be installed via:The simulator can be invoked via:Before flashing the FPGA board, the USB access permissions need a minor adjustment that will allow the tools towrite a bitstream on the device
google-bbcpu	Build environment	Create a new file at:Add this line inside:Make sure that the icestick board is connected to the host PC.Flashing the bitstream on the FPGA can be done by invoking:The default program will currently calculate the fibonacci sequence of numbers.As mentioned before the 'OUT' instruction will transmit the register 'A' contents on the second UART port.The serial device will usually appear on the host as '/dev/ttyUSB1'
google-bbcpu	Build environment	The configuration used right now is: 1 :  2 :  3 :  4 :  5 : 
google-beacon-platform	Beacon Platform	This repository contains sample apps that demonstrate how to use the Proximity Beacon API the  Proximity Beacon API  and Eddystone  an open beacon format from Google.
google-beautiful-audio-editor	Overview	This audio editor runs in a web browser and uses the Web Audio API
google-beautiful-audio-editor	Overview	Chimade some efforts to embed it within a web view and make it an Androidapp, but halted after facing memory issues.This project uses Google Closure, which encompasses a javascript compiler,library, Google Stylesheets  GSS  for structuring pieces of HTML 
google-beautiful-audio-editor	Overview	Closure standardizes javascript
google-beautiful-audio-editor	Overview	For instance,it introduces private/protected variables, normal  non-prototypical inheritance like java, and compile-time error checking.This is not an official Google product
google-beautiful-audio-editor	Overview	Chi just thought that the Chrome WebStore needed a nimble audio editing tool, both before and after Android apps canrun on Chromebooks.
google-beautiful-audio-editor	Setup	 Install java Give Google Closure build tools relevant execute permissions:The project uses a python script  do.py  for building, which is kind of simple.We're open to using more robust build systems such as bazel or gulp.Some uses:Compile the javascript  including soy templates  and CSS, which is outputted into the build directory:To run the editor, start up a web server in the home repository directory.For example, in the repository directory, runYou can then view the compiled editor at You can view the uncompiled editor at While developing, you don't have to recompile to view changes in the uncompiled version.However, you have to recompile to see changes if you made changes to the dependency graph  altered calls to goog.require ,made any stylesheet changes  changes to GSS files , or altered soy templates  which generate javascript files upon template compilation .
google-beautiful-audio-editor	Coding Guidelines	This project currently uses  Google's javascript style guide To help check for style throughout the project, run python do.py lint in the home audio-cat directory.
google-beautiful-audio-editor	Location	Source code is located in the src folder.Soon, each folder will have a README describing its contents
google-beautiful-audio-editor	Location	Each javascript file also contains a block comment describing it.TODO chihuahua : uh..
google-beautiful-audio-editor	Location	do that
google-beautiful-audio-editor	Location	write those readmes.
google-beautiful-audio-editor	Organization of JavaScript Classes	In broad strokes, this project's javascript classes fall into 5 categories:
google-beautiful-audio-editor	src/js/original/state	This folder contains files that maintain the state of individual audio projects.For instance, audioCat.state.Clip encapsulates information about an individual clip within a section.Classes in this folder typically dispatch events when their states change, notifyingother entities such as audio-play-related and UI entities of changes in state.For instance, when a new track is added, the audioCat.state.TrackManager fires an eventnotifying the audio graph to play the track as well as the UI  audioCat.ui.TrackListingManager to visualize the track.
google-beautiful-audio-editor	src/js/original/audio	This folder contains classes related to playing audio and hooking up with theWeb Audio API
google-beautiful-audio-editor	src/js/original/audio	For instance, audioCat.audio.play.PlayManager maintains thecurrent play status
google-beautiful-audio-editor	src/js/original/audio	audioCat.audio.AudioGraph maintains the connectionsbetween junctions in the audio graph.Files in this directory heed events dispatched by entities within src/js/original/stateas well as fires its own events for the UI to listen to
google-beautiful-audio-editor	src/js/original/audio	For instance, whenplaying starts, the UI responds by switching the play icon to a pause icon.
google-beautiful-audio-editor	src/js/original/ui	This folder contains files that updates the UI
google-beautiful-audio-editor	src/js/original/ui	Classes in this folder typicallyencapsulate state and audio play
google-beautiful-audio-editor	src/js/original/ui	When the user interacts with the UI, classes inthis folder directly modify the state objects
google-beautiful-audio-editor	src/js/original/ui	The state then fires events that updatethe UI.
google-beautiful-audio-editor	src/js/original/app	The files in this directory hook up the whole app together
google-beautiful-audio-editor	src/js/original/app	app.js for instanceis a megamoth file that instantiates the whole app.
google-beautiful-audio-editor	src/js/original/action	This folder contains Action objects that perform a certain action
google-beautiful-audio-editor	src/js/original/action	Each action object can be retreived from the ActionManager by a specific key
google-beautiful-audio-editor	src/js/original/action	We can invoke actions based on various interactions.
google-beautiful-audio-editor	src/js/original/utility	This folder is a collection of convenience classes that are used throughout theproject
google-beautiful-audio-editor	src/js/original/utility	For instance, audioCat.utility.IdGenerator generates IDs uniquethroughout the application used by many types of objects.
google-beautiful-audio-editor	src/js/original/android	This folder contains code that allows the editor to be embedded within an Android web view
google-beautiful-audio-editor	src/js/original/android	Efforts towards making a mobile app were abandoned after the decision to keep the editor a web app
google-beautiful-audio-editor	src/js/original/android	This folder is basically a noop.
google-beautiful-audio-editor	Testing	Unit tests currently use Google Closure's junit library
google-beautiful-audio-editor	Testing	To add a unit test,Code up a _test.js and _test.html file
google-beautiful-audio-editor	Testing	See id-generator_test for an example.Run python do.py to aggregate all tests into auto_generated/all_tests.js.Unit tests for certain javascript classes can be run by starting a web serverin the home repository directory, again with sayClick Start to run tests.We currently lack integration tests with say web driver, Selenium, or Google
google-benchmark	benchmark	   ! Build status     ! slackin  A library to support the benchmarking of functions, similar to unit-tests
google-benchmark	benchmark	Discussion group IRC channel:  freenode  #googlebenchmark Additional Tooling Documentation  docs/tools.md  Assembly Testing Documentation  docs/AssemblyTests.md 
google-benchmark	Building	The basic steps for configuring and building the library look like this:dependency can be provided two ways:  dependencies.If you do not wish to build and run the tests, add -DBENCHMARK_ENABLE_GTEST_TESTS=OFFto CMAKE_ARGS.
google-benchmark	Installation Guide	For Ubuntu and Debian Based SystemFirst make sure you have git and cmake installed  If not please install them The main branch contains the latest stable version of the benchmarking library;the API of which can be considered largely stable, with source breaking changesbeing made only upon the release of a new major version.Newer, experimental, features are implemented and tested on the v2 branch  Users who wishto use, test, and provide feedback on the new features are encouraged to trythis branch
google-benchmark	Installation Guide	However, this branch provides no stability guarantees and reservesthe right to change and break the API at any time.
google-benchmark	Further knowledge	It may help to read the  Google Test documentation as some of the structural aspects of the APIs are similar.
google-benchmark	Basic usage	Define a function that executes the code to be measured, register it as abenchmark function using the BENCHMARK macro, and ensure an appropriate mainfunction is available:
google-benchmark	#include 	static void BM_StringCreation benchmark::State& state  {  for  auto _ : state // Register the function as a benchmarkBENCHMARK BM_StringCreation ;// Define another benchmarkstatic void BM_StringCopy benchmark::State& state  {  std::string x = "hello";  for  auto _ : state BENCHMARK BM_StringCopy ;BENCHMARK_MAIN  ;Don't forget to inform your linker to add benchmark library e.g
google-benchmark	#include 	through -lbenchmark_main to get the same default behavior.The benchmark library will measure and report the timing for code within thefor ..
google-benchmark	#include 	 loop.
google-benchmark	Platform-specific libraries	When the library is built using GCC it is necessary to link with the pthreadlibrary due to how GCC implements std::thread
google-benchmark	Platform-specific libraries	Failing to link to pthread willlead to runtime exceptions  unless you're using libc++ , not linker errors
google-benchmark	Platform-specific libraries	See issue #67  for more details
google-benchmark	Platform-specific libraries	Youcan link to pthread by adding -pthread to your linker command
google-benchmark	Platform-specific libraries	Note, you canalso use -lpthread, but there are potential issues with ordering of commandline parameters if you use that.If you're running benchmarks on Windows, the shlwapi library  -lshlwapi  isalso required.If you're running benchmarks on solaris, you'll want the kstat library linked intoo  -lkstat .
google-benchmark	Passing arguments	Sometimes a family of benchmarks can be implemented with just one routine thattakes an extra argument to specify which one of the family of benchmarks torun
google-benchmark	Passing arguments	For example, the following code defines a family of benchmarks formeasuring the speed of memcpy   calls of different lengths:short-hand
google-benchmark	Passing arguments	The following invocation will pick a few appropriate arguments inthe specified range and will generate a benchmark for each such argument.the command above selects   8, 64, 512, 4k, 8k  
google-benchmark	Passing arguments	In the following code therange multiplier is changed to multiples of two.Now arguments generated are   8, 16, 32, 64, 128, 256, 512, 1024, 2k, 4k, 8k  .You might have a benchmark that depends on two or more inputs
google-benchmark	Passing arguments	For example, thefollowing code defines a family of benchmarks for measuring the speed of setshort-hand
google-benchmark	Passing arguments	The following macro will pick a few appropriate arguments in theproduct of the two specified ranges and will generate a benchmark for each suchprogrammatic specification of an arbitrary set of arguments on which to run thebenchmark
google-benchmark	Passing arguments	The following example enumerates a dense range on one parameter,and a sparse range on the second.Asymptotic complexity might be calculated for a family of benchmarks
google-benchmark	Passing arguments	Thefollowing code will calculate the coefficient for the high-order term in therunning time and the normalized root-mean square error of string comparison.calculated automatically.that might be used to customize high-order term calculation.Templated benchmarks work the same way: This example produces and consumesmessages of size sizeof v  range_x times
google-benchmark	Passing arguments	It also outputs throughput in theabsence of multiprogramming.In C++11 mode, a ranged-based for loop should be used in preference tothe KeepRunning loop for running the benchmarks
google-benchmark	Passing arguments	For example:because KeepRunning requires a memory load and store of the iteration countever iteration, whereas the ranged-for variant is able to keep the iteration countin a register.For example, an empty inner loop of using the ranged-based for method looks like:the benchmark loop should be preferred.In C++11 it is possible to define a benchmark that takes an arbitrary numberof extra arguments
google-benchmark	Passing arguments	The BENCHMARK_CAPTURE func, test_case_name, ...args macro creates a benchmark that invokes func  with the benchmark::State asthe first argument followed by the specified args....The test_case_name is appended to the name of the benchmark andshould describe the values passed.Note that elements of ...args may refer to global variables
google-benchmark	Passing arguments	Users shouldavoid modifying global state inside of a benchmark.
google-benchmark	Using RegisterBenchmark name, fn, args... 	The func st, args..
google-benchmark	Using RegisterBenchmark name, fn, args... 	 where st is a benchmark::State object.Unlike the BENCHMARK registration macros, which can only be used at the globalscope, the RegisterBenchmark can be called anywhere
google-benchmark	Using RegisterBenchmark name, fn, args... 	This allows forbenchmark tests to be registered programmatically.Additionally RegisterBenchmark allows any callable object to be registeredas a benchmark
google-benchmark	Using RegisterBenchmark name, fn, args... 	Including capturing lambdas and function objects.For Example:auto BM_test =    benchmark::State& st, auto Inputs  { /int main int argc, char*  for  auto& test_input : { /  benchmark::Initialize &argc, argv ;  benchmark::RunSpecifiedBenchmarks  ;
google-benchmark	Multithreaded benchmarks	In a multithreaded test  benchmark invoked by multiple threads simultaneously ,it is guaranteed that none of the threads will start until all have reachedthe start of the benchmark loop, and all will have finished before any threadexits the benchmark loop
google-benchmark	Multithreaded benchmarks	 This behavior is also provided by the KeepRunning  API  As such, any global setup or teardown can be wrapped in a check against the threadsingle-threaded code, you may want to use real-time  "wallclock"  measurementsfor latency comparisons:
google-benchmark	Manual timing	For benchmarking something for which neither CPU time nor real-time arecorrect or accurate enough, completely manual timing is supported usingthe UseManualTime function.When SetIterationTime once per iteration of the benchmark loop toreport the manually measured time.An example use case for this is benchmarking GPU execution  e.g
google-benchmark	Manual timing	OpenCLor CUDA kernels, OpenGL or Vulkan or Direct3D draw calls , which cannotbe accurately measured using CPU time or real-time
google-benchmark	Manual timing	Instead, they can bemeasured accurately using a dedicated API, and these measurement resultscan be reported back with SetIterationTime.static void BM_ManualTiming benchmark::State& state  {  int microseconds = state.range 0 ;  std::chrono::duration sleep_duration {  };  }BENCHMARK BM_ManualTiming ->Range 1, 1UseManualTime  ;
google-benchmark	Preventing optimisation	To prevent a value or expression from being optimized away by the compilerthe benchmark::DoNotOptimize ..
google-benchmark	Preventing optimisation	 and benchmark::ClobberMemory  functions can be used.memory or a register
google-benchmark	Preventing optimisation	For GNU based compilers it acts as read/write barrierfor global memory
google-benchmark	Preventing optimisation	More specifically it forces the compiler to flush pendingwrites to memory and reload any other values as necessary.Note that DoNotOptimize   does not prevent optimizations on in any way
google-benchmark	Preventing optimisation	 may even be removed entirely when the result is alreadyknown
google-benchmark	Preventing optimisation	For example:  /  int foo int x  { return x + 42; }  while  ..
google-benchmark	Preventing optimisation	 DoNotOptimize foo 0  ; // Optimized to DoNotOptimize 42 ;  int bar int  __attribute__  const  ;  while  ..
google-benchmark	Preventing optimisation	 DoNotOptimize bar 0  ; // Optimized to:  // int __result__ = bar 0 ;  // while  ..
google-benchmark	Preventing optimisation	 DoNotOptimize __result__ ;The second tool for preventing optimizations is ClobberMemory   prevents the call to v.push_back 42  from being optimized
google-benchmark	Set time unit manually	If a benchmark runs a few milliseconds it may be hard to visually compare themeasured times, since the output data is given in nanoseconds per default
google-benchmark	Set time unit manually	Inorder to manually set the time unit, you can specify it manually:By default each benchmark is run once and that single result is reported.However benchmarks are often noisy and a single result may not be representativeof the overall behavior
google-benchmark	Set time unit manually	For this reason it's possible to repeatedly rerun theThe number of runs of each benchmark is specified globally by theRepetitions on the registered benchmark object
google-benchmark	Set time unit manually	When a benchmark is run morethan once the mean, median and standard deviation of the runs will be reported.Additionally the ReportAggregatesOnly bool  function can be used to change how repeated testsare reported
google-benchmark	Set time unit manually	By default the result of each repeated run is reported
google-benchmark	Set time unit manually	When thisoption is true only the mean, median and standard deviation of the runs is reported.Calling ReportAggregatesOnly bool  on a registered benchmark object overridesthe value of the flag for that benchmark.
google-benchmark	User-defined statistics for repeated benchmarks	While having mean, median and standard deviation is nice, this may not beenough for everyone
google-benchmark	User-defined statistics for repeated benchmarks	For example you may want to know what is the largestobservation, e.g
google-benchmark	User-defined statistics for repeated benchmarks	because you have some real-time constraints
google-benchmark	User-defined statistics for repeated benchmarks	This is easy.The following code will specify a custom statistic to be calculated, definedby a lambda function.void BM_spin_empty benchmark::State& state  {  for  auto _ : state  {  }BENCHMARK BM_spin_empty   ->ComputeStatistics "max",    const std::vector& v  -> double {  }   ->Arg 512 ;
google-benchmark	Fixtures	Fixture tests are created byfirst defining a type that derives from ::benchmark::Fixture and thencreating/registering the tests using the following macros:class MyFixture : public benchmark::Fixture {};BENCHMARK_F MyFixture, FooTest  benchmark::State& st  {  }BENCHMARK_DEFINE_F MyFixture, BarTest  benchmark::State& st  {  }/BENCHMARK_REGISTER_F MyFixture, BarTest ->Threads 2 ;
google-benchmark	Templated fixtures	Also you can create templated fixture by using the following macros:templateclass MyFixture : public benchmark::Fixture {};BENCHMARK_TEMPLATE_F MyFixture, IntTest, int  benchmark::State& st  {  }BENCHMARK_TEMPLATE_DEFINE_F MyFixture, DoubleTest, double  benchmark::State& st  {  }BENCHMARK_REGISTER_F MyFixture, DoubleTest ->Threads 2 ;
google-benchmark	User-defined counters	You can add your own counters with user-defined names
google-benchmark	User-defined counters	The example belowwill add columns "Foo", "Bar" and "Baz" in its output:and Counter values
google-benchmark	User-defined counters	The latter is a double-like class, via an implicitconversion to double&
google-benchmark	User-defined counters	Thus you can use all of the standard arithmeticassignment operators  =,+=,-=,*=,/=  to change the value of each counter.In multithreaded benchmarks, each counter is set on the calling thread only.When the benchmark finishes, the counters from each thread will be summed;the resulting sum is the value which will be shown for the benchmark.The Counter constructor accepts two parameters: the value as a doubleand a bit flag which allows you to show counters as rates and/or asper-thread averages:  // sets a simple counter  state.counters "Foo"  = numFoos;  // by the duration of the benchmark
google-benchmark	User-defined counters	 state.counters "FooRate"  = Counter numFoos, benchmark::Counter::kIsRate ;  // be presented divided by the number of threads
google-benchmark	User-defined counters	 state.counters "FooAvg"  = Counter numFoos, benchmark::Counter::kAvgThreads ;  state.counters "FooAvgRate"  = Counter numFoos,benchmark::Counter::kAvgThreadsRate ;When you're compiling in C++11 mode or later you can use std::initializer_list:When using the console reporter, by default, user counters are are printed atthe end after the table, the same way as items_processed
google-benchmark	User-defined counters	This is best for cases in which there are few counters,or where there are only a couple of lines per benchmark
google-benchmark	User-defined counters	Here's an example ofthe default output:passing the flag --benchmark_counters_tabular=true is passed:BM_UserCounter to BM_Factorial
google-benchmark	User-defined counters	This is because BM_Factorial doesnot have the same counter set as BM_UserCounter.
google-benchmark	Exiting Benchmarks in Error	When errors caused by external influences, such as file I/O and networkcommunication, occur within a benchmark theKeepRunning   are skipped
google-benchmark	Exiting Benchmarks in Error	For the ranged-for version of the benchmark loopUsers must explicitly exit the loop, otherwise all iterations will be performed.Users may explicitly return to exit the benchmark immediately.The SkipWithError ..
google-benchmark	Exiting Benchmarks in Error	 function may be used at any point within the benchmark,including before and after the benchmark loop.For example:static void BM_test benchmark::State& state  {  auto resource = GetResource  ;  if  !resource.good    {  }  for  state.KeepRunning    {  }static void BM_test_ranged_fo benchmark::State & state  {  state.SkipWithError "test will not be entered" ;  for  auto _ : state  {  }
google-benchmark	Running a subset of the benchmarks	The --benchmark_filter= option can be used to only run the benchmarkswhich match the specified 
google-benchmark	Running a subset of the benchmarks	For example:When the benchmark binary is executed, each benchmark function is run serially.The number of iterations to run is determined dynamically by running thebenchmark a few times and measuring the time taken and ensuring that theultimate result will be statistically stable
google-benchmark	Running a subset of the benchmarks	As such, faster benchmarkfunctions will be run for more iterations than slower benchmark functions, andthe number of iterations is thus reported.In all cases, the number of iterations for which the benchmark is run isgoverned by the amount of time the benchmark takes
google-benchmark	Running a subset of the benchmarks	Concretely, the number ofiterations is at least one, not more than 1e9, until CPU time is greater thanthe minimum time, or the wallclock time is 5x minimum time
google-benchmark	Running a subset of the benchmarks	The minimum time isset per benchmark by calling MinTime on the registered benchmark object.Average timings are then reported over the iterations run
google-benchmark	Running a subset of the benchmarks	If multiplerepetitions are requested using the --benchmark_repetitions command-lineoption, or at registration time, the benchmark function will be run severaltimes and statistical results across these repetitions will also be reported.As well as the per-benchmark entries, a preamble in the report will includeinformation about the machine on which the benchmarks are run.
google-benchmark	Output Formats	The library supports multiple output formats
google-benchmark	Output Formats	Use the--benchmark_format= flag to set the format type
google-benchmark	Output Formats	consoleis the default format.The Console format is intended to be a human readable format
google-benchmark	Output Formats	By defaultthe format generates color output
google-benchmark	Output Formats	Context is output on stderr and thetabular data on stdout
google-benchmark	Output Formats	Example tabular output looks like:The JSON format outputs human readable json split into two top level attributes.The The CSV format outputs comma-separated values
google-benchmark	Output Formats	The 
google-benchmark	Output Files	The library supports writing the output of the benchmark to a file specifiedby --benchmark_out does not suppress the console output.
google-benchmark	Result comparison	It is possible to compare the benchmarking results
google-benchmark	Result comparison	See  Additional Tooling Documentation  docs/tools.md 
google-benchmark	Debug vs Release	By default, benchmark builds as a debug library
google-benchmark	Debug vs Release	You will see a warning in theoutput when this is the case
google-benchmark	Debug vs Release	To build it as a release library instead, use:cache variables, if autodetection fails.If you are using clang, you may need to set LLVMNM_EXECUTABLE and LLVMRANLIB_EXECUTABLE cmake cache variables.
google-benchmark	Compiler Support	Google Benchmark uses C++11 when building the library
google-benchmark	Compiler Support	As such we requirea modern C++ toolchain, both compiler and standard library.The following minimum versions are strongly recommended build the library:Note: Using the library and its headers in C++03 is supported
google-benchmark	Compiler Support	C++11 is onlyrequired to build the library.
google-benchmark	Disable CPU frequency scaling	If you see this error:
google-berrydb	BerryDB 	    **This is not an official Google product.*widely used at Google.This is an experimental implementation of a key-value store.
google-berrydb	Prerequisites	This project uses  CMake  for building and testing
google-berrydb	Prerequisites	CMake isavailable in all popular Linux distributions, as well as in Homebrew This project uses submodules for dependency management.autocomplete-clang and linter-clang with you-complete-me
google-berrydb	Prerequisites	This requires setting up ycmd The following commands build the project.The following command  when executed from build/   re builds the project andruns the tests.The following command builds the project against the Android NDK, which isuseful for benchmarking against ARM processors.components
google-berrydb	Prerequisites	CMakeLists.txt enforces these constraints, and third_party/README.md  ./third_party/README.md  describes the motivationsbehind them.
google-berrydb	Static Analysis	This project is experimenting with Facebook Infer  for static analysis
google-berrydb	Static Analysis	Thefollowing command collects diagnostics.
google-bgu	Bilateral Guided Upsampling	This is not an official Google product.
google-bgu	Overview	This is an implementation of **Bilateral Guided Upsampling*
google-bgu	Code structure	We include a MATLAB implementation of the slow global optimization algorithm and a  Halide  implementation of the fast approximation algorithm
google-bgu	Code structure	We also provide a trivial GLSL shader for the performing slicing on the GPU
google-bgu	Code structure	A full OpenGL demo application in on our roadmap.We thank Elena Adams for the Parrot photo.
google-bgu	Build instructions  MATLAB 	Run MATLAB.
google-bgu	Build instructions  Halide, Linux and MacOS 	Our code should build and run on Windows but we have not tested it.Look at high_res_out.png and high_res_out_gray.png.
google-bgu	License	Apache 2.0.
google-binexport	BinExport   	Copyright 2011-2017 Google Inc.Disclaimer: This is not an official Google product  experimental or otherwise ,it is just code that happens to be owned by Google.
google-binexport	Table of Contents	BinExport is the exporter component of the  BinNaviproject  as well as BinDiff  It is a plugin for thecommercial IDA Pro disassembler and exports disassemblies into the PostgreSQLdatabase format that BinNavi requires.This repository contains the complete source code necessary to build the IDA Proplugin for Linux, macOS and Windows.
google-binexport	Installation	Download the binaries from the release page and copy them into the IDA Proplugins directory
google-binexport	Installation	These are the default paths:| OS| ------| Linux   | /opt/ida-7.0/plugins| macOS   | /Applications/IDA Pro 7.0/idabin/plugins  || Windows | %ProgramFiles x86 %\IDA 7.0\pluginsTo install just for the current user, copy the files into one of thesedirectories instead:| OS| ----------| Linux/macOS | ~/.idapro/plugins| Windows
google-binexport	Usage	The main use case is via  BinNavi  However,BinExport can also be used to export IDA Pro disassembly to files of various In IDA, select Help|About programm..
google-binexport	Usage	Click Addons..
google-binexport	Usage	If installed correctly, the following dialog box appears:
google-binexport	Via the UI	 Open an IDB Select Edit|Plugins|BinExport 10 The following dialog box appears: Select the type of the file to be exportedNote: There is no UI for the database export.
google-binexport	IDC Scripting	The BinExport plugin registers the IDC functions below
google-binexport	IDC Scripting	The function names areversioned in order to support side-by-side installation of different versions i.e
google-binexport	IDC Scripting	BinDiff's BinExport 8 .| IDC Function name| ---------------------| BinExport2Sql10| BinExport2Diff10| BinExport2Text10| BinExport2Statistics10 | Statistics text file | filenameBinExport also supports exporting to a database via the RunPlugin   IDCcase
google-binexport	IDC Scripting	See also the CBinExportImporter class in BinNavi.
google-binexport	IDAPython	The option flags are the same as IDC  listed above .BinExport defines the following plugin options, that can be specified on IDA'scommand line:| Option| -------------------------------| -OExporterHost:| -OExporterPort:| -OExporterUser:| -OExporterPassword:| -OExporterDatabase:| -OExporterSchema:| -OExporterLogFile:| -OExporterAlsoLogToStdErr:TRUE | If specified, also log to standard errorNote that these options must come before any files.
google-binexport	Preparing the build environment	As we support exporting into PostgreSQL databases as well as a Protocol Bufferbased format, there are quite a few dependencies to satisfy:
google-binexport	Prerequisites	The preferred build environment is Mac OS X 10.12 "Sierra"  64-bit Intel  usingXcode 8.Using macOS 10.13 "High Sierra" should also work.After installing the Developer Tools, make sure to install the command-linerequired by the PostgreSQL dependency
google-binexport	Prerequisites	You can install Autotools via Homebrew   recommended  or via MacPorts  Follow the installationinstructions on the respective websites.For Homebrew:of the cloned repository.
google-binexport	IDA SDK	Unzip the contents of the IDA SDK into third_party/idasdk
google-binexport	IDA SDK	Shown commands arefor IDA 7.0:With all prerequisites in place, configure and build BinExport:libraries
google-binexport	IDA SDK	If all went well, the build_mac/binexport-prefix directory shouldcontain two IDA plugin binaries binexport10.dylib and binexport1064.dylibfor use with ida and ida64, respectively.
google-binexport	CMake	Download and install CMake from its  downloadpage  Make sure to select "Add CMake to the systemPATH for all users".
google-binexport	Windows	The preferred build environment is Windows 10  64-bit Intel  using the VisualStudio 2017 compiler and the  Windows SDK for Windows10  The previous VisualStudio 2015 and earlier versions of Windows also work.
google-binexport	Git	Download and install Git from its  downloadpage  Make sure to select the followingoptions: %ProgramFiles%\Git\bin\git.exe have the setup utility add Git to your system path
google-binexport	Git	console window" 
google-binexport	Perl	Download and install ActiveState Perl from its  downloadpage  This should add Perl tothe system path.
google-binexport	Prepare	The following sections assume an open command prompt with the current workingdirectory located at the root of the cloned BinExport repository:Unzip the contents of the IDA SDK into third_party/idasdk
google-binexport	Prepare	Shown commands arefor IDA 7.0, assuming that Git was installed into the default directory first:With all prerequisites in place, configure and build BinExport:This will download and build OpenSSL, Protocol Buffers and the PostgreSQL clientlibraries
google-binexport	Prepare	If all went well, the build_msvc\binexport-prefix directory shouldcontain two IDA plugin binaries binexport10.dll and binexport1064.dll for usewith ida.exe and ida64.exe, respectively.
google-binnavi	BinNavi   	Copyright 2011-2016 Google Inc.
google-binnavi	Introduction	BinNavi is a binary analysis IDE navigate, edit, and annotate control-flow-graphs of disassembled code, do thesame for the callgraph of the executable, collect and combine execution traces,and generally keep track of analysis results among a group of analysts.
google-binnavi	Complications from a third-party dependency	BinNavi uses a commercial third-party graph visualisation library  yFiles  fordisplaying and laying out graphs
google-binnavi	Complications from a third-party dependency	This library is immensely powerful, and noteasily replaceable.In order to perform direct development using yFiles, you need a developerlicense for it
google-binnavi	Complications from a third-party dependency	At the same time, we want the community to be able to contribute toBinNavi without needing a commercial yFiles license
google-binnavi	Complications from a third-party dependency	In order to do this andconform to the yFiles license, all interfaces to yFiles need to be properlyIn order to achieve this, we did the following:1  BinNavi and all the libraries have been split into two: The parts of theproject that directly depend on yFiles were split into subpackages calledsubpackages or add code in BinNavi and do not have a yFiles license, you can freely do pretty much  whatever you want in the non-yfileswrap packages put the lib/yfileswrap-obfuscated.jar into your classpath to test and seethe results.If you wish to make changes to the yfileswrap subdirectories, please be awarethat you will need a valid yFiles license to the BinNavi project has to honor their license agreement
google-binnavi	Complications from a third-party dependency	This means thatyou can't simply expose their inner APIs under different names etc.We will enforce this BinNavi with the yFiles dependency, and we will make sure that any code we pullin respects the yFiles license.
google-binnavi	Note for maintainers/yFiles license holders	To rebuild the yFiles wrapper library, first copy third_party/java/yfiles
google-binnavi	Note for maintainers/yFiles license holders	Then rebuild with:
google-binnavi	Building BinNavi from scratch	BinNavi uses Maven for its dependency management, but not for the actual buildyet
google-binnavi	Building BinNavi from scratch	To build from scratch use these commands:
google-binnavi	Running BinNavi for the first time	Please be aware that BinNavi makes use of a central PostgreSQL database forstoring disassemblies/comments/traces running somewhere accessible to you
google-binnavi	Running BinNavi for the first time	You can launch BinNavi as follows:*Note: HiDPI displays may not scale properly with Java Use Java 9 if this is an issue for you.*
google-binnavi	Importing the project into Eclipse	Loading the code into Eclipse for further development requires a little bit ofInstall the dependencies  as described above  and make sure you have aCreate a new "Java Project From Existing Ant Buildfile" and use the file build.xmlSelect the "javac" task found in target "build-binnavi-jar"Open the "Project Properties" dialog and choose "Java build Path" showing the "Source" tab.Remove all but one source folder and edit it to have the following properties:Go to "Run->Run As", select "Java Application" and then search for CMain.You should be ready to go from here.
google-binnavi	Exporting disassemblies from IDA	As part of this project, we are distributing an IDA Pro plugin that exportsdisassemblies from IDA into the PostgreSQL database format that BinNavirequires
google-binnavi	Exporting disassemblies from IDA	When running BinNavi, simply configure the right path for IDA,click on the "install plugin" button if necessary -import disassemblies.
google-binnavi	Using other disassemblers than IDA	Right now, we only have the IDA export plugin that someone will help us build export functionality for other disassemblersin the near future.
google-binnavi	Building BinNavi with Gradle	*Please note that at current the Maven build is the authorative build system for BinNavi
google-binnavi	Building BinNavi with Gradle	Gradle is purely experimental and is likely to change.*You can build BinNavi with gradle by running the following:On Linux / OS X:  On Windows:  ./gradlew.bat clean jarThis will produce the jar in the project route under build/libs/
google-binnavi	Loading the project into Eclipse with Gradle	On Linux / OS X:  On Windows:  ./gradlew.bat eclipseAs part of the project creation process it will download the dependencies
google-binnavi	Loading the project into Eclipse with Gradle	Once completedo the following to load into Eclipse:Open Eclipse.File > Import..
google-binnavi	Loading the project into Eclipse with Gradle	from menu bar.From the window that appears select General > Existing Projects into Workspace.Ensure the "Select root directory" radio button is selected.Click Browse..
google-binnavi	Loading the project into Eclipse with Gradle	and navigate to the project directory
google-binnavi	Loading the project into Eclipse with Gradle	The projects area should now have "binnavi" and a tick next to it.Press Finish.You Eclipse workspace is now setup and complete for BinNavi
google-binnavi	Loading the project into IntelliJ with Gradle	On Linux / OS X:  On Windows:  ./gradlew.bat ideaAs part of the project creation process it will download the dependencies
google-binnavi	Loading the project into IntelliJ with Gradle	Once completedo the following to load into IntelliJ:Open IntelliJ.Select "Open" from main window.Navigate to the project folder and should see the IntelliJ icon
google-binnavi	Loading the project into IntelliJ with Gradle	This signifies its a project.Press Ok and wait for it to import and load
google-binnavi	Loading the project into IntelliJ with Gradle	IntelliJ might not recognise it as a gradle project
google-binnavi	Loading the project into IntelliJ with Gradle	Select enable from the popup window and use local gradle
google-binnavi	Loading the project into IntelliJ with Gradle	Your IntelliJ environment is now setup and complete for IntelliJ.
google-bitutils	bitutils	This is a collection of scripts which make working with binary numbers a bit
google-bloaty	Bloaty McBloatface: a size profiler for binaries	  Ever wondered what's making your binary big?  BloatyMcBloatface will show you a size profile of the binary soyou can understand what's taking up space inside.Bloaty works on binaries, shared objects, object files, andstatic libraries  .a files 
google-bloaty	Bloaty McBloatface: a size profiler for binaries	 The following file formatsare supported:in adding support for them  I may implement these myself butwould also be happy to get contributions! 
google-bloaty	Building Bloaty	Bloaty uses CMake to build
google-bloaty	Building Bloaty	 All dependencies are included as Git submodules.To build, simply run:Run it directly on a binary target
google-bloaty	Building Bloaty	 For example, run it on itself.will take when it is loaded into memory
google-bloaty	Building Bloaty	 The "FILE SIZE"column tells you about how much space the binary is takingon disk
google-bloaty	Building Bloaty	 These two can be very different from each other:   zero-initialized data .The default breakdown in Bloaty is by sections, but manyother ways of slicing the binary are supported such assymbols and segments
google-bloaty	Building Bloaty	 If you compiled with debug info, youcan even break down by compile units and inlines!Bloaty McBloatface: a size profiler for binaries.USAGE: bloaty  OPTION ..
google-bloaty	Building Bloaty	FILE..
google-bloaty	Building Bloaty	 -  --tsv  -c FILE  -d SOURCE,SOURCE   Comma-separated list of sources to scan
google-bloaty	Building Bloaty	 --debug-file=FILE  Use this file for debug symbols and/or symbol table
google-bloaty	Building Bloaty	 -C MODE  --demangle=MODE  --disassemble=FUNCTION  -n NUM  -w  --help  --list-sourcesOptions for debugging Bloaty:  --debug-fileoff=OFF  -v
google-bloaty	Size Diffs	You can use Bloaty to see how the size of a binary changed.On the command-line, pass -- followed by the files youwant to use as the diff base.For example, here is a size diff between a couple different versionsof Bloaty, showing how it grew when I added some features.its previous size
google-bloaty	Size Diffs	 Most sections grew, but one section atthe bottom  .debug_str  shrank
google-bloaty	Size Diffs	 The "TOTAL" line showshow much the size changed overall.
google-bloaty	Hierarchical Profiles	Bloaty supports breaking the binary down in lots ofdifferent ways
google-bloaty	Hierarchical Profiles	 You can combine multiple data sources intoa single hierarchical profile
google-bloaty	Hierarchical Profiles	 For example, we can use thesegments and sections data sources in a single report:values are grouped into an  Other  bin
google-bloaty	Hierarchical Profiles	 Use -n to override this setting
google-bloaty	Hierarchical Profiles	 If you pass -n 0, all datawill be output without collapsing anything into  Other .
google-bloaty	Debugging Stripped Binaries	Bloaty supports reading debuginfo/symbols from separatebinaries
google-bloaty	Debugging Stripped Binaries	 This lets you profile a stripped binary, even fordata sources like "compileunits" or "symbols" that requirethis extra information.Bloaty uses build IDs to verify that the binary and thedebug file match
google-bloaty	Debugging Stripped Binaries	 Otherwise the results would be nonsense this kind of mismatch might sound unlikely but it's a veryeasy mistake to make, and one that I made several times evenas Bloaty's author! .If your binary has a build ID, then using separate debugfiles is as simple as:
google-bloaty	ELF	For ELF, make sure you are compiling with build IDs enabled.With gcc this happens automatically, but  Clang decided notto make this the default, since it makes the linkslower For Clang add -Wl,--build-id to your link line
google-bloaty	ELF	  If youwant a slightly faster link and don't care aboutreproducibility, you can use -Wl,--build-id=uuid instead .Bloaty does not currently support the GNU debuglink orlooking up debug files by build ID,  which are the methodsGDB uses to find debugfiles If there are use cases where Bloaty's --debug-file optionwon't work, we can reconsider implementing these.
google-bloaty	Mach-O	Mach-O files always have build IDs  as far as I can tell ,so no special configuration is needed to make sure you getMach-O puts debug information in separate files which youcan create with dsymutil:Any options that you can specify on the command-line, youcan put into a configuration file instead
google-bloaty	Mach-O	 Then use can use-c FILE to load those options from the config file
google-bloaty	Mach-O	 Also,a few features are only available with configuration filesand cannot be specify on the command-line.The configuration file is a in Protocol Buffers text format.The schema is the Options message in src/bloaty.proto  src/bloaty.proto .The two most useful cases for configuration files are:You have too many input files to put on the command-line.For custom data sources, it can be very useful to put
google-bloaty	Data Sources	Bloaty has many data sources built in
google-bloaty	Data Sources	 These all providedifferent ways of looking at the binary
google-bloaty	Data Sources	 You can alsocreate your own data sources by applying regexes to thebuilt-in data sources  see "Custom Data Sources" below .While Bloaty works on binaries, shared objects, objectfiles, and static libraries  .a files , some of the datasources don't work on object files
google-bloaty	Data Sources	 This applies especiallyto data sources that read debug info.
google-bloaty	Segments	Segments are what the run-time loader uses to determine whatparts of the binary need to be loaded/mapped into memory.There are usually just a few segments: one for each set ofmmap   permissions required:Object files and static libraries don't have segments.However we fake it by grouping sections by their flags.This gives us a break-down sort of like real segments.Sections give us a bit more granular look into the binary.If we want to find the symbol table, the unwind information,or the debug information, each kind of information lives inits own section
google-bloaty	Segments	 Bloaty's default output is sections.Symbols come from the symbol table, and represent individualfunctions or variables.or --demangle=MODE flag
google-bloaty	Segments	 You can also specify thedemangling mode explicitly in the -d switch
google-bloaty	Segments	 We havethree different demangling modes:  are omitted
google-bloaty	Segments	 For example:  bloaty::dwarf::FormReader<>::GetFunctionForForm<>  
google-bloaty	Segments	 This is the default.One very handy thing about -C short  the default  is thatit groups all template instantiations together, regardlessof their parameters
google-bloaty	Segments	 You can use this to determine how muchcode size you are paying by doing multiple instantiations oftemplates
google-bloaty	Segments	 Try bloaty -d shortsymbols,fullsymbols.
google-bloaty	Input Files	When you pass multiple files to Bloaty, the inputfilessource will let you break it down by input file:When you are running Bloaty on a .a file, the armemberssource will let you break it down by .o file inside thefiles, but it won't be very useful since it will always justresolve to the input file  the .a file .
google-bloaty	Compile Units	Using debug information, we can tell what compile unit  andcorresponding source file  each bit of the binary came from.There are a couple different places in DWARF we can look forthis information; currently we mainly use the.debug_aranges section
google-bloaty	Compile Units	 It's not perfect and sometimesyou'll see some of the binary show up as  None  if it'snot mentioned in aranges  improving this is a TODO 
google-bloaty	Compile Units	 But itcan tell us a lot.The DWARF debugging information also contains "line info"information that understands inlining
google-bloaty	Compile Units	 So within afunction, it will know which instructions came from aninlined function from a header file
google-bloaty	Compile Units	 This is theinformation the debugger uses to point at a specific sourceline as you're tracing through a program.Sometimes you want to munge the labels from an existing datasource
google-bloaty	Compile Units	 For example, when we use "compileunits" on Bloatyitself, we see files from all our dependencies mixedfrom, we can write a custom data source
google-bloaty	Compile Units	 It specifies thebase data source and a set of regexes to apply to it
google-bloaty	Compile Units	 Theregexes are tried in order, and the first matching regexwill cause the entire label to be rewritten to thereplacement text
google-bloaty	Compile Units	 Regexes follow  RE2syntax  and thereplacement can refer to capture groups.custom_data_source: {  name: "bloaty_package"  base_data_source: "compileunits"  }  rewrite: {  }Then use the data source like so:bloaty_package source with the original compileunitsHere are some tentative plans for future features.
google-bloaty	Understanding Symbol References	If we can analyze references between symbols, this wouldenable a lot of features:  -fdata-sections -Wl,-gc-sections 
google-bloaty	Understanding Symbol References	 binary in this way.
google-blockly-devtools	Blockly Developer Tools	This is the home of Google's Blockly Developer Tools.Find out more at the develop page  on GitHub  or on the developer forum Production version is stored here   source Want to contribute? Great! First, read our guidelines for contributors 
google-blockly-devtools	Install node and NW.js	In order to properly run and test Blockly's devtools, install node.js  and NW.js  on your computer.Instructions for installation can be found on the linked sites.
google-blockly-devtools	Install Devtools	In your devtools directory runFind the relative path to nwjs/nw that you installed onto your computer.Run the following command from the devtools repo's directory.
google-blockly-devtools	Closure dependency error	If you get an error about "closure" upon loading the app, it probably means theblockly-devtools/closure-library/ directory has not been set up.Try running:Alternatively, install the  closure-library into that directory
google-blockly-devtools	Closure dependency error	If you are working with the web library, you may prefer to share a localcopy via a  symlink   i.e., ln -s path/to/closure-library .We are currently working on removing this dependency, but this will fix the issue until then.
google-blockly-ios	Blockly for iOS	 Blockly  1  is a library for building drag-and-drop visual editors forJavaScript, Python, Lua, and several other programming languages.Blockly for iOS is similar to its web counterpart in terms of API, but is:Here is a demo of using Blockly for iOS to program a "turtle":
google-blockly-ios	Features	Blockly for iOS includes:all three platforms to support cross-platform development.
google-blockly-ios	Requirements	Supports devices running **iOS 8.0 or above**.
google-blockly-ios	Get Started	To get started using Blockly for iOS, follow  this guide  4 .To run through an exercise in creating an iOS app with Blockly, see our  codelab  10 .
google-blockly-ios	API Reference	For complete API documentation, visit our  API Reference Page  5 .
google-blockly-ios	License	Google is proud to offer Blockly for iOS for free and open sourceunder the  Apache License, version 2.0  6 .
google-blockly-ios	Community	Blockly has an active  developer forum  7 
google-blockly-ios	Community	Please drop by and say hello
google-blockly-ios	Community	Show usyour prototypes early; collectively we have a lot of experience and can offerhints which will save you time.
google-blockly-ios	Registration	Help us focus our development efforts by telling us  what you are doing withBlockly  8 
google-blockly-ios	Registration	The questionnaire only takes a few minutes and will help us bettersupport the Blockly community.
google-blockly-ios	Contributing	Want to contribute? Great! First, read  our guidelines for contributors  9 
google-blockly-ios	Contributing	1 :  "Blockly documentation" 2 :  "Blockly for Web repo on GitHub" 3 :  "Blockly for Android repo on GitHub" 4 :  "Blockly for iOS developer tutorial" 5 :  "Blockly for iOS API Reference Documentation" 6 :  "Apache open source license, version 2.0" 7 :  "Blockly developer forum" 8 :  "Blockly developer registration form" 9 :  "Contributor guidelines" 10 : 
google-blockly	Blockly     	Google's Blockly is a web-based, visual programming editor
google-blockly	Blockly     	 Users can dragblocks together to build programs
google-blockly	Blockly     	 All code is free and open source.**The project page is !  Blockly has an active  developer forum  Please drop by and say hello
google-blockly	Blockly     	Show us your prototypes early; collectively we have a lot of experience and can offer hints which will save you time.Help us focus our development efforts by telling us  what you are doing withBlockly  The questionnaire only takesa few minutes and will help us better support the Blockly community.Want to contribute? Great! First, read  our guidelines for contributors 
google-blue-green-deployment-controller	Blue-Green Deployment controller	**This is not an official Google product**This repository implements a simple blue-green deployment controller based on  kubebuilder  framework.The controller maintains 2 ReplicaSets  blue and green  all the time, alternating between the colors for new rollouts.
google-blue-green-deployment-controller	Running Locally	3 terminals are needed to run the controller locally  one for running local cluster, another for running the controller, and last one for interacting with the controller .Following step-by-step commands assume downloaded release files have been extracted to a directory named bgd
google-blue-green-deployment-controller	navigate to "bgd" directory	cd //bgd
google-blue-green-deployment-controller	compile the codes	GOBIN=$ pwd /bin go install //bgd/cmd/controller-manager
google-blue-green-deployment-controller	run the controller	bin/controller-manager --kubeconfig /var/run/kubernetes/admin.kubeconfig
google-blue-green-deployment-controller	third terminal ###	kubectl edit bluegreendeployment blue-green-deployment
google-blue-green-deployment-controller	export kubeconfig	export KUBECONFIG=/var/run/kubernetes/admin.kubeconfig
google-blue-green-deployment-controller	create BlueGreenDeployment object	kubectl create -f hack/sample/bluegreendeployment.yaml 
google-blue-green-deployment-controller	check ReplicaSets, pods, and service created through the custom resource	kubectl get allWhen the BlueGreenDeployment  BGD  object is created, the controller creates 2 ReplicaSets based on pod spec of the BGD object
google-blue-green-deployment-controller	check ReplicaSets, pods, and service created through the custom resource	Blue RS is active  has specified number of available pods  while green RS is inactive  0 available pods 
google-blue-green-deployment-controller	check ReplicaSets, pods, and service created through the custom resource	The controller also creates a service pointing to the active blue RS.
google-blue-green-deployment-controller	Details	The controller runs an infinite loop to check pod spec difference between the active RS and BGD object.If there is a discrepancy, the controller checks whether inactive RS has matching pod spec.If it is a match, the controller changes service to point to the inactive RS and makes the active RS inactive.If it is not a match, the controller deletes the inactive RS, creates a new RS, and waits for all pods of the new RS to become available.After the new RS becomes available, the controller points the service to the new RS and makes the active RS inactive.You can edit the BGD object to roll out new deployment versions:
google-blue-green-deployment-controller	Cleanup	When the controller is terminated, all created resources will stay intact
google-blue-green-deployment-controller	Cleanup	When the controller is rebooted, it will pick up the resources
google-blue-green-deployment-controller	Cleanup	If you want the resources to be cleaned up after terminating the controller, you have to delete them manually.You can clean up the CRD with:CRD deletion cleans up the CRD, bluegreendeployment custom resource, and ReplicaSets.You can also clean up the bluegreendeployment custom resource with:Custom resource deletion cleans up the custom resource and ReplicaSets.For now, you have to manually delete the bgd-svc service.
google-bluesky-watchface	Blue Sky	! Screenshot  screenshot.png Blue Sky is a watchface that shows the Sun as an hour hand against the bluesky
google-bluesky-watchface	Blue Sky	 Calendar events are displayed as buildings in a city's skyline around a12 or 24 hour face
google-bluesky-watchface	Blue Sky	 Shorter events resemble tall towers while longer eventslook more like wide warehouses
google-bluesky-watchface	Blue Sky	 While Pebble's built in timeline feature makesit easy to find out more about these events, a companion app is required to getthe same information into the watch face itself
google-bluesky-watchface	Blue Sky	 Only Android is supported.Before submitting a pull request, please review CONTRIBUTING.md  CONTRIBUTING.md .Licensed under Apache 2.0, see  LICENSE  LICENSE .This is not an official Google product.
google-bluesky-watchface	Installation	Since this app is not yet available in the  Pebble Appstore   , it can only beinstalled using developer tools.Install the watchface:Install the  Pebble SDK   .Learn how to tell the command line tools where your watch is:  Pebblepebble install Pebble Appstore :  Pebble SDK :  Pebble Tools : Install the Android companion app:Install the  Android SDK   .Set the ./gradlew installDebugLaunch the companion app
google-bluesky-watchface	Installation	 Until a newly installed app is launched for the Android SDK :  Android Pebble App : 
google-bluesky-watchface	To Do	The main task right now is to fix the flow of communication
google-bluesky-watchface	To Do	 It's been drivenby Pebble-side logic, but should be driven by the device with the largerSee  doc/faults.md  doc/faults.md  for more details.Once the above is complete, it'll be time to fix up the user interface
google-bluesky-watchface	To Do	 date.Finally, a bit more work can be done to polish things up and publish this foranyone to use.
google-boardgame.io	Installation	See  changelog  docs/CHANGELOG.md .
google-boardgame.io	Contributing	See the contributing  guidelines  CONTRIBUTING.md 
google-boardgame.io	Contributing	Also take a look at the  roadmap  docs/roadmap.md to find things that you could contribute to.
google-boardgame.io	Disclaimer	This is not an official Google product
google-boardgame.io	Disclaimer	It's a Googler'shobby project that's supported by contributions from the
google-bochspwn-reloaded	Bochspwn Reloaded	Bochspwn Reloaded is an instrumentation module for the  Bochs IA-32 emulator  similar to the original  Bochspwn  project from It performs taint tracking of the kernel address space of the guest operating systems, to detect the disclosure of uninitialized kernel stack/heap memory to user-mode and other data sinks
google-bochspwn-reloaded	Bochspwn Reloaded	It helped us identify over  70  bugs in the Windows kernel, and more than  10  lesser bugs in Linux in 2017 and early The tool was discussed at the  REcon Montreal   Black Hat USA  and  INFILTRATE  conferences, as well as in the    Detecting Kernel Memory Disclosure with x86 Emulation and Taint Tracking  white paper
google-bochspwn-reloaded	Bochspwn Reloaded	The paper includes a comprehensive description of the general kernel infoleak bug class, as well as an in-depth study of Bochspwn Reloaded and its inner workings
google-bochspwn-reloaded	Bochspwn Reloaded	We highly recommend the read before diving right into the source code, as it may answer many potential questions that may arise while experimenting with the tool
google-bochspwn-reloaded	Bochspwn Reloaded	Specifically, Chapter 3 covers the fundamental ideas behind it and the implementation details of the software.
google-bochspwn-reloaded	Instrumentation types	The repository contains four directories, each comprising a separate Bochs instrumentation module:
google-bochspwn-reloaded	Building	The steps required to cross-compile Bochspwn Reloaded on Linux to run on Windows are enumerated below
google-bochspwn-reloaded	Building	For additional reference, you may find the  Bochspwn documentation  useful.Install the This should result in the creation of a 64-bit PE file named bochs, which can be then copied to a Windows host and run from there:In order to use the newly compiled Bochs emulator on your Windows host, perform the following steps:Download and install Bochs for Windows, which will supply parts of the executive environment such as ROM code not being built into the main executable.Create a bochsrc.txt Bochs configuration file, or modify an existing one.Create a raw disk image with the tested guest operating system, preferably by first installing the OS in a normal virtual machine such as VirtualBox, and then converting a .vdi or other file into the raw format.Extract all kernel drivers from the guest system, and save them on the host machine
google-bochspwn-reloaded	Building	In case of Windows, download the corresponding .pdb files for each of them from the  Microsoft Symbol Server  This is needed to symbolize stack traces in the output log, and to correctly traverse call stacks on 64-bit builds of Windows.Create a Bochspwn configuration INI file, or adjust an existing one to your needs
google-bochspwn-reloaded	Building	For each of the four instrumentation modules, an example configuration file is provided in this repository.If you are testing Windows and intend to attach a kernel debugger to the emulated system, install  WinDbg  on your host, configure the guest to boot in debug mode, and redirect a serial port  COM  to a Windows named pipe in the bochsrc.txt configuration file.Create a Bochs start up batch script  e.g
google-bochspwn-reloaded	Building	start.bat , for example:
google-bochspwn-reloaded	Example reports	_Report of the  CVE-2017-8473  bug detected on Windows 7 32-bit:_----------------------------- pid/tid: 000006f0/00000740  { Pool allocation not recognized Allocation origin: 0x90334988  win32k.sys!__SEH_prolog4+00000018 Destination address: 1b9d380Shadow bytes: 00 ff ff ff Guest bytes: 00 bb bb bb Stack trace: #0  0x902df30f  win32k.sys!NtGdiGetRealizationInfo+0000005e  #1  0x8288cdb6  ntoskrnl.exe!KiSystemServicePostCall+00000000 _Report of the  CVE-2018-0894  bug detected on Windows 7 64-bit:_----------------------------- pid/tid: 000001a0/000001a4  {Allocation origin: 0xfffff80002a1110100000000: 00 00 00 00 ff ff ff ff 00 00 00 00 00 00 00 00 ................00000010: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................00000020: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................00000030: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ................00000000: 2e 00 30 00 aa aa aa aa 20 30 a6 00 a0 f8 ff ff ..00000010: 5c 00 44 00 65 00 76 00 69 00 63 00 65 00 5c 00 \.D.e.v.i.c.e.\.00000020: 48 00 61 00 72 00 64 00 64 00 69 00 73 00 6b 00 H.a.r.d.d.i.s.k.00000030: 56 00 6f 00 6c 00 75 00 6d 00 65 00 32 00 00 00 V.o.l.u.m.e.-- #0  0xfffff80002698600  ntoskrnl.exe!memmove+00000000  #1  0xfffff80002a11319  ntoskrnl.exe!IopQueryNameInternal+00000289  #2  0xfffff800028d4426  ntoskrnl.exe!IopQueryName+00000026  #3  0xfffff800028e8fa8  ntoskrnl.exe!ObpQueryNameString+000000b0  #4  0xfffff8000291313b  ntoskrnl.exe!NtQueryVirtualMemory+000005fb  #5  0xfffff800026b9283  ntoskrnl.exe!KiSystemServiceCopyEnd+00000013 _Report of  a bug  in 
google-bochspwn-reloaded	Disclaimer	This is not an official Google product.
google-bochspwn	Bochspwn	Bochspwn is a system-wide instrumentation project designed to log memory accesses performed by operating system kernels and examine them in search of patterns indicating the presence of certain bugs, such as "double fetches"
google-bochspwn	Bochspwn	Information about memory references is obtained by running the guest operating systems within the  Bochs IA-32 emulator  with the custom instrumentation component compiled in
google-bochspwn	Bochspwn	It was written in 2013, and was used to discover over 50 race conditions in the Windows kernel, fixed across numerous security bulletins   MS13-016   MS13-017   MS13-031   MS13-036  For further information, see  Read more  #read-more .
google-bochspwn	Support status	The toolset is not actively maintained, and its source code is released "as is", mostly for reference purposes
google-bochspwn	Support status	It was originally released as *kfetch-toolkitInformation about the address space layout of kernel drivers is stored in a separate file  modules.bin by default , and each driver is referenced by its index in the main log file
google-bochspwn	Support status	This was done to save disk space, by preventing the reduntant information  image names and base addresses  from being needlessly saved for every stack trace item in the log.Information about the presence of an active exception handler in each stack frame was added to the access log protocol buffer, allowing us to detect a number of local Windows DoS vulnerabilities  see examples  1   2   3   4 Information about the value of  PreviousMode  at the time of the memory access in Windows was added to the protocol buffer.The "online" double-fetch detection mode was removed from the code, as it was deemed too slow to be practically useful.Some symbolization-related and other minor bugs were fixed in the code.The instrumentation was also ported to Bochs version 2.6.9, the latest one at the time of this writing.
google-bochspwn	Building and usage	For general instructions, see  DOCUMENTATION.old.md  DOCUMENTATION.old.md .You may wish to use more recent versions of the referenced software  e.g
google-bochspwn	Building and usage	Bochs 2.6.9, libprotobuf 3.4.1 etc
google-bochspwn	Building and usage	, and update the Bochspwn configuration file to account for the 2017 changes
google-bochspwn	Building and usage	When in doubt, please refer to the source code or  contact us  mailto:mjurczyk@google.com  with any questions.
google-bochspwn	Example report	-----------------------------Read no
google-bochspwn	Example report	1: pid/tid/ct: 000000fc/00000100/01d27c3a91e567e6  { previous mode: 1 
google-bochspwn	Read more	In 2017, we implemented a new type of full-system instrumentation on top of the Bochs emulator, named *Bochspwn Reloaded*
google-bochspwn	Read more	The instrumentation performs taint tracking of the guest kernel address space, and detects the disclosure of uninitialized kernel stack/heap memory to user-mode
google-bochspwn	Read more	It helped us identify over  70  bugs in the Windows kernel, and more than  10  lesser bugs in Linux in 2017 and early The tool was discussed at the  REcon Montreal   Black Hat USA  and  INFILTRATE  conferences, as well as in the    Detecting Kernel Memory Disclosure with x86 Emulation and Taint Tracking  whitepaper
google-bochspwn	Read more	It is also an open-source project, and its source code can be found in the  bochspwn-reloaded  repository.
google-bochspwn	Disclaimer	This is not an official Google product.
google-boringssl	BoringSSL	BoringSSL is a fork of OpenSSL that is designed to meet Google's needs.Although BoringSSL is an open source project, it is not intended for generaluse, as OpenSSL is
google-boringssl	BoringSSL	We don't recommend that third parties depend upon it
google-boringssl	BoringSSL	Doingso is likely to be frustrating because there are no guarantees of API or ABIPrograms ship their own copies of BoringSSL when they use it and we updateeverything as needed when deciding to make API changes
google-boringssl	BoringSSL	This allows us tomostly avoid compromises in the name of compatibility
google-boringssl	BoringSSL	It works for us, but itmay not work for you.BoringSSL arose because Google used OpenSSL for many years in various ways and,over time, built up a large number of patches that were maintained whiletracking upstream OpenSSL
google-boringssl	BoringSSL	As Google's product portfolio became more complex,more copies of OpenSSL sprung up and the effort involved in maintaining allthese patches in multiple places was growing steadily.Currently BoringSSL is the SSL library in Chrome/Chromium, Android  but it'snot part of the NDK  and a number of other apps/programs.There are other files in this directory which might be helpful:
google-bottery	A conversational agent prototyping platform by  Kate Compton 	 This is not an official Google product
google-bottery	What is this?	Bottery is a syntax, editor, and simulator for prototyping **generative contextual conversations*Bottery takes inspiration from the ** Tracery  open-source project for generative text  also by katecompton@ in a non-google capacity  and the  Cheap Bots, Done Quick!  bot-hosting platform, as well as open FSM-based storytelling tools like Twine.The goal of Bottery is to help *everyone*, from designers to writers to coders, be able to write simple and engaging  contextual conversational agents, and to test them out in a realistic interactive simulation, mimicking how they'd work on a "real" platform like DialogFlow.Users in Tracery write **grammars**, JSON objects that recursively define how to generate some text, like  the musings of a lost self-driving car  or  outer-space adventures   Tracery grammars are lists of symbol names  like "animal"  and their expansion rules  like "emu, okapi, pangolin" .In Bottery, users write **maps**
google-bottery	What is this?	Each map is composed of four sub-componentsYou can imagine a Bottery map like a finite state machine or a  boardgame board  there are spaces, and connections between the spaces, and rules for how to move between them
google-bottery	What is this?	 The map itself doesn't change or store information during play
google-bottery	What is this?	 Instead, you have a **pointer*An RPG map might use the blackboard to store the number of hit points for the main character, their current weapon and its stats, their gold, and quest progress
google-bottery	What is this?	 A quiz bot might store all of its categories, questions and answers, the players' current points, and which questions it wants to ask next
google-bottery	What is this?	 You can store strings, booleans, numbers, hierarchical objects, and arrays in the blackboard
google-bottery	What is this?	 Storing and retrieving information is done with a JavaScript-like syntax: foo.bar 5  gets the value at the 5th index of object bar in object foo
google-bottery	What is this?	 foo.baz 10  20  = 10 behaves similarly, though unlike JavaScript, if these parameters don't exist, it will create new objects or arrays and fill them rather than throwing an error
google-bottery	What is this?	See parseMapPath in map.js for details.Variables in the blackboard can be accessed from within Tracery with the syntax You have guessed #/guessCount# times.
google-bottery	States	Each state is a node in the Bottery map
google-bottery	States	A state has
google-bottery	Exits	Exits are described by strings in the format: conditions  ->TARGET_NAME  actions to take when taken Syntax for actions and conditions are described below.If all the conditions are true then the exit becomes active
google-bottery	Exits	If there are *noThen there is an arrow  ->  and a target
google-bottery	Exits	 The target is either an **id of a state*The list of actions is in **action syntax*
google-bottery	Condition	Conditions fall under the following categories:Action syntax is similar to condition syntax:When the pointer enters a state, the following things happen:Any onEnter actions are executed.Any **suggestion chips*All available exits  including the exits specified in the state, as well as global exits  are collected.The pointer then waits for state change
google-bottery	Condition	At the moment, state change includes user input, and the passage of time
google-bottery	Condition	If no wait conditions are present, then the bot will wait for user input forever
google-bottery	Condition	When that state change occurs, the pointer will re-evaluate all the conditions on the currently available exits
google-bottery	Condition	If all the conditions on an exit evaluate to true, then that exit becomes active.It is often the case that multiple exits are active at the same time
google-bottery	Condition	For example:If the user types "yes", both exits are active
google-bottery	Condition	The first exit in in the list of active exits is selected
google-bottery	Condition	In this case "yes" ->startGame will be chosen.When the pointer uses an exit, the following occurs:The actions associated with the exit are executed.The pointer moves to the state of that exit and the process begins anew.
google-bottery	Interface Overview	! UI overview  doc_images/bottery_ui.png?raw=true 
google-bottery	Chat	Tab for interacting with the bot
google-bottery	Chat	Occasionally, the player may be offered suggestion chips  e.g., "heads" and "tails"  that can allow the player to interact without entering text.
google-bottery	Controls	Switches between text and speech, and also commands for working with state.If there are errors in the bot’s underlying script, then they will appear here.
google-bottery	Editor	An inline editor for the underlying bot script
google-bottery	Editor	A user can edit the script and see changes without having to edit the underlying .js files
google-bottery	Editor	Changes here will be saved in local storage, so they will only be accessible to the current user.
google-bottery	Blackboard	Displays the current state of the variables known by the bot
google-bottery	Blackboard	These variables can be used to affect conditional behavior  e.g., the mood of the bot , some tracked information  e.g., the number of correct guesses in a quiz , the name of something  e.g., something the player is allowed to name , and much more.This information is typically invisible to an end user interacting with the bot.
google-bottery	Inspector	Presents a view of the bot’s state machine
google-bottery	Inspector	This shows all the states that the bot can traverse through, and within them indicates the commands that are executed by the bot, and the ways to traverse to the next state s 
google-bottery	Inspector	The initial state is always "origin"
google-bottery	Inspector	This view is not interactive, but is a visual representation of the underlying script.
google-bottery	State view	This is a representation of the current state of the bot, and the potential next states, as well as the conditions for enabling these particular transitions.
google-bottery	Viz	Displays the directed connectivity graph of states and exits
google-bottery	Viz	Highlights the current state and any active exit transitions.
google-bottery	Example bot  kitten simulator! 	Now that we have reviewed the underlying concepts and the interface, it is time to build a bot!When you have checked out the git repository, create a new file kittens.js in the bots directory, and add kittens to the list of bots in bots.js.We can start with the following in kittens.js:A note on syntax: The format of this is valid javascript, and is very similar to JSON, but is not valid JSON because of two key differences: trailing commas are permitted, and object keys do not require quotes.
google-bottery	Interactive kitten	A bot isn't very interesting until you can interact with it, so let's add some interactivity:Interacting with this bot, you can see that the **viz*!   doc_images/kittens1.png?raw=true 
google-bottery	Suggestion chips	User interactions can be expedited though the use of suggestion chips
google-bottery	Suggestion chips	These are prompts that are shown to the user when interacting through text.A little more flavor can be added using a Tracery grammar:
google-bottery	Petting the kitten	What are some of the things that a user might want to do with a kitten bot? A natural thing to do would be to pet the kitten
google-bottery	Petting the kitten	Real life kittens are temperamental creatures, and can behave unpredictably
google-bottery	Petting the kitten	We can use the blackboard to store a variable indicating the number of times the kitten wants to be petted, and anything beyond that will cause the kitten to bite the user.!   doc_images/kittens3.png?raw=true 
google-bottery	State flow	Finally, we should add some idle behavior for the kitten when it is not being petted.!   doc_images/kittens4.png?raw=true 
google-bottery	Additional resources.	This concludes the tutorial
google-bottery	Additional resources.	For more examples of types of bots, check out:
google-bottlerocket	BottleRocket RV32IMC Core	This is not an officially supported Google product.
google-bottlerocket	Overview	BottleRocket is a 32-bit, RISC-V microcontroller-class processor core that isbuilt as a customized microarchitecture from components of the Free ChipsProject Rocket core
google-bottlerocket	Overview	It is implemented in the Chisel HDL, and it consists of abasic, 3-stage pipeline with separate instruction and data ARM AMBA AXI4Litebuses
google-bottlerocket	Overview	It has an assortment of features that are designed to support typical useas a control processor for memory-mapped devices.
google-bottlerocket	Features	The BottleRocket core is designed to be as simple as possible to allow for easy,application-specific changes
google-bottlerocket	Features	It uses several key components from Rocket Chip,an open-source RISC-V chip generator framework, including the instructiondecoder and control & status register  CSR  finite state machine
google-bottlerocket	Features	These twocomponents are responsible for implementing the majority of the nuanced featuresof the user ISA and the privileged architecture, respectively
google-bottlerocket	Features	This approach hasseveral key advantages
google-bottlerocket	Features	 the most spec-compliant hardware implementation
google-bottlerocket	Features	 prediction   coherent caches
google-bottlerocket	Features	In order to use the core in a simpler context, creating a  simpler top-level module would be desirable for readability purposes
google-bottlerocket	Features	 have been used in multiple projects to create different core microarchitectures  or pipelines with relatively low effort  BOOM, ZScale   within a single stage
google-bottlerocket	Features	It is well-verified and supports all of the RISC-V  standard extensions in their latest incarnations
google-bottlerocket	Features	 encoding, this universal expander handles all of the RVC extension, aside from  the extra complication of designing fetch logic to handle 16-bit aligned  program counters
google-bottlerocket	Features	 hundred lines of total new Chisel code.
google-bottlerocket	Building and Running	The first step to using BottleRocket is making sure that the work environment isready to support RISC-V development
google-bottlerocket	Building and Running	It is helpful to follow the convention thatthe RISCV environment variable points to the RISC-V toolchain installation.Add the following to your environment using configuration files and/or aClone and install the RV32IMC toolchain
google-bottlerocket	Building and Running	Note, this requires changing theEnter the BottleRocket directory and run the standalone tests
google-bottlerocket	Building and Running	NOTE: you mayThe generated Verilog is in generated-src/BottleRocketCore.v -Try running sbt  “Simple Build Tool,” the most popular build tool for Scala
google-box2d.dart	A Dart 2D physics engine	    *This is a Dart port of Java's Box2D libraries.**The Java Box2D library was originally written by Daniel Murphy  statusFebruary 2015 .*done by Dominic Hamon
google-box2d.dart	A Dart 2D physics engine	We are grateful for his work.__*Not an official Google project*__
google-breadboard	Overview	The Breadboard scripting library is a graph based scripting system designed withgames in mind
google-breadboard	Overview	Complex behvaiors for game entities can be organized byinterlinking nodes representing game actions.
google-breadboard	Dependencies	Breadboard depends on the following library:fplutil::intrusive_list internally to build lists to track various structureswithout doing unnecessary allocations.Additionally, Breadboard ships with some example Modules
google-breadboard	Dependencies	These additionalmodules in the module_library folder depend on the following libraries:your needs
google-breadboard	Dependencies	See the options at the top of the root level CMakeLists.txt to seehow to configure the module library to include just what you need.
google-breadboard	Notes	For applications on Google Play that integrate this tool, usage is tracked.This tracking is done automatically using the embedded version string  seesrc/breadboard/version.cpp , and helps us continue to optimize it
google-breadboard	Notes	 Aside fromconsuming a few extra bytes in your application binary, it shouldn't affect yourapplication at all
google-breadboard	Notes	 We use this information to let us know if Pindrop is usefuland if we should continue to invest in it
google-breadboard	Notes	Since this is open source, you arefree to remove the version string but we would appreciate if you would leave it   CORGI :   FlatBuffers :   Pindrop : 
google-breakpad	Breakpad	Breakpad is a set of client and server components which implement acrash-reporting system
google-breakpad	Breakpad	First,  download depot_tools  Create a new directory for checking out the source code  it must be named Run the fetch tool from depot_tools to download all the source repos
google-breakpad	Breakpad	Build the source
google-breakpad	Breakpad	Optionally, run tests
google-breakpad	Breakpad	Optionally, install the built librariesIf you need to reconfigure your build be sure to run make distclean first.To update an existing checkout to a newer revision, you cangit pull as usual, but then you should run gclient sync to ensure that thedependent repos are up-to-date.
google-breakpad	To request change review	 Follow the steps above to get the source and build it
google-breakpad	To request change review	Make changes
google-breakpad	To request change review	Build and test your changes
google-breakpad	To request change review	Commit your changes to your local repo and upload them to the server
google-breakpad	To request change review	At  you'll find your issue listed;
google-brotli-wheels	Brotli wheels	This repository is used to build and publish brotli " wheels " package
google-brotli-wheels	Brotli wheels	   
google-brotli-wheels	What are wheels?	Wheels are the new standard of Python distribution and are intended to replace eggs
google-brotli	Introduction	Brotli is a generic-purpose lossless compression algorithm that compresses datausing a combination of a modern variant of the LZ77 algorithm, Huffman codingand 2nd order context modeling, with a compression ratio comparable to the bestcurrently available general-purpose compression methods
google-brotli	Introduction	It is similar in speedwith deflate but offers more dense compression.The specification of the Brotli Compressed Data Format is defined in  RFC 7932 Brotli is open-sourced under the MIT License, see the LICENSE file.Brotli mailing list:    
google-brotli	Autotools-style CMake	 configure-cmake  is anautotools-style configure script for CMake-based projects  not supported on Windows .The basic commands to build, test and install brotli are:
google-brotli	Bazel	See  Bazel 
google-brotli	CMake	The basic commands to build and install brotli are:You can use other  CMake  configuration.
google-brotli	Premake5	See  Premake5 
google-brotli	Python	To install the latest release of the Python module, run the following:To install the tip-of-the-tree version, run:See the  Python readme  python/README.md  for more details on installingfrom source, development, and testing.
google-brotli	Benchmarks	> **Disclaimer:*Independent  decoder  implementation by Mark Adler, based entirely on format specification.JavaScript port of brotli  decoder  Could be used directly via npm install brotliHand ported  decoder / encoder  in haxe by Dominik Homberger
google-brotli	Benchmarks	Output source code: JavaScript, PHP, Python, Java and C#7Zip  plugin Dart  native bindings 
google-btls	btls	btls is a TLS and cryptography library for Haskell
google-btls	btls	It’s built on top of BoringSSL  Google’s audited forkof OpenSSL.Although BoringSSL does not have a stable API or ABI, we expect that btls willconverge to a stable API before we release btls version In the meantime, theAPI remains unstable, we do not follow the  Package VersioningPolicy  and we will not post btls on Hackage.**btls is not production ready yet.*undergone review or auditing.
google-btls	Building	btls includes a copy of BoringSSL as a Git submodule
google-btls	Building	Ensure you’ve checked outthat submodule before building
google-btls	Building	If you’ve just cloned btls, git submoduleupdate --init should do it
google-btls	Building	You’ll also need all of BoringSSL’s builddependencies
google-btls	Building	On Debian, runto install them
google-btls	Building	You do not need to build BoringSSL itself; btls’s Setup.hs willtake care of that for you.btls needs GHC, c2hs and a few Haskell libraries to build
google-btls	Building	On Debian,should get you everything you need; you can also runif you want to install everything you can through APT instead of Cabal
google-btls	Building	Onceyou’ve done so, you can build and run the test suite.This is not an official Google product.This product includes cryptographic software written by  EricYoung  mailto:eay@cryptsoft.com .This product includes software written by  TimHudson  mailto:tjh@cryptsoft.com .This product includes software developed by the OpenSSL Project for use in the OpenSSL Toolkit 
google-btree	BTree implementation for Go	This package provides an in-memory B-Tree implementation for Go, useful asan ordered, mutable data structure.The API is based off of the wonderful and is meant to allow btree toact as a drop-in replacement for gollrb trees.See  for documentation.
google-budou	Budou	 ! PyPI version    English uses spacing and hyphenation as cues to allow for beautiful and legible line breaks.Certain CJK languages have none of these, and are notoriously more difficult.Breaks occur randomly, usually in the middle of a word.This is a long standing issue in typography on web, and results in degradation of readability.Budou automatically translates CJK sentences into organized HTML codewith lexical chunks wrapped in non-breaking markup so as to semantically control line breaks.Budou uses  Google Cloud Natural Language API  NL API  to analyze the input sentence, and it concatenates proper words inorder to produce meaningful chunks utilizing part-of-speech  pos  tagging andsyntactic information.Processed chunks are wrapped with inline-block in CSS.
google-budou	Install	Install the library by running pip install budou.Also, a credential json file is needed for authorization to NL API.
google-budou	How to use	Get the parser by completing authentication with a credential file for NL API,which can be downloaded from  Google Cloud Platform by navigating through "API Manager" > "Credentials" > "Create credentials" >"Service account key" > "JSON".import budou
google-budou	Login to Cloud Natural Language API with credentials	parser = budou.authenticate '/path/to/credentials.json' result = parser.parse u'今日も元気です', attributes={'class': 'wordwrap'}, language='ja' print result 'html_code'    # => "今日も元気です"print result 'chunks'  0  'word'    # => "今日も"print result 'chunks'  1  'word'    # => "元気です"Semantic units in the output HTML will not be split at the end of line byconditioning each SPAN tag with display: inline-block in CSS.! Nexus Example Image 
google-budou	Supported Language	Thai, will be added as Cloud Natural Language API adds support.
google-budou	Korean support?	Korean has spaces between chunks, so you can organize line breaking simply byputting word-break: keep-all in your CSS
google-budou	Korean support?	No need for Budou : 
google-budou	Where to use	Budou is designed to be used mostly in eye-catching sentences such as titles andheadings assuming split chunks would be more stood out negatively in larger typography.
google-budou	Caching	Budou supports caching by default in order to save unnecessary requests to NLAPI and make the processing faster
google-budou	Caching	If you want to force refresh the cache,put use_cache=False.In a standard environment, Budou will create a cache file with python pickle  format.In  Google App Engine Python Standard Environment Budou will use  memcache to make the cache available across instances.
google-budou	Entity mode	Default parser only uses results from Syntactic Analysis for parsing, but youcan also utilize Entity Analysis by specifying use_entity=True.Entity Analysis will improve the accuracy of parsing for some phrases,especially proper nouns, so it is recommended to use if your target sentencesinclude a name of an individual person, place, organization etc.Please note that Entity Analysis will results in additional pricing because itrequires additional requests to NL API
google-budou	Entity mode	For more detail about API pricing, pleaserefer to  Pricing | Google Cloud Natural Language API Documentation import budou
google-budou	Login to Google Cloud Natural Language API with credentials	parser = budou.authenticate '/path/to/credentials.json' 
google-budou	Without Entity mode  default 	result = parser.parse u'六本木ヒルズでご飯を食べます。', use_cache=False, language='ja' print result 'html_code'    # => "六本木ヒルズにいます。"
google-budou	With Entity mode	result = parser.parse u'六本木ヒルズでご飯を食べます。', use_cache=False, language='ja', use_entity=True print result 'html_code'    # => "六本木ヒルズにいます。"
google-budou	Maximum chunk length	Some words  マルチスクリーン, インフルエンザ, etc  may stand out in certain formats due to their length
google-budou	Maximum chunk length	For example:
google-budou	Accessibility	Some screen reader software read wrapped chunks one by one when Budou isapplied, which may degrades user experience for those who need audio support.You can attach any attribute to the output chunks to enhance accessibility.For example, you can make screen readers to read undivided sentences bycombining aria-describedby and aria-label attribute in the output.**Input  your-script.py *input_text = u'やりたいことのそばにいる'element_id = 'description'result = parser.parse input_text, {'aria-describedby': element_id}, language='ja' **Template  your-template.tpl ***HTML Output  your-output.html *  やりたい  ことの  そばに  いる
google-budou	Options	parser.parse   method accepts options below in addition to the input text.| Option | Type | Default | Description || --| attributes | dictionary | {'class': 'ww'} | A key-value mapping for attributes of output SPAN tags
google-budou	Options	|| use_cache | boolean | True | Whether to use caching
google-budou	Options	|| language | str | None | Language of the text
google-budou	Options	If None is provided, NL API tries to detect from the input text
google-budou	Options	|| use_entity | boolean | False | Whether to use Entity mode
google-budou	Options	|| max_length | int | None | Maximum chunk length
google-budou	Options	If a chunk is longer than this it will not be wrapped in a SPAN tag
google-budou	Options	|
google-budou	Pricing	Budou is backed up by Google Natural Language API, so cost may be incurred whenusing that API.In other languages including Japanese, the default parser uses *Syntax AnalysisIf you enable Entity mode by specifying use_entity=True, the parser uses bothof *Syntax Analysiswhich will incur additional cost.Google Cloud Natural Language API has free quota to start testing the feature atfree of cost, but please refer to  Google Cloud Natural Language API Pricing Guide for more detailed pricing information.
google-budou	Author	Shuhei IitsukaThis library is authored by a Googler and copyrighted by Google, butis not an official Google product.
google-budou	License	Copyright 2017 Google Inc
google-budou	License	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-build-debian-cloud	Debian bootstrapping script for Amazon machine images and Google Compute Engine images ##	This script bootstraps a vanilla Debian installation to create eitheran Amazon machine image or a Google Compute Engine image.The image contains no latent logfiles no .bash\_history or even the apt package cache
google-build-debian-cloud	Debian bootstrapping script for Amazon machine images and Google Compute Engine images ##	 The machine configuration this script creates has been thoroughly tested.*This script has been tested on Debian squeeze and wheezy.
google-build-debian-cloud	Official AMIs provided by the Debian community and Amazon ##	The Debian community and Amazon have together created AMIs using this bootstrapperand replicated them across AWS regions
google-build-debian-cloud	Official AMIs provided by the Debian community and Amazon ##	The images have been tested for security and bugs.They are available on the  aws marketplace For each new official AMI a commit in this repository will be  tagged marking the version the AMI was bootstrapped with.More information about these images and links to the gzipped volume images can be found on the Debian wiki page  dedicated to those images.
google-build-debian-cloud	Usage ##	The script is started with ./build-debian-cloud.You can choose to either bootstrap a Debian AMI  ./build-debian-cloud ec2 or a Google Compute Engine image  ./build-debian-cloud gce .Both modes have sensible defaults and can be configured with options and plugins.To see a list of options use --help.When creating an AMI the script at least needs to know your AWS credentials.There are no interactive prompts, the bootstrapping can run entirely unattendedfrom start till finish.Some plugins are included in the  plugins directory A list of external plugins is also provided there
google-build-debian-cloud	Usage ##	If none of those scratchyour itch, you can of course  write your own plugin 
google-build-debian-cloud	Bootstrapper  AMI  features ###	  have been replaced with  euca2ools 
google-built_collection.dart	Built Collections for Dart	  
google-built_collection.dart	Introduction	Built Collections are immutable collections using the builder pattern Each of the core SDK collections is split in two: a mutable builder classand an immutable "built" class
google-built_collection.dart	Introduction	Builders are for computation,"built" classes are for safely sharing with no need to copy defensively.Immutable collections work particularly well with immutable values
google-built_collection.dart	Introduction	See built_value You can read more about built_collection on medium 
google-built_collection.dart	Design	Built Collections:
google-built_collection.dart	A note about strong mode	Please note that from version 1.1.0 built_collection must be used inconjunction with strong mode to get all the type guarantees
google-built_collection.dart	A note about strong mode	That is, your project must have no warnings orerrors when analyzed with the strong mode analyzer
google-built_collection.dart	A note about strong mode	This allows some runtimechecks to be skipped because the equivalent check can be done statically.
google-built_collection.dart	Recommended Style	A project can benefit greatly from using Built Collections throughout.Methods that will not mutate a collection can accept the "built" version,making it clear that no mutation will happen and completely avoidingthe need for defensive copying.For code that is public to other projects or teams not usingBuilt Collections, prefer to accept Iterable where possible
google-built_collection.dart	Recommended Style	That wayyour code is compatible with SDK collections, Built Collections and anyother collection implementation that builds on Iterable.It's okay to accept BuiltMap.toMap and BuiltSetMultimap.toMap.
google-built_collection.dart	Built Collections are Immutable	Built Collections do not offer any methods that modify the collection
google-built_collection.dart	Built Collections are Immutable	Inorder to make changes, first call toBuilder to get a mutable builder.In particular, Built Collections do not implement or extend their mutablecounterparts
google-built_collection.dart	Built Collections are Immutable	BuiltSetMultimap share no interface with the SDK collections.Built Collections can contain mutable elements
google-built_collection.dart	Built Collections are Immutable	However, this use is notrecommended, as mutations to the elements will break comparison and
google-built_collection.dart	Built Collections are Comparable	Core SDK collections do not offer equality checks by default.Built Collections do a deep comparison against other Built Collectionsof the same type, only
google-built_collection.dart	Built Collections are Comparable	Hashing is used to make repeated comparisons fast.
google-built_collection.dart	Built Collections are Hashable	Core SDK collections do not compute a deep hashCode.Built Collections do compute, and cache, a deep hashCode
google-built_collection.dart	Built Collections are Hashable	That means theycan be stored inside collections that need hashing, such as hash sets andhash maps
google-built_collection.dart	Built Collections are Hashable	They also use the cached hash code to speed up repeated
google-built_collection.dart	Built Collections Reject Nulls	A null in a collection is usually a bug, so Built Collections and theirbuilders throw if given a null element, key or value.
google-built_collection.dart	Built Collections Require Generic Type Parameters	A List is error-prone because it can be assigned to a List ofany type without warning
google-built_collection.dart	Built Collections Require Generic Type Parameters	So, all Built Collections must be created withexplicit element, key or value types.
google-built_collection.dart	Built Collections Reject Wrong-type Elements, Keys and Values	Collections that happen to contain elements, keys or values that are not ofthe right type can lead to difficult-to-find bugs
google-built_collection.dart	Built Collections Reject Wrong-type Elements, Keys and Values	So, all BuiltCollections and their builders are aggressive about validating types, evenwith checked mode disabled.
google-built_collection.dart	Built Collections Avoid Copying Unnecessarily	Built Collections and their builder and helper types collaborate to avoidcopying unless it's necessary.In particular, BuiltSet.toSet, BuiltMap.toMap and BuiltSetMultimap.toMap do not makea copy, but return a copy-on-write wrapper
google-built_collection.dart	Built Collections Avoid Copying Unnecessarily	So, Built Collections can beefficiently and easily used with code that needs core SDK collections butdoes not mutate them.When you want to provide a collection that explicitly _throws_ when amutation is attempted, use BuiltListMultimap.asMap, BuiltSet.asSet, BuiltSetMultimap.asMapand BuiltMap.asMap.
google-built_collection.dart	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-built_collection.dart	Features and bugs	tracker : 
google-built_json.dart	Built JSON for Dart	Now available from  built_value 
google-built_value.dart	Built Values for Dart	  
google-built_value.dart	Introduction	Built Values provides: built_collection 
google-built_value.dart	Articles	For an end to end example see the chat example  which was demoed  at the Dart Summit The data model used both client and server side, uses value types, enums and serialization fromSimple examples are here Since v5.2.0 codegen is triggered by running pub run build_runner build todo a one-off build or pub run build_runner watch to continuously watch yoursource and update the generated output when it changes
google-built_value.dart	Articles	Note that you need adev dependency on built_value_generator and build_runner
google-built_value.dart	Articles	See the example pubspec.yaml If using Flutter, the equivalent command is flutter packages pub run build_runner build.Alternatively, put your built_value classes in a separate Dart package with no dependencyon Flutter
google-built_value.dart	Articles	You can then use built_value as normal.If using a version before v5.2.0, codegen is triggered via either a build.dart to do a one-off build or a watch.dart to continuously watch your source and update generated output.
google-built_value.dart	Value Types	Value types are, for our purposes, classes that are consideredinterchangeable if their fields have the same values.Common examples include Date, Money and Url
google-built_value.dart	Value Types	Most code introducesits own value types
google-built_value.dart	Value Types	For example, every web app probably has someversion of Account and User.Value types are very commonly sent by RPC and/or stored for laterThe problems that led to the creation of the Built Value library have discussed at great length in the context of AutoValue for Java.In short: creating and maintaining value types by hand requires a lot ofboilerplate
google-built_value.dart	Value Types	It's boring to write, and if you make a mistake, you verylikely create a bug that's hard to track down.Any solution for value types needs to allow them to participate in objectoriented design
google-built_value.dart	Value Types	Date, for example, is the right place for code thatdoes simple date manipulation
google-built_value.dart	Value Types	AutoValue solves the problem for Java with code generation, and Built Values doesthe same for Dart
google-built_value.dart	Value Types	The boilerplate is generated for you, leaving you tospecify which fields you need and to add code for the behaviour of the
google-built_value.dart	Generating boilerplate for Value Types	Value types require a bit of boilerplate in order to connect it to generatedcode
google-built_value.dart	Generating boilerplate for Value Types	Luckily, even this bit of boilerplate can be got automated using codesnippets support in your favourite text editor
google-built_value.dart	Generating boilerplate for Value Types	For example, in IntelliJ youcan use following live template:class name which is something that can't be automated.
google-built_value.dart	Enum Class	Enum Classes provide classes with enum features.Enums are very helpful in modelling the real world: whenever there are asmall fixed set of options, an enum is a natural choice
google-built_value.dart	Enum Class	For an objectoriented design, though, enums need to be classes
google-built_value.dart	Enum Class	Dart falls short here,so Enum Classes provide what's missing!Built Values comes with JSON serialization support which allows you toserialize a complete data model of Built Values, Enum Classes andBuilt Collections
google-built_value.dart	Enum Class	The chat example  shows how easy this makes building a full application with Dart on the server andHere are the major features of the serialization support:It _fully supports object oriented design_: any object model that you can design can be serialized, including full use of generics and interfaces.Some other libraries require concrete types or do not fully support generics.It _allows different object oriented models over the same data_
google-built_value.dart	Enum Class	Forexample, in a client server application, it's likely that the client and serverwant different functionality from their data model
google-built_value.dart	Enum Class	So, they are allowed to havedifferent classes that map to the same data
google-built_value.dart	Enum Class	Most other libraries enforce a 1:1mapping between classes and types on the wire.It _requires well behaved types_
google-built_value.dart	Enum Class	They must be immutable, can useinterface but not concrete inheritance, must have predictable nullability,hashCode, equals and toString
google-built_value.dart	Enum Class	In fact, they must be Enum Classes, BuiltCollections or Built Values
google-built_value.dart	Enum Class	Some other libraries allow badly behaved types tobe serialized.It _supports changes to the data model_
google-built_value.dart	Enum Class	Optional fields can be added orremoved, and fields can be switched from optional to required, allowing yourdata model to evolve without breaking compatbility
google-built_value.dart	Enum Class	Some other libraries breakcompatability on any change to any serializable class.It's _modular_
google-built_value.dart	Enum Class	Each endpoint can choose which classes to know about;for example, you can have multiple clients that each know about only a subset ofthe classes the server knows
google-built_value.dart	Enum Class	Most other libraries are monolithic, requiring allendpoints to know all types.It's _multi language_
google-built_value.dart	Enum Class	Support will be come first for Dart, Java andJava/GWT
google-built_value.dart	Enum Class	Many other libraries support a single language only.It _has first class support for validation_ via Built Values
google-built_value.dart	Enum Class	An important part of a powerful data model is ensuring it's valid, so classes can makeguarantees about what they can do
google-built_value.dart	Enum Class	Other libraries also support validationbut usually in a less prominent way.It's _pluggable_
google-built_value.dart	Enum Class	You can add serializers for your own types, and you can add plugins which run before and after all serializers
google-built_value.dart	Enum Class	This could be used tointeroperate with other tools or to add hand coded high performance serializersfor specific classes
google-built_value.dart	Enum Class	Some other libraries are not so extensible.
google-built_value.dart	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-built_value.dart	Features and bugs	tracker : 
google-bundletool	bundletool	Bundletool is a tool to manipulate Android App Bundles.The **Android App Bundle*distribution stores such as Google Play.Bundletool has a few different responsibilities: g.co/androidappbundle 
google-bundletool	Releases	Latest release:  0.5.0 
google-burst-denoising	Burst Denoising with Kernel Prediction Networks	Ben Mildenhall | Jonathan T
google-burst-denoising	Burst Denoising with Kernel Prediction Networks	Barron | Jiawen Chen | Dillon Sharlet | Ren Ng | Robert CarrollThis is not an official Google product
google-burst-denoising	Burst Denoising with Kernel Prediction Networks	This repository contains code for training models from the paper  Burst Denoising with Kernel Prediction Networks 
google-burst-denoising	Dependencies	This code uses the following external packages:Synthetic training data is generated using the OpenImages dataset, which can be manually downloaded following  these instructions Run the following command to train the kernel prediction network  KPN  burst denoising model:python kpn_train.py --dataset_dir $OPEN_IMAGES_DATASET_DIR --data_dir $REAL_BURST_DATA_DIR
google-butteraugli	butteraugli	> A tool for measuring perceived differences between images
google-butteraugli	Introduction	Butteraugli is a project that estimates the psychovisual similarity of twoimages
google-butteraugli	Introduction	It gives a score for the images that is reliable in the domain of barelynoticeable differences
google-butteraugli	Introduction	Butteraugli not only gives a scalar score, but alsocomputes a spatial map of the level of differences.One of the main motivations for this project is the statistical differences inlocation and density of different color receptors, particularly the low densityof blue cones in the fovea
google-butteraugli	Introduction	Another motivation comes from more accurate modelingof ganglion cells, particularly the frequency space inhibition.
google-butteraugli	Use	Butteraugli can work as a quality metric for lossy image and video compression.On our small test corpus butteraugli performs better than our implementations ofthe reference methods, psnrhsv-m, ssim, and our yuv-color-space variant of ssim.One possible use is to define the quality level setting used in a jpegcompressor, or to compare two or more compression methods at the same level ofpsychovisual differences.Butteraugli is intended to be a research tool more than a practical tool forchoosing compression formats
google-butteraugli	Use	We don't know how well butteraugli performs withmajor deformations -roughly corresponding to jpeg qualities 90 to 
google-butteraugli	Interface	Only a C++ interface is provided
google-butteraugli	Interface	The interface takes two images and outputs amap together with a scalar value defining the difference
google-butteraugli	Interface	The scalar value canbe compared to two reference values that divide the value space into threeexperience classes: 'great', 'acceptable' and 'not acceptable'.
google-butteraugli	Build instructions	Install  Bazel  by following the instructions  Run bazel build -c opt//:butteraugli in the directory that contains this README file to build the command-line utility  #cmdline-tool 
google-butteraugli	Build instructions	If you want to use Butteraugli as alibrary, depend on the //:butteraugli_lib target.Alternatively, you can use the Makefile provided in the butteraugli directory,after ensuring that  libpng  and libjpeg  are installed
google-butteraugli	Build instructions	On some systems you might need to alsoinstall corresponding -dev packages.The code is portable and also compiles on Windows after defining_CRT_SECURE_NO_WARNINGS in the project settings.
google-butteraugli	Command-line utility {#cmdline-tool}	Butteraugli, apart from the library, comes bundled with a comparison tool
google-butteraugli	Command-line utility {#cmdline-tool}	Thecomparison tool supports PNG and JPG images as inputs
google-butteraugli	Command-line utility {#cmdline-tool}	To compare images, run:will be output as a PNM image
google-butteraugli	Command-line utility {#cmdline-tool}	To produce one, run:
google-bzip2-rpc	Serialization	The first core feature for an RPC framework is some kind of serializationmechanism &ndash; a way to convert different kinds of data structures to and fromsequences of bytes, ready for transmission between processes.A serialization mechanism typically includes a number of base types &ndash;integers, characters, booleans, floating point values, strings &ndash; that maponto the base types of the programming language.On top of the base types, various compound types are normally available:The serialization mechanism for an RPC framework may or may not require the useof an explicit **schema**, which describes the valid data structures for aparticular RPC interface
google-bzip2-rpc	Serialization	 For example, to transmit the data for a 3-dimensionalFrameworks with schemas are more complex and require more set-up  to specifythe schema , but are more robust &ndash; messages that don't match the expectedschema can be automatically detected and rejected.
google-bzip2-rpc	Transport	Once a collection of information has been serialized, it needs to betransmittted to the other process involved in the RPC exchange
google-bzip2-rpc	Transport	 This requires atransport mechanism, but the RPC framework may or may not consider this part oftheir remit:
google-bzip2-rpc	RPC Invocation	To be convenient, invoking functionality in a different process needs to be morethan just sending and receiving messages
google-bzip2-rpc	RPC Invocation	 Ideally, it should take a similarform to invoking functionality in the same process, via a function call
google-bzip2-rpc	RPC Invocation	 To dothis, the RPC mechanism needs to bundle up all of the input parameters for aremote function into a **request*from the function invocation
google-bzip2-rpc	RPC Invocation	  As the two processes do not normally share anaddress space, this approach works best with data that is passed by value .
google-bzip2-rpc	Event Model and Threading	Sending and receiving messages between processes requires some sort of eventprocessing system that handles receipt notifications and  possibly  inter-threadscheduling
google-bzip2-rpc	Event Model and Threading	 An RPC framework may include an event processing model, or mayrequire the application to integrate RPC processing into its own existing eventmodel in some way
google-bzip2-rpc	Event Model and Threading	 An RPC framework may also require the use of multiplethreads, or may be written assuming use in a single-threaded manner  and thusneed external synchronization for use in a multi-threaded application .The event model also affects whether it is possible for invocation of remotefunctionality to look identical to invocation of local functionality i.e
google-bzip2-rpc	Event Model and Threading	apparently synchronous .
google-bzip2-rpc	File Descriptor Transfer	For sandboxing mechanisms that restrict access to the local environment e.g
google-bzip2-rpc	File Descriptor Transfer	Capsicum , it is important to know whether the RPC framework allows thetransfer of file descriptors between processes on the same machine; thisallows a remote process to operate on a kernel resource owned by the invoker,even though the remote process cannot open that resource on its own.Any such mechanism relies on the SCM_RIGHTS feature of an underlying UNIXdomain socket transport.
google-bzip2-rpc	Language Support	Some RPC frameworks include support for applications written in differentlanguages, which in turn would allow for different components of a privilegeseparated application to be written in different languages.Note that C and C++ are a special case here; a C-based framework can alwaysbe used by C++ code, and it's often possible to write a C wrapper layer thatallows a C++-based framework to be used
google-bzip2-rpc	Language Support	 However, this does normally stillinvolve a run-time dependency on the libstdc++ C++ standard library.
google-bzip2-rpc	Dependencies	Simpler RPC frameworks are self-contained, and have no additionaldependencies; others impose a requirement that dependent libraries  e.g
google-bzip2-rpc	Dependencies	thelibstdc++ for a C++ framework  are available on the system
google-bzip2-rpc	Dependencies	 The set ofdependencies needed for an application written in C is of particular interest.RPC Framework CandidatesThis section gives an overview of possible candidate RPC frameworks
google-bzip2-rpc	Dependencies	 It doesnot include technologies that are purely serialization mechanisms  e.g
google-bzip2-rpc	Dependencies	ASN.1  withoutany RPC aspects.
google-bzip2-rpc	Hand-Rolled Code	The least common denominator for performing RPC is not to use any framework, butto individually code the mechanisms required.FreeBSD 11.x includes the libnv library created by Pawel Jakub Dawidek, which deals with building andtransferring lists of name-value pairs.D-Bus is a message bus system intended for use in UNIX desktop systems
google-bzip2-rpc	Hand-Rolled Code	 Bydefault, it assumes that applications will communicate via either asystem-wide or session-wide daemon; however, it is possible to set up aprivate point-to-point connection between two processes
google-bzip2-rpc	Hand-Rolled Code	gRPC  was released in 2015 by Google, as a general RPCframework
google-bzip2-rpc	Hand-Rolled Code	 gRPC uses an updated  v3  version of protocol buffers for itsserialization mechanism, but also includes communication libraries for RPCclient and server applications.Note that although gRPC claims to support C  and its core internals are writtenin C , there is no C API for serialization or RPC invocation
google-bzip2-rpc	Hand-Rolled Code	Cap'n Proto  was created for the Sandstorm  project by Kenton Varda  who was one of thecreators of V2 of Google's protocol buffers 
google-bzip2-rpc	Hand-Rolled Code	bzip2  is the example target used to explore thedifferences between different RPC frameworks; this target is chosen because Ben Laurie  has previously manually converted  it to be privilegedseparated in order to apply the Capsicum security framework It is also of a manageable size, without being too trivial.To make bzip2 more suitable for having a remote implementation, we first makea couple of modifications to the library.
google-bzip2-rpc	Modification: FILE	The bzlib API includes a number of entrypoints that take a FILE* argument;however, this is not a good type to be used on an inter-process boundary,because the C library adds buffering and other metadata that cannot be easilymirrored between processes.To cope with this, we add ...OpenFd   entrypoints that are analogous to theexisting ...Open   entrypoints, but which take a file descriptor argumentinstead of a FILE* argument.
google-bzip2-rpc	Modification: Streaming API Entrypoints	As it stands, the bzip2 codebase includes a BZ2_bz..
google-bzip2-rpc	Modification: Streaming API Entrypoints	  functions in libbz2  and a main command-line utility bzip2that uses that API to do compression and decompression
google-bzip2-rpc	Modification: Streaming API Entrypoints	 However, the API isquite low-level, involving reading and writing chunks of data from thecompressed file; it does not include any entrypoints that process an entirefile at once.The compressStream and decompressStream, which loop around using the bzlibentrypoints; these are the entrypoints that are remoted in the manualremoting example for Capsicum mentioned above.Therefore, in order to compare like with like, we add an additional wrapperlayer to the bzlib API, with the following entrypoints:
google-bzip2-rpc	Modification: Annotate API	The process of generating serialization and deserialization code that mapsbetween function parameters and message fields is tedious and time-consumingto do manually
google-bzip2-rpc	Modification: Annotate API	 To allow for the future possibility of a tool to automatethis process, we extend the bzlib.h header file with extra annotations.These annotations give a richer semantics than the base C language allows cf
google-bzip2-rpc	Modification: Annotate API	Microsoft's Security Annotation Language for example:IDL_GENERATE is defined, so a normal build of the library is unaffected.API Remoting StructureAll of the API remoting examples in this repository share a similar baseThis sequence diagram assumes that the second process is already available;that can be accomplished on first use of the API by forking a sub-process thatin turn invokes a new program containing the API driver program:! RPC Process Setup  rpc-setup.png 
google-bzip2-rpc	File Descriptor Inheritance	Not all of the RPC frameworks used support the passing of file descriptorsover their transports
google-bzip2-rpc	File Descriptor Inheritance	 For those that do not  gRPC and Cap'n Proto , wecurrently use a UNIX socket that runs in parallel to the main RPC socket.To send a file descriptor: Note that this mechanism is currently implemented in a naive fashion,with no integration of the parallel socket into the program's event loop
google-bzip2-rpc	File Descriptor Inheritance	----------This is not an official Google product.
google-cabal2bazel	cabal2bazel	A tool to help with fetching Cabal packages from Hackage and importingthem as packages into cabal2bazel
google-cabal2bazel	cabal2bazel	 cabal2bazel --fetch   cabal2bazel --fetch binary  cabal2bazel --fetch binary-0.5.0.2  cabal2bazel --recursive --fetch lensThe process for installing third-party Haskell packages is specified at:and is no substitute for code review
google-cabal2bazel	cabal2bazel	But it will automate the bulk ofchores, including:cabal2bazel attempts to map the dependencies of a Cabal library orexecutable to the 'deps' attribute of the resulting Bazel target.Things that still need manual attention include:NOTE: You will need an appropriate version of 'cabal' to be availableon your path; cabal2bazel uses it for downloading and unpacking packages.NOTE: Sometimes it is necessary to edit the cabal file and re-runcabal2bazel
google-cabal2bazel	cabal2bazel	In such cases rerun cabal2bazel as follows to resume  cabal2bazel --wire-up //third_party/haskell/binary/v0_5_0_2
google-cadvisor	cAdvisor	cAdvisor  Container Advisor  provides container users an understanding of the resource usage and performance characteristics of their running containers
google-cadvisor	cAdvisor	It is a running daemon that collects, aggregates, processes, and exports information about running containers
google-cadvisor	cAdvisor	Specifically, for each container it keeps resource isolation parameters, historical resource usage, histograms of complete historical resource usage and network statistics
google-cadvisor	cAdvisor	This data is exported by container and machine-wide.cAdvisor has native support for  Docker  containers and should support just about any other container type out of the box
google-cadvisor	cAdvisor	We strive for support across the board so feel free to open an issue if that is not the case
google-cadvisor	cAdvisor	cAdvisor's container abstraction is based on  lmctfy  so containers are inherently nested hierarchically.! cAdvisor  logo.png "cAdvisor" 
google-cadvisor	Quick Start: Running cAdvisor in a Docker Container	To quickly tryout cAdvisor on your machine with Docker, we have a Docker image that includes everything you need to get started
google-cadvisor	Quick Start: Running cAdvisor in a Docker Container	You can run a single cAdvisor to monitor the whole machine
google-cadvisor	Quick Start: Running cAdvisor in a Docker Container	Simply run:**Note**: If you're running on CentOS, Fedora, or RHEL  or are using LXC , take a look at our  running instructions  docs/running.md .We have detailed  instructions  docs/running.md#standalone  on running cAdvisor standalone outside of Docker
google-cadvisor	Quick Start: Running cAdvisor in a Docker Container	cAdvisor  running options  docs/runtime_options.md  may also be interesting for advanced usecases
google-cadvisor	Quick Start: Running cAdvisor in a Docker Container	If you want to build your own cAdvisor Docker image, see our  deployment  docs/deploy.md  page.For  Kubernetes  users, cAdvisor can be run as a daemonset
google-cadvisor	Quick Start: Running cAdvisor in a Docker Container	 See the  instructions  deploy/kubernetes  for how to get started, and for how to  kustomize  it to fit your needs.
google-cadvisor	Building and Testing	See the more detailed instructions in the  build page  docs/development/build.md 
google-cadvisor	Building and Testing	This includes instructions for building and deploying the cAdvisor Docker image.
google-cadvisor	Exporting stats	cAdvisor supports exporting stats to various storage plugins
google-cadvisor	Exporting stats	See the  documentation  docs/storage/README.md  for more details and examples.
google-cadvisor	Web UI	cAdvisor exposes a web UI at its port:See the  documentation  docs/web.md  for more details.
google-cadvisor	Remote REST API & Clients	cAdvisor exposes its raw and processed stats via a versioned remote REST API
google-cadvisor	Remote REST API & Clients	See the API's  documentation  docs/api.md  for more information.There is also an official Go client implementation in the  client  client/  directory
google-cadvisor	Remote REST API & Clients	See the  documentation  docs/clients.md  for more information.
google-cadvisor	Roadmap	cAdvisor aims to improve the resource usage and performance characteristics of running containers
google-cadvisor	Roadmap	Today, we gather and expose this information to users
google-cadvisor	Roadmap	In our roadmap:Contributions, questions, and comments are all welcomed and encouraged! cAdvisor developers hang out on  Slack  in the #sig-node channel  get an invitation  here  We also have the  kubernetes-users Google Groups mailing list 
google-caja	Caja	Caja is a tool for making third party HTML, CSS and JavaScript safe to embed in your website
google-caja	Caja	It enables rich interaction between the embedding page and the embedded applications
google-caja	Caja	Caja uses an object-capability security model to allow for a wide range of flexible security policies, so that your website can effectively control what embedded third party code can do with user data.Caja supports most HTML and CSS and the recently standardized "strict mode" JavaScript version of JavaScript -
google-calblink	What is this?	Calblink is a small program to watch your Google Calendar and set a blink 1  USBLED to change colors based on your next meeting
google-calblink	What is this?	The colors it will use are:
google-calblink	What do I need use it?	To use calblink, you need the following: A blink 1  from  ThingM  A place to put the blink 1  where you can see it
google-calblink	What do I need use it?	The latest version of  Go  The calblink code, found in this directory
google-calblink	What do I need use it?	libusb
google-calblink	What do I need use it?	The  go-blink1  page has details
google-calblink	What do I need use it?	A directory to run this in
google-calblink	What do I need use it?	A few go packages, which we'll install later in the Setup section
google-calblink	What do I need use it?	A Google Calendar account
google-calblink	What do I need use it?	A Google Calendar OAuth 2 client ID
google-calblink	What do I need use it?	 We'll discuss getting one in the Setup
google-calblink	How do I set this up?	 Install Go, and plug your blink 1  in somewhere that you can see it
google-calblink	How do I set this up?	Bring up a command-line window, and create the directory you want to run Put calblink.go into the directory you just created
google-calblink	How do I set this up?	Install libusb, if needed
google-calblink	How do I set this up?	If you needed to, and used Homebrew as instructed Install the Google APIs for Go: Install the blink 1  library for Go: Get an OAuth 2 ID as described in step 1 of the  Google Calendar Run the calblink program: go run calblink.go It will request that you go to a URL and give it the token that you getThat's it! It should just run now, and set your blink 1  to change colorOptionally, set up a config file, as below.
google-calblink	What are the configuration options?	First off, run it with the --help option to see what the command-line optionsare
google-calblink	What are the configuration options?	Useful, perhaps, but maybe not what you want to use every time you run it.calblink will look for a file named  by default  conf.json for its configurationoptions
google-calblink	What are the configuration options?	conf.json includes several useful options you can set:
google-caliper	Caliper	Caliper is a tool for measuring Java code performance, primarily focused on
google-caliper	Building	To build the JVM version of Caliper  the only supported version at the moment ,Caliper currently has a number of artifacts related to Android
google-caliper	Building	These are ina transitional state and no easy way to run Caliper benchmarks on Android iscurrently available.If you are interested in building the Android artifacts for any reason, you canthat way, and/or -Dandroid.sdk.version= to specify a version otherthan 25  but note that the build may not work with a version lower than 25 .
google-cameraview	CameraView	*This is a preview release
google-cameraview	CameraView	The API is subject to change.*This is not an official Google product.CameraView aims to help Android developers easily integrate Camera features.Requires API Level The library uses Camera 1 API on API Level 9-20 and Camera2 on 21 and above.| API Level | Camera API | Preview View || 9-13| 14-20| 21-23| 24
google-cameraview	Features	You can see a complete usage in the demo app.
google-cameraview	Contribution	See  CONTRIBUTING.md  /CONTRIBUTING.md .
google-canvas-5-polyfill	Canvas 5 Polyfill	Canvas 5 Polyfill is a Javascript polyfill library to fill in new features for HTML 5Canvas that browsers may not have implemented yet, such as Path2D objects andellipse   on CanvasRenderingContext2D.
google-canvas-5-polyfill	Installation	Canvas 5 Polyfill uses  Bower  to make installation easy:
google-canvas-5-polyfill	Status	Canvas 5 Polyfill adds the following classes and methods to an existing HTMLCanvas implementation if they are missing, if they are not missing the nativeimplementations are used:The polyfill adds the following methods to CanvasRenderingContext2D:It also adds Path2D with the following constructors:Where Path2D has the following methods:
google-canvas-5-polyfill	Caveats	With this polyfill installed, the calls to context.clip path ,context.isPointInPath path, x, y  and context.isPointInStroke path, x, y all affect the current path.When using the polyfill the best approach is to move strictly to usingPath2D objects to describe paths and then use the path enabled callson the context, such as ctx.fill path 
google-canvas-5-polyfill	Caveats	Do not mix and match such calls.
google-cap-library	Common Alerting Protocol Library   	Copyright 2014 Google Inc.The CAP Library is a collection of code and tools to work with public alertingmessages in the  Common Alerting Protocol  format.Namely, a well-tested and easy-to-use Java library that supports to validate the correctness of CAP messages.
google-cap-library	About	The CAP Library is designed to support CAP versions 1.0, 1.1, and 1.There are classes that can parse XML CAP messages as well as easilycreate new messages and write them to XML, JSON,  soon  ASN.1, and  soon  KML.The main data structures are auto-generated from a Google protocolbuffer implementation of the CAP spec in proto/cap.proto
google-cap-library	About	Protocol buffers are Google's language-neutral, platform-neutral, extensible mechanism forserializing structured data The generated classes offer a clean API for creating and manipulatingalert objects
google-cap-library	About	The alert data structures are immutable; they provide onlygetters
google-cap-library	About	 New alerts are constructed via Builder classes
google-cap-library	About	See javatests/com/google/publicalerts/cap/TestUtil.java, for an example.javatests/com/google/publicalerts/cap/EndToEndTest.java provides a goodoverview of how to get started using the library.To learn more about Google protocol buffers, see and
google-cap-library	###Install ant	You can download and install Apache Ant from 
google-capillary	Capillary	This is a library to simplify the sending of end-to-end  E2E  encrypted push messages fromJava-based application servers to Android clients
google-capillary	Capillary	Please check the instructions below and the demo  demo  for more details.
google-capillary	Installation	To add a dependency using Maven:            To add a dependency using Gradle:  dependencies {  }    dependencies {  }  
google-capillary	API docs	To use push messaging services to send messages to connected devices, developers must send themthrough a third party messaging service, such as Firebase Cloud Messaging   FCM .It’s simple to encrypt message contents between the developer and the messaging service using https.Major messaging services, including  FCM  alsoencrypt messages between their servers and client devices.However, messages between the developer server and the user devices are not encryptedend-to-end  E2E :! no e2ee  img/no_e2ee.png E2E encryption can be achieved by generating an asymmetric encryption key pair on the client,registering the public key with the developer messaging service, encrypting outgoing messages withthe public key, and decrypting messages on the client using the private key:! with capillary  img/with_capillary.png Capillary handles these operations for push messaging services used by Android apps
google-capillary	API docs	It includes: KitKat   API level 19 .As a bonus, it also allows developers to require that devices are unlocked before selected messagescan be decrypted
google-capillary	API docs	This includes messages on devices using File-Based Encryption   FBE :encrypted messages are cached in Device Encrypted  DE  storage and message decryption keys arestored in Android keystore  requiring user authentication This allows developers to specify messages with sensitive content to remain encrypted in cached formuntil the user has unlocked and decrypted their device.
google-capillary	Web Push vs RSA-ECDSA	  developers to share code and key storage infrastructure with existing Web Push implementations
google-capillary	Web Push vs RSA-ECDSA	 Web Push protocol is based on the Elliptic-curve Diffie-Hellman  ECDH  key exchange algorithm,  which is highly efficient for performance-constrained devices
google-capillary	Web Push vs RSA-ECDSA	Note that apps  as opposed to  browsers  cannot receive raw Web Push messages through FCM, but Web Push messages can easily be  wrapped in the appropriate FCM JSON by a proxy implementation, allowing you to use the same  infrastructure with minor modifications
google-capillary	Web Push vs RSA-ECDSA	 RSA key stored in keystore meaning that EC private key plaintext is available in user memory  during crypto operations
google-capillary	Web Push vs RSA-ECDSA	 and signs the ciphertext with a developer-generated ECDSA public key  for integrity 
google-capillary	Web Push vs RSA-ECDSA	RSA crypto  operations  encrypt, decrypt  are supported by Android Keystore from SDK versions 18  Jelly Bean   and above, meaning key material is not available outside of the trusted execution environment
google-capillary	Web Push vs RSA-ECDSA	 This means even a sophisticated attacker with access to the device memory cannot access private  key material  for example, to decrypt future messages arriving in Direct Boot mode .
google-capillary	Auth vs NoAuth	Auth bound keys ensures that messages cannot be read by users when their device is locked, meaningsensitive content will not be readable by shoulder-surfers or if the device is lost or stolen.
google-capillary	API Overview	Capillary provides the core crypto functionality required to send  from an application server  andreceive encrypted push messages in Android apps
google-capillary	API Overview	This covers:Because server-side architectures and push messaging use-cases are many and varied, it is notpractical to provide a server-side API to handle all possible push message implementations.Therefore, we have decoupled the crypto functionality above from message transmission andserver-side key storage/retrieval functions
google-capillary	API Overview	We have, however, provided a full-stack implementationthat uses Capillary to send E2E-encrypted push messages from a Java-based server to Android clientsin the  demo application  demo 
google-capillary	API Overview	In summary, you will need to implement the following aspects of thesolution yourself  using the  demo application  demo  and instructions below for guidance whererequired :  the screen .
google-capillary	API Integration	Please follow the following steps to integrate with the Capillary library.
google-capillary	Prerequisites	Before the Capillary library can be used, it must be initialized at runtime as follows:import com.google.capillary.Config;Config.initialize  ;If you are using RSA-ECDSA algorithm, you need to generate an ECDSA public/private key pair and makethe public key available to your Android app  e.g., as a raw resource and private key available to your application server
google-capillary	Prerequisites	Use the  utility program  tools  that we haveprovided to generate such ECDSA key pairs:
google-capillary	Capillary Handler Implementation	The Capillary library uses methods of the  CapillaryHandler  lib-android/src/main/java/com/google/capillary/android/CapillaryHandler.java interface to provide responses, such as public keys, decrypted plaintexts, etc., back to the Androidapp
google-capillary	Capillary Handler Implementation	Therefore, the first step in integrating an Android app with the Capillary library is toimplement the CapillaryHandler  lib-android/src/main/java/com/google/capillary/android/CapillaryHandler.java interface with your app-specific logic to handle the responses mentioned above
google-capillary	Capillary Handler Implementation	You can see howthe Capillary library's  demo Android app  demo/android  implements the CapillaryHandler  lib-android/src/main/java/com/google/capillary/android/CapillaryHandler.java  interfacein  DemoCapillaryHandler  demo/android/src/main/java/com/google/capillary/demo/android/DemoCapillaryHandler.java  class.
google-capillary	Key Generation	Each Capillary key pair is identified by a key pair ID  aka keychain ID , which is an arbitrarystring that is up to you to decide
google-capillary	Key Generation	To generate a key pair:import android.content.Context;import com.google.capillary.android.RsaEcdsaKeyManager;import com.google.capillary.android.WebPushKeyManager;import java.io.InputStream;Context context = ..
google-capillary	Key Generation	// The current app context.String keychainId = ..
google-capillary	Key Generation	// Some identifier for the key pair.boolean isAuth = ..
google-capillary	Key Generation	// Whether the private key usage should be guarded by the device lock.// To generate an RSA-ECDSA key pair.InputStream senderVerificationKey = ..
google-capillary	Key Generation	// The ECDSA public key of the server.RsaEcdsaKeyManager.getInstance context, keychainId, senderVerificationKey .generateKeyPair isAuth ;// To generate a Web Push key pair.WebPushKeyManager.getInstance context, keychainId .generateKeyPair isAuth ;There is also a  generateKeyPairs  lib-android/src/main/java/com/google/capillary/android/KeyManager.java method to generate both Auth and NoAuth keys in a single method call.
google-capillary	Public Key Retrieval	After generating a Capillary key pair, you can retrieve the generated public key in a byte array asjavaimport android.content.Context;import com.google.capillary.android.CapillaryHandler;import com.google.capillary.android.RsaEcdsaKeyManager;import com.google.capillary.android.WebPushKeyManager;import java.io.InputStream;Context context = ..
google-capillary	Public Key Retrieval	// The current app context.String keychainId = ..
google-capillary	Public Key Retrieval	// The identifier for the key pair.boolean isAuth = ..
google-capillary	Public Key Retrieval	// Whether the private key usage is guarded by the device lock.CapillaryHandler handler = ..
google-capillary	Public Key Retrieval	// An implementation of CapillaryHandler interface.Object extra = ..
google-capillary	Public Key Retrieval	// Any extra information to be passed back to the handler.// To obtain an RSA-ECDSA public key.InputStream senderVerificationKey = ..
google-capillary	Public Key Retrieval	// The ECDSA public key of the server.RsaEcdsaKeyManager.getInstance context, keychainId, senderVerificationKey // To obtain a Web Push public key.WebPushKeyManager.getInstance context, keychainId .getPublicKey isAuth, handler, extra ;// The Capillary library returns a byte array representing the Capillary public key via the// handlePublicKey method of the CapillaryHandler instance.
google-capillary	Decryption	After receiving a ciphertext generated using a Capillary public key, you can decrypt it as follows:import android.content.Context;import com.google.capillary.android.CapillaryHandler;import com.google.capillary.android.RsaEcdsaKeyManager;import com.google.capillary.android.WebPushKeyManager;import java.io.InputStream;byte   ciphertext = ..
google-capillary	Decryption	// The ciphertext received through FCM.Context context = ..
google-capillary	Decryption	// The current app context.String keychainId = ..
google-capillary	Decryption	// The identifier for the key pair.CapillaryHandler handler = ..
google-capillary	Decryption	// An implementation of CapillaryHandler interface.Object extra = ..
google-capillary	Decryption	// Any extra information to be passed back to the handler.// To decrypt a ciphertext and pass the plaintext to the CapillaryHandler instance,//  e.g
google-capillary	Decryption	for display to the user :// For RSA-ECDSA:InputStream senderVerificationKey = ..
google-capillary	Decryption	// The ECDSA public key of the server.RsaEcdsaKeyManager.getInstance context, keychainId, senderVerificationKey // For Web Push:WebPushKeyManager.getInstance context, keychainId // The Capillary library returns a byte array representing the plaintext via the handleData// method of the CapillaryHandler instance.Keep in mind that during decryption, the Capillary library may automatically re-generatethe underlying Capillary key pairs if those key pairs are irrecoverably corrupted, which can happen,for example, when the user adds/resets the device lock, resets app storage, etc
google-capillary	Decryption	Such a newlygenerated public key along with the Capillary ciphertext bytes that triggered key re-generationwill be passed to the Android app via the appropriate methods of the CapillaryHandler  lib-android/src/main/java/com/google/capillary/android/CapillaryHandler.java .If the ciphertext has been generated using an Auth key but the Android device is in anunauthenticated context, the Capillary library internally saves the ciphertext to be decrypted laterand informs the Android app via the authCiphertextSavedForLater  lib-android/src/main/java/com/google/capillary/android/CapillaryHandler.java method
google-capillary	Decryption	This allows the Android app to handle cached ciphertexts, e.g
google-capillary	Decryption	by telling the user messagesare available upon unlock
google-capillary	Decryption	Upon the user unlocking the device, you can have the Capillary librarydecrypt any saved ciphertexts as follows:import android.content.Context;import com.google.capillary.android.CapillaryHandler;import com.google.capillary.android.RsaEcdsaKeyManager;import com.google.capillary.android.WebPushKeyManager;import java.io.InputStream;Context context = ..
google-capillary	Decryption	// The current app context.String keychainId = ..
google-capillary	Decryption	// The identifier for the key pair.CapillaryHandler handler = ..
google-capillary	Decryption	// An implementation of CapillaryHandler interface.Object extra = ..
google-capillary	Decryption	// Any extra information to be passed back to the handler.// To decrypt saved ciphertexts and pass the plaintexts to the CapillaryHandler instance,//  e.g
google-capillary	Decryption	for display to the user :// For RSA-ECDSA:InputStream senderVerificationKey = ..
google-capillary	Decryption	// The ECDSA public key of the server.RsaEcdsaKeyManager.getInstance context, keychainId, senderVerificationKey // For Web Push:WebPushKeyManager.getInstance context, keychainId // For each decrypted ciphertext, the Capillary library returns a byte array representing the// plaintext via the handleData method of the CapillaryHandler instance.There are several ways to trigger the handler for cached ciphertext upon device unlock
google-capillary	Decryption	The approachused by the Capillary library's  demo Android app  demo/android  is to listen for the ACTION_USER_PRESENT broadcast intent
google-capillary	Decryption	See DeviceUnlockedBroadcastReceiver  android/src/main/java/com/google/capillary/demo/android/DeviceUnlockedBroadcastReceiver.java for more details.
google-capillary	Key Deletion	To delete a Capillary key pair:import android.content.Context;import com.google.capillary.android.RsaEcdsaKeyManager;import com.google.capillary.android.WebPushKeyManager;import java.io.InputStream;Context context = ..
google-capillary	Key Deletion	// The current app context.String keychainId = ..
google-capillary	Key Deletion	// The identifier for the key pair.boolean isAuth = ..
google-capillary	Key Deletion	// Whether the private key usage is guarded by the device lock.// To delete an RSA-ECDSA key pair.InputStream senderVerificationKey = ..
google-capillary	Key Deletion	// The ECDSA public key of the server.RsaEcdsaKeyManager.getInstance context, keychainId, senderVerificationKey .deleteKeyPair isAuth ;// To delete a Web Push key pair.WebPushKeyManager.getInstance context, keychainId .deleteKeyPair isAuth ;
google-capillary	On Java Application Servers	The Capillary library provides the functionality to encrypt messages on Java-based applicationservers
google-capillary	Encryption	To encrypt a message using a Capillary public key:import com.google.capillary.EncrypterManager;import com.google.capillary.RsaEcdsaEncrypterManager;import com.google.capillary.WebPushEncrypterManager;import java.io.InputStream;byte   recipientPublicKey = ..
google-capillary	Encryption	// The Capillary public key of the client.byte   message = ..
google-capillary	Encryption	// The message to be sent to the client.// To create an RSA-ECDSA ciphertext.InputStream senderSigningKey = ..
google-capillary	Encryption	// The ECDSA private key of the server.EncrypterManager rsaEcdsaEncrypterManager = new RsaEcdsaEncrypterManager senderSigningKey ;rsaEcdsaEncrypterManager.loadPublicKey recipientPublicKey ;byte   ciphertext = rsaEcdsaEncrypterManager.encrypt message ;// This step is not strictly necessary, but it ensures that the EncrypterManager releases the// stored public key for garbage collection.rsaEcdsaEncrypterManager.clearPublicKey  ;// To create a Web Push ciphertext.EncrypterManager webPushEncrypterManager = new WebPushEncrypterManager  ;webPushEncrypterManager.loadPublicKey recipientPublicKey ;byte   ciphertext = webPushEncrypterManager.encrypt message ;webPushEncrypterManager.clearPublicKey  ;
google-capillary	Maintainers	The Capillary library is maintained by the following Googlers:
google-capirca	Capirca	Capirca is a tool designed to utilize common definitions of networks, services and high-level policy files to facilitate the development and manipulation of network access control lists  ACLs  for various platforms
google-capirca	Capirca	It was developed by Google for internal use, and is now open source.
google-capsicum-test	Capsicum User Space Tests	This directory holds unit tests for  Capsicum object-capabilities
google-capsicum-test	Capsicum User Space Tests	The tests exercise the syscall interface to a Capsicum-enabled operating system,currently either  FreeBSD >=10.x  or a modified Linux kernel  the capsicum-linux  project .The tests are written in C++98, and use the  Google Test framework, with some additions to fork off particular tests  because a process that enters capabilitymode cannot leave it again .
google-capsicum-test	Provenance	The original basis for these tests was:comparative testing across multiple OSes, and then substantially extended.
google-capsicum-test	Linux	The following additional development packages are needed to build the full test suite on Linux.The Capsicum userspace library is held in the libcaprights/ subdirectory
google-capsicum-test	Linux	 Ideally, thislibrary should be built  with ./configure; make or dpkg-buildpackage -uc -us  andinstalled  with make install or dpkg -i libcaprights*.deb  so that the tests willuse behave like a normal Capsicum-aware application.However, if no installed copy of the library is found, the GNUmakefile will attemptto use the local libcaprights/*.c source; this requires ./configure to have beenperformed in the libcaprights subdirectory
google-capsicum-test	Linux	The local code is also used forcross-compiled builds of the test suite  e.g
google-capsicum-test	Linux	make ARCH=32 or make ARCH=x32 .
google-capture-thread	 Capture Thread Library  google/capture-thread 	Framework for loggers, tracers, and mockers in multithreaded C++ programs.* This is not an official Google product
google-capture-thread	 Capture Thread Library  google/capture-thread 	*
google-capture-thread	Motivation	When developing C++ projects,  instrumentation  instrumentation  is frequentlyused to collect information from the system, inject information into the system,or both
google-capture-thread	Motivation	The role of this information within the system rarely lines up with theactual structure of the project.For example:This library is designed to handle all of these situations with minimalintrusion into your project, and without leaking details in your API.
google-capture-thread	Summary	The **Capture Thread Library*thread-locality, which allows the sharing of static variables *only within thecurrent thread*
google-capture-thread	Summary	Canonical static variables, on the other hand, are problematicdue to ownership and thread-safety issues.This library establishes the following idiom * using logging as an example *: The instrumentation is 100% passive unless it is explicitly enabled
google-capture-thread	Summary	* For Instrumentation is enabled in the current thread by *instantiating While enabled, the instrumentation transparently alters the behavior of Instrumentation can be shared across threads in *explicitly-specified
google-capture-thread	Key Design Points	The **Capture Thread Library*and reliable:
google-capture-thread	Caveats	In some cases, it might not be appropriate  or possible  to use the **CaptureThread Library**:
google-capture-thread	Quick Start	Instrumenting a project has four steps
google-capture-thread	Quick Start	These assume that your project isalready functional, and is just lacking instrumentation
google-capture-thread	Quick Start	Create an instrumentation class to contain the state to be shared
google-capture-thread	Quick Start	Instrument your project with logging points, tracing points, or mocking Where control is passed between threads, e.g., creating a thread or passing As needed, instantiate the instrumentation class es  to enable theComplexity estimates below are estimates of how much additional work will benecessary as your project grows.
google-capture-thread	Step 1: Instrumentation Class  O 1  	The instrumentation class es  will generally be written once and then leftalone
google-capture-thread	Step 1: Instrumentation Class  O 1  	They might also be general enough for use in multiple projects.
google-capture-thread	#include "thread-capture.h"	// This class provides the instrumentation logic, both at the point the// instrumentation is used  e.g., logging points  and where it is enabled  e.g.,// log-capture points
google-capture-thread	#include "thread-capture.h"	 Note that instances of ThreadCapture cannot be moved,// copied, or dynamically allocated.class Logger : public capture_thread::ThreadCapture { public:  Logger   : cross_and_capture_to_ this  {}  // no-op if no instrumentation is in scope
google-capture-thread	#include "thread-capture.h"	 static void Log const std::string& line  {  }  // to access its contents
google-capture-thread	#include "thread-capture.h"	This is only necessary when the instrumentation is  // gathering information, as opposed to propagating information
google-capture-thread	#include "thread-capture.h"	 std::list GetLines   {  } private:  // The private implementation applies to the instrumentation only when it's in  // scope
google-capture-thread	#include "thread-capture.h"	This does not need to exactly mirror the static API, and in fact  // only needs to differentiate between default and override behaviors
google-capture-thread	#include "thread-capture.h"	 void LogLine const std::string& line  {  }  std::list lines_;  // Add an AutoThreadCrosser to ensure that scoping is handled correctly
google-capture-thread	#include "thread-capture.h"	If  // you absolutely don't want the instrumentation crossing threads, use  // ScopedCapture instead
google-capture-thread	#include "thread-capture.h"	Always initialize with 
google-capture-thread	Step 2: Instrument the Code  O n  	Instrumenting the code with your new instrumentation class will generallyconsist of one-line additions throughout the code
google-capture-thread	Step 2: Instrument the Code  O n  	There will often be a largenumber of instrumentation points in the code.// #include the header for your instrumentation class.// This function already exists in your code, and performs some sort of work for// which you want to use the instrumentation.void MyExistingFunction   {  // Add calls to the static API where you need access to the instrumentation
google-capture-thread	Step 2: Instrument the Code  O n  	 Logger::Log "MyExistingFunction called" ;
google-capture-thread	Step 3: Cross Threads  O log n  	Crossing threads is necessary when the process you are tracking splits workamong multiple threads
google-capture-thread	Step 3: Cross Threads  O log n  	The complexity here depends on both what you consider asingle task  e.g., processing a query  and how that work is split among threads.
google-capture-thread	#include "thread-crosser.h"	//  You don't need to #include the header for your instrumentation class here
google-capture-thread	#include "thread-crosser.h"	// This function already exists in your code, and parallelizes some// functionality that needs to use the instrumentation, but doesn't need to use// the instrumentation itself.void ParallelizeWork   {  // Previously, the code just created a thread
google-capture-thread	#include "thread-crosser.h"	 // std::thread worker &MyExistingFunction ;  // WrapCall when passing work to a worker thread, e.g., a thread pool
google-capture-thread	#include "thread-crosser.h"	 std::thread worker   worker.join  ;
google-capture-thread	Step 4: Enable Instrumentation  O 1  	Your instrumentation must have default behavior that makes sense when theinstrumentation is not enabled
google-capture-thread	Step 4: Enable Instrumentation  O 1  	Instrumentation can only be enabled byinstantiating the implementation, and will only be available until that instancegoes out of scope
google-capture-thread	Step 4: Enable Instrumentation  O 1  	There should be *very fewusually just one per instrumentation type  in your code.// #include the header for your instrumentation class.int main   {  // If no instrumentation is in scope, the default behavior of the static API  // is used where instrumentation calls are made
google-capture-thread	Step 4: Enable Instrumentation  O 1  	In this case, this will just  // print the line to std::cerr
google-capture-thread	Step 4: Enable Instrumentation  O 1  	 ParallelizeWork  ;  // instantiate your class
google-capture-thread	Step 4: Enable Instrumentation  O 1  	The framework will take care of the rest
google-capture-thread	Step 4: Enable Instrumentation  O 1  	 Logger logger;  // rather than the default behavior of printing to std::cerr
google-capture-thread	Step 4: Enable Instrumentation  O 1  	 ParallelizeWork  ;  // the local instance
google-capture-thread	Step 4: Enable Instrumentation  O 1  	 for  const std::string& line : logger.GetLines    {  }The instantiation point will depend on the semantics you are going for
google-capture-thread	Step 4: Enable Instrumentation  O 1  	Forexample, if you are mocking, you might only instantiate the instrumentation inunit tests, and use the default behavior in the released code.
google-capture-thread	Contributing	See  CONTRIBUTING.md  CONTRIBUTING.md  for guidelines
google-capture-thread	Contributing	All contributions mustfollow the Google C++ style guide at **Contributions should bemade to the  current  current  branch, which will periodically be merged with master  master  after a more thorough review.** google/capture-thread :  master :  current :  instrumentation : 
google-cargo-raze	cargo-raze: Bazel BUILD generation for Rust Crates	  An experimental support Cargo plugin for distilling a workspace-levelCargo.toml into BUILD targets that code using  rules_rust can depend on directly.
google-cargo-raze	Disclaimer	This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-cargo-raze	Overview	This project synthesizes the dependency resolution logic and some of thefunctionality of Cargo such as features and build scripts into executablerules that Bazel can run to compile Rust crates
google-cargo-raze	Overview	Though the standard rules_rustrules can be used to compile Rust code from scratch, the fine granularity of thedependency ecosystem makes transforming dependency trees based on that ecosystemonerous, even for code with few dependencies.
google-cargo-raze	Usage	cargo-raze can generate buildable targets in one of two modes: Vendoring, orNon-Vendoring
google-cargo-raze	Usage	In the vendoring mode, developers use the common cargo-vendortool to retrieve the dependencies indicated by their workspace Cargo.toml intodirectories that cargo-raze then populates with BUILD files
google-cargo-raze	Usage	In thenon-vendoring mode, cargo-raze generates a flat list of BUILD files, and aworkspace-level macro that can be invoked in the WORKSPACE file to pull down thedependencies automatically in similar fashion to Cargo itself.In both cases, the first step is to decide where to situate the Cargodependencies in the workspace
google-cargo-raze	Usage	This library was designed with monorepos in mind,where an organization decides upon a set of dependencies that everyone pointsat
google-cargo-raze	Usage	It is intended that stakeholders in the dependencies collaborate to upgradedependencies atomically, and fix breakages across their codebase simultaneously.In the event that this isn't feasible, it is still possible to use cargo-raze ina decentralized scenario, but its unlikely that such decoupled repositorieswould interact well together with the current implementation.Regardless of the approach chosen, the rust_rules should be brought in to theWORKSPACE
google-cargo-raze	Usage	Here is an example:git_repository  load "@io_bazel_rules_rust//rust:repositories.bzl", "rust_repositories" rust_repositories  
google-cargo-raze	Vendoring Mode	In Vendoring mode, a root directly is selected that will house the vendoreddependencies and become the gateway to those build rules
google-cargo-raze	Vendoring Mode	"//cargo" isconventional, but "//third_party/cargo" may be desirable to satisfyorganizational needs
google-cargo-raze	Vendoring Mode	Vendoring directly into root isn't well supported due toimplementation-specific idiosyncracies, but it may be supported in the future.From here forward, "//cargo" will be the assumed directory.
google-cargo-raze	Generate a Cargo.toml	Generate a Cargo.toml, similar to Vendoring mode but add a new directive in theThis tells Raze not to expect the dependencies to be vendored and to generatedifferent files.
google-cargo-raze	Mandatory  or Cargo tooling is unhappy 	 lib path = "fake_lib.rs" dependencies log = "=0.3.6" raze 
google-cargo-raze	The WORKSPACE relative path to the Cargo.toml working directory.	workspace_path = "//cargo"
google-cargo-raze	The target to generate BUILD rules for.	target = "x86_64-unknown-linux-gnu"
google-cargo-raze	Generate buildable targets	First, install cargo-raze.Next, execute cargo raze from within the cargo directoryFinally, invoke the remote library fetching function within your WORKSPACE:load "//cargo:crates.bzl", "raze_fetch_remote_crates" raze_fetch_remote_crates  This tells Bazel where to get the dependencies from, and how to build them:using the files generated into //cargo.You can depend on any *explicit
google-cargo-raze	Remote Dependency Mode	In Remote mode a directory similiar to the vendoring mode is selected
google-cargo-raze	Remote Dependency Mode	In thiscase though it contains only BUILD files, a vendoring instruction for the WORKSPACE,and aliases to the explicit dependencies
google-cargo-raze	Remote Dependency Mode	Slightly different plumbing is
google-cargo-raze	Handling Unconventional Crates	Some crates execute a "build script", which, while technically unrestricted inwhat it can do, usually does one of a few common things.All options noted below are enumerated in the src/settings.rs  ./src/settings.rs  file.
google-cargo-raze	Crates that generate files using locally known information	In some cases, a crate uses only basic information in order to generate a Rustsource file
google-cargo-raze	Crates that generate files using locally known information	These build-scripts rules can actually be executed and used withinBazel by including a directive in your Cargo.toml prior to generation:script and to direct its generated  OUT_DIR-style  outputs to the parent crate.
google-cargo-raze	Crates that depend on certain flags being determined by a build script	Some build scripts conditionally emit directives to stdout that Cargo knows howto propagate
google-cargo-raze	Crates that depend on certain flags being determined by a build script	Unfortunately, its not so simple to manage build-time generateddependency information, so if the flags are statically known  perhaps, since thecompilation target is statically known , they can be provided from within theCargo.toml, in the following mannerFlags provided in this manner are directly handed to rustc
google-cargo-raze	Crates that depend on certain flags being determined by a build script	It may be helpful torefer to the build-script section of the documentation to interpret buildscripts and stdout directives that are encountered, available here:There are two ways to provide system libraries that a crate needs forcompilation
google-cargo-raze	Crates that depend on certain flags being determined by a build script	The first is to vendor the system library directly, craft a BUILDrule for it, and add the dependency to the corresponding toml raze.crates.openssl-sys.'0.9.24' additional_flags =    # Vendored openssl is 1.0.2m  "--cfg=ossl102",  "--cfg=version=102", additional_deps =    "@//third_party/openssl:crypto",  "@//third_party/openssl:ssl",  raze.crates.openssl.'0.10.2' additional_flags =    # Vendored openssl is 1.0.2m  "--cfg=ossl102",  "--cfg=version=102",  "--cfg=ossl10x", In some cases, directly wiring up a local system dependency may be preferable.To do this, refer to the In a few cases, the sys crate may need to be overridden entirely
google-cargo-raze	Crates that depend on certain flags being determined by a build script	This can befacilitated by removing and supplementing dependencies in the Cargo.toml, Some crates provide useful binaries that themselves can be used as part of acompilation process: Bindgen is a great example
google-cargo-raze	Crates that depend on certain flags being determined by a build script	Bindgen produces Rust sourcefiles by processing C or C++ files
google-cargo-raze	Crates that depend on certain flags being determined by a build script	A directive can be added to the Cargo.tomlto tell Bazel to expose such binaries for you:binaries and libraries to share the same target name, Bazel disallows this.
google-cargo-raze	Why choose Bazel to build a Rust project?	Bazel  "fast", "correct", choose two  is a battle tested build system used byGoogle to compile incredibly large, multilingual projects without duplicatingeffort, and without compromising on correctness
google-cargo-raze	Why choose Bazel to build a Rust project?	It accomplishes this in part bylimiting what mechanisms a given compilation object can use to discoverdependencies and by forcing buildable units to express the complete set oftheir dependencies
google-cargo-raze	Why choose Bazel to build a Rust project?	It expects two identical sets of build target inputs to produce abyte-for-byte equivalent final result.In exchange, users are rewarded with a customizable and extensible build systemthat compiles any kind of compilable target and allows expressing "unconventionaldependencies", such as Protobuf objects, precompiled graphics shaders, orgenerated code, while remaining fast and correct.Its also probable  though not yet demonstrated with benchmarks  that largeapplications built with Bazel's strengths in mind: highly granular build units,will compile significantly faster as they are able to cache more aggressivelyand avoid recompilation of as much code while iterating.
google-cargo-raze	Why try to integrate Cargo's dependencies into this build tool?	For better or worse, the Rust ecosystem heavily depends on Cargo crates in orderto provide functionality that is often present in standard libraries
google-cargo-raze	Why try to integrate Cargo's dependencies into this build tool?	This isactually a fantastic thing for the evolution of the language, as it describes astructured process to stabilization  experimental crate -> 1.0 crate -> RFC ->inclusion in stdlib , but it means that people who lack access to this ecosystemmust reinvent many wheels.Putting that aside there are also fantastic crates that help Rust developersinteract with industry standard systems and libraries which can greatlyaccelerate development in the language.
google-cargo-raze	Why not build directly with Cargo / Why generate rustc invocations?	Though the burden of emulating Cargo's functionality  where possible at all!  ishigh, it appears to be the only way to maintain the guarantees  correctness,reproducibility  that Bazel depends on to stay performant
google-cargo-raze	Why not build directly with Cargo / Why generate rustc invocations?	It is possible andlikely with inflight RFCs that Cargo will become sufficiently flexible toallow it to be used directly for compilation but at this point in time itappears that maintaining a semblance of feature parity is actually easier thanavoiding all of the sharp edges introduced by treating Cargo like the Rust
google-cargo-raze	What is buildable right now with Bazel, and what is not?	With a little bit of elbow grease it is possible to build nearly everything,including projects that depend on openssl-sys
google-cargo-raze	What is buildable right now with Bazel, and what is not?	Many sys crates will requireidentifying the system library that they wrap, and either vendoring it into theproject, or telling Bazel where it lives on your system
google-cargo-raze	What is buildable right now with Bazel, and what is not?	Some may require minorsource tweaks, such as eliminating hardcoded cargo environment variablerequirements
google-cargo-raze	What is buildable right now with Bazel, and what is not?	Fixes can be non-trivial in a few cases, but a good number ofthe most popular crates have been built in an example repo, available at
google-cargo-raze	Example Repos	See these examples of providing crate configuration:**Using vendored mode**:The  raze  section is derived from a struct declared in  impl/src/settings.rs  ./impl/src/settings.rs .
google-categorybuilder	Category Builder	This repository contains data and code for the Category Builder system.Category Builder can do set expansion while dealing robustly with polysemy.See category_builder_paper.pdf in this directory.
google-categorybuilder	Installation	Download code and data using git
google-categorybuilder	Installation	You will need to have installed  git lfs _Note: This will take a few minutes to initalize
google-categorybuilder	Installation	Two files totaling 7 GB are produced._| Seeds   | Expansion || :------|ford, nixon | nixon, obama, bush, johnson, clinton, ford, reagan, ..
google-categorybuilder	Installation	||ford, chevy | ford, chevy, toyota, chevrolet, honda, bmw, nissan, ..
google-categorybuilder	Installation	||ford,  stallone| ford, stallone, khan, kapoor, sylvester stallone, depp, tom cruise, ..
google-categorybuilder	Installation	||cancer, diabetes| cancer, diabetes, disease, asthama, infection, breast cancer, syndrome, ...||cancer, taurus| virgo, pisces, libra, taurus, scorpio, saggitarius, cancer, aries, capricorn, aquarius, gemini, leo, ...||safari, trip|trip, tour, trips, safari, vacation, adventure, holiday, excursion, cruisetours, journey, ...||safari, ie|firefox, internet explorer, chrome, explorer, safari, ie, google chrome, browsers, web browser, ...||beautiful, serene|beautiful, serene, peaceful, tranquil, picturesque, quite, lovely, stunning, scenic, secluded, ...||beautiful, poignant| beautiful, poignant, romantic, evocative, gorgeous, poetic, haunting, funny, sad, vivid, ...||beautiful, chic|elegant, chic, stylish, beautiful, gorgeous, stunning, trendy, lovely, vintage, classy, sleek, ...|
google-categorybuilder	How to do analogies	The same system can solve analogies such as "What is the mount everest of africa?"Note that these are harder than "proportional" analogies such as "hand:glove::foot:?"
google-categorybuilder	How to do analogies	People don't need to be provided the first term  "hand"  and can answer "What is the glove for a foot?"
google-categorybuilder	Example Output	The items are labeled B and C because analogies are often shown as A:B::C:D.|  B   | C | What is the B of C? ||mount everest|africa| kilimanjaro||mount everest|alaska| denali||glove | foot | shoe ||darwin | physics | einstein ||corolla|honda|honda civic||dollar|india|rupee||voldemort|tolkien|sauron||voldemort|star wars|vader|
google-cauliflowervest	Overview	**Note: OAUTH_CLIENT_ID moved from src/cauliflowervest/client/settings.py to Cauliflower Vest  ../../wiki/ThatName  is a recovery key escrow solution.The project initially started with end-to-end Mac OS X FileVault 2 support,and later added support for BitLocker  Windows , LUKS  Linux , Duplicity, andFirmware/BIOS passwords  Mac & Linux 
google-cauliflowervest	Overview	The goal of this project is to streamlinecross-platform enterprise management of disk encryption technologies.Cauliflower Vest offers the ability to:Full source is available for all components.To get started, begin with the  Introduction  ../../wiki/Introduction wiki page.
google-cauliflowervest	Warning	Upon releasing the  update to App Engine, start the schema update  /ui/#/admin/  otherwisesearch and key retrieval will break
google-cauliflowervest	Warning	Progress can bemonitored in  App Engine logs Logs will containfor each volume type after successful migration.
google-cauliflowervest	Contact	Please search, join, and/or email the discussion list with questions at  cauliflowervest-discuss@googlegroups.com To reach only engineers on the project, emailThanks to  Dorothy Marczak for the logo.
google-cctz	Overview	CCTZ contains two libraries that cooperate with  to give C++programmers all the necessary tools for computing with dates, times, and timezones in a simple and correct manner
google-cctz	Overview	The libraries in CCTZ are:These libraries are currently known to work on **Linux**, **Mac OS X**, andThey will also work on **Windows*interested, though, in an implementation of the cctz::TimeZoneIf interface thatcalls the Windows time APIs instead
google-cctz	Overview	Please contact us if you're interested in
google-cctz	Getting Started	CCTZ is best built and tested using the  Bazel  build systemand the  Google Test  framework
google-cctz	Getting Started	 There isalso a simple  Makefile and a CMakeLists.txt that should work if you're unable to use Bazel
google-cctz	Getting Started	 Download/install Get the cctz source: git clone  then cd Build cctz and run the tests: bazel test :allWith CMake: Make sure you have CMake >= 2.8.12 installed
google-cctz	Getting Started	Get the cctz source: git clone  then cd Build cctz so that is can be used by shared libraries and run the tests  use Use in your CMake-based project with:Note: When using CCTZ in your own project, you might find it easiest to compilethe sources using your existing build system.Next Steps: See the documentation for the libraries in CCTZ: Look at the examples in  Join our mailing list to ask questions and keep informed of changes:* The concepts presented here describe general truths about the problem domainand are library and language agnostic
google-cctz	Getting Started	An understanding of these concepts helpsthe programmer correctly reason about even the most-complicated time-programmingchallenges and produce the simplest possible solutions
google-cctz	Getting Started	*There are two main ways to think about time in a computer program: as *absolutetime*, and as *civil time*
google-cctz	Getting Started	Both have their uses and it is important tounderstand when each is appropriate
google-cctz	Getting Started	Absolute and civil times may be convertedback and forth using a *time zoneconvert between them
google-cctz	Getting Started	Let us now look more deeply at the three main concepts oftime programming: Absolute Time, Civil Time, and Time Zone.*Absolute timeIt has no notion of calendars, or dates, or times of day
google-cctz	Getting Started	Instead, it is ameasure of the passage of real time, typically as a simple count of ticks sincesome epoch
google-cctz	Getting Started	Absolute times are independent of all time zones and do not sufferfrom human-imposed complexities such as daylight-saving time  DST 
google-cctz	Getting Started	Many C++types exist to represent absolute times, classically std::chrono::time_point.*Civil timeaffairs  cf
google-cctz	Getting Started	 It is ahuman-scale representation of time that consists of the six fields &mdash; year,month, day, hour, minute, and second  sometimes shortened to "YMDHMS"  &mdash;and it follows the rules of the Proleptic Gregorian Calendar, with 24-hour daysdivided into 60-minute hours and 60-second minutes
google-cctz	Getting Started	Like absolute times, civiltimes are also independent of all time zones and their related complexities e.g., DST 
google-cctz	Getting Started	While std::tm contains the six civil-time fields  YMDHMS , plus afew more, it does not have behavior to enforce the rules of civil time.*Time zonesshared to convert between the absolute-time and civil-time domains
google-cctz	Getting Started	A timezone's rules include things like the region's offset from the UTC time standard,daylight-saving adjustments, and short abbreviation strings
google-cctz	Getting Started	Time zones oftenhave a history of disparate rules that apply only for certain periods, becausethe rules may change at the whim of a region's local government
google-cctz	Getting Started	For thisreason, time-zone rules are usually compiled into data snapshots that are usedat runtime to perform conversions between absolute and civil times
google-cctz	Getting Started	There iscurrently no C++ standard library supporting arbitrary time zones.In order for programmers to reason about and program applications that correctlydeal with these concepts, they must have a library that correctly implements theabove concepts
google-cctz	Getting Started	CCTZ adds to the existing C++11  library to fullyimplement the above concepts.
google-cctz	Hello February 2016	This "hello world" example uses a for-loop to iterate the days from the first ofFebruary until the month of March
google-cctz	Hello February 2016	Each day is streamed to output, and if theday happens to be the 29th, we also output the day of the week.
google-cctz	#include "cctz/time_zone.h"	int main   {  cctz::time_zone nyc;  cctz::load_time_zone "America/New_York", &nyc ;  const auto moon_walk =  if  !cctz::load_time_zone "Australia/Sydney", &syd   return -1;  std::cout << "Moon walk in SYD: "The output of the above program isfirst walk on the moon is the same no matter the time zone of the viewer  thesame time point is used in both calls to format   
google-cctz	#include "cctz/time_zone.h"	The only difference is thetime zone in which the moon_walk time point is rendered
google-cctz	#include "cctz/time_zone.h"	And in this case wecan see that our friend in Sydney was probably eating lunch while watching thathistoric event.
google-cdep	CDep	CDep is a decentralized native package dependency manager with a focus on Android.Here are some things you can do to get started with CDep.Get started with CDep on Windows, enter the following in the command line:After this, the instructions are the same as Linux and Mac.
google-cdep	Getting started on Linux and Mac	Get started with CDep on Linux or Mac by following these steps:Open a terminal window and navigate to the directory where your project is located.Enter the following commands:Open cdep.yml and add the following line:Run the cdep command to download SQLite and generate CMake module for it.If you have a CMake project, open your CMakeLists.txt and add the following code at the end of the file
google-cdep	Getting started on Linux and Mac	This tells CMake to locate the module glue file and add all the dependencies in that file to your_target_library.For more details on setting up CMake build with CDep visit  Add CDep dependencies to an existing Android Studio CMake project 
google-cel-cpp	C++ Implementations of the Common Expression Language	For background on the Common Expression Language see the  cel-spec  1  repo.Released under the  Apache License  LICENSE .Disclaimer: This is not an official Google product
google-cel-cpp	C++ Implementations of the Common Expression Language	1 :  
google-cel-go	Common Expression Language 	    ! Go Report Card  This repo contains the Go toolchain for the Common Expression Language  CEL .CEL is a non-Turing complete language designed to be portable and fast
google-cel-go	Common Expression Language 	It isbest suited to  applications where sandboxing a full-fledged language likeJavaScript or Lua would be too resource intensive, but side-effect free dynamiccomputations are strongly desired
google-cel-go	Want to contribute?	Write an expression in the CEL syntax, then parse, check, and interpret.| Step| Parse| Check| Interpret | Evaluates parsed expressions against a set of inputs.Type-checking an expression in an optional, but strongly encouraged step thatcan be used to reject some expressions as semantically invalid using staticanalysis
google-cel-go	Want to contribute?	Additionally, the type-check produces some additional metadatarelated to function overload resolution and object field selection which maybe used by the interpret step to speed up execution.
google-cel-go	Example	The following example shows the parse, check, and intepretation of a simpleprogram
google-cel-go	Example	After the parse and type-check steps, the service checks whether thereare any errors that need to be reported.import  // Parse the expression and returns the accumulated errors.p, errors := parser.ParseText "a || b && c.exists x, x > 2 " if len errors.GetErrors    != 0 {// Check the expression matches expectations given the declarations for// the identifiers a, b, c where the identifiers are scoped to the default// package  empty string :typeProvider := types.NewProvider  env := checker.NewStandardEnv packages.DefaultPackage, typeProvider, errors env.Add decls.NewIdent "a", decls.Bool, nil ,c := checker.Check p, env, "" if len errors.GetErrors    != 0 {// Interpret the checked expression using the standard overloads.i := interpreter.NewStandardInterpreter packages.DefaultPackage, typeProvider eval := i.NewInterpretable interpreter.NewCheckedProgram c  result, state := eval.Interpret More examples like these can be found within the unit tests which can be runusing  Bazel  5 :Released under the  Apache License  LICENSE .Disclaimer: This is not an official Google product
google-cel-go	Example	1 :   2 :   3 :   4 :   5 :   6 :  
google-cel-spec	Common Expression Language	  The Common Expression Language  CEL  implements common semantics for expressionevaluation, enabling different applications to more easily interoperate.Key ApplicationsGuiding philosophy: Keep it small & fast
google-cel-spec	Common Expression Language	Make it extensible
google-cel-spec	Common Expression Language	Developer-friendly.The required components of a system that supports CEL are:Example of boolean conditions and object construction: c// Conditionaccount.balance >= transaction.withdrawal// Object constructioncommon.GeoPoint{ latitude: 10.0, longitude: -5.5 }For more detail, see:Disclaimer: This is not an official Google product.
google-certificate-transparency-go	Certificate Transparency: Go Code	   ! Go Report Card   ! GoDoc  This repository holds Go code related to Certificate Transparency   CT 
google-certificate-transparency-go	Certificate Transparency: Go Code	 Therepository requires Go version 1.The main parts of the repository are:
google-certificate-transparency-go	Trillian CT Personality	The trillian/ subdirectory holds code and scripts for running a CT Log basedon the  Trillian  general transparency Log.The main code for the CT personality is held in trillian/ctfe; this coderesponds to HTTP requests on the CT API paths  and translatesthem to the equivalent gRPC API requests to the Trillian Log.This obviously relies on the gRPC API definitions atgithub.com/google/trillian; the code also uses common libraries from theTrillian project for:system locally
google-certificate-transparency-go	Trillian CT Personality	 In particular:These scripts require a local database instance to be configured as describedin the  Trillian instructions 
google-certificate-transparency-go	Working on the Code	Developers who want to make changes to the codebase need some additionaldependencies and tools, described in the following sections
google-certificate-transparency-go	Working on the Code	 The Travis configuration  .travis.yml  for the codebase is also useful referencefor the required tools and scripts, as it may be more up-to-date than this
google-certificate-transparency-go	Rebuilding Generated Code	Some of the CT Go code is autogenerated from other files:Re-generating mock or protobuffer files is only needed if you're changingthe original files; if you do, you'll need to install the prerequisites:and run the following:The codebase includes a couple of external projects under the master branch and the current stable release 
google-certificate-transparency-go	Rebuilding Generated Code	 See instructions in the Trillian repo for how to update vendored subtrees.
google-certificate-transparency-go	Running Codebase Checks	The  scripts/presubmit.sh  scripts/presubmit.sh  script runs various toolsand tests over the codebase.
google-certificate-transparency-go	Install gometalinter and all linters	go get -u github.com/alecthomas/gometalintergometalinter --install
google-certificate-transparency-go	Run build, test and linters but skip code generation	./scripts/presubmit.sh  --no-generate
google-certificate-transparency-go	Or just run the linters alone:	gometalinter --config=gometalinter.json ./...
google-certificate-transparency-monitor	Certificate Transparency Log Monitor	  This repository containis the source code for the monitor that checks thatCertificate Transparency Logs are complying with  RFC 6962 and the  Chromium Certificate Transparency Log Policy This project is currently in development and so may be subject to significant
google-certificate-transparency	Build Dependencies	The following tools are needed to build the CT software and its dependencies.For a Debian-based system, the relevant packages are:autoconf automake libtool shtool cmake clang git make tcl pkg-config python2.7
google-certificate-transparency	Software Dependencies	The following collections of additional software are used by the main CTLog codebase.---------------------
google-certificate-transparency	Compiler Warnings/Errors	The CT C++ codebase is built with the Clang -Wno-error= option to CXXFLAGS.For example, on errors involving unused variables try using:in case not all dependencies are properly accounted for and rebuilt
google-certificate-transparency	Compiler Warnings/Errors	Ifproblems persist, check that the Makefile in certificate-transparencycontains the options that were passed in CXXFLAGS.
google-certificate-transparency	Working on a Branch	If you're trying to clone from a branch on the CT repository then you'll needto substitute the following command for the gclient config command above  #build-quick-start , replacing branch as appropriateThe BoringSSL fork of OpenSSL can be used in place of OpenSSL  but note thatthe experimental  CT DNS server  docs/DnsServer.md  does not support thisconfiguration 
google-certificate-transparency	Working on a Branch	 To enable this, after the first step  .gclient to add:Testing the Code
google-certificate-transparency	Unit Tests	The unit tests for the CT code can be run with the certificate-transparency/Makefile.
google-certificate-transparency	Testing and Logging Options ##	Note that several tests write files on disk
google-certificate-transparency	Testing and Logging Options ##	The default directory forstoring temporary testdata is TMPDIR= for make.End-to-end tests also create temporary certificate and server files intest/tmp
google-certificate-transparency	Testing and Logging Options ##	All these files are cleaned up after a successful testFor logging options, see the glog documentation By default, unit tests log to stderr, and log only messages with a FATALlevel  i.e., those that result in abnormal program termination 
google-certificate-transparency	Testing and Logging Options ##	 You canoverride the defaults with command-line flags.Deploying a LogThe build process described so far generates a set of executables; however,other components and configuration is needed to set up a running CT Log.In particular, as shown in the following diagram:Configuring and setting up a distributed production Log is covered in a separate document  docs/Deployment.md .Operating a LogRunning a successful, trusted, certificate transparency Log involves more thanjust deploying a set of binaries
google-certificate-transparency	Testing and Logging Options ##	 Information and advice on operating arunning CT Log is covered in a  separate document  docs/Operation.md 
google-certtostore	CertToStore	CertToStore is a Multi-Platform package that allows you to work with x509certificates on Linux and the certificate store on Windows
google-certtostore	CertToStore	TOC 
google-certtostore	Why CertToStore?	CertToStore was created to solve some specific problems when working withcertificates using Go
google-certtostore	Why CertToStore?	Ever wanted to create public/private keypairs using the TPM or create certificate requests using TPM backed keys?Both are possible using CertToStore on Windows
google-certtostore	Why CertToStore?	Linux support is also planned.__Native Certificate Store Access without the prompts__Certificate storage in CertToStore under Windows uses the certificatestore by using native Windows calls
google-certtostore	Why CertToStore?	By using native functionality, you won'tsee the all to common "do you want to import this certificate?" when installingcertificates using certtostore.Additionally, you can lookup and use existing certificates with their privatekeys through CNG, regardless of how they were issued  TPM or Software backed .__Built-in support for Cryptography API: Next Generation  CNG __CertToStore under Windows was built from the ground up to use Microsoft'sCryptography API: Next Generation  CNG 
google-certtostore	Why CertToStore?	This grants certificates generated,requested, and stored using CertToStore the ability to use your computer's TPMto safely store private key material safely.__Compatibile with packages that use x509.Certificate__x509 compatible certs means that you can use private keys and certificatesgenerated by CertToStore with just about anything else in Go that works withcertificates
google-certtostore	Why CertToStore?	Want to generate certificate requests using the TPM, and send themto your own third-party CA? Have a Go based web server that you want to use witha TPM backed certificate? Sure thing.
google-certtostore	Contact	We have a public discussion list at certtostore-discuss@googlegroups.com 
google-certtostore	Disclaimer	This is not an official Google product.
google-chained-promise	Chained Promise: functional programming tools for recurring promises	    ! Join the chat at   We often find recurring patterns when handling asynchronous logic with promises, such as an HTTP endpoint that paginates and gives you a URL pointer to the next available dataset.Chained Promise provides an extended Promise class that you can use to easily abstract out recurring patterns
google-chained-promise	Chained Promise: functional programming tools for recurring promises	See jsdocs for more detailed explanations.
google-chained-promise	Example	Suppose we are querying Wikipedia API to get the list of all linked pages from "Plato" page:import ChainedPromise from "chained-promise";ChainedPromise.from fetch apiPoint  First thing we want to do is to parse the resulting JSON:Now that the chaining of the value has been configured, we can work on the series of data.See  the example project  examples/wikipedia-list-links  for the full example code
google-chained-promise	Example	Also see jsdoc to  ChainedPromise.ts  src/ChainedPromise.ts  for more explanation of other functions such as flatMap.Disclaimer: This is not an official Google product.
google-channel-id-enclave	About	There are two related patches in this project: The BoringSSL patch enables anopaque key for Channel ID, and the Chromium patch enables an opaque key alongwith providing an implementation of hardware-backed keys using the Intel SGXSDK
google-channel-id-enclave	About	Together, these patches demonstrate how Chromium could store its Channel IDprivate keys in an Intel SGX enclave.
google-channel-id-enclave	Compile and run	Follow the following steps to compile and run:Be on a machine with an SGX processor.Enter the BIOS settings, and make sure SGX is set to Set up pkgconfig by creating the file /usr/lib/pkgconfig/sgx.pc with contents:prefix=/opt/intel/sgxsdkincludedir=${prefix}/includeName: sgxDescription: Intel SGX SDK for LinuxVersion: 1.0.0Cflags: -I${includedir}Libs: -L${libdir} -lsgx_urts -lsgx_uae_service -lsgx_tserviceLoad google.comIf you want to run tests:ninja -C out/Default net_unittestsout/Default/net_unittests --gtest_filter=*ChannelIDThere are more tests within boringssl, with instructions in
google-charted	Visualization toolkit for Dart	Charted provides
google-charted	Screenshot of Charted interactive demo	! Screenshot of Charted interactive demo 
google-charted	Get started with the interactive demo	Get started with Charted by trying out the interactive demo provided with thepackage
google-charted	Get started with the interactive demo	Follow these instructions and get it running locally on your machine Git and the Dart SDK has to be installed first :
google-chartjs.dart	Disclaimer	This is not an official Google product.
google-charts	charts_common	 ! charts_common pub package  A common library for charting packages.
google-charts	charts_flutter	 ! charts_flutter pub package  A charting package for  Flutter  supporting both Androidand iOS.All charts packages are licensed under the Apache 2 license, see the LICENSE  LICENSE  and  AUTHORS  AUTHORS  files for details.
google-chatbase-dotnet	A .NET library for the  Chatbase API  written in C#	> This is not an official Google product.
google-chatbase-dotnet	Package Information	 Nuget package page 
google-chatbase-dotnet	Install	Using the  Package Manager Console  run the following command:Please see the  Getting Started Section  for informationon configuring one's account and obtaining an API key.
google-chatbase-dotnet	One can send individual messages to the Generic and Facebook rest APIs:	using Chatbase;Chatbase.Client client = new Chatbase.Client  ;Chatbase.Message msg = new Chatbase.Message  ;msg.api_key = "123"; // requiredmsg.user_id = "xyz"; // requiredmsg.intent = "test";msg.version = "0.1";msg.content = "This is a test.";msg.type = Chatbase.Message.UserMessage; // default, requiredmsg.not_handled = false; // defaultmsg.feedback = false; //defaultvar resp = client.Send msg .Result; // Get the result of the async task// Write the return status-code from the API requestConsole.WriteLine resp.StatusCode ;using Chatbase;Chatbase.Client client = new Chatbase.Client  ;// Agent messagesagnMsg = new Chatbase.FBAgentMessage  ;agnMsg.SetRecipientID "123" ;agnMsg.SetMessageID "456" ;agnMsg.SetMessageContent "hey" ;agnMsg.intent = "say-hello";agnMsg.version = "0.2";var firstTask = client.Send agnMsg ;// User messagesusrMsg = new Chatbase.FBUserMessage  ;usrMsg.SetSenderID "abc" ;usrMsg.SetRecipientID "123" ;usrMsg.SetMessageID "456" ;usrMsg.SetMessageContent "hey" ;usrMsg.intent = "say-hello";usrMsg.version = "0.2";var secondTask = client.Send usrMsg ;
google-chatbase-dotnet	One can send sets of messages as well to the Generic and Facebook rest APIs:	using Chatbase;Chatbase.Client client = new Chatbase.Client  ;Chatbase.MessageSet set = new Chatbase.MessageSet "api-key" ;// New messages made from the set will have the api-key already setChatbase.Message msg = set.NewMessage  ;// ..
google-chatbase-dotnet	One can send sets of messages as well to the Generic and Facebook rest APIs:	Set fields as one would a regular message like the example aboveset.Add msg var task = Client.Send set ;using Chatbase;Chatbase.Client client = new Chatbase.Client  ;// Agent Message SetChatbase.FBAgentMessageSet agnSet = new Chatbase.FBAgentMessageSet "api-key" ;Chatbase.FBAgentMessage agnMsg = agnSet.NewMessage  ;// ..
google-chatbase-dotnet	One can send sets of messages as well to the Generic and Facebook rest APIs:	Set fields as one would a regular FBAgentMessageagnSet.add agnMsg var firstTask = client.Send agnSet ;// User Message SetChatbase.FBUserMessageSet usrSet = new Chatbase.FBUserMessageSet "api-key" ;Chatbase.FBUserMessage usrMsg = usrSet.NewMessage  ;// ..
google-chatbase-dotnet	One can send sets of messages as well to the Generic and Facebook rest APIs:	Set fields as one would a regular FBUserMessageusrSet.add usrMsg ;var secondTask = client.Send usrSet ;
google-chatbase-dotnet	Tests	Please place tests in Chatbase.Tests project directory enter the following in a command-prompt:
google-chatbase-node	Chatbase Node.JS Client	> This is not an official Google Product
google-chatbase-node	Use	Install Via NPMvar chatbase = require '@google/chatbase' ;chatbase.newMessage 'my-api-key' 	.setPlatform 'INTERWEBZ' 	.setMessage 'CAN I HAZ?' 	.setVersion '1.0' 	.setUserId 'unique-user-0' 	.send  	.then msg => console.log msg.getCreateResponse    	.catch err => console.error err  ;Given that a newly created message can be updated this can be achieved via the message interface as well.var chatbase = require '@google/chatbase' ;chatbase.newMessage 'my-api-key', 'my-user-id' 	.setPlatform 'INTERWEBZ' 	.setMessage 'DO NOT WORK' 	.setVersion '1.0' ;	.setUserId 'unique-user-0' 	.send  	.then msg => {		msg.setIntent 'an-intent' 	} 	.catch err => console.error err  ;Groups of messages can also be queued and sent together:var chatbase = require '@google/chatbase' ;const set = chatbase.newMessageSet  	// The following are optional setters which will produce new messages with	// the corresponding fields already set!	.setApiKey 'abc' 	.setPlatform 'chat-space' ;// Once can add new messages to the set without storing them locallyset.newMessage  	.setMessage 'test_1' 	.setIntent 'book-flight' 	.setUserId 'unique-user-0' 	.setClientTimeout 8000 	// This is a regular message object with all the same setter with the caveat	// that one cannot send the message individually
google-chatbase-node	Use	All other setter methods	// still apply though.// One can also store the reference to the individual message if one would like// to keep a reference to the individual message instanceconst msg = set.newMessage  	.setMessage 'test_2' 	// Pass msg around and profit// Once the desired messages are queued on the set it can be sentset.sendMessageSet  	.then set => {		// The API accepted our request!		console.log set.getCreateResponse   ;	} 	.catch error => {		// Something went wrong!		console.error error ;	} 
google-chatbase-python	A Python library for the  Chatbase API 	> This is not an official Google product
google-chatbase-python	Quick Start	Please see the  Getting Started Section  for informationon configuring one's account and obtaining and API key.
google-chatbase-python	One can send individual messages to the Generic and Facebook rest APIs:	from chatbase import Messagemsg = Message api_key="x",resp = msg.send  from chatbase import FacebookAgentMessage, FacebookUserMessage
google-chatbase-python	Agent messages	agnMsg = FacebookAgentMessage api_key="x", intent="y", version="1", message="a" 
google-chatbase-python	Make sure to set the recipient and message IDs	agnMsg.set_recipient_id "123" agnMsg.set_message_id "xyz" resp = agnMsg.send  
google-chatbase-python	User messages	usrMsg = FacebookUserMessage api_key="x", intent="y", version="1", message="a" 
google-chatbase-python	Make sure to set the recipient, sender and message IDs	usrMsg.set_recipient_id "123" usrMsg.set_sender_id "456" usrMsg.set_message_id "xyz" resp = usrMsg.send  
google-chatbase-python	One can send sets of messages as well to the Generic and Facebook rest APIs:	from chatbase import MessageSet
google-chatbase-python	propagated to all message created from the set!	set = MessageSet api_key="x", platform="x", version="1", user_id="123" msg = set.new_message intent="impress", content="goes to 11" 
google-chatbase-python	in the containing set	msg.user_id = "shark-sandwich"
google-chatbase-python	Message type objects can be appended:	msg2 = Message api_key="x",set.append_message msg2 
google-chatbase-python	Sending the set will send all contained messages to the batch endpoint	resp = set.send  from chatbase import FacebookAgentMessageSet, FacebookUserMessageSet
google-chatbase-python	Agent Message Set	agnSet = FacebookAgentMessageSet api_key="x", version="y" msg = agnSet.new_message intent="a", message="b" 
google-chatbase-python	Don't forget to set the message and recipient ids	msg.set_recipient_id "123" msg.set_message_id "xyz" resp = agnSet.send  
google-chatbase-python	User Message Set	usrSet = FacebookUserMessageSet api_key="a", version="b" msg = usrSet.new_message intent="c", message="d" 
google-chatbase-python	Don't for get to set the message, recipient and sender ids	msg.set_recipient_id "123" msg.set_sender_id "456" msg.set_message_id "xyz" resp = usrSet.send  
google-chatbase-python	Tests	Please place tests in tests directory
google-chatbase-python	Tests	To run tests, from the repositoryroot run the following command:
google-checkers	Checkers Test Framework	  Checkers is a flexible test authoring framework for Python.You may find Checkers useful if you want to do any of the following:parts: test steps, test data, components under test, and test metadata
google-checkers	Checkers Test Framework	Checkersallows the user to have control over all of these areas, so it is easy tocustomize behavior
google-checkers	Checkers Test Framework	However, default behaviors are implemented so that writingsimple tests is still super simple.
google-checkers	Requirements	Python 2.7
google-checkers	Installation	TODO barkimedes : Describe installation in more detail
google-checkers	Installation	This is just a generalrecommendation for people who already know how to download code from GitHub.The following is a very simple Checkers test:import checkersfrom checkers import assertsfrom checkers.runners import pyunitdef test_add_2_2_4  :  asserts.are_equal 2 + 2, 4 def test_add_4_8_12  :  asserts.are_equal 4 + 8, 12 def test_divide_2_0_error  :  with asserts.expect_exception ZeroDivisionError :if __name__ == '__main__':  pyunit.main  Remember when we mentioned that tests are composed of several parts? Well, acouple of them are evidenced here.First, a test must have some test steps
google-checkers	Installation	Consider this the test logic
google-checkers	Installation	WithCheckers, this is indicated by functions that are decorated with@checkers.test
google-checkers	Installation	Each of these functions becomes a checkers.Test instance.Secondly, we must have a test runner
google-checkers	Installation	Checkers tests can be run by anything thatknows how to deal with checkers.TestRun s , but a test runner that isdistributed with Checkers is the PyUnit runner
google-checkers	Installation	This is used in the mainfunction here
google-checkers	Installation	 By default, the runner will include all of the tests in themodule containing main .
google-checkers	Defining Test Runs	Tests are always placed into test runs  checkers.TestRun instances 
google-checkers	Defining Test Runs	In theabove example, the test run was created automatically by the pyunit.mainfunction
google-checkers	Defining Test Runs	But if you want to do anything interesting, you'll probably need tocreate and manage your test runs directly.The test run allows you to provide lots of things to the test
google-checkers	Defining Test Runs	You can registersetup and teardown functions  at the test run level, setup will run oncebefore all of the tests and then teardown will run once after all of the testsare complete 
google-checkers	Defining Test Runs	You can also define test suite for organizing test cases
google-checkers	Defining Test Runs	You canadd tests directly to the test run from wherever you like
google-checkers	Defining Test Runs	You can registercomponents to be injected into the test cases
google-checkers	Defining Test Runs	Here is a more interesting testcase that does a few of those things:Before we get too fancy, let's see the above example where we explicitly createthe test run:import checkersfrom checkers import assertsfrom checkers.runners import pyunitdef test_add_2_2_4  :  asserts.are_equal 2 + 2, 4 def test_add_4_8_12  :  asserts.are_equal 4 + 8, 12 def create_test_run  :  test_run = checkers.TestRun    test_run.tests.register test_add_2_2_4   rest_run.tests.register test_add_4_8_12   # You can also load tests by module so you don't have to register each test
google-checkers	Defining Test Runs	 # If module_name isn't provided, it defaults to '__main__'  # test_run = checkers.TestRun.from_module module_name=__name__   return test_runif __name__ == '__main__':  pyunit.main test_run=create_test_run   
google-checkers	Injecting Components	Now that we know how to create a test run, let's see how component injectionImagine we have a Calculator class that is the component-under-test and wewant to inject it into the tests
google-checkers	Injecting Components	Calculator is defined in the calculator.pymodule as follows:class Calculator object :Exciting, right? Now let's take our original two tests and update them to usethe calculator to do the adding.import calculatorimport checkersfrom checkers import assertsfrom checkers.runners import pyunitdef test_add_2_2_4 calculator :  asserts.are_equal calculator.add 2, 2 , 4 def test_add_4_8_12 calculator :  asserts.are_equal calculator.add 4, 8 , 12 def create_test_run  :  test_run = checkers.TestRun.from_module    test_run.variables.register 'calculator', calculator.Calculator   return test_runif __name__ == '__main__':  pyunit.main test_run=create_test_run   Tests can take in arguments
google-checkers	Injecting Components	In the above example, the tests take in acalculator argument
google-checkers	Injecting Components	These arguments are referred to as 'variables' inCheckers
google-checkers	Injecting Components	So if you want all of the tests in a test run to have access to aparticular variable and value  in this case, a Calculator instance , thenjust register it with the test run variables and Checkers will inject it for youwhen the test runs.
google-checkers	Data-Driven  Parameterized  Tests	Test variables don't just have to be components under test
google-checkers	Data-Driven  Parameterized  Tests	There is anothermechanism for passing values into tests: parameterization
google-checkers	Data-Driven  Parameterized  Tests	And good news!! It'sbuilt natively into Checkers, so it works pretty well : There are two ways that you can parameterize a test
google-checkers	Data-Driven  Parameterized  Tests	One way is through the@checkers.parameterize decorator
google-checkers	Data-Driven  Parameterized  Tests	The other way is to register theparameterizations through the test run
google-checkers	Data-Driven  Parameterized  Tests	Hopefully this isn't too confusing, buttest run-based parameterizations are a useful feature because sometimes aparmeterization is only  useful in certain circumstances/under certainconfigurations, and this allows us to not *alwaysapplied to test cases  which is the case when decorators alone provide thisfunctionality .Anywho, the following example shows both ways of adding parameterizations:import checkersfrom checkers import assertsfrom checkers.runners import pyunitimport calculator as calcdef test_add calculator, x, y, expected :  asserts.are_equal calculator.add x, y , expected   print '%d + %d = %d' %  x, y, expected 
google-checkers	test is used in a test run. Use with caution!	@checkers.parameterize {} @checkers.test_suites 'subtract' def test_subtract calculator, x, y, expected :  asserts.are_equal calculator.subtract x, y , expected   print '%d
google-checkers	sort. This provides a built-in, flexible parameterization.	def build_add_params  :  return     def create_test_run  :  test_run = checkers.TestRun.from_module    test_run.variables.register 'calculator', calc.Calculator     # The parameterizations are applied at the test run level, so they only apply  # to this test run
google-checkers	sort. This provides a built-in, flexible parameterization.	 # You should prefer this mechanism for creating parameterizations that may be  # dependent on the environment, that you have to load data from another  # location  like a database , or where the components under test may behave  # differently from each other so the parameters would have to change between  # test runs
google-checkers	sort. This provides a built-in, flexible parameterization.	 for param in build_add_params  :  return test_runif __name__ == '__main__':  pyunit.main test_run=create_test_run   The output of running the above test is the following:Running tests under Python 2.7.6: /path/to/python2.7---------------------------------------------------------------------1 + 1 = 22 + 2 = 44 + 8 = 122 + -1 = 18 0 Note that components and parameter values are both just variables
google-checkers	sort. This provides a built-in, flexible parameterization.	Sofunctionally, it is entirely possible to include a component in aparameterization  and vice versa 
google-checkers	sort. This provides a built-in, flexible parameterization.	But conceptually, you probably want to makesure that you're keeping the two straight.
google-checkers	Test Fixtures	Checkers supports fixtures at the test run and test case levels
google-checkers	Test Fixtures	If you haveteardown functions that you want to run before or after each individual testcase, then you can use the @checkers.setup and @checkers.teardown decoratorson tests themselves, or register them with the test run.Note that test run-level fixtures will take in an optional parameter: thecheckers.Context instance.The cool thing about Checkers fixtures is that you can have as many or as fewas you like, and they can be defined as functions with names that actuallymake sense and can be shared
google-checkers	Test Fixtures	 In general, Checkers is very friendly to mixingand matching things however you like
google-checkers	Test Fixtures	There is a special variable in Checkers that is available to any test function.The context variable will always contain a checkers.Context instance, whichcontains information about the test run, the test case itself, etc
google-checkers	Test Fixtures	You'll seethat in this example, too.def logging_test_run_setup test_run :  print '#'def logging_test_run_teardown test_run :  print 'Finishing test run:', test_run.name  print '#' def register_calculator context :  calc = Calculator    print 'Registering calculator:', context.test_case.name, calc.__class__  context.variables.register 'calculator', calc def logging_test_case_setup context :  print '*'def logging_test_case_teardown context :  print 'Finishing test case:', context.test_case.full_name  print '*' def celebrate_evenness context :  print 'Awesome!! %s only has even numbers!!' % context.test_case.namedef curse_oddness context :  print 'Phooey!! %s has odd numbers :P' % context.test_case.namedef zero_division_setup  :  print 'Oops, dividing by zero in this test'@checkers.setup celebrate_evenness, zero_division_setup def test_divide_2_0  :  with asserts.expect_exception ZeroDivisionError :@checkers.teardown curse_oddness def test_add_1_1_2 calculator :  asserts.are_equal calculator.add 2, 2 , 4   print '1 + 1 = 2'@checkers.setup celebrate_evenness def test_add_2_2_4 calculator :  asserts.are_equal calculator.add 2, 2 , 4   print '2 + 2 = 4'@checkers.setup celebrate_evenness def test_add_4_8_12 calculator :  asserts.are_equal calculator.add 4, 8 , 12   print '4 + 8 = 12'def create_test_run  :  test_run = checkers.TestRun.from_module    test_run.setup.register logging_test_run_setup   test_run.teardown.register logging_test_run_teardown   test_run.test_case_setup.register logging_test_case_setup   test_run.test_case_setup.register register_calculator   test_run.test_case_teardown.register logging_test_case_teardown   return test_runif __name__ == '__main__':  pyunit.main test_run=create_test_run   The output for the above test run would be as follows:
google-checkers	################################################################################	Running tests under Python 2.7.6: /path/to/python2.7---------------------------------------------------------------------
google-checkers	Test Organization	Checkers makes it easy to organize your tests in a flexible, fluid kind of way.A nice aspect of Checkers is that you can use test suites to organize tests
google-checkers	Test Organization	Aneven nicer aspect is that the same test can be part of muliple test suites!!This can be really cool if you either have multiple ways that you want to viewtest results  perhaps one view is by module and another view is by feature 
google-checkers	Test Organization	Itcan also be helpful if you want the same test to be part of multiple suites like if tests are grouped by feature and this is an integration test thatcovers multiple features 
google-checkers	Test Organization	The nicest feature about using test suites is that,even if a test is used in multiple suites, it is only run once  assuming thetest runner that you're using is well-implemented, of course .I take that back
google-checkers	Test Organization	The *nicestdistribute your test definitions cleanly in various modules and use suites tobring them together in test runs in ways that make sense.You can assign tests to test suites in a few ways
google-checkers	Test Organization	One way is through thecheckers.TestSuite instance and register the whole suite with the test run.You can just register a test directly in the test run
google-checkers	Test Organization	Lastly, you can add avariable to a parameterization called 'test_suites' that has a list of suitenames that only that parameterization should apply to
google-checkers	Test Organization	Let's see all of theseoptions below.Imagine we've defined some subtraction tests in a separate module.import checkersfrom checkers import asserts@checkers.parameterize {} def test_subtract x, y, expected :  return asserts.are_equal x And in our main module, we can see all of the different ways that test suitescan be defined  decorator, part of a parameterization, registered with the testrun, or as individual tests registered with the test run .import checkersfrom checkers import assertsfrom checkers.runners import pyunitimport subtraction_tests@checkers.test_suites 'addition', 'multiplication' @checkers.parameterize {} def test_double x, expected :  asserts.are_equal x + x, expected   asserts.are_equal x @checkers.parameterize {} def test_add x, y, expected :  asserts.are_equal x + y, expected def create_test_run  :  test_run = checkers.TestRun.from_module    test_run.test_suites 'addition' .register test_add   subtraction_suite = checkers.TestSuite.from_module subtraction_tests   test_run.test_suites.register subtraction_suite   return test_runif __name__ == '__main__':  pyunit.main test_run=create_test_run   If you ran that code, you'd see that 24 tests were run
google-checkers	Test Organization	In reality, only 9 testswere *actuallysome tests are in multiple suites, it is reported as 24 tests
google-checkers	Test Organization	If nothing else,you can use Checkers to grossly inflate your metrics and impress folks with yourprolific test authoring!! :smiling_imp:
google-checkers	Asserts Module  checkers.asserts 	You can use any assert engine for doing asserts, from using the assertstatement directly to using a full-blown matching framework like PyHamcrest  Checkers comes with a fewbuilt-in asserters in the checkers.asserts module.Assert | Example | Descriptionhas_length | asserts.has_length 'hello', 5  | asserts that the given iterable has the expected length
google-checkers	Test Runners  checkers.runners.pyunit 	The included test runner in the package is the PyUnit runner
google-checkers	Test Runners  checkers.runners.pyunit 	This will run theCheckers tests *in addition to any other existing unittest-based tests.pyunit.main function will call unittest.main, and pass through any providedargs, so it is very easy to integrate Checkers into existing test environments.As mentioned previously, tests are always stored in test runs in Checkers
google-checkers	Test Runners  checkers.runners.pyunit 	Soany test runner can be used that takes in test run s  and executes them.
google-checkers	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-checkers_classic	Checkers Python Unit Test Framework	This is not an official Google product.Checkers is released under the Apache 2.0 license
google-checkers_classic	Checkers Python Unit Test Framework	 See the LICENSE file for details.Checkers is a python unit test framework for defining data-driven tests.Contributions are not being accepted for this code as there are significant updates with non-backwards-compatible changes in the release pipeline which will bring new features to the framework
google-checkers_classic	Checkers Python Unit Test Framework	 Even fundamentals such as the way tests are defined will change
google-checkers_classic	Checkers Python Unit Test Framework	 Because of this, if you wish to use this package it is strongly recommended that you fork this repository
google-checkers_classic	Checkers Python Unit Test Framework	 For a preview, check out google/checkers on GitHub.Checkers builds on top of the standard python unittest module
google-checkers_classic	Checkers Python Unit Test Framework	 It also includes the assertions from the python Hamcrest library.The best documentation is the tests themselves, which are located in examples/quickstart/example#_test.py
google-checkers_classic	Checkers Python Unit Test Framework	 Example 9 was depricated, however the file remains so that test results are consistent in historical tracking.Checkers is used most-simply as follows:Tests can be automatically discovered to some degree by module, see example3_test.pyThere is some support for creating test suites from a protocol buffer, but this support will be dropped in the next version
google-checkers_classic	Checkers Python Unit Test Framework	 If this is relied upon it is *stronglyCheckers also allows the specification of startup/setup and shutdown callbacks
google-checkers_classic	Checkers Python Unit Test Framework	 See example8_test.py and example11_test.py.
google-chicago-brick	Quick Start	To use this software, first download and install  node Then, check you have a recent node:Next, install the external npm deps that aren't in the repo:Then, to run the server in 1x1 mode with stars module:And open a Chrome window to You should be able to see many stars zooming towards you.If you don't see that, try running the npm install command again.Or, to run the server in 2x2 mode with stars module:And open the client windows like so:You should be able to see the same thing with four browser windows instead.You can play with different modules by substituting the stars argumentwith other names in chicago-brick/config/demo-playlist.json.
google-chicago-brick	Modules	A chicago brick module is a directory with a brick.json file
google-chicago-brick	Modules	 This fileprovides the module's configuration
google-chicago-brick	Modules	 See examples in demo_modules
google-chicago-brick	Modules	Anydirectory  or glob  that should be included should be passed in using the--module_dir flag.
google-chicago-brick	Modules as deps	A module can be included by installing its package as a dependency
google-chicago-brick	Modules as deps	By defaultbrick will load any modules found in node_modules subdirectories.
google-chicago-brick	API Doc	You can view some API Docs at  – Chicago Brick Team
google-chkstream	Checked Exception Streams	**Checked Exception Streams*Java 8 Stream API.ChkStreams is not an official Google product.
google-chkstream	Overview	Have you ever wanted to write something like this, but been foiled by thedreaded Unhandled exception type IOException?ChkStreams extends the existing Java 8 Stream API
google-chkstream	Overview	To use it, simply: Wrap any Stream using ChkStreams.of Stream  to get a ChkStream
google-chkstream	Overview	Declare one or more checked exceptions by callingUse the same Stream API you're used to  except now your lambdas can throw theHandle the checked exceptions in the usual way  catch or declare thrown  in
google-chkstream	Features	  ChkStream#toStream   will throw unchecked exceptions  specifically  ChkStreamWrappedException  when checked exceptions occur in the stream
google-chkstream	Features	  Retrolambda  Enjoy the power of  ChkStream on Java 6+ and Android!
google-chkstream	License	This project is licensed under the GNU GPLv2 with Classpath Exception, which isthe same license as OpenJDK itself.
google-chord	Chord: Scripting Cross-Device Interactions	Chord is a framework for developers to create cross-device wearable interactionby scripting
google-chord	Chord: Scripting Cross-Device Interactions	This directory contains the implementation for the Chord frameworkand a viewer for a set of interactive emulators.*This project is previously named "Weave"
google-chord	Chord: Scripting Cross-Device Interactions	We renamed this project to avoidconfusion with the  Brillo and Weaveplatform   Note: This is a differentproject! *
google-chord	Goals	Chord provides a set of high-level APIs, based on JavaScript, for developers toeasily distribute UI output and combine user input and sensing events acrossdevices
google-chord	Goals	These high-level APIs as well as their underlying scripting conceptsallow developers to focus on their target interaction behaviors and think abouttarget devices regarding their capabilities and affordances, rather than lowChord also contributes an environment for developers to test cross-devicebehaviors, and when ready, deploy these behaviors to its runtime environment onusers’ ad-hoc network of mobile and wearable devices.
google-chord	Requirements and Setup	Chord is implemented as a Chrome packaged app
google-chord	Requirements and Setup	Please install Chrome  and load the directory viewer/ see  instructions to launch a Chrome app 
google-chord	Progress	This current version enables developers to load chord scripts and interact withthe emulators, including a smartphone, a smart watch, and a tablet.In our next update, developers will be able to connect live Android devices onthe network, and test with devices.
google-chord	Publication	This work has been published at  CHI 2015 Interaction
google-chord	Publication	In *Proceedings of the 33rd Annual ACM Conference on Human Factorsin Computing Systems  CHI 2015 *
google-chord	Publication	ACM, New York, NY, USA, 3923- DOI= 
google-chord	Disclaimer	This is not an official Google product
google-chord	Disclaimer	The application uses third partylibraries listed under the directory third_party/.
google-chord	Contacts	This package is active and maintained
google-chord	Contacts	If you have any questions, please sendthem to: Peggy Chi   peggychi@cs.berkeley.edu  mailto:peggychi@cs.berkeley.edu   and  YangLi    yangli@acm.org  mailto:yangli@acm.org  ! Chord UI  /docs/img/chord_UI.png 
google-chrome-opt-out-extension	This code has been deprecated.	The Keep My Opt-Outs project is now part of theDigital Advertising Alliance Self-Regulatory Program.Google has worked with the DAA to include theKeep My Opt-Outs functionality in the DAA's Protect My Choices Because of this, Google has ceased maintaining thisproject
google-chrome-opt-out-extension	This code has been deprecated.	You can still use the code as is under theapplicable license s , but this project is not goingto accept or receive changes anymore.
google-chrome-ssh-agent	SSH Agent for Google Chrome™	This is a bare-bones SSH agent extension for Google Chrome™
google-chrome-ssh-agent	SSH Agent for Google Chrome™	 It provides anSSH agent implementation that can be used with the Secure Shell Chrome extension 
google-chrome-ssh-agent	Installation	Install the extension from the  Chrome Web Store 
google-chrome-ssh-agent	Adding and Using Keys	Click on the SSH Agent extension's icon in to Chrome toolbar.Configure a new private key by clicking the 'Add Key' button
google-chrome-ssh-agent	Adding and Using Keys	 Give it a nameClick the 'Load' button and enter the key's passphrase to load the key intoWhen creating a new connection in the Secure Shell extension, add
google-chrome-ssh-agent	Credits	Portions of the code and approach are heavily based on the MacGyver  Chrome extension
google-chrome-ssh-agent	Credits	Inparticular, the following:    details 
google-chrome-ssh-agent	Disclaimer	This is not an officially supported Google product.
google-chrome-tabber	Chrome Tabber Project	This repository contains the open source project Chrome Tabber.This project uses the Apache license.
google-chrome-tabber	What does Chrome Tabber Do?	Chrome Tabber allows you to share your browser tabs across devices very simply,using your Google account.By default, when you open the Chrome browser, the tabs are initialized to thesame state as when you closed the browser *on that device.*Although there is a setting that lets you change that behavior, you cannoteasily restore tabs from another device
google-chrome-tabber	What does Chrome Tabber Do?	The official way to do that in Chromeis to save your current tabs as a group bookmark  *"Bookmark Open Pages..."* and then open that bookmark on another device.Chrome Tabber lets you instantly sync your tabs across Chrome browsers on anydevice logged into your Google account
google-chrome-tabber	What does Chrome Tabber Do?	It provides several modes of operationso you can customize this behavior to fit your needs.
google-chrome-tabber	How to use Chrome Tabber	After installing Chrome Tabber it will display a little icon in Chrome'sextension icon area  typically the upper right of the browser 
google-chrome-tabber	How to use Chrome Tabber	Click this iconin order see Chrome Tabber's popup UI.On Tabber's popup, you can see status, perform manual syncing, or change themode of operation
google-chrome-tabber	How to use Chrome Tabber	The mode of operation is persistent, and applies to the*current devicedevices  which is a useful and typical way to set up your devices .
google-chrome-tabber	Chrome Tabber Modes	By setting various modes on your devices, you can support different use cases.Here are some common scenarios:QUESTION: I have one main device and multiple secondary devices
google-chrome-tabber	Chrome Tabber Modes	How do I set upChrome Tabber so that whenever I start Chrome on a secondary device, it openswith the same tabs I last used on my main device?ANSWER: Set your main device to *Auto-Savedevices do not get reflected back to your main device.QUESTION: I have several devices I use
google-chrome-tabber	Chrome Tabber Modes	How do I make it so they all show thesame tabs all the time?ANSWER: Set all devices to *Fully Automatic*QUESTION: I use one device almost all the time, but occasionally I do some workon another device
google-chrome-tabber	Chrome Tabber Modes	How do I make it so that I can move from device to device,and always 'pick up where I left off?'ANSWER: There are several ways to do this: Set all devices to *Fully Automatic* Set main device to *Fully Automatic Use manual save and load operations to 'move' your work whenever you like.Best Practice: Set main device to *Fully Automatic*Startup Only.click the "Save the Tabs I have Now" button.
google-chrome-tabber	NOTE	This is not an official Google product.
google-chromeos-filesystems	Chrome OS Filesystem Providers	  travis image   travis  ! Code Climate  codeclimate image   codeclimate This repository contains various filesystem providers for Chrome OS
google-chromeos-filesystems	Chrome OS Filesystem Providers	They offer a way to access files stored on remote servers through the Files app, from a variety of sources
google-chromeos-filesystems	Chrome OS Filesystem Providers	There are two categories of provider:
google-chromeos-filesystems	Current	Work has started on the following providers
google-chromeos-filesystems	Planned	There are many more providers we would like to implement, includingTo work on any of these providers, you will need Git, Node.js, Google Chrome and Make installed
google-chromeos-filesystems	Planned	You should also install Grunt and Bower globally:All providers read the files needed by their unit tests from the server in the testserver directory
google-chromeos-filesystems	Planned	To start it:The Photoshop project files for the various sizes of icon for each provider are contained in the psd directory in the provider's directory
google-chromeos-filesystems	Planned	You will need to install  Photoshop    or a  PSD-compatible image editor  psdeditor  to edit them
google-chromeos-filesystems	Planned	Rendered icons are stored in extension/icon.It will then run indefinitely in the background on port This can be changed by modifying config.js.
google-chromeos-filesystems	Creating new providers	Please refer to the  wiki page  create-provider  for instructions on how to create your own provider
google-chromeos-filesystems	Creating new providers	Remember to follow the  guidelines  CONTRIBUTING.md  for contributing to this repository.
google-chromeos-filesystems	License	All providers are licensed under the BSD license
google-chromeos-filesystems	License	See the LICENSE file for details.All original source code is Copyright 2014 The Chromium Authors
google-chromeos-filesystems	License	travis image :  travis :  codeclimate image :  codeclimate :  photoshop :  psdeditor :  create-provider : 
google-ci_edit	What is ci_edit	ci_edit is a text editor
google-ci_edit	What is ci_edit	It can help you view or edit text files.ci_edit runs in the command line  also called the terminal 
google-ci_edit	What is ci_edit	To start usingci_edit, download ci_edit and open  execute  ci.py.
google-ci_edit	What ci_edit can do for you	Many other command line text editors require learning a different set of mouseand keyboard commands
google-ci_edit	What ci_edit can do for you	Many of us use a graphical editor  GUI  that supportsa common set of commands like ctrl+q to quit  that is, hold the control key andpress Q 
google-ci_edit	What ci_edit can do for you	Here are a few common commands:common in command line editors.So, what if you'd like to edit a file in the terminal window but don't want torecall how to save or quit in an unfamiliar editor? This is where ci_editshines, because ci_edit does support those familiar key sequences
google-ci_edit	What ci_edit can do for you	You alreadyknow how to save in ci_edit, it's ctrl+s
google-ci_edit	What ci_edit can do for you	Simple.This version of ci_edit still doesn't have all the intended features, but it'sa start
google-ci_edit	What ci_edit can do for you	It's has the necessary features of a basic text editor and a few fancyextras
google-ci_edit	What ci_edit can do for you	Those fancy extras stay out of your way until you want them.
google-ci_edit	Installation  Linux / Mac OS 	  the path to the installation file  i.e
google-ci_edit	Installation  Linux / Mac OS 	./ PATH_TO_FILE /install.sh 
google-ci_edit	Installation  Linux / Mac OS 	 link is created in the directory /usr/local/bin/, which is generally  designated for user programs not managed by the distribution package manager
google-ci_edit	Usage	  manually.The help we now need is finding out what puts users off; what causes someone whotries the editor to stop using it
google-ci_edit	Usage	We intend to address those issues so thatmore users are happy users for a longer time.
google-ci_edit	Origins	The world does need another text editor
google-ci_edit	Origins	 Or at least I think so .There are other fine curses based editors
google-ci_edit	Origins	I found that I was often trying totweak them to get just what I wanted
google-ci_edit	Origins	Almost as often, some aspect of thoseeditors prevented that last little bit of customization
google-ci_edit	Origins	So writing a texteditor should allow all the customization I like, right?Writing a text editor is an interesting project
google-ci_edit	Origins	Give it a try sometime.
google-ci_edit	Note	This is not an official Google product.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-citest	Summary	Cloud Integration Testing Framework  citest  is a python package to facilitatewriting integration tests against the REST style APIs typically used bycloud services.The gist is to allow tests to be written using a literary programming stylewhere the core framework accommodates for asynchronous calls and even retriesif appropriate.
google-citest	Setup	pip install -r requirements.txt
google-citest	Example	A test case might look something like this:  def create_google_load_balancer self :Where the test can be executed like this:
google-citest	Abstract Model	Integration tests are written against services by sending an operation tothe service then observing the effects of that operation and verifying themagainst expectations.citest introduces a BaseAgent class for adapting external servicesto the framework where the agent is responsible for understanding thetransport and protocol for exchanging messages with the service
google-citest	Abstract Model	It introducessome basic concrete types such as HttpAgent and CliAgent where the primarymeans is HTTP messaging or running a command-line program
google-citest	Abstract Model	Specific systemsmay need to further specialize these to understand any additional applicationprotocols added, such as status responses for asynchronous HTTP messaging.BaseAgent also acts as an AgentOperation factory where the operationsprovide a means to wrap these service calls as first-class objects understoodby the core citest framework
google-citest	Abstract Model	This allows citest to invoke  or reinvoke the operation when it is appropriate to do so, rather than when the static codeis specifying what the test will be
google-citest	Abstract Model	When executed, the AgentOperation willcreate an OperationStatus allowing citest to track its progress andeventual result.In order to verify the operation, citest uses Contract objects
google-citest	Abstract Model	A contractis a collection of ContractClause where each clause can look for differenteffects
google-citest	Abstract Model	A ContractClause is typically composed of an observation on theeffects and an assertion about what is expected to be observed
google-citest	Abstract Model	The observationis made by an Observer that collects data in an Observation by working witha BaseAgent to collect the data  e.g
google-citest	Abstract Model	an HTTP GET on someJSON resource 
google-citest	Abstract Model	The assertion is made by looking for expected values andpatterns in the collected resources
google-citest	Abstract Model	Each clause can collect differentThe assertions are written using specialized ValuePredicate objects, whichare python callable classes that take the object value to be validate and returna PredicateResult containing the conclusion and justification for it.When a test is run, it will provide a trace of the operations performed,data collected and justifications as to why it thinks the collected datameets or does not meet expectations, ultimately passing or failing the test.SubPackage | Purposejson_contract | Introduces a means to specify observers to collect JSON documents, and to define contracts specifying expectations of the collected JSON content.json_predicate | Introduces a means to locate and attributes within JSON objects, and compare their values
google-citest	Abstract Model	These are used as the basis of json_contract.service_testing | Introduces the core framework, base classes, and generic utilities.aws_testing | Specializations and extensions to support testing on Amazon Web Services  AWS gcp_testing | Specializations and extensions to support testing on Google Cloud Platform  GCP openstack_testing | Specializations and extensions to support testing on OpenStackazure_testing | Specializations and extensions to support testing on Microsoft Azure  AZ tests | Tests for this package
google-citest	More Examples	For more examples, see:The  Usage Overview Document  overview.md  provides some instructions andexamples to guide basic usage.
google-citest	Contributing	See the CONTRIBUTING file for more information.
google-citest	License	See the LICENSE file for more information.The package is composed of several subpackages of individual modules.
google-citest	Contact Info	For more information, problems, or interest, contact ewiseblatt@google.com.
google-clasp	Features	**🗺️ Develop Locally:***🔢 Manage Deployment Versions:***📁 Structure Code:*First download clasp: If that fails, run this: 
google-clasp	Login	Logs the user in
google-clasp	Login	Saves the client credentials to an rc file.
google-clasp	Options	Displays the help function.
google-clasp	 Get Project ID  #get-project-id 	Run clasp open.Click Resources > Cloud Platform project...Copy the project ID project-id-xxxxxxxxxxxxxxxxxxx into .clasp.json
google-clasp	 Get Project ID  #get-project-id 	It should look like this:
google-clasp	Ignore File  .claspignore 	Like .gitignore, .claspignore allows you to ignore files that you do not wish to not upload on clasp push
google-clasp	Ignore File  .claspignore 	Steps:Create a file called .claspignore in your project's root directory.Add patterns to be excluded from clasp push
google-clasp	Ignore File  .claspignore 	_Note_: The .claspignore file is parsed with  Anymatch  which is different from .gitignore, especially for directories
google-clasp	Ignore File  .claspignore 	To ignore a directory, use syntax like **/node_modules/**.A sample .claspignore ignoring everything except the manifest and build/main.js:When running clone or create, a file named .clasp.json is created in the current directory to describe clasp's configuration for the current project
google-clasp	Ignore File  .claspignore 	The following configuration values can be used in it:
google-clasp	scriptId  required 	Specifies the id of the Google Script project that clasp will target
google-clasp	scriptId  required 	It is the part located inbetween /d/ and /edit in your project's URL: /edit.
google-clasp	rootDir  optional 	Specifies the **local*
google-clasp	Troubleshooting	The library requires **Node version >= 4.7.4**
google-clasp	Troubleshooting	Use this script to check your version and **upgrade Node if necessary**:See  the develop guide  docs/develop.md  for instructions on how to build clasp
google-clasp	Troubleshooting	It's not that hard!
google-clasp	Contributing	The main purpose of this tool is to enable local Apps Script development.If you have a core feature or use-case you'd like to see, find a GitHub issue orcreate a detailed proposal of the use-case.PRs are very welcome! See the  issues   especially **good first issue*
google-clasp	How to Submit a Pull Request	Look over the test cases in tests/test.ts, try cases that the PR may affect.Run  tslint  npm run lint.Submit a pull request after testing your feature to make sure it works.⚡ Powered by the  Apps Script API 
google-classp	#BUILDING AND TESTING	The source code is in the src subdirectory
google-classp	#BUILDING AND TESTING	It runs on Linux and builds with Bison 3.02or later, Flex 2.5.39 or later, and g++ 4.8.Cd to the src directory and type  make classp  This will create all intermediate and object files as well as the executable,classp, in the srce directory
google-classp	#BUILDING AND TESTING	To run tests of the code generation type  make tests  To have some tests actually run and execute sample parses type  make samples  
google-classp	#CLASSP FOR THE IMPATIENT	After building Classp as described above, here is a quick example of using it
google-classp	#CLASSP FOR THE IMPATIENT	Supposethe main directory is DIR, then enter the following lines in the shell:It tells you what commands it is executing so that you can try themindividually if you want
google-classp	#CLASSP FOR THE IMPATIENT	It prints the string that it is about toparse: '1+2+3' and then formats the parsed AST back out: '1 + 2 + 3'.To run your own tests, build a statically linked library:The system does not have any hooks for doing anything with the AST once itis constructed other than formatting it or printing a tree representation.Essentially, this is still a demo system and not a real parsing tool.Avoid using precedence indicators on productions with array attributes
google-classp	#CLASSP FOR THE IMPATIENT	Thegrammars generated from this can cause the Bison-generated parsers to gointo an infinite loop.This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-cld3	Compact Language Detector v3  CLD3 	CLD3 is a neural network model for language identification
google-cld3	Compact Language Detector v3  CLD3 	This package contains the inference code and a trained model
google-cld3	Compact Language Detector v3  CLD3 	The inference code extracts character ngrams from the input text and computes the fraction of times each of them appears
google-cld3	Compact Language Detector v3  CLD3 	For example, as shown in the figure below, if the input text is "banana", then one of the extracted trigrams is "ana" and the corresponding fraction is 2/The ngrams are hashed down to an id within a small range, and each id is represented by a dense embedding vector estimated during training.The model averages the embeddings corresponding to each ngram type according to the fractions, and the averaged embeddings are concatenated to produce the embedding layer
google-cld3	Compact Language Detector v3  CLD3 	The remaining components of the network are a hidden  Rectified linear  layer and a softmax layer.To get a language prediction for the input text, we simply perform a forward pass through the network.! Figure  model.png "CLD3" 
google-cld3	Installation	CLD3 is designed to run in the Chrome browser, so it relies on code in Chromium The steps for building and running the demo of the language detection model are:Open a  GitHub issue  for this repository to file bugs and feature requests.
google-cld3	Announcements and Discussion	For announcements regarding major updates as well as general discussion list, please subscribe to: cld3-users@googlegroups.com 
google-cld3	Credits	Original authors of the code in this package include  in alphabetical order :
google-clerk	Clerk	Clerk is a passive netflow/IPFIX generator designed for high-throughput andtestimony-based packet sharing.
google-clerk	Architecture	clerk uses  to get packets across N threads.Currently, clerk uses a fixed template  actually 2, one for IPv4, the otherfor IPv6 :solves most of our internal needs quite nicely.
google-clerk	Disclaimer	This is not an official Google product.
google-clicktrackers-panel	Web panel simplifying clicktracker creation in DCM. AppEngine Standard compatible.	This is a Python web application that allows a quick and simple creation ofclick tracking ads in DCM
google-clicktrackers-panel	Web panel simplifying clicktracker creation in DCM. AppEngine Standard compatible.	It exposes a simple webpage with a backend meant tobe hosted on Google AppEngine Standard environment.
google-clicktrackers-panel	Setup instructions:	 Create a GCP project with AppEngine enabled Set your local env to use the newly created project in CLI Change to the directory with the source code Install google-api-python-client to lib directory pip install -t lib/ Enable DCM API Try running the app locally: dev_appserver.py 
google-clicktrackers-panel	Setup instructions:	and check that it works as Deploy the app to AppEngine gcloud app deploy and press yes Verify the deployed app works: gcloud app browse
google-clif	C++ Language Interface Foundation  CLIF 	CLIF provides a common foundation for creating C++ wrapper generators forvarious languages.
google-clif	Overview	It consists of four parts:  Matcher  Generator  Runtime
google-clif	Parser	The parser converts a language-friendly C++ API description to thelanguage-agnostic internal format and passes it to the Matcher.
google-clif	Matcher	The matcher parses selected C++ headers with Clang  LLVM's C++ compiler  andcollects type information
google-clif	Matcher	 That info is passed to the Generator.
google-clif	Generator	The generator emits C++ source code for the wrapper.The generated wrapper needs to be built according with language extension rules.Usually that wrapper will call into the Runtime.
google-clif	Runtime	The runtime C++ library holds type conversion routines that are specific toeach target language but are the same for every generated wrapper.
google-clif	Python CLIF	See complete implementation of a Python wrapper generator in the /python/subdirectory
google-clif	Python CLIF	 Both Python 2 and 3 are supported.
google-clif	Prerequisites	 We use  CMake  so make sure CMake We use Google You must have  virtualenv  You must have Subversion installed, so we can fetch LLVM
google-clif	Prerequisites	You must have pyparsing installed, so we can build protobuf
google-clif	Prerequisites	Use Make sure pkg-config --libs python works  e.g
google-clif	Prerequisites	install python-dev and
google-clif	Building	The steps below are in INSTALL.sh but outlined here for clarification.The install script sets up a Python virtual environment where it installs CLIF
google-clif	Building	Checkout LLVM and Clang source trees  the exact SVN version as specified Build and install the CLIF backend
google-clif	Building	If you use Get back to your CLIF python checkout and install it using pip.That version is guaranteed to work
google-clif	Building	Older versions likely do not work  they lacksome APIs ; later versions might work, at your own risk.INSTALL.sh will build and install CLIF for Python  and LLVM Clang as an internaltool  to your system by default in $HOME/opt/clif and $HOME/opt/clif/clang.To run Python CLIF use $HOME/opt/clif/bin/pyclif.
google-clif	Using your newly built pyclif	First, try some examples:For more details please refer to:  CLIF Python Primer  clif/python/primer.md   CLIF FAQ  clif/python/faq.md 
google-clif	Disclaimer	This is not an official Google product.
google-climb-tracker	Climb Tracker for Android and Android Wear	Android Studio project for the Climb Tracker Android app.! climbtracker-architecture Uses Firebase as storage  with offline enabled  and authentication mechanism
google-climb-tracker	Climb Tracker for Android and Android Wear	The DataApi from the Wear SDK is used to send data from the wearable to the phone.This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-clojure-turtle	clojure-turtle	clojure-turtle is a Clojure library that implements the Logo programming language in a Clojure context
google-clojure-turtle	clojure-turtle	  Quil  is used for rendering.Logo is a simple language that is useful in introducing programming to beginners, especially young ones
google-clojure-turtle	clojure-turtle	 Logo also happens to be a dialect of Lisp
google-clojure-turtle	clojure-turtle	 clojure-turtle tries to maintain those beneficial aspects of Logo while using Clojure and Clojure syntax
google-clojure-turtle	clojure-turtle	 The goal is to make learning programming and/or Clojure easier by disguising powerful concepts with fun!
google-clojure-turtle	Artifacts	clojure-turtle artifacts are  released to Clojars If you are using Maven, add the following repository definition to your pom.xml:With Leiningen:First,  install Leiningen Second, run a REPL session that has clojure-turtle loaded inside it
google-clojure-turtle	Artifacts	 This can be done in a couple of ways:Load the clojure-turtle.core namespace.The symbol repeat is overridden to behave more like the Logo function, but the Clojure core function is still available as clojure.core/repeat.Now load a new window that shows our Quil sketch using the new-window form
google-clojure-turtle	Artifacts	The sketch is where our turtle lives and operates.
google-clojure-turtle	forward, back, right, left	It's forward, back, right, and left as in Logo
google-clojure-turtle	forward, back, right, left	 Go forward and back by a length  in pixels 
google-clojure-turtle	forward, back, right, left	 Right and left turn the turtle by an angle, in degrees
google-clojure-turtle	forward, back, right, left	 It's Clojure syntax, so 'executing commands'  function calls  are done within parentheses.
google-clojure-turtle	repeat, all	repeat is like the Logo function, or like Clojure's repeatedly
google-clojure-turtle	repeat, all	 Going from the Logo syntax to clojure-turtle's syntax for repeat, commands that are being repeated are put within parentheses notation
google-clojure-turtle	repeat, all	 The square brackets that group the repeated commands are replaced with  all ..
google-clojure-turtle	repeat, all	 
google-clojure-turtle	repeat, all	 The equivalent of the Logo REPEAT 3  FORWARD 30 RIGHT 90  would beLet's see how we can simplify this.As you just saw above, we can take the instructions that we pass into repeat, give them a single name, and refer to that name to get the same effect.Let's simplify further.So given a named set of instructions, we can invoke the instructions by putting the name in parentheses just like we do for functions like forward, left, and repeat def square-and-turn  all  square   left 90    left 90  square-and-turn !  
google-clojure-turtle	penup, pendown, setxy, setheading	The turtle has a pen that it drags along where it goes, creating a drawing
google-clojure-turtle	penup, pendown, setxy, setheading	 We can pick the pen up and put the pen down when we need to draw unconnected lines
google-clojure-turtle	penup, pendown, setxy, setheading	 setxy also teleports the turtle without drawing
google-clojure-turtle	penup, pendown, setxy, setheading	 setheading turns the turtle in an exact direction.
google-clojure-turtle	clean, home	clean erases all drawing
google-clojure-turtle	clean, home	 home brings the turtle to its original position and direction.
google-clojure-turtle	color	Color can be set for the turtle
google-clojure-turtle	color	 A color is specified by a vector ofsize 1, 3, or A three-element color vector has 3 integers for the red,green, and blue components of the color  in that order  in the range0  this page for examples of specifying color in terms of RGB values
google-clojure-turtle	color	The turtle sprite  the triangle representing the turtle  will be drawnin the same color as the turtle's pen.We can also use our color value to fill the interior of shapes that wedraw
google-clojure-turtle	color	 To draw shapes will a fill color, we first have to indicatewhen we start and when we end drawing the shape
google-clojure-turtle	color	 For that, we use thestart-fill and end-fill commands
google-clojure-turtle	color	 Every line segment that the turtledraws in between start-fill and end-fill is assumed to form theperimeter of the shape.Let us define filled-octagon as the combination of commands to draw a filledoctagon
google-clojure-turtle	color	 In between the start-fill and end-fill that demarcate ourfill shape, we will use our octagon function to draw the perimeter of theoctagon that we want filled.as the "alpha" value
google-clojure-turtle	color	 In clojure-turtle, the alpha value is also aninteger that ranges from 0 to  The value 0 represents fulltransparency, and 255 represents full opacity.overlap, so we will create a points vector of 4 x,y-coordinates fromwhich we will start drawingeach octagon.set our position to that first point, and then draw our first octagonfrom there
google-clojure-turtle	color	let  point-1  first points    setxy x y    filled-octagon    Next, we will draw our the remaining 3 octagons
google-clojure-turtle	color	 Since we willperform similar actions in repetition, let's create a function tostore the behavior we want to repeat.!  A color vector of size 1 creates a grayscale color ranging from blackto white
google-clojure-turtle	color	 The grayscalecolor is equivalent to using a 3-element RGB color vector where thevalues for red, green, and blue are the same.
google-clojure-turtle	wait and animation	We can use wait to make the turtle pause
google-clojure-turtle	wait and animation	 The number passed to waitindicates how many milliseconds the turtle should wait  1 millisecond= 0.001 seconds = 1 / 1000 seconds .watch the turtle move and perceive motion
google-clojure-turtle	wait and animation	clean  home  defn slower-octagon       repeat 8  fn    repeat 12  all  slower-octagon   right 30   What happens when you combine wait with clean?  If we repeatedlydraw, wait, and clean images in a loop, we can create the effect ofmotion!  See the  Animation page  for moreinformation and examples.
google-clojure-turtle	What next?	clojure-turtle uses Quil, which uses  Processing  clojure-turtle also has the full power and fun of Clojure available to it, too.What do you get when you enter the following? defn square-by-length   side-length    repeat 4  all  forward side-length   right 90     square-by-length 10  square-by-length 20  defn times-2   x     right 90  map square-by-length  map times-2 lengths   right 90  ->> lengths defn polygon-side   num-sides side-length    forward side-length    right  / 360 num-sides    defn polygon   num-sides side-length    repeat num-sides  all  polygon-side num-sides side-length     clean  right 180  polygon 5 20  def side-counts  6 7 8 10 12   def lengths  reverse  30 40 50 60 70    map polygon side-counts lengths  defn rand-side       forward  rand-int 50     setheading  rand-int 360    fn? rand-side  fn? side  clean  home  repeat 4 side  repeat 100 rand-side What possibilities exist when you incorporate the full power of Clojure?  What can you create?
google-clojure-turtle	Using the ClojureScript Version	The same codebase in clojure-turtle can be compiled to JS and used in a JS runtime in addition to JVM bytecode
google-clojure-turtle	Using the ClojureScript Version	 A demo of the JS version can be executed by first running the command:Then, in your browser, visit the URL in the terminal output from the command -
google-clojure-turtle	Mailing List	Join the  clojure-turtle mailing list  to post questions and receive announcements.
google-clojure-turtle	How to Contribute	Interested in contributing code to the project?  We would love to haveyour help!Before you can contribute, you should first read the page on contributing  ./CONTRIBUTING.md  and agree to the ContributorLicense Agreement
google-clojure-turtle	How to Contribute	 Signing the CLA can be done online and is fast.This is a one-time process.Thereafter, contributions can be initiated through a  pullrequest 
google-clojure-turtle	License	Distributed under the Apache 2 license.
google-clojure-turtle	Disclaimer	This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-clojure-turtle	Dependencies	Quil is distributed under the Eclipse Public License either version 1.0  or at your option  any later version.The official Processing.org's jars, used as dependencies of Quil, are distributed under LGPL and their code can be found on 
google-closure-builder	Required ####	These basic required options for compiling are:These options could be used for adding additional information.The following options are available for the closure and soy compiler:To adjust the Closure compiler warnings, you could useoptions.closure.jscomp_..
google-closure-builder	Required ####	or the shortcut jscomp_....The following options are partially implemented and should not be used:is possible.If you need to know exactly if a tasks has finished you could add a callbackfunction as well.var closureBuilder = require 'closure-builder' ;var callbackExample = function errors, warnings, files, results  {  ...closureBuilder.build {  ...}, callbackExample.bind this  ;The callback will be called with the following parameters:You could define as many build rules you want.Please keep in mind to add the needed require before like:var closureBuilder = require 'closure-builder' ;var glob = closureBuilder.globSupport  ;closureBuilder.build {  ...} ;
google-closure-builder	Compile Closure JavaScript files ####	Compiling Closure JavaScript files for the given namespace to an singleJavaScript file.
google-closure-builder	Compile Closure JavaScript files with Soy files ####	Compiling Closure JavaScript files and associated Soy files to a singlejavascript file.
google-closure-builder	Compile Closure JavaScript files with externs ####	Compiling Closure JavaScript files with JavaScript externs.javascript file.
google-closure-builder	Compile Closure JavaScript files over remote service ####	Compiling Closure JavaScript files with the remote service to a singlejavascript file.Please keep in mind that the remote service is not supporting all features andoptions of the closure compiler.
google-closure-builder	Compile Closure Template files ####	Compiling Soy files into Soy JavaScript files to an targeted directory.
google-closure-builder	Compile Closure Stylesheet files ####	Compiling closure stylesheet files into css files to an targeted directory.
google-closure-builder	Compile JavaScript files ####	Combine several JavaScript files to a single JavaScript file.
google-closure-builder	Compile Node.js files ####	Combine node.js JavaScript files with browserify to a single JavaScript bundle.
google-closure-builder	Compile Rollup files ####	Combine JavaScript files with rollup to a single JavaScript bundle.
google-closure-builder	Compile CSS files ####	Combine and minified several CSS files to a single CSS file.
google-closure-builder	Copy resources ####	Copy static resources from the different location to the target directory.Copy resources from an remote location to the target directory.Convert markdown  .md  to .html file.They could be placed in an "build" folder or something like this.Example: This allows you to rebuild only some of the files if needed.Example package.json:closure-builder project.
google-closure-builder	Get the sources	Download the source files manual from GitHub or with git by running:
google-closure-builder	Init / update submodules	In some cases you need to init and update the submodules manually by:
google-closure-builder	Get required packages	Enter the "closure-builder" directory and get the required packages by:
google-closure-builder	Updating dependencies ###	Before you start working, run npm run update to update the dependencies tothe latest package versions.
google-closure-builder	Code Style ###	Run npm run lint to make sure that your code is according the general style.
google-closure-builder	Testing ###	Tests could be performed with npm run test
google-closure-builder	Testing ###	Before the test runs it willautomatically run the linter to make sure that the code has no syntax errors.
google-closure-builder	Deploying ###	Add all your files and create your commit, but instead of using "git push"directly please use npm run deploy instead.It will automatically run some tests and increase the versions number by 0.0.--------------------
google-closure-compiler-js	closure-compiler-js	**Note**: This package is now deprecated
google-closure-compiler-js	closure-compiler-js	Distribution of the JavaScript version has been moved to the main npm distribution at  This package will continueto work, but no new versions of the package will be published.Check, compile, transpile, optimize and compress JavaScript with Closure Compiler in JS.This repo tracks issues related to the publication to npmjs.org and associated plugins.Any bugs not related to the plugins themselves should be reported to the  main repository Unlike other packages, this allows Closure Compiler to run entirely in JS.*Java is not required.*This is an experimental release 
google-closure-compiler-js	Usage	*These instructions will continue to work, but the package is deprecated.Development has moved to First, install the latest version:By default, this compiles ES6 to ES5 and includes the default set of ECMAScript externs files.For example:const compile = require 'google-closure-compiler-js' .compile;const flags = {  jsCode:  {src: 'const x = 1 + 2;'} ,const out = compile flags ;console.info out.compiledCode ;  // will print 'var x = 3;\n'Or to install the command-line version, do:The google-closure-compiler-js command can read from stdin or from a file.For example:
google-closure-compiler-js	Webpack	Your webpack.config.js should look like this:const ClosureCompiler = require 'google-closure-compiler-js' .webpack;const path = require 'path' ;module.exports = {  entry:     ,  output: {  },  plugins:     
google-closure-compiler-js	Gulp	Your gulpfile.js should contain a task like this:const compiler = require 'google-closure-compiler-js' .gulp  ;gulp.task 'script', function   {  return gulp.src './path/to/src.js', {base: './'} } ;
google-closure-compiler-js	Flags	| Flag| angularPass | false | Generate $inject properties for AngularJS for functions annotated with @ngInject || applyInputSourceMaps | true | Compose input source maps into output source map || assumeFunctionWrapper | false | Enable additional optimizations based on the assumption that the output will be wrapped with a function wrapper
google-closure-compiler-js	Flags	This flag is used to indicate that "global" declarations will not actually be global but instead isolated to the compilation unit
google-closure-compiler-js	Flags	This enables additional optimizations
google-closure-compiler-js	Flags	|| checksOnly | false | Don't generate output
google-closure-compiler-js	Flags	Run checks, but no optimization passes
google-closure-compiler-js	Flags	|| compilationLevel | SIMPLE | Specifies the compilation level to use
google-closure-compiler-js	Flags	Options: WHITESPACE_ONLY, SIMPLE, ADVANCED || dartPass | false | || defines | null | Overrides the value of variables annotated with @define, an object mapping names to primitive types || env | BROWSER | Determines the set of builtin externs to load
google-closure-compiler-js	Flags	Options: BROWSER, CUSTOM || exportLocalPropertyDefinitions | false | || generateExports | false | Generates export code for those marked with @export
google-closure-compiler-js	Flags	|| languageIn | ES6 | Sets what language spec that input sources conform to
google-closure-compiler-js	Flags	|| languageOut | ES5 | Sets what language spec the output should conform to
google-closure-compiler-js	Flags	|| newTypeInf | false | Checks for type errors using the new type inference algorithm
google-closure-compiler-js	Flags	|| outputWrapper | null | Interpolate output into this string, replacing the token %output% || polymerVersion | null | Specify the Polymer version pass to use
google-closure-compiler-js	Flags	|| preserveTypeAnnotations | false | || processCommonJsModules | false | Process CommonJS modules to a concatenable form, i.e., support require statements
google-closure-compiler-js	Flags	|| renamePrefixNamespace | | Specifies the name of an object that will be used to store all non-extern globals
google-closure-compiler-js	Flags	|| rewritePolyfills | true | Rewrite ES6 library calls to use polyfills provided by the compiler's runtime
google-closure-compiler-js	Flags	|| useTypesForOptimization | false | Enable or disable the optimizations based on available type information
google-closure-compiler-js	Flags	Inaccurate type annotations may result in incorrect results
google-closure-compiler-js	Flags	|| warningLevel | DEFAULT | Specifies the warning level to use
google-closure-compiler-js	Flags	Options: QUIET, DEFAULT, VERBOSE || jsCode |    | Specifies the source code to compile
google-closure-compiler-js	Flags	|| externs |    | Additional externs to use for this compile
google-closure-compiler-js	Flags	|| createSourceMap | false | Generates a source map mapping the generated source file back to its original sources
google-closure-compiler-js	Flags	|
google-closure-compiler-js	Languages	The Closure Compiler supports the following languages:Unless you're using Gulp's or Webpack's plugins, you'll need to specify code via flags:The JavaScript version of the Closure-Compiler is transpiled by GWT from the Java source.For more details on the differences in behavior see the  super sourced files  1  in the main 1 : 
google-closure-compiler-js	Version History	Closure Compiler release notes can be found on the main repository wiki 
google-closure-compiler-js	License	Copyright © 2017 The Closure Compiler AuthorsLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-closure-compiler-npm	google-closure-compiler	    ! npm version  Check, compile, optimize and compress Javascript with Closure-CompilerThis repository tracks issues related to the publication to npmjs.org and associated plugins.Any bugs not related to the plugins themselves should be reported to the main repository 
google-closure-compiler-npm	Getting Started	If you are new to  Closure-Compiler  makesure to read and understand the compilation levels  asthe compiler works very differently depending on the compilation level selected.For help or questions with the compiler, the best resource is Stack Overflow  Posts thereare monitored by multiple Closure Compiler team members.You may also post in the Closure Compiler Discuss Google Group *Please don't cross post to both Stackoverflow and Closure Compiler Discuss.*The compiler is distributed as a Java jar and a JavaScript library
google-closure-compiler-npm	Getting Started	Mac OS and Linux also have native binaries.
google-closure-compiler-npm	Native Binary Version	On Mac OS or Linux, optional dependencies will install a native binary of the compiler.Native binaries offer faster compile times without requiring Java to be installed and available.Compilations with a very large number of source files may be slightly slower than the java version.
google-closure-compiler-npm	Java Version	const ClosureCompiler = require 'google-closure-compiler' .compiler;console.log ClosureCompiler.COMPILER_PATH ; // absolute path the compiler jarconsole.log ClosureCompiler.CONTRIB_PATH ; // absolute path the contrib folder which containsconst closureCompiler = new ClosureCompiler {  js: 'file-one.js',  compilation_level: 'ADVANCED'} ;const compilerProcess = closureCompiler.run  exitCode, stdOut, stdErr  => {  //compilation complete} ;
google-closure-compiler-npm	JavaScript Version	const ClosureCompiler = require 'google-closure-compiler' .jsCompiler;console.log ClosureCompiler.CONTRIB_PATH ; // absolute path the contrib folder which containsconst closureCompiler = new ClosureCompiler {  compilation_level: 'ADVANCED'} ;const compilerProcess = closureCompiler.run  { path: 'file-one.js', src: 'alert "hello world" ', sourceMap: null // optional input source map} ,  exitCode, stdOut, stdErr  => {  //compilation complete} ;
google-closure-compiler-npm	Usage	The simplest way to invoke the compiler  e.g
google-closure-compiler-npm	Usage	if you're just trying it out  is with  npx The npx version will attempt to detect the best platform to use
google-closure-compiler-npm	Usage	You can also specify the platformwith the special --platform flag.
google-closure-compiler-npm	Installation	See the  full list of compiler flags The build tool plugins take options objects
google-closure-compiler-npm	Installation	The option parameters map directly to thecompiler flags without the leading '--' characters
google-closure-compiler-npm	Installation	You may also use camelCase option names.Values are either strings or booleans
google-closure-compiler-npm	Installation	Options which have multiple values can be arrays.than passing the string on to the compiler
google-closure-compiler-npm	Installation	To prevent this it is necessary to quotecertain arguments:The compiler package also includes build tool plugins for  Grunt  and  Gulp  There is also an  official webpack plugin Additionally, community members have created plugins leveraging this library.
google-closure-compiler-npm	Changing the Path to the Java SDK	Override the path before first use.const Compiler = require 'google-closure-compiler' ;Compiler.prototype.javaPath = '/node_modules/MODULE_NAME/jre/jre1.8.0_131.jre/Contents/Home/bin/java';const compiler = new Compiler {args} ;
google-closure-compiler-npm	Running the compiler using nailgun	*Note: nailgun users are encouraged to try the native binary versions where available.*This gets around the long startup time of Google Closure Compiler using Nailgun  which runs a single java process in the backgroundand keeps all of the classes loaded.First you need to install closure-gun by running the following command.Then point the package to use closure-gun rather than the JDK.const compilerPackage = require 'google-closure-compiler' ;compilerPackage.compiler.JAR_PATH = undefined;compilerPackage.compiler.prototype.javaPath = './node_modules/.bin/closure-gun'Note that when using gulp, Only invocations without gulp.src work with nailgun.
google-closure-compiler-npm	Native Node Usage  for Plugin Authors 	A low-level node class is included to facilitate spawning the compiler jar as a process from Node.In addition, it exposes a static property with the path to the compiler jar file.
google-closure-compiler-npm	License	Copyright 2015 The Closure Compiler AuthorsLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-closure-compiler-npm	Version History	Closure Compiler release notes can be found on the main repository wiki 
google-closure-compiler	 Google Closure Compiler 	   ! Open Source Helpers  The  Closure Compiler  is a tool for making JavaScript download and run faster
google-closure-compiler	 Google Closure Compiler 	It is a true compiler for JavaScript
google-closure-compiler	 Google Closure Compiler 	Instead of compiling from a source language to machine code, it compiles from JavaScript to better JavaScript
google-closure-compiler	 Google Closure Compiler 	It parses your JavaScript, analyzes it, removes dead code and rewrites and minimizes what's left
google-closure-compiler	 Google Closure Compiler 	It also checks syntax, variable references, and types, and warns about common JavaScript pitfalls.
google-closure-compiler	Getting Started	Post in the  Closure Compiler Discuss Group Ask a question on  Stack Overflow Consult the  FAQ 
google-closure-compiler	Building it Yourself	Note: The Closure Compiler requires  Java 8 or higher 
google-closure-compiler	Using  Maven 	Download  Maven Add sonatype snapshots repository to ~/.m2/settings.xml:On the command line, at the root of this project, run mvn -DskipTests  omit the -DskipTests if you want to run all theunit tests too .
google-closure-compiler	Using  Eclipse 	Download and open  Eclipse IDE  Disable Project > Build automatically during this process.On the command line, at the root of this project, run mvn eclipse:eclipse -DdownloadSources=true to download JARs and build Eclipse project configuration.Run mvn clean and mvn -DskipTests to ensure AutoValues are generated and updated.In Eclipse, navigate to File > Import > Maven > Existing Maven Projects and browse to closure-compiler.Import both closure-compiler and the nested externs project.Disregard the warnings about maven-antrun-plugin and build errors.Configure the project to use the  Google Eclipse style guide Edit .classpath in closure-compiler-parent
google-closure-compiler	Using  Eclipse 	Delete the  line, then add:Ensure the Eclipse project settings specify 1.8 compliance level in "Java Compiler".Build project in Eclipse  right click on the project closure-compiler-parent and select Build Project .See *Using Maven
google-closure-compiler	Running	On the command line, at the root of this project, typeand "Enter" again
google-closure-compiler	Running	The Compiler will respond:output to a file, checking your code, and running optimizations
google-closure-compiler	Running	To learn more, documentation 
google-closure-compiler	Run using Eclipse	Open the class src/com/google/javascript/jscomp/CommandLineRunner.java or create your own extended version of the class.Run the class in Eclipse.See the instructions above on how to use the interactive modeIf you have multiple scripts, you should compile them all together with onecompile command.
google-closure-compiler	Recursively include all js files in subdirs	java -jar compiler.jar --js_output_file=out.js 'src/**.js'
google-closure-compiler	Use single-quotes, so that bash doesn't try to expand the '!'	java -jar compiler.jar --js_output_file=out.js 'src/**.js' '!**_test.js'The Closure Compiler will concatenate the files in the order they're passed atthe command line.If you're using globs or many files, you may start to run intoproblems with managing dependencies between scripts
google-closure-compiler	Use single-quotes, so that bash doesn't try to expand the '!'	In this case, you shoulduse the  Closure Library  Itcontains functions for enforcing dependencies between scripts, and Closure Compilerwill re-order the inputs automatically.
google-closure-compiler	Reporting a bug	First make sure that it is really a bug and not simply the way that Closure Compiler works  especially true for ADVANCED_OPTIMIZATIONS .If it hasn't been reported yet, post a new issue
google-closure-compiler	Reporting a bug	Make sure to add enough detail so that the bug can be recreated
google-closure-compiler	Reporting a bug	The smaller the reproduction code, the better.
google-closure-compiler	Suggesting a Feature	Consult the  FAQ  to make sure that the behaviour you would like isn't specifically excluded  such as string inlining .Make sure someone hasn't requested the same thing
google-closure-compiler	Suggesting a Feature	See the list of  known issues Read up on  what type of feature requests are accepted Submit your request as an issue.
google-closure-compiler	Submitting patches	All contributors must sign a contributor license agreement  CLA .To make sure your changes are of the type that will be accepted, ask about your patch on the  Closure Compiler Discuss Group Fork the repository.Make your changes
google-closure-compiler	Submitting patches	Check out ourSubmit a pull request for your changes
google-closure-compiler	Submitting patches	A project developer will review your work and then merge your request into the project.
google-closure-compiler	Closure Compiler License	Copyright 2009 The Closure Compiler Authors.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License at Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-closure-compiler	Rhino	          implementation of JavaScript for the JVM
google-closure-compiler	Rhino	 The JavaScriptparse tree data structures were extracted and modifiedsignificantly for use by Google's JavaScript compiler
google-closure-compiler	Rhino	 relevant to the parse tree has been removed
google-closure-compiler	Rhino	A JsDoc parser and static typingsystem have been added
google-closure-compiler	Rhino	 
google-closure-compiler	Args4j	        options/arguments in your CUI application
google-closure-compiler	Args4j	   
google-closure-compiler	Guava Libraries	            
google-closure-compiler	JSR 305	            
google-closure-compiler	JUnit	            
google-closure-compiler	Protocol Buffers	        an encoding of structured data
google-closure-compiler	Protocol Buffers	   
google-closure-compiler	Truth	            
google-closure-compiler	Ant	        without make's wrinkles and with the full portability of pure java code
google-closure-compiler	Ant	   
google-closure-compiler	GSON	            
google-closure-compiler	Node.js Closure Compiler Externs	              
google-closure-library	Closure Library   	Closure Library is a powerful, low-level JavaScript library designedfor building complex and scalable web applications
google-closure-library	Closure Library   	It is used by manyGoogle web applications, such as Google Search, Gmail, Google Docs,Google+, Google Maps, and others.For more information, visit the Google Developers  or GitHub  sites.Download the latest stable version on our  releases page Developers, please see the Generated API Documentation See also the goog.ui Demos 
google-closure-library	Using with Node.js	Install the  official package  from npm.require "google-closure-library" ;goog.require "goog.crypt.Sha1" ;var sha1 = new goog.crypt.Sha1  ;sha1.update "foobar" ;var hash = sha1.digest  ;
google-closure-linter	Closure Linter 	Please note that the **closure linter is deprecated**
google-closure-linter	Closure Linter 	Esp
google-closure-linter	Closure Linter 	if you use ES6features, the tool will not work for you.To install the application, run python ./setup.py installAfter installing, you get two helper applications installed into /usr/local/bin:
google-closure-stylesheets	Closure Stylesheets	Closure Stylesheets is an extension to CSS that adds** variables  #variables **, ** functions  #functions **,** conditionals  #conditionals **, and ** mixins  #mixins *CSS
google-closure-stylesheets	Closure Stylesheets	The tool also supports ** minification  #minification **,** linting  #linting **, ** RTL flipping  #rtl-flipping **, and CSS class** renaming  #renaming **.
google-closure-stylesheets	Get Closure Stylesheets!	Closure Stylesheets is available as a Java jar named closure-stylesheets.jar.You can either  download  a precompiled jar or  build it from source .Using Closure Stylesheets requires Java
google-closure-stylesheets	Get Closure Stylesheets!	To make sure that Java is installedcorrectly, try running the following command to print the list of command-lineoptions for Closure Stylesheets: build it from source :Internally at Google, Closure Stylesheets are frequently referred to as "GoogleStylesheets" or "GSS", so you will see references to GSS in the source code  Somedevelopers prefer to be explicit about which files use the Closure Stylesheetsextensions to CSS by using a **.gss*
google-closure-stylesheets	Variables	Variables can be defined in Closure Stylesheets using **@def*variable name and then a value
google-closure-stylesheets	Variables	Variables can also be defined in terms of othervariables
google-closure-stylesheets	Variables	Consider the following file, **variable-example.gss**:@def BG_COLOR@def DIALOG_BORDER_COLOR   rgb 107, 144, 218 ;@def DIALOG_BG_COLORbody {  background-color: BG_COLOR;.dialog {  background-color: DIALOG_BG_COLOR;  border: 1px solid DIALOG_BORDER_COLOR;Running **java -jar closure-stylesheets.jar --pretty-printClosure Stylesheets provides support for several arithmetic functions:purely numeric or CSS sizes with units  though add 3px, 5ex 
google-closure-stylesheets	Variables	Here is an example of when it might be helpful to use add  :@def LEFT_HAND_NAV_WIDTH@def LEFT_HAND_NAV_PADDING  3px;.left_hand_nav {  position: absolute;  width: LEFT_HAND_NAV_WIDTH;  padding: LEFT_HAND_NAV_PADDING;.content {  position: absolute;  margin-left: add LEFT_HAND_NAV_PADDING,  /Running **java -jar closure-stylesheets.jar --pretty-print CSS3 calc    because they do not allowyou to mix units as calc   does, they can still help produce more maintainableThere are also built-in functions that deal with colors
google-closure-stylesheets	Variables	For now, you need to see the code for details, but here are the functions and the arguments that they take:It is also possible to define your own functions in Java by implementing GssFunctionMapProvider and passing the fully-qualified class name to Closure Stylesheets via thelikely want to compose DefaultGssFunctionMapProvider so that your GssFunctionMapProvider provides your custom functions in addition to the built-in arithmetic functions.
google-closure-stylesheets	Mixins	Mixins make it possible to reuse a list of parameterized declarations
google-closure-stylesheets	Mixins	A mixindefinition  **@defmixin**  can be seen as a function with arguments thatcontains a list of declarations
google-closure-stylesheets	Mixins	At the place where a mixin is used **@mixin** , the values for the arguments are defined and the declarationsare inserted
google-closure-stylesheets	Mixins	A mixin can be used in any place where declarations are allowed.The names of the arguments in the **@defmixin*Global constants defined with **@def*mixins
google-closure-stylesheets	Mixins	They can be used both within the definition of a mixin, or as anargument when using a mixin.For example, consider defining a mixin in **mixin-simple-example.gss*could be used to create a shorthand for declaring the dimensions of an element:@defmixin size WIDTH, HEIGHT  {  width: WIDTH;  height: HEIGHT;.logo {  @mixin size 150px, 55px ;  background-image: url 'Running **java -jar closure-stylesheets.jar --pretty-printcross-browser behavior for styles such as gradients:@defmixin gradient POS, HSL1, HSL2, HSL3, COLOR, FALLBACK_COLOR  {  background-color: FALLBACK_COLOR; /  background-image: -webkit-linear-gradient POS, hsl HSL1, HSL2, HSL3 , COLOR ;  /  /  /.header {  @mixin gradient top, 0%, 50%, 70%, #cc0000, #f07575 ;The above is compiled to:
google-closure-stylesheets	Conditionals	Variables can be defined using conditionals with **.goog-inline-block, but it can be done explicitly in Closure Stylesheets byusing conditionals as shown in **conditionals-example.gss**:@if  BROWSER_IE  {  @if  BROWSER_IE6  {  } @elseif  BROWSER_IE7  {  } @else {  }} @elseif  BROWSER_FF2  {  @def GOOG_INLINE_BLOCK_DISPLAY} @else {  @def GOOG_INLINE_BLOCK_DISPLAY.goog-inline-block {  position: relative;  display: GOOG_INLINE_BLOCK_DISPLAY;Values for the conditionals can be set via a **--define*all conditional variables are assumed to be false, so running **java -jarclosure-stylesheets.jar --pretty-print conditionals-example.gss*-jar closure-stylesheets.jar --define BROWSER_IE --define BROWSER_IE6--pretty-print conditionals-example.gss*agent, one must generate a separate stylesheet for each user agent and thenserve it appropriately.
google-closure-stylesheets	Additional Features	The Closure Stylesheets tool also offers some features that are not extensionsto CSS.
google-closure-stylesheets	Minification	You can concatenate and minify a list of stylesheets with the following command:to write the output to using the **--output-file***MOZILLA**, **OPERA**, **MICROSOFT**, and **KONQUEROR**
google-closure-stylesheets	Minification	When this flagis present, all vendor-specific properties for other vendors will be removed.
google-closure-stylesheets	Linting	Closure Stylesheets performs some static checks on your CSS
google-closure-stylesheets	Linting	For example, itsmost basic function is to ensure that your CSS parses: if there are any parseerrors, Closure Stylesheets will print the errors to standard error and returnwith an exit code of 
google-closure-stylesheets	--allowed-non-standard-function, --allow-unrecognized-functions	It will also error out when there are unrecognized function names or duplicatestyle declarations
google-closure-stylesheets	--allowed-non-standard-function, --allow-unrecognized-functions	For example, if you ran Closure Stylesheets onUnknown function \"urel\" in linting-example.gss at line 4 column 21:  background-image: urel 'Detected multiple identical, non-alternate declarations in the same ruleset.If this is intentional please use the /border-color: rgba 0,0,0,0.1   in linting-example.gss at line 7 column 1:^2 error s In this particular case, the function urel   should have been url  , thoughif you are using a function that is not on the whitelist  see CssFunctionNode for the list of recognized functions, which is admittedly incomplete , then youcan specify **--allowed-non-standard-function*functions that should be whitelisted:It is also possible to disable the check for unknown functions altogether usingthe **--allow-unrecognized-functions*Further, in this example, the multiple declarations of border-color areintentional
google-closure-stylesheets	--allowed-non-standard-function, --allow-unrecognized-functions	They are arranged so that user agents that recognize rgba   willuse the second declaration whereas those that do not will fall back on the firstdeclaration
google-closure-stylesheets	--allowed-non-standard-function, --allow-unrecognized-functions	In order to suppress this error, use the /annotation that the error message suggests as follows:error
google-closure-stylesheets	--allowed-non-standard-function, --allow-unrecognized-functions	It is also common to use this technique with multiple backgrounddeclarations that use -webkit-linear-gradient, -moz-linear-gradient, etc
google-closure-stylesheets	--allowed-non-standard-function, --allow-unrecognized-functions	Ingeneral, using  conditionals  #Conditionals.md  to select the appropriatedeclaration based on user agent is preferred; however, that requires theadditional overhead of doing user agent detection and serving the appropriatestylesheet, so using the @alternate annotation is a simpler solution.
google-closure-stylesheets	--allow-unrecognized-properties, --allowed-unrecognized-property	By default, Closure Stylesheets validates the names of CSS properties used in astylesheet
google-closure-stylesheets	--allow-unrecognized-properties, --allowed-unrecognized-property	We have attempted to capture all legal properties in the hardcoded list of recognized properties that is bundled with Closure Stylesheets
google-closure-stylesheets	--allow-unrecognized-properties, --allowed-unrecognized-property	However, you can allow properties thataren't in the list with the **--allowed-unrecognized-property*the file **bleeding-edge.gss**:-webkit-amp-volume is an unrecognized property in bleeding-edge.gss at line 3 column 3:  -webkit-amp-volume: 11;  ^1 error s You can whitelist -webkit-amp-volume with thespecified multiple times, once for each property to whitelist
google-closure-stylesheets	--allow-unrecognized-properties, --allowed-unrecognized-property	We discourageusing the blanket --allow-unrecognized-properties because it lets througheverything, including simple spelling mistakes.Note that some recognized properties will emit warnings
google-closure-stylesheets	--allow-unrecognized-properties, --allowed-unrecognized-property	These warnings will notbe silenced with the --allowed-unrecognized-property flag.
google-closure-stylesheets	RTL Flipping	Closure Stylesheets has support for generating left-to-right  LTR  as well asright-to-left  RTL  stylesheets
google-closure-stylesheets	RTL Flipping	By default, LTR is the assumed directionalityfor both the input and output, though those settings can be overridden byFor example, consider the following stylesheet, **rtl-example.gss**, which isdesigned for an LTR page:.logo {  margin-left: 10px;.shortcut_accelerator {  /  /  border-right:\t2px solid #ccc;  padding: 0 2px 0 4px;Generating the equivalent stylesheet to use on an RTL version of the page can beachieved by running **java -jar closure-stylesheets.jar --pretty-print--output-orientation RTL rtl-example.gss**, which prints:property instead of alongside it:Closure Stylesheets makes it possible to rename CSS class names in the generatedstylesheet, which helps reduce the size of the CSS that is sent down to yourusers
google-closure-stylesheets	RTL Flipping	Of course, this is not particularly useful unless the class names arerenamed consistently in the HTML and JavaScript files that use theCSS
google-closure-stylesheets	RTL Flipping	Fortunately, you can use the Closure Compiler  to update the classnames in your JavaScript and Closure Templates  to update theclass names in your HTML.To get the benefits of CSS renaming in Closure, instead of referencing a CSSclass name as a string literal, you must use that string literal as an argumentto goog.getCssName  : css command {namespace example} */{template .dialog}  {$title}  {call .content data=\"all\" /}When you generate the JavaScript for the template, be sure to use the--cssHandlingScheme GOOG option with SoyToJsSrcCompiler
google-closure-stylesheets	RTL Flipping	This ensures thatthe generated JavaScript code will also use goog.getCssName  
google-closure-stylesheets	RTL Flipping	For example, ifthe above were named **dialog.soy**, then the following command would be usedto create **dialog.soy.js**:// This file was automatically generated from dialog.soy.// Please don't edit this file by hand.goog.provide 'example' ;goog.require 'soy' ;goog.require 'example' ;example.dialog = function opt_data  {  return '            This ensures that when **goog.getCssName 'dialog-content' *returns **'a-b'**
google-closure-stylesheets	RTL Flipping	In this way, the abbreviated name is used in place of theoriginal name throughout the code.An astute reader will note that so far, we have reduced only the size of thestylesheet, but not the JavaScript
google-closure-stylesheets	RTL Flipping	To reduce the size of the JavaScript code,we must use the  Closure Compiler  in SIMPLE or ADVANCED mode with the **--process_closure_primitives*default 
google-closure-stylesheets	RTL Flipping	When enabled, if it finds a call to **goog.setCssNameMapping  *any of its inputs, it will use the argument to goog.setCssNameMapping   as thebasis of a renaming map that is applied at compile time
google-closure-stylesheets	RTL Flipping	To create theappropriate renaming map with Closure Stylesheets, use **CLOSURE_COMPILED*the argument to **--output-renaming-map-format**:our original snippet of JavaScript code:**renaming_map.js**, it will be transformed to the following afterthe behavior of the application.Admittedly, using CSS renaming is a fairly advanced option that requires awell-organized build system to ensure that the appropriate CSS and JS assets areproduced for both development and production
google-closure-stylesheets	RTL Flipping	See MoreOnCssRenaming for moredetails on this topic.by using the **--excluded_classes_from_renaming*if some of your HTML is generated by a process that does not take CSS renaminginto account
google-closure-stylesheets	RTL Flipping	For example, if you are using a Python Django server and are usingits template system, then any CSS classes used in those templates will not berenamed  unless you introduce a process to do so 
google-closure-stylesheets	RTL Flipping	In order to ensure that theJS and CSS that use the HTML reference CSS classes consistently, each CSS classin the Django template should be passed as an argument to Closure Stylesheetswith the **--excluded_classes_from_renaming*References to CSS class names that are excluded from renaming should _never_ bewrapped in goog.getCssName  , or else they run the risk of being partially
google-closure-templates	Closure Templates	Closure Templates are a clientdynamically build reusable HTML and UI elements
google-closure-templates	Closure Templates	They have a simple syntaxthat is natural for programmers, and you can customize them to fit yourapplication's needs
google-closure-templates	Closure Templates	 In contrast to traditional templating systems,in whichyou must create one monolithic template per page, you can think ofClosure Templates as small components that you compose to form your userinterface
google-closure-templates	Closure Templates	You can also use the built-in message support to easily localizeyour applications.Closure Templates are implemented for both JavaScript and Java, so that you canuse the same templates on both the server and client side
google-closure-templates	Closure Templates	They use a data modeland expression syntax that work for either language
google-closure-templates	Closure Templates	For the client side,Closure Templates are precompiled into efficient JavaScript.
google-closure-templates	What are the benefits of using Closure Templates?	  extra readability
google-closure-templates	What are the benefits of using Closure Templates?	 You can put multiple templates in one source file.
google-closure-templates	Getting Started	Closure Templates is widely used and well maintained internally at Google butdoes not currently have staffing to support the open source release
google-closure-templates	Getting Started	 As suchthis project is mostly a 'code dump' and support is _minimal_
google-closure-templates	Getting Started	 For certainissues, like build integration we are in an especially bad position to offerTo get assistance you can use any of the following forumsLook through the  documentation Post a question to the  closure-templates-discuss File a  bug on github Though, given our support staffing, we may not be able to help.
google-closure-templates	Using Closure Templates with other open source frameworks	There are many Closure Template integrations with other popular open sourceframeworks
google-closure-templates	Using Closure Templates with other open source frameworks	Here are a few options for getting started:  *  *  * 
google-cloud-berg	Design goal	Berg is a minimal tool for running experiments with GPU instances on Cloud and storing the results in a bucket
google-cloud-berg	Design goal	It’s 400 lines of python
google-cloud-berg	Non-goals	Clone and install the berg tool on your local machineAfter installing gcloud, run the following locallyLaunch two experiments  that each use all the GPUs on single instance, and shut down after they complete their job The python command will be run from the root of your github repo
google-cloud-berg	Non-goals	It will run rsync files from /root/berg_results/sweep1/ and results will show up in  gs:///berg_results/sweep1
google-cloud-berg	Launch a devbox with 4 p100 gpus, CUDA, Tensorflow and Pytorch	After it starts you can ssh into it with berg ssh 
google-cloud-berg	How does berg work?	The best way to understand berg is to just read the code  it's very small 
google-cloud-berg	How does berg work?	Here’s an even shorter TLDR:Executing berg run  does the following:Helpful shortcuts  all of which are aliases for gcloud commands You can also use the gce web interface which allows filtering and bulk management of all of your instances.
google-cloud-berg	Running a large scale job with MPI	This will start num_machines devboxes with 4 GPUs each
google-cloud-berg	Running a large scale job with MPI	Then ssh into the first machine, and run mpi  to run your program across all machines using MPI
google-cloud-berg	Running a large scale job with MPI	Here mpi is an alias calling mpirun with all the necessary flags, and starting one worker process per GPU in your cluster
google-cloud-berg	Running a large scale job with MPI	The easiest way of running multi machine tensorflow/pytorch experiments is to use Horovod, which now comes pre-installed on the golden image.
google-cloud-berg	Creating a custom golden image	If you’d like to use a different image, you can edit the default_image value in ~/.berg/berg.jsonWe recommend starting with one of the  official GCE deep learning images  and then modifying it slightly.Berg will log into your image as the root user, and requires the following:
google-cloud-cup-android	Cloud Cup Android client	This repository contains the source code of the player screen of the Cloud Cup game
google-cloud-cup-android	Cloud Cup Android client	Click for video: ! Cloud Cup video thumbnail  It is an Android application, designed to be built using Android Studio.It relies on the  Firebase Android SDK  to provide backend and real-time features.This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-cloud-cup	Cloud Cup Main screen	This repository contains the source code of the main screen of the Cloud Cup game.Click for video: ! Cloud Cup video thumbnail  It is a web application, built using AngularJS and relying on Firebase
google-cloud-cup	Cloud Cup Main screen	It has been boostrapped using the  angular-seed  project.This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-cloud-cup	Install Dependencies	We have two kinds of dependencies in this project: tools and angular framework code
google-cloud-cup	Install Dependencies	 The tools helpus manage and test the application.folders in your project.angularfire-seed changes this location through the .bowerrc file
google-cloud-cup	Install Dependencies	 Putting it in the app folder makesit easier to serve the files by a webserver.*
google-cloud-cup	Configure the Application	 Open app/js/config.js and add your Firebase URL Go to your Firebase dashboard and enable email/password authentication under the Simple Login tab Copy/paste the contents of config/security-rules.json into your Security tab, which is also under your Firebase dashboard.
google-cloud-cup	Run the Application	We have preconfigured the project with a simple development web server
google-cloud-cup	Run the Application	 The simplest way to startthis server is:
google-cloud-cup	Deploying the application to Firebase Hosting	Simply type firebase deploy
google-cloud-print-connector	Introduction	Share printers from your Windows, Linux, FreeBSD or OS X computer with ChromeOS and Android devices, using the Cloud Print Connector
google-cloud-print-connector	Introduction	The Connector is a purpose-built system process
google-cloud-print-connector	Introduction	It can share hundreds of printers on a powerful server, or one printer on a Raspberry Pi.Lots of help can be found in  the wiki 
google-cloud-print-connector	Mailing list	Please join the mailing list at  Anyone can post and view messages.
google-cloud-print-connector	Build Status	Copyright 2015 Google Inc
google-cloud-print-connector	Build Status	All rights reserved.Use of this source code is governed by a BSD-stylelicense that can be found in the LICENSE file or at
google-cloudevents-demo	Demo for Kubecon	This repo contains source for the CloudEvents demo at KubeCon Copenhagen.The demo receives CloudEvents version 0.1 from from the storage systems inAmazon S3, Microsoft Azure, and Google Cloud Storage
google-cloudevents-demo	Demo for Kubecon	The event handlerthen performs some trivial operation  Computer vision  and posts the resultsto Twitter.You can see a live version of this demo at @CloudEventsBot 
google-cloudevents-demo	Code Structure	  Structured HTTP encoding.| Product| --------------------| pkg/event| cmd/sendevent| cmd/twittervision | See separate  README  cmd/twittervision/README.md  || eventsource
google-cloudprober	Cloudprober	 cloudprober.org Cloudprober is a monitoring software that makes it super-easy to monitoravailability and performance of various components of your system
google-cloudprober	Cloudprober	Cloudproberemploys the "active" monitoring model
google-cloudprober	Cloudprober	It runs probes against  or on  yourcomponents to verify that they are working as expected
google-cloudprober	Cloudprober	For example, it can runa probe to verify that your frontends can reach your backends
google-cloudprober	Cloudprober	Similarly it canrun a probe to verify that your in-Cloud VMs can actually reach your on-premisesystems
google-cloudprober	Cloudprober	This kind of monitoring makes it possible to monitor your systems'interfaces regardless of the implementation and helps you quickly pin downwhat's broken in your system.! Cloudprober UseCase 
google-cloudprober	Features	Visit  cloudprober.org  to get started with Cloudprober.We'd love to hear your feedback
google-cloudprober	Features	If you're using Cloudprober, would you pleasemind sharing how you use it by adding a comment to the  issue #123   It will be a great help inplanning Cloudprober's future progression.Join  Cloudprober Group  fordiscussion and release announcements.
google-clspv	clspv	compute shaders.It consists of:Clspv depends on external projects:Clspv is licensed under the terms of the  Apache 2.0 license  LICENSE .The  AUTHORS  AUTHORS  file lists the copyright owners, while individualcredit is given in the  CONTRIBUTORS  CONTRIBUTORS  file.To contribute, see  CONTRIBUTING.md  CONTRIBUTING.md .Materials in projects Clspv depends on are licensed undertheir own terms.Clspv is not an official Google product.
google-clspv	Status	The compiler is an incomplete prototype, with many rough edges.The input language is a subset of OpenCL C version 1.The  OpenCL C on Vulkan Specification  docs/OpenCLCOnVulkan.md describes the specific subset, and also the mapping into Vulkan compute
google-clspv	Examples	Compile a set of kernels into a SPIR-V binary module:Emit SPIR-V assembly:Emit SPIR-V assembly to standard output:Emit the binary as a C initializer list, for easy embedding of a shader inin a C or C++ program source:Predefine some preprocessor symbols:Use OpenCL compiler options:Show help:
google-clspv	Tools	You will need:Clspv depends on the sources for other projects, at specific commits.Run the following command to download those dependencies, and place themin the third_party directory:
google-clspv	Building	Then, create a build directory:Then configure and build the code:This will build the clspv command line compiler and place it inlocation bin/clspv under the build directory.
google-clspv	Using Ninja to build, and other build options	We recommend you use the  Ninja  Ninja  build tool if it's available.To do so, replace the last two commands with:Other useful configuration options  the first cmake command :See the  CMake  CMake   documentation  CMake-doc  for more generic options.
google-clspv	Test	To run the test suite from within the build directory:Or if you are using Ninja: Clang :  CMake-doc :  CMake :  LLVM :  Ninja :  SPIRV-Headers :  SPIRV-Tools : 
google-cluster-data	Overview	This repository describes various traces from parts of the Google clustermanagement software and systems.Please let us know about any issues, insights, or papers you publish using thesetraces bysending  email  mailto:googleclusterdata-discuss@googlegroups.com to the discussion group  And please join this group to be kept up to date with new announcements! The more specific the data, the more likely we are to be able to help you.If you have  or generate  tools that help analyze or decode the trace data, oruseful analyses, do please share them with this community.A ** trace bibliography  bibliography.bib *about or derived from these traces
google-cluster-data	Overview	 If you publish one, please email  mailto:googleclusterdata-discuss@googlegroups.com  a bibtex entry forit, so it can be added to the bibliography
google-cluster-data	Overview	  Try to mimic the format used thereas exactly as possible
google-cluster-data	Cluster workload traces	These are traces of workloads running on Google compute cells.
google-cluster-data	ETA traces	These are  execution traces from ETA  ETAExplorationTraces.md   ExploratoryTesting Architecture  between distrinbuted, concurrently-executing components.
google-cluster-insight	Cluster Insight: a context graph generator for Kubernetes clusters	Cluster Insight is a Kubernetes service that collects runtime metadata about resources in a Kubernetes cluster, and infers relationships between them to create a *context graph*.A context graph is a point-in-time snapshot of the cluster’s state
google-cluster-insight	Cluster Insight: a context graph generator for Kubernetes clusters	Clients of the Cluster Insight service, such as user interfaces, can retrieve context graphs through the service's REST API
google-cluster-insight	Cluster Insight: a context graph generator for Kubernetes clusters	Each call may produce a different context graph, reflecting the inherent dynamicity in the Kubernetes cluster.A context graph provides contextual information that can be combined with resource level monitoring data to enable visual navigation of the dynamic state of a Kubernetes cluster.The nodes of the context graph are cluster resources  cluster, nodes, services, replication controllers, pods, containers, and images , and the edges are the inferred relationships  contains, runs, monitors, loadBalances, createdFrom .
google-cluster-insight	How to set up and access the service	Deploying Cluster Insight involves creating a service and a replication controller
google-cluster-insight	How to set up and access the service	The replication controller creates one pod, which contains one container
google-cluster-insight	How to set up and access the service	The container image is  here  on Docker Hub.
google-cluster-insight	Preliminaries	In the following, we will assume that you have a Kubernetes cluster running and kubectl configured to talk to it
google-cluster-insight	Preliminaries	If you have set up the Kubernetes cluster from the command line with gcloud container clusters create or kube-up.sh, then kubectl will have been configured for you
google-cluster-insight	Preliminaries	If you have set it up from the Google Developers Console, you can configure kubectl by running gcloud container clusters get-credentials.If you have several Kubernetes clusters configured, you can determine the corresponding *context names
google-cluster-insight	Setup	Assuming you have configured kubectl to talk to your Kubernetes cluster, deploying Cluster Insight is a simple matter of invoking kubectl create:
google-cluster-insight	Access	Cluster Insight provides detailed information about your cluster, including the values of environment variables, which many people use to inject secret credentials into containers
google-cluster-insight	Access	Access to its API needs to be restricted
google-cluster-insight	Access	An easy and safe way to access it is using kubectl proxy.Cluster Insight makes its REST API available through the cluster-insight service in the default namespace, on the named port cluster-insight
google-cluster-insight	Access	With kubectl proxy running, the help page for the API will be available at the following URL:It is easy to run Cluster Insight locally on your workstation for development purposes:git clone  --branch=v2cd cluster-insight/collectorpip install -r requirements.txtexport KUBERNETES_API=python collector.py --debug --host=localhostRunning the pip and python commands above under  virtualenv  is highly recommended, but not required.Now the Cluster Insight help page will be available at    and if you have kubectl proxy running, the REST API will be operational.
google-cluster-insight	REST API	Cluster Insight makes available the following endpoints:
google-cluster-insight	Context graph format	The context graph is a JSON document with the following format:Resources and relations have a timestamp attribute, indicating when they were first observed or inferred, respectively
google-cluster-insight	Context graph format	The timestamp value should remain constant as long as the corresponding resource or relation did not change substantially.When comparing resource values, we compute the hash of the JSON representation after removing the attributes timestamp, lastHeartbeatTime and resourceVersion, because their values are ephemeral and do not indicate a substantial change in the corresponding resource
google-cluster-insight	Context graph format	All data older than one hour is deleted automatically from the cache
google-cluster-insight	Context graph format	The value of the timestamp attribute will therefore remain constant for at most one hour.The entire context graph has a separate timestamp, which is the maximum of the timestamps of the resources and relations contained in the graph
google-cluster-insight	Context graph format	If the timestamp of the entire context graph did not change, then there wasno substantial change in any of the resources and relations inside it.
google-cluster-scheduler-simulator	Cluster scheduler simulator overview	This simulator can be used to prototype and compare different cluster scheduling strategies and policies
google-cluster-scheduler-simulator	Cluster scheduler simulator overview	It generates synthetic cluster workloads from empirical parameter distributions  thus generating unique workloads even from a small amount of input data , simulates their scheduling and execution using a discrete event simulator, and finally permits analysis of scheduling performance metrics.The simulator was originally written as part of research on the "Omega" shared-state cluster scheduling architecture at Google
google-cluster-scheduler-simulator	Cluster scheduler simulator overview	A paper on Omega, published at EuroSys 2013, uses of this simulator for the comparative evaluation of Omega and other alternative architectures  referred to as a "lightweight" simulator there   1 
google-cluster-scheduler-simulator	Cluster scheduler simulator overview	As such, the simulators design is somewhat geared towards the comparative evaluation needs of this paper, but it does also permit more general experimentation with:
google-cluster-scheduler-simulator	Downloading, building, and running	The source code for the simulator is available in a Git repository hosted on Google Code
google-cluster-scheduler-simulator	Downloading, building, and running	Instructions for downloading  can be found at at The simulator is written in Scala, and requires the Simple Build Tool  sbt  to run
google-cluster-scheduler-simulator	Downloading, building, and running	A copy of sbt is package with the source code, but you will need the following prerequisites in order to run the simulator:
google-cluster-scheduler-simulator	Using command line flags	The simulator can be passed some command-line arugments via configuration flags, such as --thread-pool-size NUM_THREADS_INT and --random-seed SEED_VAL_INT
google-cluster-scheduler-simulator	Using command line flags	To view all options run:Note that when passing command line options to the sbt run command you need to include the word run and all of the options that follow it within a single set of quotes
google-cluster-scheduler-simulator	Using command line flags	sbt can also be used via the sbt console by simply running bin/sbt which will drop you at a prompt
google-cluster-scheduler-simulator	Using command line flags	If you are using this sbt console option, you do not need to put quotes around the run command and any flags you pass.
google-cluster-scheduler-simulator	Configuration file	If a file conf/cluster-sim-env.sh exists, it will be sourced in the shell before the simulator is run
google-cluster-scheduler-simulator	Configuration file	This was added as a way of setting up the JVM  e.g
google-cluster-scheduler-simulator	Configuration file	heap size  for simulator runs
google-cluster-scheduler-simulator	Configuration file	Check out conf/cluster-sim-env.sh.template as a starting point; you will need to uncomment and possibly modify the example configuration value set in that template file  and, of course, you will need to create a copy of the file removing the ".template" suffix .
google-cluster-scheduler-simulator	Configuring experiments	The simulation is controlled by the experiments configured in the src/main/scala/Simulation.scala setup file
google-cluster-scheduler-simulator	Configuring experiments	Comments in the file explain how to set up different workloads, workload-to-scheduler mappings and simulated cluster and machine sizes.Most of the workload setup happens in src/main/scala/Workloads.scala, so read through that file and make modifications there to have the simulator read from a trace file of your own  see more below about the type of trace files the simulator uses, and the example files included .Workloads in the simulator are generated from *empirical parameter distributions*
google-cluster-scheduler-simulator	Configuring experiments	These are typically based on cluster *snapshotsFor further details, see traces/README.txt and traces/job-distribution-traces/README.txt.**Please note that the resource amounts specified in the example data files, and the example cluster machines configured in Simulation.scala do *notA possible starting point for generating realistic input data is the public Google cluster trace  2, 3 
google-cluster-scheduler-simulator	Configuring experiments	It should be straightforward to write scripts that extract the relevant data from the public trace's event logs
google-cluster-scheduler-simulator	Configuring experiments	Although we do not provide such scripts, it is worth noting that the "cluster C" workload in the EuroSys paper  1  represents the same workload as the public trace
google-cluster-scheduler-simulator	Configuring experiments	 If you do write scripts for converting the public trace into simulator format, please let us know, and we will happily include them in the simulator code release! 
google-cluster-scheduler-simulator	Experimental results: post-processing	Experimental results are stored in serialized Protocol Buffers in the experiment_results directory at the root of the source tree by default: one subdirectory for each experiment, and with a unique name identifying the experimental setup as well as the start time
google-cluster-scheduler-simulator	Experimental results: post-processing	The schemas for the .protobuf files are stored in src/main/protocolbuffers.A script for post-processing and graphing experimental results is located in src/main/python/graphing-scripts, and src/main/python also contains scripts for converting the protobuf-encoded results into ASCII CSV files
google-cluster-scheduler-simulator	Experimental results: post-processing	See the README file in the graphing-scripts directory for detailed explanation.
google-cluster-scheduler-simulator	Changing and compiling the protocol buffers	If you make changes to the protocol buffer file  in src/main/protocolbuffers , you will need to recompile them, which will generate updated Java files in src/main/java
google-cluster-scheduler-simulator	Changing and compiling the protocol buffers	To do so, you must install the protcol buffer compiler and run src/main/protocolbuffers/compile_protobufs.sh, which itself calls protoc  which it assumes is on your PATH .
google-cluster-scheduler-simulator	Known issues	Please use  the Google Code  project issue tracker  for all bug reports, pull requests and patches, although we are unlikely to be able to respond to feature requests
google-cluster-scheduler-simulator	Known issues	You can also send any kind of feedback to the developers,  Andy Konwinski  and  Malte Schwarzkopf 
google-cluster-scheduler-simulator	References	 1  Malte Schwarzkopf, Andy Konwinski, Michael Abd-El-Malek and John Wilkes
google-cluster-scheduler-simulator	References	** Omega: flexible, scalable schedulers for large compute clusters  In *Proceedings of the 8th European Conference on Computer Systems  EuroSys 2013 *
google-cluster-scheduler-simulator	References	2  Charles Reiss, Alexey Tumanov, Gregory Ganger, Randy Katz and Michael Kotzuch
google-cluster-scheduler-simulator	References	** Heterogeneity and Dynamicity of Clouds at Scale: Google Trace Analysis  In *Proceedings of the 3rd ACM Symposium on Cloud Computing  SoCC 2012 *
google-cluster-scheduler-simulator	References	3  Google public cluster workload traces
google-cluster-scheduler-simulator	References	  
google-cmockery	Cmockery Unit Testing Framework	Cmockery is a lightweight library that is used to author C unit tests.There are a variety of C unit testing frameworks available however many ofthem are fairly complex and require the latest compiler technology
google-cmockery	Cmockery Unit Testing Framework	 Somedevelopment requires the use of old compilers which makes it difficult touse some unit testing frameworks
google-cmockery	Cmockery Unit Testing Framework	 In addition many unit testing frameworksassume the code being tested is an application or module that is targeted tothe same platform that will ultimately execute the test
google-cmockery	Cmockery Unit Testing Framework	 Because of thisassumption many frameworks require the inclusion of standard C library headersin the code module being tested which may collide with the custom orincomplete implementation of the C library utilized by the code under test.Cmockery only requires a test application is linked with the standard Clibrary which minimizes conflicts with standard C library headers
google-cmockery	Cmockery Unit Testing Framework	 Also,Cmockery tries avoid the use of some of the newer features of C compilers.This results in Cmockery being a relatively small library that can be usedto test a variety of exotic code
google-cmockery	Cmockery Unit Testing Framework	 If a developer wishes to simply test anapplication with the latest compiler then other unit testing frameworks maybe
google-cmockery	Overview	Cmockery tests are compiled into stand-alone executables and linked withthe Cmockery library, the standard C library and module being tested
google-cmockery	Overview	 Anysymbols external to the module being tested should be mocked functions that return values determined by the test application
google-cmockery	Overview	 Even though significant differences may exist between the targetexecution environment of a code module and the environment used to test thecode the unit testing is still valid since its goal is to test the logic of acode modules at a functional level and not necessarily all of its interactionswith the target execution environment.It may not be possible to compile a module into a test application withoutsome modification, therefore the preprocessor symbol *UNIT_TESTINGbe defined when Cmockery unit test applications are compiled so code within themodule can be conditionally compiled for tests.
google-cmockery	Test Execution	Cmockery unit test cases are functions with the signature*void function void &#42;&#42;state *
google-cmockery	Test Execution	 Cmockery test applications initialize atable with test case function pointers using *unit_test&#42;  table is then passed to the *run_tests  *run_tests  other data structures prior to running each test function
google-cmockery	Test Execution	  When a unit testis complete *run_tests  the test succeeded.
google-cmockery	Using run_tests  	 run_tests.c  src/example/run_tests.c 
google-cmockery	#include 	 typedef struct KeyValue {} KeyValue;void set_key_values KeyValueextern KeyValueextern void sort_items_by_key  ;static KeyValue key_values   = {void create_key_values void **state  {void destroy_key_values void **state  {void test_find_item_by_value void **state  {void test_sort_items_by_key void **state  {int main int argc, char~~~
google-cmockery	Exception Handling	Before a test function is executed by *run_tests  *,exception / signal handlers are overridden with a handler that simplydisplays an error and exits a test function if an exception occurs
google-cmockery	Exception Handling	 If anexception occurs outside of a test function, for example in Cmockery itself,the application aborts execution and returns an error code.
google-cmockery	Failure Conditions	If a failure occurs during a test function that's executed via*run_tests  *, the test function is aborted and the application'sexecution resumes with the next test function.Test failures are ultimately signalled via the Cmockery function *fail  *.The following events will result in the Cmockery library signalling a testRuntime assert macros like the standard C library's *assert  be redefined in modules being tested to use Cmockery's *mock_assert   test failure  #FailureConditions 
google-cmockery	Failure Conditions	 If a function is called usingthe *expect_assert_failure  within the function will result in the execution of the test
google-cmockery	Failure Conditions	 If nocalls to *mock_assert  *expect_assert_failure  
google-cmockery	Using mock_assert  	 assert_module.c  src/example/assert_module.c 
google-cmockery	#if UNIT_TESTING	extern voidextern voidextern void _test_free void
google-cmockery	#endif // UNIT_TESTING	void leak_memory   {void buffer_overflow   {void buffer_underflow   {~~~ allocate_module_test.c  src/example/allocate_module_test.c 
google-cmockery	Assert Macros	Cmockery provides an assortment of assert macros that tests applicationsshould use use in preference to the C standard library's assert macro
google-cmockery	Assert Macros	 On anassertion failure a Cmockery assert macro will write the failure to thestandard error stream and signal a test failure
google-cmockery	Assert Macros	 Due to limitations of theC language the general C standard library assert   and Cmockery'sassert_true   and assert_false   macros can only display the expression thatcaused the assert failure
google-cmockery	Assert Macros	 Cmockery's type specific assert macros,assert_{type}_equal   and assert_{type}_not_equal  , display the data thatcaused the assertion failure which increases data visibility aidingdebugging of failing test cases.
google-cmockery	Using assert_{type}_equal   macros	 assert_macro.c  src/example/assert_macro.c 
google-cmockery	Dynamic Memory Allocation	To test for memory leaks, buffer overflows and underflows a module beingtested by Cmockery should replace calls to *malloc  *, *calloc  *free  *test_free  *test_free  a  test failure  #FailureConditions  is signalled
google-cmockery	Dynamic Memory Allocation	 All blocksallocated using the *test_&#42;  Cmockery library
google-cmockery	Dynamic Memory Allocation	 When a test completes if any allocated blocks  memory leaks remain they are reported and a test failure is signalled.For simplicity Cmockery currently executes all tests in one process.Therefore all test cases in a test application share a single address spacewhich means memory corruption from a single test case could potentially causethe test application to exit prematurely.
google-cmockery	Using Cmockery's Allocators	 allocate_module.c  src/example/allocate_module.c 
google-cmockery	Mock Functions	A unit test should ideally isolate the function or module being testedfrom any external dependencies
google-cmockery	Mock Functions	 This can be performed using mock functionsthat are either statically or dynamically linked with the module being tested.Mock functions must be statically linked when the code being tested directly references external functions
google-cmockery	Mock Functions	 Dynamic linking is simply the process of setting a function pointer in a table used by the tested module to reference a mock function defined in the unit test.
google-cmockery	Return Values	In order to simplify the implementation of mock functions Cmockery providesfunctionality which stores return values for mock functions in each testcase using *will_return  *
google-cmockery	Return Values	 These values are then returned by each mock function using calls to *mock  *.Values passed to *will_return  specified
google-cmockery	Return Values	 Each successive call to *mock  return value from the queue
google-cmockery	Return Values	 This makes it possible for a mock function to usemultiple calls to *mock  return value
google-cmockery	Return Values	 In addition this allows the specification of return values for multiple calls to a mock function.
google-cmockery	Using will_return  	 database.h  src/example/database.h typedef struct DatabaseConnection DatabaseConnection;typedef unsigned int  *QueryDatabase  // Connection to a database.struct DatabaseConnection {// Connect to a database.~~~ customer_database.c  src/example/customer_database.c 
google-cmockery	#endif // _WIN32	// Connect to the database containing customer information.} unsigned int get_customer_id_by_name ~~~ customer_database_test.c  src/example/customer_database_test.c 
google-cmockery	Checking Parameters	In addition to storing the return values of mock functions, Cmockeryprovides functionality to store expected values for mock function parametersusing the expect_*   functions provided
google-cmockery	Checking Parameters	 A mock function parameter can thenbe validated using the check_expected   macro.Successive calls to expect_*   macros for a parameter queues values tocheck the specified parameter
google-cmockery	Checking Parameters	 check_expected   checks a function parameteragainst the next value queued using expect_*  , if the parameter check fails atest failure is signalled
google-cmockery	Checking Parameters	 In addition if check_expected   is called andno more parameter values are queued a test failure occurs.
google-cmockery	Using expect_*  	 product_database.c  src/example/product_database.c 
google-cmockery	Test State	Cmockery allows the specification of multiple setup and tear down functionsfor each test case
google-cmockery	Test State	 Setup functions, specified by the *unit_test_setup  shared between multiple test cases
google-cmockery	Test State	 In addition, tear down functions,specified by the *unit_test_teardown  *unit_test_setup_teardown  executed for a test case even when it fails.
google-cmockery	Using unit_test_setup_teardown  	 key_value.c  src/example/key_value.c 
google-cmockery	Example	A small command line calculator calculator.c  src/example/calculator.c  applicationand test application that full exercises the calculator application calculator_test.c  src/example/calculator_test.c are provided as an example of Cmockery's features discussed in this document.
google-cocoapods-size	CocoaPods Size Measurement	According to  this article  the number one reason users uninstall apps is the size
google-cocoapods-size	CocoaPods Size Measurement	Having a large app can significantly reduce adoption and retention  at the time of writing, apps over 150MB cannot be downloaded over a cellular network 
google-cocoapods-size	CocoaPods Size Measurement	As an SDK developer, it is even more critical to keep your library size in check, as app developers will refuse using your SDK if it adds too much bloat to their app.This repository provides a set of tools which help with the measurement of the final binary size for the given set of CocoaPods.
google-cocoapods-size	Usage examples	Measuring the size of the CocoaPod named AFNetworking using the latest released version:./measure_cocoapod_size.py --cocoapods AFNetworking// Output:Size comes out to be 231568 bytes  measured at version 3.2.1 ./measure_cocoapod_size.py --cocoapods AFNetworking:3.2.0// Output:Size comes out to be 231544 bytes./measure_cocoapod_size.py --cocoapods FirebaseMessaging:3.0.2 FirebaseAnalytics:5.0.0// Output:Size comes to be 1800752 bytes
google-cocoapods-size	Usage examples	This is 298212 bytes less when measured together vs each measured individually due to shared dependencies../measure_cocoapod_size.py --cocoapods AFNetworking:3.2.0 --spec_repos SPEC_REPO./xcode_project_diff.py --source_project=PROJECT1 --source_scheme=PROJECT1_SCHEME --target_project=PROJECT2 --target_scheme=PROJECT2_SCHEME
google-cocoapods-size	measure_cocoapod_size.py	./measure_cocoapod_size.py --cocoapods $POD_NAME:$POD_VERSION $POD_NAME1:$POD_VERSION1This tool provides the size measurement given a combination of CocoaPods
google-cocoapods-size	measure_cocoapod_size.py	This tool internally uses the xcode_project_diff.py tool.Please use ./measure_cocoapod_size.py -h to get the full usage description and a complete list of the available flags.
google-cocoapods-size	xcode_project_diff.py	./xcode_project_diff.py --source_project=$SOURCE_PROJECT --source_scheme=$SOURCE_SCHEME --target_project=$TARGET_PROJECT --target_scheme=$TARGET_SCHEMEThis tool takes in two Xcode project targets and provides the size difference between the two Xcode project targets
google-cocoapods-size	xcode_project_diff.py	Please use ./xcode_project_diff.py -h to get the full usage description and a complete list of the available flags.
google-cocoapods-size	Methodology	Our methodology involves doing the following:iTunes Connect reports both download and install sizes for apps in TestFlight
google-cocoapods-size	Methodology	We have used this to instrument a standalone app, and measured it before and after adding FirebaseAnalytics
google-cocoapods-size	Methodology	The numbers we found here are close to our measurements.For example, for iPhone 6S:Download size: **925 KiB*The install size is within a range of 3% from our measurements.
google-code-prettify	JavaScript code prettifier	An embeddable script that makes source-code snippets in HTML prettier
google-code-prettify	JavaScript code prettifier	See an example  2 .
google-code-prettify	Setup	Put code snippets in ..
google-code-prettify	Setup	and it will automatically beclass Voila {  // Voila  static const string VOILA = "Voila";
google-code-prettify	For which languages does it work?	The comments in prettify.js are authoritative but the lexer should work on anumber of languages including C and friends, Java, Python, Bash, SQL, HTML,XML, CSS, JavaScript, Makefile, and Rust.It works passably on Ruby, PHP, VB, and Awk and a decent subset of Perl andRuby, but because of commenting conventions, doesn't work on Smalltalk, OCaml,etc
google-code-prettify	For which languages does it work?	without a language extension.Other languages are supported via extensions: Apollo  src/lang-apollo.js ; Basic  src/lang-basic.js ; Clojure  src/lang-clj.js ; CSS  src/lang-css.js ; Dart  src/lang-dart.js ; Erlang  src/lang-erlang.js ; Go  src/lang-go.js ; Haskell  src/lang-hs.js ; Lasso  src/lang-lasso.js ; Lisp, Scheme  src/lang-lisp.js ; LLVM  src/lang-llvm.js ; Logtalk  src/lang-logtalk.js ; Lua  src/lang-lua.js ; MATLAB  src/lang-matlab.js ; MLs: F#, Ocaml,SML  src/lang-ml.js ; Mumps  src/lang-mumps.js ; Nemerle  src/lang-n.js ; Pascal  src/lang-pascal.js ; Protocol buffers  src/lang-proto.js ; R, S  src/lang-r.js ; RD  src/lang-rd.js ; Rust  src/lang-rust.js ; Scala  src/lang-scala.js ; SQL  src/lang-sql.js ; Swift  src/lang-swift.js ; TCL  src/lang-tcl.js ; LaTeX  src/lang-tex.js ; Visual Basic  src/lang-vb.js ; VHDL  src/lang-vhdl.js ; Wiki  src/lang-wiki.js ; XQ  src/lang-xq.js ; YAML  src/lang-yaml.js If you'd like to add an extension for your favorite language, please look atsrc/lang-lisp.js and submit a pull request.
google-code-prettify	How do I specify the language of my code?	You don't need to specify the language since prettyprint class:inside the  and using language-java style classes:Yes
google-code-prettify	How do I specify the language of my code?	Prettifying obfuscated code is like putting lipstick on a pig &mdash;i.e
google-code-prettify	How do I specify the language of my code?	outside the scope of this tool.
google-code-prettify	Which browsers does it work with?	It's been tested with IE 6, Firefox 1.5 & 2, and Safari 2.0.Look at the tests  4  to see if it works in your browser.
google-code-prettify	What's changed?	See the  changelog  CHANGES.md .
google-code-prettify	Why doesn't Prettyprinting of strings work on WordPress?	Apparently wordpress does "smart quoting" which changes close quotes
google-code-prettify	Why doesn't Prettyprinting of strings work on WordPress?	 Thiscauses end quotes to not match up with open quotes.This breaks prettifying as well as copying and pasting of code samples
google-code-prettify	Why doesn't Prettyprinting of strings work on WordPress?	 See WordPress's help center  5  for info on how to stop smart quoting of code
google-code-prettify	How do I put line numbers in my code?	You can use the linenums class to turn on line numbering
google-code-prettify	How do I put line numbers in my code?	 If your codedoesn't start at line number 1, you can add a colon and a line number to theend of that class as in linenums:52
google-code-prettify	How do I put line numbers in my code?	For example:You can use the nocode class to identify a span of markup that is not code:
google-code-prettify	I get an error message "a is not a function" or "opt_whenDone is not a function"	If you are calling prettyPrint via an event handler, wrap it in a function.Instead of doing:which will confuse it.
google-code-prettify	How can I customize the colors and styles of my code?	Prettify adds  with classes describing the kind of code
google-code-prettify	How can I customize the colors and styles of my code?	 You cancreate CSS styles to matches these classes.See the  theme gallery  1  for examples.
google-code-prettify	I can't add classes to my code  because it comes from Markdown, etc. 	Instead of  you can use a comment or processinginstructions that survives processing instructions:  worksas explained in  Getting Started  docs/getting_started.md .
google-code-prettify	How can I put line numbers on every line instead of just every fifth line?	Prettify puts lines into an HTML list element so that line numbers aren'tcaught by copy/paste, and the line numbering is controlled by CSS in thedefault stylesheet, prettify.css.The following should turn line numbering back on for the other lines:Please use the official  support group  7  for discussions, suggestions, andgeneral feedback.
google-code-prettify	License	 Apache License 2.0  COPYING  1 :  2 :  3 :  4 :  5 :  6 :  7 : 
google-code-review-bot	Usage	First, ensure that you have installed Go and set up crbot tool:And then to use it:
google-code-review-bot	Development	Install  GoMock Just what you might expect:See  CONTRIBUTING.md  CONTRIBUTING.md  for more details.
google-code-review-bot	License	Apache 2.0; see  LICENSE  LICENSE  for more details.
google-code-review-bot	Disclaimer	This project is not an official Google project
google-code-review-bot	Disclaimer	It is not supported by Googleand Google specifically disclaims all warranties as to its quality,merchantability, or fitness for a particular purpose.
google-codemirror-mode-jsonnet	codemirror-mode-jsonnet	 Jsonnet  integration for codemirror
google-codemirror-mode-jsonnet	codemirror-mode-jsonnet	Try it out  here 
google-codemirror-mode-jsonnet	Features	Token colorization for the full language, including correct handling of ||| and the various string
google-codemirror-mode-jsonnet	Usage instructions	See index.html in this repo
google-codemirror-mode-jsonnet	Usage instructions	 Also available via npm install codemirror-mode-jsonnet.
google-codemirror-mode-jsonnet	More Info	For more info on Jsonnet:! A screenshot of Jsonnet syntax highlighting 
google-codemirror.dart	codemirror.dart	   ! Dart strong mode  
google-codemirror.dart	What is it?	A Dart wrapper around the CodeMirror text editor
google-codemirror.dart	What is it?	From  codemirror.net > CodeMirror is a versatile text editor implemented in JavaScript for thebrowser
google-codemirror.dart	What is it?	It is specialized for editing code, and comes with a number of languagemodes and addons that implement more advanced editing functionality.
google-codemirror.dart	An example	Map options = {  'mode':  'javascript',  'theme': 'monokai'CodeMirror editor = new CodeMirror.fromElement editor.getDoc  .setValue 'foo.bar 1, 2, 3 ;' ;See also our example/ 
google-codemirror.dart	How do I use it?	In your main html file, link to the style sheet:and, in your Dart code, import the library:
google-codemirror.dart	What about modes? Addons?	This Dart package ships with several language modes built in
google-codemirror.dart	What about modes? Addons?	CodeMirror itselfsupports over 100 modes; the modes built into the Dart package include theusual suspects for web development well as a few others In order to add additional modes, you'll need to reference the mode file fromyour html entry-point
google-codemirror.dart	What about modes? Addons?	So,will bring in support for Lua.Similarly with addons, we've included a few common ones, and have made theothers available to import on a case-by-case basis
google-codemirror.dart	What about modes? Addons?	In order to use theactive-line addon, import:Be aware that many addons need additional configuration in order to enable then.This is generally done by passing values into the options of the CodeMirrorSome addons are exposed through the main Dart interface
google-codemirror.dart	What about modes? Addons?	Some are exposed viaside-car Dart libraries available in the main package  and somehave yet to be exposed
google-codemirror.dart	What about modes? Addons?	Pull requests welcome : 
google-codemirror.dart	Themes	By importing the codemirror.css file:You get access to all the CodeMirror themes
google-codemirror.dart	Themes	If you only want a few, or don'twant to pay the network roundtrip cost to load all the themes, you can importonly the ones you're interested in:
google-codemirror.dart	Polymer transformer	The Polymer transfomer will inline our theme css references incorrectly.Currently, to use the codemirror package with Polymer, you'll need to add thefollowing lines to your pubspec.yaml file.This is not an official Google product.
google-codeu_coding_assessment_2017	CodeU Coding Sample	This project allows students to demonstrate their coding skills before enteringCodeU
google-codeu_coding_assessment_2017	CodeU Coding Sample	Students will complete this JSON-lite object and JSON-lite parser.
google-codeu_coding_assessment_2017	DISCLAIMER	CODEU is an invitation-only program created by Google to develop the skills ofaspiring technologists
google-codeu_coding_assessment_2017	DISCLAIMER	This project is not an offical Google Product
google-codeu_coding_assessment_2017	DISCLAIMER	Thisproject allows students who have been invited to CodeU to demonstrate theircoding skills before entering the program.
google-codeu_coding_assessment_2017	What is JSON-lite?	Well it doesn't really exists
google-codeu_coding_assessment_2017	What is JSON-lite?	For the purpose of this question we are definingJSON-lite to be a stripped down version of JSON
google-codeu_coding_assessment_2017	What is JSON-lite?	In JSON-lite there are onlytwo variable types: STRINGS and OBJECTS.A STRING is a series of characters starting with a " and ending with a ".Inside of a string quotes  "  and backslashes  \  must be escaped with aback-slash  \ 
google-codeu_coding_assessment_2017	What is JSON-lite?	Some characters can be escaped to give them special meaning.They are t and n
google-codeu_coding_assessment_2017	What is JSON-lite?	If you are familiar with programming, you may know thatthere are other escapable characters, but in JSON-lite they are not supported.The following are all valid strings: "" "abc" "\"a\tb\nc\""The following are all invalid strings: """ "\g"An OBJECT is a series of KEY-VALUE pairs starting with a } and separated by commas
google-codeu_coding_assessment_2017	What is JSON-lite?	KEY-VALUE pairs are expressed as a KEY:VALUE wherethe key must be a STRING and the value can be an OBJECT or STRING.The following is a valid key-value pair:  "name":"sam doe"The following is invalid key-value pair:  name:"sam doe"The following are a valid objects:  {  }The following is an invalid object:  {  }The following is a key-value pair where the value is an object:  "name": { "first":"sam", "last":"doe" }It should be noted that between the brances, commas, or colons can be anynumber of whitespace characters.
google-codeu_coding_assessment_2017	What do I need to do?	We want you to write a parser that can parse JSON-lite syntax and represent thevalue in memory
google-codeu_coding_assessment_2017	What do I need to do?	What structures you use to hold the parsed data is up to you.How you parsed the data is up to you
google-codeu_coding_assessment_2017	What do I need to do?	What is not up to you is the data that wewill test it with
google-codeu_coding_assessment_2017	What do I need to do?	To help you out we have supplied some samples of validJSON-lite objects:  { }  { "name": "sam doe" }  { "name": { "first": "sam", "last": "doe" } }
google-codeu_coding_assessment_2017	What should my code look like?	We have provided the interfaces for you to implement
google-codeu_coding_assessment_2017	What should my code look like?	To make it even easier wehave created the skeleton code for you
google-codeu_coding_assessment_2017	What should my code look like?	You just need to fill in the methods inMyJSON and MyJSONParser that have "TODO" written in them.To make sure you are on the right track we have implemented a few tests you canuse to test your understanding
google-codeu_coding_assessment_2017	What should my code look like?	Keep in mind that the tests are just to help youget started; they are not exhaustive
google-codeu_coding_assessment_2017	What should my code look like?	To make sure you code is correct, wesuggest you add some more tests.
google-codeu_coding_assessment_2017	How do I submit my code?	You will be forking our repository, making a copy of your own, on which you willthen upload your solution.Please follow carefully these steps, since we will not accept solutionssubmitted in any other way
google-codeu_coding_assessment_2017	How do I submit my code?	These instructions assume a basic familiarity withthe GitHub workflow
google-codeu_coding_assessment_2017	How do I submit my code?	If you are new to GitHub, you can familiarize youself withthe interface and the workflow using one of the many tutorials available online
google-codeu_coding_assessment_2017	How do I submit my code?	Click on the "Fork" button that you should see on the top right corner of Follow the on screen instructions to fork this repository to your personal **Only now* Working on the copy of your repository that you just cloned, Write and test Once you have pushed your solution, Copy and paste the link to yourPlease follow these steps precisely, and verify that your code is uploadedcorrectly by checking it on the GitHub web interface before submitting.**We cannot accept any other form of submission.**
google-codeu_coding_assessment_b_2017	Overview	This project allows students to demonstrate their coding skills by implementinga component of a larger system.MathLang is a made-up math scripting language
google-codeu_coding_assessment_b_2017	Overview	Students are expected toimplement com.google.codeu.mathlang.impl.MyTokenReader
google-codeu_coding_assessment_b_2017	Overview	The class has alreadybeen created and students only need to finish implementing its functionality.MyTokenReader is responsible for parsing the text input and converting it toa stream of tokens that the MathLang parser will use to build statements.Statements are then passed to the interpreter to be executed
google-codeu_coding_assessment_b_2017	Overview	Everything exceptfor MyTokenReader has already been implemented.To further understand how com.google.codeu.mathlang.core.tokens.TokenReader
google-codeu_coding_assessment_b_2017	Overview	TokenReader is theinterface that MyTokenReader implements and contains in-code documentationfor how each method should behave.
google-codeu_coding_assessment_b_2017	The Goal	When students have finished their implementation of MyTokenReader
google-codeu_coding_assessment_b_2017	The Goal	Students are encouraged to write their own tests to ensuretheir implementation is working.Students should not use any third-party libraries to complete this assessment.The one exception is the use of a third-party test library to help test theirimplementation of MyTokenReader.When done, an evaluator should be able to run the student's project using thesame build and run instructions provided here
google-codeu_coding_assessment_b_2017	The Goal	This means that if a studentuses a third-party test library, all dependencies must be included with theproject and build.sh and run.sh must be updated.
google-codeu_coding_assessment_b_2017	Build Instructions	These instructions are based on a Linux environment using BASH and JAVA To clean, run ./clean.sh.To build, run ./build.sh.To run all tests, run ./run.sh.
google-codeu_project_2017	DISCLAIMER	CODEU is a program created by Google to develop the skills of future softwareengineers
google-codeu_project_2017	DISCLAIMER	This project is not an offical Google Product
google-codeu_project_2017	DISCLAIMER	This project is aplayground for those looking to develop their coding and software engineering
google-codeu_project_2017	ENVIRONMENT	All instructions here are relative to a LINUX environment
google-codeu_project_2017	ENVIRONMENT	There will be somedifferences if you are working on a non-LINUX system
google-codeu_project_2017	ENVIRONMENT	We will not support anyother development environment.This project was built using JAVA It is recommended that you installJAVA&nbsp;7 when working with this project.
google-codeu_project_2017	GETTING STARTED	All running images write informational and exceptional events to log files.The default setting for log messages is "INFO"
google-codeu_project_2017	GETTING STARTED	You may change this to getmore or fewer messages, and you are encouraged to add more LOG statementsto the code
google-codeu_project_2017	GETTING STARTED	The logging is implemented in codeu.chat.util.Logger.java,which is built on top of java.util.logging.Logger, which you can refer tofor more information.In addition to your team's client and server, the project also includes aRelay Server and a script that runs it  run_relay.sh .This is not needed to get started with the project.
google-codeu_project_2017	Finding your way around the project	All the source files  except test-related source files  are in./src/codeu/chat
google-codeu_project_2017	Finding your way around the project	 The test source files are in ./test/codeu/chat
google-codeu_project_2017	Finding your way around the project	If youuse the supplied scripts to build the project, the .class files will be placedin ./bin
google-codeu_project_2017	Finding your way around the project	There is a ./third_party directory that holds the jar files forJUnit  a Java testing framework 
google-codeu_project_2017	Finding your way around the project	Your environment may or may not already havethis installed
google-codeu_project_2017	Finding your way around the project	The supplied scripts use the version in ./third_party.Finally, there are some high-level design documents in the project Wiki
google-codeu_project_2017	Finding your way around the project	Pleasereview them as they can help you find your way around the sources.The major project components have been separated into their own packages
google-codeu_project_2017	Finding your way around the project	Themain packages/directories under src/codeu/chat are:
google-codeu_project_2017	codeu.chat.client	Classes for building the two clients  codeu.chat.SimpleGuiClientMain .
google-codeu_project_2017	codeu.chat.server	Classes for building the server  codeu.chat.ServerMain .
google-codeu_project_2017	codeu.chat.relay	Classes for building the Relay Server  codeu.chat.RelayMain 
google-codeu_project_2017	codeu.chat.relay	The Relay Serveris not needed to get started.
google-codeu_project_2017	codeu.chat.common	Classes that are shared by the clients and servers.
google-codeu_project_2017	codeu.chat.util	Some basic infrastructure classes used throughout the project.
google-codeu_project_2018	CodeU Example Project	This is an example chat application
google-codeu_project_2018	CodeU Example Project	It's complete and functional, but leavesplenty of room for improvement.
google-codeu_project_2018	Step 1: Download Java	Check whether you already have Java installed by opening a console and typing:step If the version number is less than javac_1.8, then you have an oldversion of Java and should probably upgrade by following these instructions.Download the JDK  not the JRE  from  here Retry the javac -version command **in a new console window*installation
google-codeu_project_2018	Step 1: Download Java	If you still don't see a version number, then update your PATHenvironment variable so it contains Java's bin directory
google-codeu_project_2018	Step 1: Download Java	Follow  thesedirections  to do so.
google-codeu_project_2018	Step 2: Download Maven	This project uses  Maven  to compile and run ourcode
google-codeu_project_2018	Step 2: Download Maven	Maven also manages dependencies, runs the dev server, and deploys to AppDownload Maven from  here  Unzip thefolder wherever you want.Make sure you have a JAVA_HOME environment variable that points to your Javainstallation, and then add Maven's bin directory to your PATH environmentvariable
google-codeu_project_2018	Step 2: Download Maven	Instructions for both can be found here Open a console window and execute mvn -v to confirm that Maven is correctly
google-codeu_project_2018	Step 3: Install Git	This project uses  Git  for source version control and GitHub  to host our repository.Download Git from  here Make sure Git is on your PATH by executing this command:
google-codeu_project_2018	Step 4: Setup your repository	Follow the instructions in the first project to get your repository setup.
google-codeu_project_2018	Step 5: Run a development server	In order to test changes locally, you'll want to run the server locally, on yourown computer.To do this, open a console to your codeu_project_2018 directory and execute this command:App Engine server.You should now be able to use a local version of the chat app by opening yourbrowser to   
google-codeu_project_2018	Step 6: Make a change!	App Engine devserver.index.jsp file
google-codeworld	Leaky GHCJS Sandboxing ###	While the installation process installs most of its files inside codeworld/build, it doesclobber ~/.ghc, ~/.ghcjs, and ~/.cabal
google-codeworld	Leaky GHCJS Sandboxing ###	 I recommend that you run CodeWorld as adedicated user account to avoid causing problems for other Haskell installations
google-codeworld	Leaky GHCJS Sandboxing ###	 If youdon't, note that you will lose your user package database.See bug #4 for details.
google-codeworld	Authentication	CodeWorld offers two modes of authentication or the ability to run withauthentication disabled with reduced functionality
google-codeworld	Authentication	The two methods providedare as follows:CodeWorld site; this allows CodeWorld to offload account and credentialmanagement to a third partythis is useful for applications where minimal external dependencies is requiredRunning CodeWorld in one of these two modes allows users to save and managetheir projects and folders
google-codeworld	Authentication	With no authentication enabled, users are able towrite, build and run code but lose the ability to save and manage projects and
google-codeworld	 Google authentication	For Google authentication to work, you will need to obtain a Google API key andstore it in web/clientId.txt.To get a Google API key for your CodeWorld installation, please consult thefollowing resources:CodeWorld instance will immediately pick up changes to this file.In general, the Google authentication system will be the easiest system tomaintain since no local password stores are required
google-codeworld	 Google authentication	This is the mechanismused by the official, live version of CodeWorld.
google-codeworld	 Local authentication	For applications in which external dependencies, such as Google accounts, arenot acceptable, we provide a simple local authentication system:Google authentication  i.e
google-codeworld	 Local authentication	stateless client-side sessions 
google-codeworld	 Local authentication	Currently, noweb-based administrative interface is provided
google-codeworld	 Local authentication	Instead, you can use thecodeworld-auth CLI tool to manage accounts.The local authentication system may be useful for situations where aninstructor cannot reasonably expect all students to have a valid Google accountand in which the instructor is willing to deploy a local CodeWorld stack.
google-codeworld	Create account database	Local authentication will be enabled if a codeworld-auth.db file is presentin the application's root directory
google-codeworld	Create account database	To create this database, run the followingfrom the root of the Git repository:
google-codeworld	Create one or more user accounts	Assuming you have already created an account database as described above, youcan create a new account as follows:password
google-codeworld	Create one or more user accounts	The account will be set to "Expired" which means the user will beprompted to enter a new password at next sign-in time.Other subcommands are provided for updating and deleting accounts etc
google-codeworld	Create one or more user accounts	ForTo use local authentication, you will also need to generate a JWT secret storedin a file named codeworld-auth.txt
google-codeworld	Create one or more user accounts	This is used to sign JWT tokens passedback and forth between the server and the browser
google-codeworld	Create one or more user accounts	From the Git repository'sroot directory, run the following command:this secret to external users.
google-codeworld	Swap Space ###	If you are installing CodeWorld on a virtual server, be aware that the defaultRAM on these servers is often not sufficient for GHC
google-codeworld	Swap Space ###	 CodeWorld needs to compile verylarge Haskell projects during its installation
google-codeworld	Swap Space ###	 The following should be sufficient toresolve any out-of-memory problems you encounter:This creates a 2 GB swap file to increase available virtual memory
google-codeworld	Swap Space ###	 Installation witha swap file may be slow, but it will succeed
google-codeworld	Swap Space ###	  Unless you intend to write very largeprograms in CodeWorld, it's usually safe to remove the swap file after running theserver for the first time
google-coding-with-chrome	Chrome App version	To install the Chrome App version:Visit the  Chrome Web Store  1 Click __Add to Chrome__Go to  chrome://apps  chrome://apps  or use the "Overview" ○ LauncherLaunch __Coding with Chrome__
google-coding-with-chrome	Mac OS and Windows version  alpha 	To install the Mac OS and/or Windows binary version:Visit the  Release Page  2  and look for the latest entryDownload and extract the corresponding **.zip file*Go into the extracted folder and launch __Coding with Chrome__ .app/.exe Build the Coding with Chrome AppIf you want to build the latest Coding with Chrome App from the source code,please check the  build instructions  BUILD.md .Supported hardware and system
google-coding-with-chrome	Supported hardware	Computers and Laptops with Chrome OS or any OS which is able to run theDesktop Chrome Browser are supported.For additional features Bluetooth and/or USB are required.
google-coding-with-chrome	Supported systems	The following operating systems are supported by Coding with Chrome:The following robots are supported, out of the box by Coding with Chrome:For any issues or feature requests, we would really appreciate it if you reportthem using our  issue tracker -------------Contributing to Coding with Chrome is subject to the guidelines in the CONTRIBUTING.md  CONTRIBUTING.md  file, which, in brief, requires thatcontributors sign the  Individual Contributor License Agreement  CLA   3 .For more information about develop for Coding with Chrome, please check doc/DEVELOPMENT.md  doc/DEVELOPMENT.md 
google-coding-with-chrome	Translation	For translation instruction, please check  doc/I18N.md  doc/I18N.md .--------Coding with Chrome is made possible by other  open source software  NOTICE.md 
google-coding-with-chrome	Translation	1 :  2 :  3 : 
google-cog	A dataset and architecture for visual reasoning with a working memory	This is the code accompanying ECCV 2018 paper  .
google-cog	Getting started	You need to have the following libraries installed:You can use your favorite python IDE to import the project
google-cog	Getting started	Alternatively, you can add the base directory to your PYTHONPATH.
google-cog	Datasets	We have pre-generated two variants of the COG dataset:python cognitive/generate_dataset.py --examples_per_family=227280 \  --parallel=12 --output_dir=/tmp/cog/data_4_3_1 \  --epochs=4 --max_memory=3 --max_distractors=1python cognitive/generate_dataset.py --examples_per_family=227280 \  --parallel=12 --output_dir=/tmp/cog/data_8_7_10 \  --epochs=8 --max_memory=7 --max_distractors=10You can generate other variants using similar command lines.The --parallel flag instructs the script to generate the dataset in parallel usingthe provided number of processes
google-cog	Datasets	By default dataset files are gzip'ed.If you don't want to gzip automatically, use --compress=false flag.Use -h to see all the options.
google-cog	Dataset format	Data is stored in text files
google-cog	Dataset format	Each line of a file contains serialzied json string
google-cog	Dataset format	An examples of such a string  pretty printed  is included below.of the list is equal to the number of epochs
google-cog	Dataset format	The string values include a specialvalue 'invalid' which means that the question has no valid answer after the corresponding epoch.
google-cog	COG	You can train a network locally with default hyperparameters by runningIf no data_dir is given train.py will generate examples for training and validation on the fly.When training on a canonical dataset on GPU, you should see the results of intermediary evaluation every 10-20 minutes
google-cog	COG	You can use --display_step to perform evaluation more often  default value is 3000 batches 
google-cog	COG	Use -h to see all the options
google-cog	COG	The default hyper-parameter values are set in the get_default_hparams_dict function.
google-cog	CLEVR	To train in CLEVR, first, you need to download the CLEVR dataset and unzip it.Then, convert it to TFRecord format using the following command line:Conversion can take about 20min.To train on CLEVR dataset use the following commandTo produce CLEVR test set outputs, run:This is not an officially supported Google product.
google-comid	CodeMirror In Dart  comid 	A code editing component for Dart.
google-comid	Usage	TODO: Add embedding example.A simple usage example:import 'package:comid/comid.dart';main   {  var editor = new CodeMirror  ;
google-comid	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker .
google-comid	Credits	CodeMirror in Dart borrows heavily from the work of Marijn Haverbeke on CodeMirror
google-comid	Credits	It is licensed under the MIT open-source license
google-comid	Credits	Please see the  CodeMirror  site  website for more information
google-comid	Credits	tracker :  site : 
google-compact_enc_det	Introduction	Compact Encoding Detection CED for short  is a library written in C++ thatscans given raw bytes and detect the most likely text encoding.Basic usage:
google-compact_enc_det	#include "compact_enc_det/compact_enc_det.h"	const charbool is_reliable;int bytes_consumed;Encoding encoding = CompactEncDet::DetectEncoding 
google-compact_enc_det	How to build	You need  CMake  to build the package
google-compact_enc_det	How to build	After unzippingthe source code , run autogen.sh to build everything automatically.The script also downloads  Google Test framework needed to build the unittest.project files for Visual Studio.
google-compare_gan	Compare GAN code.	This is the code that was used in "Are GANs Created Equal? A Large-Scale Study"paper  and in "The GAN Landscape: Losses, Architectures, Regularization, and Normalization" If you want to see the version used only in the first paper 
google-compare_gan	Pre-trained models	The pre-trained models are available on TensorFlow Hub
google-compare_gan	Pre-trained models	Please see  this colab for an example how to use them.
google-compare_gan	Best hyperparameters	This repository also contains the values for the best hyperparameters for different combinations of models, regularizations and penalties.You can see them in generate_tasks_lib.py file and train using --experiment=best_models_sndcgan
google-compare_gan	Installation:	To install, run:WARNING: by default this script only downloads and installs small datasetscompare_gan has two binaries:
google-compare_gan	Create tasks for experiment "test" in directory /tmp/results. See "src/generate_tasks_lib.py" to see other possible experiments.	compare_gan_generate_tasks --workdir=/tmp/results --experiment=test
google-compare_gan	Run task 0  training and eval 	compare_gan_run_one_task --workdir=/tmp/results --task_num=0 --dataset_root=/tmp/datasets
google-compare_gan	Run task 1  training and eval 	compare_gan_run_one_task --workdir=/tmp/results --task_num=1 --dataset_root=/tmp/datasetsResults  FID and inception scores for checkpoints  will be stored in /tmp/results/TASK_NUM/scores.csv.
google-concatenate.js	How does it work	This is using multiple eval calls with  @sourceURL  annotations in a single output stream.
google-concatenate.js	How about source maps	This is better than source maps under these circumstances:When you have a syntax error at least V8 based browsers will not show you a line number.
google-concatenate.js	Browser support	 For the generated JS The exported function supports a second param which is a function that gets to modify the output after the eval was added
google-concatenate.js	Browser support	You may find this useful for i.e
google-concatenate.js	Browser support	adding CommonJS module wrappers
google-concatenate.js	Browser support	For an example see example_common_js_simulator.js.
google-concatenate.js	Fine print	  AuthorMalte Ubl  Google Inc
google-concatenate.js	Fine print	  CopyrightCopyright © 2013 Google, Inc
google-concatenate.js	Fine print	 LicenseApache 2.0
google-conferenceDB	conferencedb	Website with a list of conferences
google-conferenceDB	conferencedb	This is not an official Google product.
google-conferenceDB	Getting Started	For install dependence and test your application in local servercd conferencedbnpm install -g gulp bower && cd third_party/ && npm install && cd .
google-conferenceDB	Getting Started	&& bower installcd third_party/gulp serveFor deploy your application on firebase hostingcd third_partycd ../ONLY FIRST TIME: firebase init 	Chose in Firebase Service: Only hosting	Chose in Public folder: dist	Chose in Rewrite all urls to Index.html: y	Chose in Overwrite index.html: N	Chose your project or create a new projectfirebase deployFor test your application before deploycd third_partygulp serve:dist
google-conscrypt	Download JARs	You can download the JARs directly from the Maven repositories.
google-conscrypt	Native Classifiers	The OpenJDK artifacts are platform-dependent since each embeds a native library for a particularplatform
google-conscrypt	Native Classifiers	We publish artifacts to Maven Central for the following platforms:Classifier | OS | Architecture-----------| ------linux-x86_64 | Linux | x86_64  64-bit osx-x86_64 | Mac | x86_64  64-bit windows-x86 | Windows | x86  32-bit windows-x86_64 | Windows | x86_64  64-bit 
google-conscrypt	Gradle	If you are making changes to Conscrypt, see the  buildinginstructions  BUILDING.md .
google-conscrypt	Uber JAR	For convenience, we also publish an Uber JAR to Maven Central that contains the sharedlibraries for all of the published platforms
google-conscrypt	Uber JAR	While the overall size of the JAR islarger than depending on a platform-specific artifact, it greatly simplifies the task ofdependency management for most platforms.To depend on the uber jar, simply use the conscrypt-openjdk-uber artifacts.
google-conscrypt	Android	The Android AAR file contains native libraries for x86, x86_64, armeabi-v7a, and
google-container-rfc	How to Contribute	Please fork, then issue a pull request
google-container-rfc	How to Contribute	We will discuss in the PRs
google-container-rfc	Goals	The basic format is a root filesystem containing all the dependencies needed to run an application
google-container-rfc	Goals	A basic chroot should be a sufficient test to see if your filesystem is setup correctly
google-container-rfc	Goals	For the purposes of this document, we are ignoring transport or packaging
google-container-rfc	Goals	The runtime simply needs a root filesystem to start from.These files do not need to have any contents, but should be provided either by the runtime or the contents of the file.
google-container-rfc	/etc/os-release	 Operating system identification  Can be a blank file, but the runtime can inspect it before starting
google-container-rfc	/etc/os-release	Here are a  few comments  on why it is important
google-container-rfc	/etc/resolv.conf	If provided by the container, the runtime must respect it
google-container-rfc	/etc/resolv.conf	If not provided, the runtime can inject or add it to the container
google-container-rfc	Example RFC minimal container	What is the smallest container we can make to test this?
google-container-rfc	Entry point	The runtime should provide a mechanism to enter the container through an arbitrary executable
google-container-rfc	Entry point	If not specified, runtime should default to /sbin/init
google-container-rfc	Entry point	Otherwise fail
google-container-rfc	Environment Variables	Runtime should support configuring environment variables via a file
google-container-rfc	Networking types	The runtime should support three types of networking
google-container-rfc	Host networking	The hosts network adapter is attached directly to the container
google-container-rfc	Host networking	No networking namespace
google-container-rfc	Private networking	A network namespace just for the container, no external networking
google-container-rfc	Virtual/NAT networking	Optionally, the runtime can provide its own networking virtualization layer
google-container-rfc	Virtual/NAT networking	This should be exposed to the host as a nic
google-container-rfc	Namespace support	Runtime should support full process, filesystem, user, network namespaces
google-container-rfc	Cgroup support	Runtime should support memory limiting, memory with swap limiting, disk IO limits, and CPU thresholds.
google-container-rfc	Unique ID	Once running, the runtime should provide a globally unique ID for the running container
google-container-rfc	Questions?	|Runtime Support|Docker| systemd+nspawn |native LXC| libvirt-lxc |lmctfy|OpenVZ||/etc/resolv.conf|/usr/sbin/init|NAT networking|Private networking   |yes|yes||Host networking|Socket activation|Unique container id  |yes|yes||Network namespaces   |yes|yes||Filesystem namespaces|yes|yes||Process namespaces   |yes|yes||User namespaces|MAC-based security   |yes|no |
google-container-rfc	References	Some places of inspiration for this.
google-containerregistry	containerregistry	  A set of Python libraries and tools for interacting with a Docker Registry.Bazel users see   rules_docker, which relies heavily on these tools.
google-containerregistry	puller.par	usage: puller.par  -h   --name NAME   --directory DIRECTORY Pull images from a Docker Registry, faaaaast.optional arguments:  -h, --help  --name NAME  --directory DIRECTORY  --stderrthreshold STDERRTHRESHOLD
google-containerregistry	pusher.par	usage: pusher.par  -h   --name NAME   --tarball TARBALL   --config CONFIG Push images to a Docker Registry, faaaaaast.optional arguments:  -h, --help  --name NAME  --tarball TARBALL  --config CONFIG  --digest DIGEST  --layer LAYER  --stamp-info-file STAMP_INFO_FILE  --oci  --stderrthreshold STDERRTHRESHOLD
google-containerregistry	importer.par	usage: importer.par  -h   --tarball TARBALL   --format {tar,tar.gz} Import images from a tarball into our faaaaaast format.optional arguments:  -h, --help  --tarball TARBALL  --format {tar,tar.gz}  --directory DIRECTORY  --stderrthreshold STDERRTHRESHOLD
google-containerregistry	flatten.par	usage: flatten.par  -h   --tarball TARBALL   --config CONFIG Flatten container images.optional arguments:  -h, --help  --tarball TARBALL  --config CONFIG  --digest DIGEST  --layer LAYER  --uncompressed_layer UNCOMPRESSED_LAYER  --diff_id DIFF_ID  --filesystem FILESYSTEM  --metadata METADATA   The name of where to write the container startup  --stderrthreshold STDERRTHRESHOLD
google-containerregistry	appender.par	usage: appender.par  -h   --src-image SRC_IMAGE   --tarball TARBALL Append tarballs to an image in a Docker Registry.optional arguments:  -h, --help  --src-image SRC_IMAGE  --tarball TARBALL  --dst-image DST_IMAGE  --stderrthreshold STDERRTHRESHOLD
google-containerregistry	digester.par	usage: digester.par  -h   --tarball TARBALL  --output-digest OUTPUT_DIGESTCalculate digest for a container image.optional arguments:  -h, --help  --tarball TARBALL  --output-digest OUTPUT_DIGEST  --config CONFIG  --digest DIGEST  --layer LAYER  --oci  --stderrthreshold STDERRTHRESHOLD
google-contentbox	Project general objective	Distribution of social and virtual content with an open and collaborative educational environment, availableto communities around the world in one place, with a standard format and quality.Users  feature options  Testing Portal You can validate the model using this test portal
google-contentbox	Project general objective	 Remember that this website is into a test instance 
google-contentbox	Localhost testing	and API key from the previous step and save.is staff and is superuser and saving
google-contentbox	Localhost testing	Now you can access the admin site in   More details about the project and support   You can visit this website  contentbox.info  for more installation details
google-copr-sundry	Synopsis	Collection of rpm spec files for various packages
google-copr-sundry	Synopsis	Built packages availablevia copr at 
google-copr-sundry	Motivation	Project exists to collect various packages missing from official CentOS andFedora repositories as well as to backport some of the packages from Fedora to CentOS.
google-copr-sundry	Installation	Please see instructions at 
google-copr-sundry	License	Apache 2.Please see text of the license in LICENSE file.
google-copr-sundry	DISCLAIMER	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-copybara	Copybara	*A tool for transforming and moving code between repositories.*Copybara is a tool used internally at Google
google-copybara	Copybara	It transforms and moves code between repositories.Often, source code needs to exist in multiple repositories, and Copybara allows you to transformand move source code between these repositories
google-copybara	Copybara	A common case is a project that involvesmaintaining a confidential repository and a public repository in sync.Copybara requires you to choose one of the repositories to be the authoritative repository, so thatthere is always one source of truth
google-copybara	Copybara	However, the tool allows contributions to any repository, andany repository can be used to cut a release.The most common use case involves repetitive movement of code from one repository to another.Copybara can also be used for moving code once to a new repository.Examples uses of Copybara include:Currently, the only supported type of repository is Git
google-copybara	Copybara	Copybara also supports reading from Mercurial repositories, but the feature is still experimental.Support for other repositories types will be added in the future.
google-copybara	Example	core.workflow  Copybara doesn't have a release process yet, so you need to compile from HEAD
google-copybara	Example	In order to do thatyou need:If you use Intellij and the Bazel plugin, use this project configuration:directories:  copybara/integration  java/com/google/copybara  javatests/com/google/copybara  third_party  //copybara/integration/..
google-copybara	Example	 //java/com/google/copybara/..
google-copybara	Example	 //javatests/com/google/copybara/..
google-copybara	Example	 //third_party/...Note that configuration files can be stored in any place, even in a local folder
google-copybara	Example	We recommend touse a VCS  like git  to store them; treat them as source code.
google-copybara	Using Docker to build and run Copybara	*NOTE: Docker use is currently experimental, and we encourage feedback or contributions.*You can build copybara using Docker like sodocker run -it -v "$ pwd ":/usr/src/app copybara copybaraA few environment variables exist to allow you to change how you run copybara:There are a number of ways by which to share your git config and ssh credentials with the docker container, an example with OS X is below:We are still working on the documentation
google-copybara	Using Docker to build and run Copybara	Here are some resources:If you have any questions about how Copybara works please contact us at our  mailing list 
google-copybara	Optional tips	  
google-coq-bpf	Coq BPF interpreter	This is a BPF interpreter written in the Coq proof assistant
google-coq-bpf	Coq BPF interpreter	It also hastactic machinery to construct proven-equivalent Gallina programs for BPFThis is not an official Google product.
google-cornerstoneTools	Install	**Via NPM:*npm install --save cornerstone-tools**Get a packaged source file:** UNPKG  offers a quick/neat solution for grabbing versioned copies of the source
google-cornerstoneTools	Install	For example:See the  live examples  and  wiki  for documentation  Soon to be replaced by  tools.cornerstonejs.org  on how to use this library**A common setup when using modules:**// Load NPM packagesimport Hammer from 'hammerjs';import import // Specify external dependenciescornerstoneTools.external.cornerstone = cornerstone;cornerstoneTools.external.Hammer = Hammer;*Note: cornerstoneTools.external's only need to be specified in cornerstone-tools versions 1.0.0+**A common setup when using package source files:**// Load Packaged Sources// Specify external dependenciescornerstoneTools.external.cornerstone = cornerstone;cornerstoneTools.external.Hammer = Hammer;*Note: cornerstoneTools.external's only need to be specified in cornerstone-tools versions 1.0.0+------------We love contributions, and we have plenty of work queued up for all skill levels
google-cornerstoneTools	Install	If you have an idea, feel free to create a new topic on  our community discussion board  or comment on an existing  enhancement   up-for-grabs   bug   documentation  issue
google-cornerstoneTools	Install	A quick "here is how I intend to approach this problem", with sign-off from someone like @swederik, will go a long way toward increasing the chances your hard work will be merged :+1:**How To Contribute:**Fork this repositoryClone the forked repositoryBefore committing code, create a branch-per-feature, or branch-per-bugCreate pull requests against cornerstonejs/cornerstoneTools/master**What To Contribute:**If you're looking to get your feet wet, start by:----------cornerstoneTools will be maintained under the  Semantic Versioning Guidelines  as much as possible
google-cornerstoneTools	Install	Releases will be numbered with the following format:And constructed with the following guidelines:This project uses webpack to build the software.Update dependencies  after each pull :> npm installRunning the build:> npm startAutomatically running the build and unit tests after each source change:> npm run watch------------ license-url : LICENSE npm-url :  npm-version-image :  npm-downloads-image :  travis-url :  travis-image :  coverage-url :  coverage-image : 
google-coursebuilder-android-container-module	coursebuilder-android-container-module	This module allows your users to write Android code on the web and get resultsin their browser, without intalling or configuring anything
google-coursebuilder-android-container-module	coursebuilder-android-container-module	It is not anofficial Google product.The system is comprised of three parts: a client, which renders UI for users andsends requests to the balancer; a balancer, which receives client requests,manages their state, and dispatches them to a worker pool; and a worker pool,which receives requests from the balancer, builds user code, executes it in avirtual machine, and relays results or errors back to the balancer
google-coursebuilder-android-container-module	coursebuilder-android-container-module	The balanceris part of  Course Builder ; this module contains a client and a workerimplementation
google-coursebuilder-android-container-module	coursebuilder-android-container-module	The sample implementation's output looks like! sample UI  images/editor.png The source has two main components
google-coursebuilder-android-container-module	coursebuilder-android-container-module	First, the android/ subdirectory is abundle of code for creating worker machines that build and run user code in realAndroid VMs
google-coursebuilder-android-container-module	coursebuilder-android-container-module	You can run these workers anywhere - Amazon EC2 , etc.The remaining root files and subdirectories are a  Course Builder  module thatdelivers the page users interact with to write and execute their code
google-coursebuilder-android-container-module	coursebuilder-android-container-module	 CourseBuilder  serves as the balancer.To run, first set up your worker machines
google-coursebuilder-android-container-module	coursebuilder-android-container-module	Exactly how you do this depends onthe requirements of your production system; see android/worker.py for details.We recommend running a pool of many workers behind a balancer; each worker canbuild and run one student submission at a time.Next, download Course Builder: Active
google-coursebuilder-android-container-module	coursebuilder-android-container-module	Set gcb_external_task_balancer_worker_url to Active with the valueof the URL for your worker or worker pool.The demo is then available at 
google-coursebuilder-android-container-module	coursebuilder-android-container-module	The former shows editing an XMLfile; the latter shows editing of Java code.To edit the set of available projects, create a new Android project and put itunder android/projects
google-coursebuilder-android-container-module	coursebuilder-android-container-module	Then edit android/projects/config.json withinformation about your project
google-coursebuilder-android-container-module	coursebuilder-android-container-module	See android/projects/config.json for examples.Your project must use gradle for its build system; the default project for Android Studio  does this and is a good baseline.
google-coursebuilder-android-container-module	Architecture	The system has 3 main parts:A web page users interact with, running a JavaScript client
google-coursebuilder-android-container-module	Architecture	In this example,see src/templates/index.html for the HTML.A balancer
google-coursebuilder-android-container-module	Architecture	This is the  Course Builder  installation above
google-coursebuilder-android-container-module	Architecture	It's a  GoogleApp Engine  application that acts as a proxy and manager for tasks executed on apool of workers.A pool of 1 or more workers, running anywhere but behind one URL
google-coursebuilder-android-container-module	Architecture	Thesemachines do the actual work of accepting user code, building it into .apks,installing the .apks on an Android VM, running the user code, taking ascreenshot, and relaying results back to the proxy.All wire communication is JSON against REST endpoints
google-coursebuilder-android-container-module	Architecture	Both the balancer and theworkers expose APIs for the other's use
google-coursebuilder-android-container-module	Architecture	There are a number of important caveatshere you must read before running this system in production; see the Course Builder Balancer Module  code for details.
google-coursebuilder-android-container-module	Expected flow	The expected flow for the system as a whole is:User visits a page containing a JS client, with an interface for writing andrunning code.On page load, the client fetches project definition information from thebalancer
google-coursebuilder-android-container-module	Expected flow	The balancer dispatches this request to any machine in the workerThe user's page displays UX
google-coursebuilder-android-container-module	Expected flow	The user authors code and hits an element totrigger a run action.The user's client dispatches a request to the balancer to create a *task*
google-coursebuilder-android-container-module	Expected flow	Atask is a data object that holds bookkeeping information and the state of onerun of user code
google-coursebuilder-android-container-module	Expected flow	For example, it contains an identifier for the user, the lastknown state of the task, and the task's *ticket*, which uniquely identifies it.The balancer dispatches a request to create a new task to the worker pool,sending along bookkeeping information about that task  the ticket, what projectit's for, a patch with the code the user wrote, etc
google-coursebuilder-android-container-module	Expected flow	.A worker recieves the create task request
google-coursebuilder-android-container-module	Expected flow	It forks a background process topatch the user's code onto the project, build .apks, run them, and store theirresult on disk
google-coursebuilder-android-container-module	Expected flow	This is nonblocking and the worker immediately returns after theThe balancer returns a response to the user's client with the ticket for thecreated task and the id of the worker allocated to that task  or an error if itcould not create a task for any reason, like all workers being busy .The client receives the ticket and worker id, and polls the balancer forcurrent status.The balancer relays status polls to the correct worker
google-coursebuilder-android-container-module	Expected flow	Each poll, the workerreads the current result of the run from disk and sends it to the balancer.The balancer relays current state to the client
google-coursebuilder-android-container-module	Expected flow	The client stops pollingwhen the returned state is terminal and updates its UI.Worker implementations are in charge of fitting this flow and maintaining theirhealth  for example, they will need to garbage collect results of old tasks sotheir disks don't fill up 
google-coursebuilder-android-container-module	Expected flow	See android/worker.py for a sample implementation.See src/resources/client.js for a sample client.
google-coursebuilder-android-container-module	Limitations	In addition to the limitations of the  Course Builder Balancer Module  -administrator because different deployments will have different securityrequirements -Worker builds and code execution are both single threaded and lock guarded.This means a single worker may only build/run one task at a time  though it canhandle other requests, like the balancer polling for past task results,concurrently with each other and with the build/run task 
google-coursebuilder-android-container-module	Limitations	Multiple, concurrentrequests for additional build/run tasks will fail instantly with an HTTP 500error indicating the worker is currently locked
google-coursebuilder-android-container-module	Limitations	This could be addressed in anumber of ways  for example, by running multiple Android VMs per worker, each onits own port .We do no defense against malicious user code submissions
google-coursebuilder-android-container-module	Limitations	The most trivialmalicious code submission is simply an infinite loop; this would lock a workerand never unlock it
google-coursebuilder-android-container-module	Limitations	Multiple submissions of code with an infinite loop wouldeventually lock the entire worker pool
google-coursebuilder-android-container-module	Limitations	There are multiple ways to address thisproblem, such as time-boxing the execution of user code,whitelisting/blacklisting allowed functionality, etc.We do not supply machine images for properly secured workers
google-coursebuilder-android-container-module	Limitations	Securing theworker pool is up to deployment administrators, and care must be taken to keepsystems other than the balancer from being able to issue operations against theworker pool.There are some additional, smaller caveats; see android/worker.py for details.Broadly speaking, the intent of this project is to demonstrate feasibility forthe design as a whole, not to serve as a performant, secure production system.For any real deployment, administrators will need to take additional steps toensure performance and security.
google-coursebuilder-android-container-module	Compatibility	We specify versions for all dependencies in code
google-coursebuilder-android-container-module	Compatibility	Specifically:The  Course Builder  version and revision are specified in  and maynot work with other versions
google-coursebuilder-android-container-module	Compatibility	The example projects and emulators use Android APIlevel 19  4.4, KitKat ; other versions may work but we haven't tried them
google-coursebuilder-android-container-module	Compatibility	Android Studio : Amazon EC2 : Course Builder : Course Builder Balancer Module : Google App Engine : Google Compute Engine :
google-coursebuilder-hello-world-module	coursebuilder-hello-world-module	This is an example  Course Builder  module that shows you how to create, run,and test extensions to the system
google-coursebuilder-hello-world-module	coursebuilder-hello-world-module	It is not an official Google product.We strongly recommend making customizations by creating a module, avoidingchanges to the core Course Builder codebase where possible
google-coursebuilder-hello-world-module	coursebuilder-hello-world-module	This not only makesyou less likely to accidentally break something with your changes, but you'llalso find it much easier to upgrade to new versions of Course Builder as they're
google-coursebuilder-hello-world-module	Requirements	You'll need a system with current versions of python 2.
google-coursebuilder-hello-world-module	Getting started	First, clone Course Builder and change directory to the Course Builder root:start by grabbing Course Builder, then using it to fetch the module you want towork with
google-coursebuilder-hello-world-module	Getting started	Let's grab this module, called hello, next:start up Course Builder with this module installed:
google-coursebuilder-hello-world-module	Module contents	The structure of this module is
google-coursebuilder-hello-world-module	module.yaml	This file defines your module
google-coursebuilder-hello-world-module	module.yaml	This is best explained by example
google-coursebuilder-hello-world-module	module.yaml	Here's themodule.yaml for this module, annotated:When you run coursebuilder/tests/ext/, respectively 
google-coursebuilder-hello-world-module	module.yaml	These locations mustmatch the dotted patterns found in your module.yaml or you will have problemsimporting your module at runtime.In most cases you will not need to modify this file, and can just copy itdirectly into a new module
google-coursebuilder-hello-world-module	module.yaml	If you are creating a new module and cannot usemodules.sh because your files are not yet found in a version control system,you can run this script directly to install your module into your local CourseBuilder directory
google-coursebuilder-hello-world-module	module.yaml	Run it with sh scripts/setup.sh -h for details.
google-coursebuilder-hello-world-module	src	Your module's source files
google-coursebuilder-hello-world-module	src	You may put whatever you want here; this samplemodule has some templates and a single Python file that declares our handlers.View that file for details on creating handlers, both with and without userauthentication, and with and without awareness of a current course
google-coursebuilder-hello-world-module	src	Whencreating a new module, remember to put an __init__.py file in this directoryor you will have import problems.
google-coursebuilder-hello-world-module	tests	Your module's test files
google-coursebuilder-hello-world-module	tests	You may put whatever you want here; this simplemodule provides an example of functional tests using  Webtest 
google-coursebuilder-hello-world-module	tests	When creating anew module, remember to put an __init__.py file in this directory or you willhave import problems.
google-coursebuilder-hello-world-module	Working with this module	After you've downloaded and installed this module, start Course Builder normallyto use it: this is what Course Builder does for you if you clicked **Create Empty Course*also assume you're starting your local server on the default hostname and port.View the global handler at 
google-coursebuilder-hello-world-module	Working with this module	Sign in and out tosee how the UI changes.Now, view the handler that's aware of the current course at
google-coursebuilder-hello-world-module	Working with this module	Notice how it can display the name of thecourse
google-coursebuilder-hello-world-module	Working with this module	Signing in and out works as before, but note you will not be able toview the handler when signed out unless you've edited the course to make itpublic
google-coursebuilder-hello-world-module	Working with this module	This is normal: Course Builder does not display newly-created courses tothe public by default so you can hold off on showing your content to peoplebefore it's done.
google-coursebuilder-hello-world-module	Running tests	You can run specific tests with test.sh, which is in coursebuilder/scripts.For example, after you've installed this module, you can run all its tests fromthe Course Builder root with:Sometimes you don't want to fetch a module from a remote repository, but insteadwant to use source from local disk
google-coursebuilder-hello-world-module	Running tests	This happens often when creating a newmodule
google-coursebuilder-hello-world-module	Running tests	The module system allows you to address this by passing a localfilesystem path into the modules script.The set of allowable paths is limited to those under /tmp, /var/folders, andone level up from where you are invoking the modules script.We suggest creating a symlink from your local file location to /$HOME/src/coursebuilder-hello-world-module, you would first create thesymlink with
google-coursebuilder-hello-world-module	That's it	Enjoy writing Course Builder modules, and please feel free to use this as abase
google-coursebuilder-hello-world-module	That's it	If you find things you can't do in modules, hit us up on the Course Builder Forums 
google-coursebuilder-hello-world-module	That's it	Course Builder : Course Builder Forums : Webtest :
google-coursebuilder-lti-module	coursebuilder-lti-module	This module adds support for  Learning ToolsInteroperability   LTI  versions 1.0through 1.2 to  Course Builder  Thisis not an official Google product.LTI is a standard that allows different online learning tools to talk to eachother
google-coursebuilder-lti-module	coursebuilder-lti-module	It is provided by  IMS Global  a nonprofitmember organization.Course Builder is an open source platform for authoring and delivering onlineeducational content for hundreds of thousands of users.Currently, IMS Global certifies this module's LTI provider for LTI 1.
google-coursebuilder-lti-module	Requirements	You will need a Bash environment to run the installation scripts
google-coursebuilder-lti-module	Requirements	The scriptsuse standard developments tools, including python version 2.7, git, and zip/unzip.
google-coursebuilder-lti-module	Configuration	Course Builder modules are managed by Course Builder
google-coursebuilder-lti-module	Configuration	To get started with this module, first clone the Course Builder repository:Once you've got a Course Builder deployment running the LTI module, you mustconfigure it for use
google-coursebuilder-lti-module	Configuration	See  the LTI implementation moduledocs for details.
google-coursebuilder-lti-module	Development and testing	To do development on this module, keep in mind that Course Builder owns the local setup of the module on your machine rather than the other way around
google-coursebuilder-lti-module	Development and testing	In particular, Course Builder owns where this module's source lives, which is in $HOME/coursebuilder_resources/modules/lti
google-coursebuilder-lti-module	Development and testing	That directory is a git repository with a remote at the git address you passed to modules.sh, which in this case is .You can modify module code and execute git commands here as you would normally
google-coursebuilder-lti-module	Development and testing	Additionally, the tests and source of this module are available under your Course Builder root directory via the following two symlinks:With this setup, you can start your server as you would with vanilla Course Builder, and the LTI module will be installed and ready for configuration:
google-coverage	Installation	Add to .emacs.elThe package requires GNU Emacs 24.3+.To test the package after installationOpen and follow instructions in files
google-coverage	Contributing	See  CONTRIBUTING.md  CONTRIBUTING.md .
google-coverage	Disclaimer	This is not an official Google product.
google-cpp-from-the-sky-down	C++ From The Sky Down 	This repository will hold explanations, documentations,examples and libraries developed for C++ From The SkyC++ From the Sky Down is an series designed to present C++ as a high-level language and to show techniques and libraries  including some developed during this course  to use C++ as a high level language while hiding the low-level stuff.This will use C++17 and C++20  as they become available  features.More explanations/documentations/examples/libraries will be added as the series progresses.g/cpp-from-the-sky-down This is not an officially supported Google product.
google-cpu_features	cpu_features     ! Build status  	A cross-platform C library to retrieve CPU features  such as availableinstructions  at runtime.
google-cpu_features	Checking features at runtime	Here's a simple example that executes a codepath if the CPU supports both theAES and the SSE4.2 instruction sets:
google-cpu_features	#include "cpuinfo_x86.h"	static const X86Info info = GetX86Info  ;static const X86Microarchitecture uarch = GetX86Microarchitecture &info ;static const bool has_fast_avx = info.features.avx && uarch != INTEL_SNB;// use has_fast_avx.This feature is currently available only for x86 microarchitectures.
google-cpu_features	Caching for faster evaluation of complex checks	If you wish, you can read all the features at once into a global variable, andthen query for the specific features you care about
google-cpu_features	Caching for faster evaluation of complex checks	Below, we store all the ARMfeatures and then check whether AES and NEON are supported.
google-cpu_features	#include "cpuinfo_arm.h"	static const ArmFeatures features = GetArmInfo  .features;static const bool has_aes_and_neon = features.aes && features.neon;// use has_aes_and_neon.This is a good approach to take if you're checking for combinations of featureswhen using a compiler that is slow to extract individual bits from bit-packed
google-cpu_features	Checking compile time flags	The following code determines whether the compiler was told to use the AVXinstruction set  e.g., g++ -mavx  and sets has_avx accordingly.
google-cpu_features	Rejecting poor hardware implementations based on microarchitecture	On x86, the first incarnation of a feature in a microarchitecture might not bethe most efficient  e.g
google-cpu_features	Rejecting poor hardware implementations based on microarchitecture	AVX on Sandy Bridge 
google-cpu_features	Rejecting poor hardware implementations based on microarchitecture	We provide a function to retrievethe underlying microarchitecture so you can decide whether to use it.Below, has_fast_avx is set to 1 if the CPU supports the AVX instructionset&mdash;but only if it's not Sandy Bridge.
google-cpu_features	Running sample code	Building cpu_features brings a small executable to test the library.
google-cpu_features	What's supported	|---------|:----:|:-------:|:-------:|:------:|:-------:|| Android | yes² |   yes¹  |   yes¹  |  yes¹  |   N/A   || iOS| Linux   | yes² |   yes¹  |   yes¹  |  yes¹  |   yes¹  || MacOs   | yes² |   N/A   | not yet |   N/A  || Windows | yes² | not yet | not yet |   N/A  |   N/A   | **Features revealed from Linux.* **Features revealed from CPU.* **Microarchitecture detection.*
google-cpu_features	License	The cpu_features library is licensed under the terms of the Apache license.See  LICENSE  LICENSE  for more information.
google-cpu_features	Build with CMake	Please check the  CMake build instructions  cmake/README.md .
google-crc32c	CRC32C	    New file format authors should consider HighwayHash  The initial version ofthis code was extracted from  LevelDB  whichis a stable key-value store that is widely used at Google.This project collects a few CRC32C implementations under an umbrella thatdispatches to a suitable implementation based on the host computer's hardwareCRC32C is specified as the CRC that uses the iSCSI polynomial in RFC 3720  The polynomial wasintroduced by G
google-crc32c	CRC32C	Castagnoli, S
google-crc32c	CRC32C	Braeuer and M
google-crc32c	CRC32C	Herrmann
google-crc32c	CRC32C	CRC32C is used insoftware such as Btrfs, ext4, Ceph and leveldb.
google-crc32c	#include "crc32c/crc32c.h"	int main   {  const std::uint8_t buffer   = {0, 0, 0, 0};  std::uint32_t result;  result = crc32c::Crc32c buffer, 4 ;  std::string string;  string.resize 4 ;  result = crc32c::Crc32c string ;  std::string_view string_view string ;  result = crc32c::Crc32c string_view ;
google-crc32c	Prerequisites	This project uses  CMake  for building and testing
google-crc32c	Prerequisites	CMake isavailable in all popular Linux distributions, as well as in Homebrew This project uses submodules for dependency management.autocomplete-clang and linter-clang with you-complete-me
google-crc32c	Prerequisites	This requires setting up ycmd The following commands build and install the project.The following command  when executed from build/   re builds the project andruns the tests.The following command builds the project against the Android NDK, which isuseful for benchmarking against ARM processors.
google-credstore	Credstore	 ! Docker Repository on Quay  "Docker Repository on Quay"  **This is not an official Google product**Credstore is a centralized server providing authentication-by-proxy model
google-credstore	Credstore	Usersor services can trade auth tokens for per-service per-rpc tokens.
google-credstore	Sample config	scopes:  method: '*'  method: '*'
google-crisis-info-hub	Crisis Info Hub	Crisis Info Hub is a super lightweight content management system, based on Google Docs.Crisis Info Hub provides a templatized Google Doc, customizable to allow organizations and individuals to disseminate crisis-relevant information in a low-bandwidth way
google-crisis-info-hub	Crisis Info Hub	A published version of this Google Doc is served through a Google App Engine instance, which provides additional functionality including translation and analytics
google-crisis-info-hub	Crisis Info Hub	 Example 
google-crisis-info-hub	Dependency Setup	 mkdir $HOME/bin; cd $HOME/bin npm install grunt-cli export PATH=$HOME/bin/node_modules/grunt-cli/bin:$PATH curl -O  unzip google_appengine_*.zip mkdir google_closure; cd google_closure curl -O  unzip compiler-latest.zip; cd .
google-crisis-info-hub	Dependency Setup	mkdir google_closure_templates; cd google_closure_templates curl -O  unzip closure-templates-for-javascript-latest.zip popdTo install dependencies for unit testing:sudo pip install unittest2
google-crisis-info-hub	Configuration Setup	---
google-crisis-info-hub	Dependencies	All users should run:git submodule updateGrunt users should also run:npm install
google-crisis-info-hub	Local Development	To run the development appserver locally:grunt appengine:run:appIf you are not using Grunt, simply run:util.sh -d
google-crisis-info-hub	Deployment	To deploy to AppEngine:grunt appengine:update:app --appid=Specifying --appid= will override any value set in config.json
google-crisis-info-hub	Deployment	 You maymodify the config.json file to avoid having to pass this parameter onevery invocation.If you are not using Grunt, simply run:util.sh -p 
google-crisis-info-hub	Detailed Dependency Information	You can find / download this at:You can find / download this at:  <>You will need all the files from this archive in the above directory:  compiler-latest.zipThe compiler is invoked with the default namespace of 'app.'  The compiledJavascript is written to out/static/app.js.You will also need the Closure Library  in the closure-library submodule ofthis repository .You can find more on the Closure Library here:  <>To use it, you will need to check out the code as a submodule by running thefollowing commands from the base directory of this repository:You can find / download Closure Templates at:  <>You will need all the files from this archive in the above directory:  closure-templates-for-javascript-latest.zipYou can build this using the ant target "zips-for-release", or download aprebuilt version  the URL is in the Dependency Setup section .The deployment script checks for the presence of .soy files in templates/soy.If found, they are compiled to a single Javascript file using theSoyToJsSrcCompiler.jar in the previously mentioned directory
google-crisis-info-hub	Detailed Dependency Information	 The resultingJavascript file is stored in static/app.soy.js, alongside the soyutils.jslibrary provided with the Closure Templates bundle that is necessary to includeon any page you plan to use Closure Templates.
google-crmint	CRMint	**Make reliable data integration and data processing with Google easy for| Status | Coverage | Branch | Description || :----|    | |    | > You can have data without information, but you cannot have information> without data.> — _Daniel Keys Moran_CRMint was created to make advertisers' data integration and processing easy,even for people without software engineering background.CRMint has simple and intuitive web UI that allows users to create, edit, run,and schedule data pipelines consisting of data transfer and data processingCRMint is a  Google App Engine  applicationwritten in Python for  Google App Engine Python StandardEnvironment  CRMintuses  Cloud SQL  to store it's business data, and Stackdriver Logging  to store it's activityDeploy CRMint to your  Google Cloud project build a data pipeline, and benefit from data integration and processing in Google Cloud **This is not an official Google product.**
google-crunchy	CrunchyCrypt 	CrunchyCrypt is an opensource library offering safe and easy-to-use cryptographyAPIs with a built-in key-versioning protocol.
google-crunchy	Table of Contents	  link 
google-crunchy	About CrunchyCrypt	CrunchyCrypt is an open-source collection of cryptography APIs, safe andeasy-to-use wrappings of lower-level crypto libraries such as boringssl.Although CrunchyCrypt is intended to primarily be a curated collection ofmodern cryptography, CrunchyCrypt is designed to be extendable to bothbleeding-edge and legacy cryptography.CrunchyCrypt has a built-in key versioning protocol, where cryptographicpayloads  signatures and ciphertexts  are  optionally  prefixed with a fewbytes of key versioning information
google-crunchy	About CrunchyCrypt	This allows project owners to gracefullyrotate new crunchy keys while maintaining backwards compatibility with old keys,even while switching the underlying algorithm.Safety and ease-of-use are primary features of CrunchyCrypt, which is good formost, but not all, use cases
google-crunchy	About CrunchyCrypt	For example, user-specificed nonces is notsomething we intend to support
google-crunchy	About CrunchyCrypt	As a consequence, CrunchyCrypt is not meant tobe a comprehensive replacement for openssl/boringssl.
google-crunchy	Codemap	CrunchyCrypt supports crypto and key management in C++
google-crunchy	Codemap	CrunchyCrypt supportscrypto in Java via JNI bindings.CrunchyCrypt supports the following primitives in C++:   We support AES-GCM and AES-EAX at 128 and 256 bits of security
google-crunchy	Codemap	  We support HMAC-SHA256 with 16-byte tags and a 32-byte key
google-crunchy	Codemap	  We support P256-ECDSA, Ed25519, and RSA-PKCS1 using SHA256 and a  2048-bit modulus
google-crunchy	Codemap	  We support ECIES using HKDF and AEADs in various combinations,  including versions using P256 and curveCrunchyCrypt supports  key management  crunchy/key_management/  in C++.CrunchyCrypt's built-in key-versioning protocol allows for graceful rotation ofkeys
google-crunchy	Codemap	 KeysetManager  crunchy/key_management/key_manager.h  is used to create,rotate, and delete keys
google-crunchy	Codemap	 Serialization of unencrypted key material is in aseparate  keyset_serialization  crunchy/key_management/keyset_serialization.h build target
google-crunchy	Codemap	Java APIs  crunchy/java/src/main/java/com/google/security/crunchy/  for theabove are implemented via  JNIbindings  crunchy/java/src/main/com/google/security/crunchy/jni .Some internal APIs may be eventually made user-facing as we gain more experienceas to how they might be used
google-crunchy	Codemap	For example, AdvancedKeysetManager  crunchy/key_management/  and  our subtle cryptoAPIs  crunchy/internal/algs  might be made non-internal if they're deemed
google-crunchy	Compatibility guarantees	We do not offer any ABI compatibility
google-crunchy	Compatibility guarantees	We will strive to not break APIcompatibility
google-crunchy	Compatibility guarantees	If we plan to break API compability, we will provide a migrationWe ask that you:
google-crunchy	License	CrunchyCrypt is licensed under the terms of the Apache License, Version 2.See LICENSE  LICENSE  for more information.
google-csp-evaluator	Introduction	Please note: this is not an official Google product.CSP Evaluator allows developers and security experts to check if a ContentSecurity Policy   CSP  serves as astrong mitigation against  cross-site scriptingattacks  It assistswith the process of reviewing CSP policies, and helps identify subtle CSPbypasses which undermine the value of a policy
google-csp-evaluator	Introduction	CSP Evaluator checks are basedon a  large-scale study  and areaimed to help developers to harden their CSP and improve the security of theirapplications
google-csp-evaluator	Introduction	This tool  also available as a  Chromeextension is provided only for the convenience of developers and Google provides noguarantees or warranties for this tool.CSP Evaluator comes with a built-in list of common CSP whitelist bypasses whichreduce the security of a policy
google-csp-evaluator	Introduction	This list only contains popular bypasses and isby no means complete.The CSP Evaluator library + frontend is deployed here:
google-csp-evaluator	Build Prerequisites	These instructions have been tested with the following software:These instructions assume a working directory of the repository root.CSP Evaluator includes an easy-to-use setup script called do.sh
google-csp-evaluator	Build Prerequisites	It supportsthe following commands:To build CSP Evaluator, run the following commands: ./do.sh install_deps ./do.sh build
google-csp-evaluator	Local Demo Server	To run the demo locally, you can use the Python SimpleHTTPServer: cd build python -m SimpleHTTPServer 9000 Navigate to  in your browser
google-csp-evaluator	Example usage	If you don't want to make any customization you can also just embed thecompiled JS  build/evaluator_binary.js  and evaluate CSP like this:
google-cssi-blogasaurus	Blogasaurus	This is a simple web application that hosts a blog with comments
google-cssi-blogasaurus	Blogasaurus	It is part ofthe educational curriculum used at Google's  Computer Science SummerInstitute Students work on this app in  multiple stages  INSTRUCTIONS.md 
google-cssi-blogasaurus	Blogasaurus	The code foreach stage is available as a separate branch in this Git repository.This app runs on the  Google App Engine Python StandardEnvironment  To runit locally,  install the Google CloudSDK  then rundev_appserver.py app.yaml.This is not an official Google product.
google-cssi-labs	CSSI Curriculum Labs	Welcome to the CSSI Curriculum Labs.This repository contains the code and instructions for the student activitiesand labs that complement the CSSI curriculum.
google-cssi-labs	How to download and complete these labs.	You will clone this repository to your local machine, and complete the exerciseslocally
google-cssi-labs	How to download and complete these labs.	You will **not*you can, if you choose, create your own repository and use it to store yoursolutions for later.
google-cssi-labs	Cloning the repository	To create your own local copy of this repository, use the following command:
google-cssi-labs	Writing your solutions	The main level folders divide the content by topic, inside each folder youwill find all the activities for that topic
google-cssi-labs	Writing your solutions	Each lab or activity has aREADME.md file with the instructions
google-cssi-labs	Writing your solutions	You can find the same instructions inthe CSSI curriculum website shared with you by your instructors.
google-cssi-labs	Saving your solutionsi  optional 	If you choose to use GitHub to track your solutions, you will **not*them to Google's original repository, but you can create your own repository inGitHub, and link it to your local copy by runningOnce you have added your remote repository, which is now named personal, youcan store your changes following these steps:Add the files you created or modified:Don't simply run git push, because that will try to update our originalrepository, which will reject your changes.
google-ct-hackday-schwag	CT Display Schwag	This is a driver for an LCD log driver that was given at the May 7th,2014 Certificate Transparency hack day.You'll need go v1.1 or higher to compile.
google-ct-hackday-schwag	Website	* 
google-ct-hackday-schwag	Building	Import into your Go workspace like this:To compile it, run the following command from the top of your Go
google-ct-hackday-schwag	Contributing	When sending pull requests, please ensure that everything's been runthrough gofmt beforehand so we can keep everything nice and tidy.
google-ctfscoreboard	CTF Scoreboard ##	This is a basic CTF Scoreboard, with support for teams or individualcompetitors, and a handful of other features.Copyright 2018 Google, Inc.Author: Please see the AUTHORS file.This is a version 2.x branch
google-ctfscoreboard	CTF Scoreboard ##	 We've eliminated categories, in favor of taggingchallenges
google-ctfscoreboard	CTF Scoreboard ##	 This simplifies the codebase significantly, and is a better fitsince so many challenges border on more than one category
google-ctfscoreboard	CTF Scoreboard ##	 However, this branchis not compatible with databases from 1.x
google-ctfscoreboard	CTF Scoreboard ##	 If you need that, check out the 1.xbranch, which will only be getting security & bug fixes.
google-ctfscoreboard	Installation ###	Install Python with PIP and setuptools
google-ctfscoreboard	Installation ###	 If you'd like to use a virtualenv,Install the dependencies:Install a database library
google-ctfscoreboard	Installation ###	 For MySQL, consider mysql-python
google-ctfscoreboard	Installation ###	 For Postgres,Write a config.py for your relevant installation
google-ctfscoreboard	Installation ###	 An example is provided in  following to your config.py, so that cookies will work:  debugging purposes
google-ctfscoreboard	Installation ###	Not useful for production usage, however.Create the database:Set up your favorite python application server, optionally behind aRegister a user
google-ctfscoreboard	Installation ###	 The first user registed is automatically made an admin.Have fun!  Maybe set up some challenges
google-ctfscoreboard	Installation ###	 Players might like that more.
google-ctfscoreboard	Installation using Docker ###	Navigate to the folder where the Dockerfile is located.Run the command below to build a docker image for the scoreboard and tag it as "scoreboard".Run the command below to create the docker container.Find the name of the container you created for the scoreboard.Run the command below to start the docker container for the scoreboard.
google-ctfscoreboard	Options ###	**SCORING**: Set to 'progressive' to enable a scoring system where the totalpoints for each challenge are divided amongst all the teams that solve thatchallenge
google-ctfscoreboard	Options ###	 This rewards teams that solve infrequently solved  hard or obscure **TITLE**: Scoreboard page titles.**TEAMS**: True if teams should be used, False for each player on their own**SQLALCHEMY_DATABASE_URI**: A SQLAlchemy database URI string.**LOGIN_METHOD**: Supports 'local' or 'appengine'
google-ctfscoreboard	Options ###	 'appengine' uses AppEngineusers API.
google-ctfscoreboard	Development ###	   ! codecov  **Use hooks****Test Cases**This project stands on the shoulders of giants.A big thanks to the following projects used to build this:
google-cxx-std-draft	#. run latexmk -pdf std	That's it! You should now have an std.pdf containing the typeset draft.Alternative instructionsIf you can't use latexmk for some reason, you can use the Makefiles instead:
google-cxx-std-draft	#. run make reindex	If you can't use latexmk or make for some reason, you can run LaTeX manually instead:
google-cxx-std-draft	#. run pdflatex std twice more.	Generated input filesTo regenerate figures from .dot files, run::For example::----------------A great deal of gratitude goes out to Pete Becker for his amazing workin the original conversion of the C++ standard drafts to LaTeX, andhis subsequent maintenance of the standard drafts up to C++Thankyou Pete.Thanks to Walter Brown for suggesting the use of latexmk.
google-dagger	Dagger 2	 ! Maven Central  mavenbadge-svg   mavencentral A fast dependency injector for Android and Java.
google-dagger	About Google's Fork	Dagger 2 is a compile-time evolution approach to dependency injection.Taking the approach started in Dagger 1.x to its ultimate conclusion,Dagger 2.x eliminates all reflection, and improves code clarity byremoving the traditional ObjectGraph/Injector in favor of user-specified@Component interfaces.This github project represents the Dagger 2 development stream
google-dagger	About Google's Fork	 The earlier project page  square   Square, Inc's repository  represents the earlier 1.0development stream
google-dagger	About Google's Fork	Both versions have benefited from strong involvement fromSquare, Google, and other contributors.Dagger is currently in active development, primarily internally at Google,with regular pushes to the open-source community
google-dagger	About Google's Fork	Snapshot releases areauto-deployed to sonatype's central maven repository on every clean build withthe version HEAD-SNAPSHOT.>  Dagger 2's main documentation website can be found here
google-dagger	About Google's Fork	 website 
google-dagger	Documentation	You can  find the dagger documentation here  website  which has extended usageinstructions and other useful information
google-dagger	Documentation	 Substantial usage information can befound in the  API documentation  20api .You can also learn more from  the original proposal  proposal , this talk by Greg Kick  gaktalk , and on the dagger-discuss@googlegroups.commailing list.
google-dagger	Bazel	If you build with bazel, follow the  bazel documentation for referencingexternal projects  bazel-external-deps  to include Dagger in your build.Given the following @com_google_dagger//:dagger_with_compiler in your deps.You will need to include the dagger-2.x.jar in your application's runtime.In order to activate code generation and generate implementations to manageyour graph you will need to include dagger-compiler-2.x.jar in your buildat compile time.
google-dagger	Maven	In a Maven project, include the annotationProcessorPaths value of the maven-compiler-plugin:the dagger-compiler artifact with the provided scope:parallelizable execution graphs , then add this to your maven configuration:// Add plugin plugins {  id "net.ltgt.apt" version "0.10"// Add Dagger dependenciesdependencies {  compile 'com.google.dagger:dagger:2.x'  apt 'com.google.dagger:dagger-compiler:2.x'
google-dagger	Android Gradle	If you're using classes in dagger.android you'll also want to include:If you're using the  Android Databinding library  databinding , you may want toincrease the number of errors that javac will print
google-dagger	Android Gradle	When Dagger prints anerror, databinding compilation will halt and sometimes print more than 100errors, which is the default amount for javac
google-dagger	Android Gradle	For more information, see Issue 306 maven-style binary artifacts, they can be downloaded directly via the Maven Central Repository  mavencentral .Developer snapshots are available from Sonatype's snapshot repository  dagger-snap , and are built on a clean build ofthe GitHub project's master branch.
google-dagger	Building Dagger	Dagger is built with  util/install-local-snapshot.sh will build all of the Dagger libraries andinstall a copy in your local maven repository with the version LOCAL-SNAPSHOT.
google-dagger	License	 20api :  bazel :  bazel-external-deps :  community :  dagger-snap :  databinding :  gaktalk :  latestapi :  mavenbadge-svg :  mavencentral :  project :  proposal :  square :  squarecommunity :  website : 
google-dana	Dana	Dana  DAta ANalysis  system provides:
google-dana	Principles	See  Principes documentation  docs/Principles.md  to understand key concepts of Dana.
google-dana	Dana APIs	Dana provides some APIs to add builds, series and samples
google-dana	Dana APIs	APIs are accessible using POST http requests or using a node client using WebSockets.See  APIs documentation  docs/Apis.md  for details.
google-dana	Have a demo	See  Demo documentation  docs/Demo.md  to know who to setup a Demo dana server on your machine in few commands.
google-dana	Setup a server	See  Setup documentation  docs/Setup.md  to know who to setup a Dana server and  Adding project pages  docs/Project.md  to know how to add dashboard pages for a project.
google-dana	Bugs, feature requests	This is not an official Google product
google-dart-emacs-plugin-unsupported	Overview	Dart mode for Emacs.
google-dart-emacs-plugin-unsupported	Development status	Not officially supported
google-dart-emacs-plugin-unsupported	Development status	You may instead want to check outthis  dart mode for emacs 
google-dart-emacs-plugin-unsupported	History	This code is based on the dart-mode.elthat was previously hosted in the Dart repositoryat tools/utils/elisp/dart-mode.el.
google-dart-gl	Dart native extension for  GLES2 	Supports Linux and Windows
google-dart-gl	Dart native extension for  GLES2 	OSX is not supported due to inherentincompatibilites in the OSX UI threading model, as well as Apple announcing thediscontinuing of support of OpenGL on OSX 
google-dart-gl	Steps to generate the bindings	Some GL libraries come with headers that list functions not implemented
google-dart-gl	Steps to generate the bindings	Thiswill fail at link time
google-dart-gl	Steps to generate the bindings	To avoid this, you can dump the symbols in libGLESv2.soto be whitelisted and use the --whitelist flag intools/gl_generator.dartThe previous method for compiling the bindings is no longer available
google-dart-gl	Steps to generate the bindings	We areworking on a new solution for both Linux and Windows.In the meantime, the Makefile in the lib/ directory is a good starting point forcompiling on Linux.
google-dart-gl	Functions with interfaces with APIs different from GLES2	If a function's only difference is moving pointer parameters to the returnvalue, it is not listed
google-dart-gl	Functions with interfaces with APIs different from GLES2	See lib/src/manual_bindings.dart for a full list.
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	OpenGL is a thread-bound API
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	That is, an OpenGL context must be bound  or "madecurrent"  on a thread before any other OpenGL functions may be called.The Dart VM uses a pool of native threads under the hood to carry out tasks onthe event queue  overview of the Dart event loop This leads to an unfortunate restriction on the use of asynchronous code whilemaking OpenGL calls from Dart
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	This is bad:glfwMakeContextCurrent context ;glClear GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT ;// other OpenGL calls ...// Wait for an async task to finish.await someFuture;// Draw a triangle.glDrawArrays GL_TRIANGLES, 0, 3 ;// etc...The issue is that the context is made current, then there is a call to await,which causes the current task to return to the event loop until someFuturecompletes
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	When control returns to the next line, it may be running on acompletely different native thread, where the context is not bound.To avoid this issue, the code must be changed to something resembling theglfwMakeContextCurrent context ;glClear GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT ;// other OpenGL calls ...// Release the context before waiting.glfwMakeContextCurrent NULL ;// Wait for an async task to finish.await someFuture;// We're back!  Reacquire the context.glfwMakeContextCurrent context ;// Draw a triangle.glDrawArrays GL_TRIANGLES, 0, 3 ;// etc...This way, the context is released from the thread before control returns to theevent loop and then reacquired when it comes back.Note that this applies to any asynchronous code  not just an await 
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	Here'sanother bad example:glfwMakeContextCurrent context ;glClear GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT ;// other OpenGL calls ...// Load an image, then create a texture.var f = new File "image.rgb" ;f.readFileAsBytes  .then  bytes  {  var tex = glGenTextures 1 ;  glBindTexture GL_TEXTURE_2D, tex ;  glTexImage2D GL_TEXTURE_2D, 1, GL_RGBA, width, height, 0, GL_UNSIGNED_BYTE,} ;// etc...In this case, there's no guarantee that the callback to the readFileAsBytes would be running on the same thread as the original task.In practice, most OpenGL code is written synchronously, as it's generally notadvisable to be waiting for other tasks to complete while in the middle ofrendering a frame
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	However, it's important to be aware of this restriction
google-dart-gl	A note about OpenGL, the Dart VM, and native threads	Whenmaking OpenGL calls, either avoid awaiting asynchronous methods and makingOpenGL calls in async callbacks, or properly release the context anytime controlreturns to the event loop, and reacquire it when ready to make OpenGL calls
google-dart-glfw	Dart bindings to  GLFW  3.2.	Supports Linux and Windows
google-dart-glfw	Dart bindings to  GLFW  3.2.	OSX is not supported due to inherentincompatibilites in the OSX UI threading model, as well as Apple announcing thediscontinuing of support of OpenGL on OSX 
google-dart-glfw	Steps to generate the bindings	The previous method for compiling the bindings is no longer available
google-dart-glfw	Steps to generate the bindings	We areworking on a new solution for both Linux and Windows.In the meantime, the Makefile in the lib/ directory is a good starting point forcompiling on Linux.
google-dart-glfw	The following functions have changed from the C GLFW API	These changes are due to the C library's use of pointer arguments to returnvalues
google-dart-glfw	The following functions have changed from the C GLFW API	See also lib/src/manual\_bindings.dart.
google-dart-immutables	Immutables   	An experiment on wrapping arbitrary values to make them *recursively_Disclaimer_: This is not an official Google product.Immutable wrappers proxy every getter & non-mutating method call to theirwrapped value, and the return values from these calls are recursively wrapped.Users can bind wrappers that implement the interface of their wrapped class to play nice with checked mode 
google-dart-immutables	Immutables   	Support for explicitly whitelisting methodsas being non-mutating is being considered.
google-dart-immutables	What is immutable?	This library assumes a couple of invocations are not mutating their targets:allows getters to cache their results and still be considered non-mutating.be non-mutating, but this might not be true for LRU caches, etc.
google-dart-immutables	Note on mirror usage	This library does not require any symbol to be preserved, but does need someway to call getters / methods by symbol  not by name 
google-dart-immutables	Note on mirror usage	This is currently donewith the  smoke  library, but since Ihaven't written the required transformer yet the whole immutable library is justdisabled when compiling with dart2js.
google-dart-immutables	Usage	For instance, if you have a class Foo that you want to expose as immutable:
google-dart-immutables	Elidable	Immutable wrappers can be removed completely from your production binary.In your pubspec / transformers section, just add  last transformers entry :transformers:
google-dart-immutables	Interaction with Angular	Avoid returning new Immutable instances from getters called by Angulartemplates: this will confuse Angular's digest mechanism  it will think thedigest doesn't stabilize 
google-dart-immutables	Interaction with Angular	Instead, store the obtained Immutable instance.
google-dart-immutables	When all else fails	The deprecated unsafeUnwrapImmutable can be used to unwrap immutable values.TODO ochafik : allow customization of normalizedTypeGetters, nonMutatingMethodPredicates, breakoutPredicates .
google-dart-scissors	sCiSSors     ! Pub Package  	**Smarter resources for Angular apps: CSS pruning, bidirectional layouts, SVG & PNG optimization, Sass compilation, locale permutations, automatic reload.**_Disclaimer_: This is not an official Google product.
google-dart-scissors	Features	All of the following features are _lazy_  only triggered when needed  andmost of them are disabled or optimized for speed with pub serve in debug mode
google-dart-scissors	Features	note: may need pub serve --force-poll on MacOS X 
google-dart-scissors	Defaults vs. debug vs. release	sCiSSors is fine-tuned for fast build in debug mode  default for pub serve and small code size in release mode  default for pub build .Its behaviour can be fully customized through transformer settings inFor instance, to enable PNG optimizations in all modes, and enable SVGoptimizations in debug only:transformers:
google-dart-scissors	Prerequisites	If you checked out scissors's sources, you can run 
google-dart-scissors	Prerequisites	./script/install_dependencies.sh to get all the required dependencies, and skip the rest of this section :- 
google-dart-scissors	Installing CSSJanus	You'll need a local install of  CSSJanus  for CSS mirroring.Note that this transformer uses Google's original cssjanus.py, not its .js port   github.com/cssjanus/cssjanus  which might work if packaged as a binary that consumes css from stdin and outputs mirrored css on stdout .To install CSSJanus, run the following command in a console  ensure you have something like export PATH=~/bin:$PATH in your ~/.profile or ~/.bashrc :  mkdir ~/bin  curl  > ~/bin/cssjanus.py  chmod +x ~/bin/cssjanus.py  
google-dart-scissors	Other deps: SassC, pngcrush...	These packages are quite standard, you can get them with brew install on MacOS X and with sudo apt-get install on Ubuntu:The default transformer will build Sass files in a blink of aneye and will optimize CSS, PNG and SVG assets in release mode pub build .Please only setup sCiSSors's transformer on projects you know respect sCiSSors'conventions and limitations  see below .Examples: see  example/angular1   example/angular2   dev_dependencies:  transformers:Valid settings:  using Angular2 with ViewEncapsulation.None  see section below .Angular 1,2  provide the following  strategies   in Angular2  in Angular2The first two strategies  Shadow DOM & its transcluded emulation  provide strictencapsulation of style at the component level: styles defined in a componentdo not leak to any of its sub-components or parent components
google-dart-scissors	Other deps: SassC, pngcrush...	This is theassumption by which sCiSSors lives, so you're safe with it.The last "unscoped" strategy means there's no filecomponent-local way of deciding if a style *couldnot use sCiSSors on packages / projects with that strategy.
google-dart-scissors	Using scissors/css_mirroring_transformer	See  BidirectionalCss  BidirectionalCss.md  for more details.Example: see  example/mirroring   dev_dependencies:  transformers:Valid settings:Example: see  example/permutations   dev_dependencies:  transformers:Valid settings:  provoking 404s in production when sourcemaps aren't served  relevant only  when the $dart2js transformer has setting sourceMaps: true .This provides an amazing development turnaround experience, whether you're usingthe other sCiSSors transformers or not.With pub serve --force-poll, as soon as you save an asset  say, foo.scss and it finished building the dependent assets  say, foo.scss.css , the appwill reload
google-dart-scissors	Using scissors/css_mirroring_transformer	That's typically before you even have the time to tab-switch tothe browser  + no need to Ctrl+R .The transformer ensures the automatic reload logic is removed in releasebuilds  pub build , without interfering with source maps.Example: see  example/permutations Just edit pubspec.yaml  note: it's in dev_dependencies, not dependencies :  dev_dependencies:  transformers:And edit main.dart:  import 'package:scissors/reloader/reloader.dart';  }  Valid settings:See  UnawaitedFutures  UnawaitedFutures.md  for more details.Keep in mind that this transformer is very experimental, and slow.It aims to complement Dart's new strong-mode analyzer with more static checks,some of which could eventually graduate to the analyzer itself
google-dart-scissors	Using scissors/css_mirroring_transformer	 dev_dependencies:  transformers:  Valid settings:
google-dart-scissors	Development	For things to do, please see  issues To setup dependencies, please run:This will download some executables used by Scissors and will export the following environment varsPlease *never
google-dart2java	Compiling the SDK	The easy way to build the SDK is to run the tool/build_sdk.sh script.The script executes the following steps:This is not an official Google product.
google-dart_google_apps	Dart APIs for Google Apps Script	This is not an official Google product
google-dart_google_apps	Dart APIs for Google Apps Script	It is not supported by the Dart team.This package is still in an experimental state.A library to write Google Apps Script.This library has been written on a per-need basis
google-dart_google_apps	Dart APIs for Google Apps Script	As such it is missing lotsof useful functionality that I just hadn't needed yet
google-dart_google_apps	Dart APIs for Google Apps Script	Until the API coverageis nearing completeness I recommend to checkout the GIT repository duringdevelopment and to use this library with a path directive, adding the missingfunctions when they are encountered.Consider contributing your changes back to the original repository.
google-dart_google_apps	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-dart_google_apps	Features and bugs	tracker : 
google-data-layer-helper	Data Layer Helper Library	This library provides the ability to process messages passed onto a dataLayer queue.A dataLayer queue is simply a JavaScript array that lives on a webpage.its state.be metadata about the page content, information about the visitor, or data about events happening on the page
google-data-layer-helper	Data Layer Helper Library	This system allows tools like analytics libraries and tag management systems to access this data in a standard way, so page authors can avoid using a bunch of proprietary, repetitive APIs.The dataLayer system make things very easy for page authors
google-data-layer-helper	Data Layer Helper Library	The syntax is simple, and there's noextra code to load
google-data-layer-helper	Data Layer Helper Library	But this system _does_ make life a little more difficult for vendors and toolsthat want to consume the data
google-data-layer-helper	Data Layer Helper Library	That's where this library comes in
google-data-layer-helper	Data Layer Helper Library	This project provides the ability to listen for dataLayer messages and to read the key/value pairs that have been set by all the previous messages
google-data-layer-helper	Data Layer Helper Library	It can be used by the tools/vendors mentioned above, or by page authors that need to read back the data they've emitted.To use this library, you'll need to get it onto the page
google-data-layer-helper	Data Layer Helper Library	You can do this by hosting a copy and sourcing it from the page, or by compiling it into your own JavaScript library
google-data-layer-helper	Data Layer Helper Library	Once it's on the page, you can create a new helper object like this:merged into the helper's **"abstract data model"**
google-data-layer-helper	Data Layer Helper Library	 This internal model object holds the most recentvalue for all keys which have been set on messages processed by the helper
google-data-layer-helper	Data Layer Helper Library	You can retrieve values from the data model by using the helper's get   method:author might push the following message, which has data multiple levels deep:
google-data-layer-helper	The Abstract Data Model	As mentioned above, the abstract data model is an internal representation, which holdsthe most recent value for all keys that have been set by a dataLayer message
google-data-layer-helper	The Abstract Data Model	This means that as each message is pushed onto the dataLayer, the abstract data model must be updated
google-data-layer-helper	The Abstract Data Model	The helper library does this using a well-defined process
google-data-layer-helper	The Abstract Data Model	As each message is processed, its key/value pairs will be added to the abstract data model
google-data-layer-helper	The Abstract Data Model	If the key doesn't currently exist in the model, this operation is simple
google-data-layer-helper	The Abstract Data Model	The pair is simply added to the model object
google-data-layer-helper	The Abstract Data Model	But in the case of key conflicts, we haveto specify how values will be overwritten and/or merged.There are two possible actions to take when merging a key/value pair onto the abstract model; overwriting the existing value or recursively merging the new value onto the existing value
google-data-layer-helper	The Abstract Data Model	The action taken will depend on the type of the two values
google-data-layer-helper	The Abstract Data Model	For this, we define three types of values:objects that were created via Object literal notation  e.g
google-data-layer-helper	The Abstract Data Model	{one: 2}  or via "new Object".Nulls, Dates, RegExps, Windows, DOM Elements, etc
google-data-layer-helper	The Abstract Data Model	are not "Plain"
google-data-layer-helper	The Abstract Data Model	Those fall into the category of "everything else", along with strings, numbers, booleans, undefined, etc.following table to describe what action will happen for that key/value pair:Existing Value | New ValueArrayPlain Object   | ArrayPlain Object   | Plain Object | Recursively mergePlain Object   | OtherOther
google-data-layer-helper	Overwriting Existing Values	When the merging action is "Overwrite exsting value", the result of the operation is verysimple
google-data-layer-helper	Overwriting Existing Values	The existing value will be completely discarded and the new value will take its place in the abstract data model
google-data-layer-helper	Overwriting Existing Values	The following table provides some examples:Existing Value   | New Value{ducks: 'quack'} |  1, 2, 3 {ducks: 'quack'} | 'hello''hello'
google-data-layer-helper	Recursively Merging Values	When the merging action is "Recursively Merge", the result of the operation will be the result of iterating through each property in the new value, and for each property, deciding how to copy that sub-key/value into the abstract data model by looking at the type of that sub-key in the existing value
google-data-layer-helper	Recursively Merging Values	If the key does not exist on the existing value, the new value is simply assigned to the abstract model
google-data-layer-helper	Recursively Merging Values	The following examples demonstrate this:Existing Value{one: 1, three: 3} | {three: 4}{one: {two: 3}}{one: {two: 3}}   1  1, {two: 3} 
google-data-layer-helper	Meta Commands	Using the above methods alone, some operations on the abstract model are somewhat cumbersome.For example, appending items onto the end of an existing array requires you to know the length of the existing array and then requires you to clumsily build an array that can be merged onto the existing value
google-data-layer-helper	Meta Commands	 To make these cases easier, we provide a set of alternative syntaxes for updating values that are already in the abstract data model
google-data-layer-helper	Meta Commands	The first of these syntaxes allows you to call any method supported on the existing type
google-data-layer-helper	Meta Commands	For example, if the existing value in the abstract model is an Array, you'd have a wide variety of APIs that can be called  e.g
google-data-layer-helper	Meta Commands	push, pop, concat, shift, unshift, etc
google-data-layer-helper	Meta Commands	 To invokethis syntax, you would push a "command array" onto the dataLayer instead of a normal message contains the key of the value to update, followed by a dot  
google-data-layer-helper	Meta Commands	, followed by the name of the method to invoke on the value
google-data-layer-helper	Meta Commands	 In the above example, the key to update is 'abc', and the method to invoke is the 'push' method
google-data-layer-helper	Meta Commands	 The string may be followed by zero or more arguments, which will be passed to the invoked method.exception, the assignment will be ignored, and a warning message will be logged to the browser's developer console  if available .
google-data-layer-helper	Native Methods	Browsers come with dozens, if not hundreds, of useful APIs
google-data-layer-helper	Native Methods	Any method supported by the existing value can be called using the command array syntax
google-data-layer-helper	Native Methods	Here are some additional examples:                In the following example, no arguments are provided:                In the following example, the value to update  bbb  is nested inside a top level object  aaa :                And the following example demonstrates an operation on a Date object
google-data-layer-helper	Native Methods	 Remember that all types are supported, not just Arrays:                Notice that because command arrays are processed asynchronously, nothing can be done with the return values from these method invocations
google-data-layer-helper	Native Methods	This brings us to our second syntax for updating values in the abstract data model.
google-data-layer-helper	Custom Methods	So far, we've seen that objects  messages  can be pushed onto the dataLayer, as well as arrays  command arrays 
google-data-layer-helper	Custom Methods	Pushing a function onto the dataLayer will also allow you to update the abstract data model, but with custom code
google-data-layer-helper	Custom Methods	This technique has the added benefit of being able to handle return values of any native method calls made from within the function.When a function is processed, it will be executed in the context of the abstract data model
google-data-layer-helper	Custom Methods	The value of "this" will be an interface that represents the current abstract data model
google-data-layer-helper	Custom Methods	This interfact will provide two APIs: get key  and set key, value 
google-data-layer-helper	Custom Methods	The following examples demonstrate how these APIs can be used to update values in the abstract data model
google-data-layer-helper	Custom Methods	           this.get 'time' .setMonth 0 ; }       The following example demonstrates updating a nested value:            var ccc = this.get 'aaa.bbb.ccc' ;  ccc.push ccc.pop   }       The following example demonstrates overwriting a value:            this.set 'abc', {xyz: this.get 'abc' } ;}       
google-data-layer-helper	Listening for Messages	When creating a DataLayerHelper object, you can also specify a callback function to be called whenever a message is pushed onto the given dataLayer
google-data-layer-helper	Listening for Messages	This allows your code to be notifiedimmediately whenever the dataLayer has been updated, which is a key advantage of the messagequeue approach.Tools that are loaded onto the page asynchronously or lazily will appreciate that you can alsoopt to process message that were pushed onto the dataLayer in the past
google-data-layer-helper	Listening for Messages	This can be done by passing true as the third parameter in the DataLayerHelper constructor.has ever been pushed onto the given dataLayer
google-data-layer-helper	Listening for Messages	And on each call to the callback, the modelwill represent the abstract model at the time of the message.
google-data-layer-helper	Summary	We've seen above that the dataLayer provides a simple API for page authors
google-data-layer-helper	Summary	They simply definean array called dataLayer, then push messages onto it
google-data-layer-helper	Summary	There are three types of messages:listens for new messages and merges them onto its abstract data model
google-data-layer-helper	Summary	You can query the modelusing the get   API, or you can get message notifications with a callback function.At this point, we highly recommend that you read the code and browse the tests for examples ofhow the library works and how it can be used.
google-data-layer-helper	Build and Test	A few prerequisites: Install Node.js and npm  Install Git Clone a copy of the project repo by running:
google-data-transfer-project	Overview	The Data Transfer Project makes it easy for people to transfer their data between online services
google-data-transfer-project	Overview	We provide a common framework and ecosystem to accept contributions from service providers to enable seamless transfer of data into and out of their service.
google-data-transfer-project	Who We Are	Data Transfer Project  DTP  is a collaboration of organizations committed to building a common framework with open-source code that can connect any two online service providers, enabling a seamless, direct transfer of data.We want all individuals across the web to be in control of their data.
google-data-transfer-project	More info	Data Transfer Project is in its early stages, and we are actively looking for partner organizations and individuals to contribute to the project
google-data-transfer-project	More info	We are continuing to define the architecture and implementation
google-data-transfer-project	More info	 Since the code is in active development, please do thorough testing and verification before implementing.
google-data-transfer-project	Contact Info	Please contact  dtp-discuss@googlegroups.com  mailto:dtp-discuss@googlegroups.com with any questions or comments.
google-data-transfer-project	About Us	The Data Transfer Project was formed in 2017 to create an open-source, service-to-service portability platform so that all individuals across the web could easily move their data between online service providers.The partners in the Data Transfer Project believe portability and interoperability are central to innovation
google-data-transfer-project	About Us	Making it easier for individuals to choose among services facilitates competition, empowers individuals to try new services and enables them to choose the offering that best suits their needs.We anticipate the Data Transfer Project solution will make a particularly big impact in global markets where downloading or uploading data is expensive and/or slow
google-data-transfer-project	About Us	The Data Transfer Project eliminates the need to download data at all
google-data-transfer-project	About Us	Instead, data is transferred directly between service providers.
google-dbm-lineitem-copier	Line Item settings copier for DBM	A tool to copy specific settings values from an ORIGIN DBM Line Item to a one ormore DESTINATION Line Items, using DBM Structured Data Files.
google-dbm-lineitem-copier	OVERVIEW	This AppScript-based tool lets you use a Google Spreadsheet to retrieve thecurrent settings from am origin DBM Line Item, select one of those values e.g
google-dbm-lineitem-copier	OVERVIEW	Geotargeting  and copy it to as many destination Line Items you want.It uses DBM APIs to download the origin/destination Line Items Data in SDFformat and requires users to manually upload the updated settings of thedestination Line items in the DBM UI.The same result could be achieved manually downloading and editing the SDFfiles, but the tool leverages the APIs and Spreadsheet functionalities toautomate the most manual steps and to easily visualize origin and destinationFor more information about DBM Structured Data Files, have a look at theDoubleClick Bid Manager Help Center:In order to use this tool you need to have valid access to the **DoubleClick BidManager APIs*in a Google Cloud Project so that you can generate the Credentials used bythe tool  see the corresponding step of Initial Setup section below .
google-dbm-trix-addon	Overview	DBM Trix Addon allows users to download reports from DoubleClick BidmanagerManager on a scheduled basis into a Google Sheets Spreadsheet
google-dbm-trix-addon	Overview	Features of thisaddon are: Go to drive.google.com and create a new spreadsheet by going to New > Copy the doc id from the URL
google-dbm-trix-addon	Overview	This is the value between the d and edit as shown in bold below: Give the spreadsheet a name  Ex: "DBM Reporting" 
google-dbm-trix-addon	Upload files manually	 Extract the zip and open all the files in a text editor  Sublime text, Open script editor by going to the spreadsheet and going to Tools > Script Give the script a name  Ex: dbm-trix-addon 
google-dbm-trix-addon	Upload files manually	Create each individual file in the script editor with the same names as the Go to View > Show manifest file in the script editor
google-dbm-trix-addon	Upload files manually	Copy the contents ofOnce completed, move to the next section to continue the setup.
google-dbm-trix-addon	Setting up authentication	 Go to File > project properties and copy the script id
google-dbm-trix-addon	Setting up authentication	You will need this In the same script editor go to Resources > Cloud platform project and Click on the button at the top left corner of the page  three horizontal Go to APIs & Services > Dashboard Click on Enable APIS and Services at the top of the page
google-dbm-trix-addon	Setting up authentication	Search for "Bid Manager" and click on DoubleClick Bid Manager API
google-dbm-trix-addon	Setting up authentication	Click on Enable
google-dbm-trix-addon	Setting up authentication	Go to APIs & Services > Credentials Create new credentials by going to Create credentials -> Oauth client id -> Give it a name  Ex: dbm-trix-addon 
google-dbm-trix-addon	Setting up authentication	Under Authorized redirect URIs which is the second field in Hit 'create' Go back to the spreadsheet and refresh the document
google-dbm-trix-addon	Setting up authentication	Verify that the addon
google-dbm-trix-addon	First time run configuration	 Go to Add-ons > dbm-trix-addon > Select DBM Report
google-dbm-trix-addon	First time run configuration	You should get a popup In the popup click on Continue
google-dbm-trix-addon	First time run configuration	Select the account you want to use this addon with
google-dbm-trix-addon	First time run configuration	In the next screen, click on Advanced, scroll to the bottom and click on Review the permissions and scroll to the bottom and click on Allow
google-dbm-trix-addon	First time run configuration	Close the popup that's open in the spreadsheet and go to Add-ons > Click on Authorize and follow the steps again
google-dbm-trix-addon	First time run configuration	If all goes well, you This authentication needs to be done only the first time for each sheet
google-dbm-trix-addon	First time run configuration	Back in the spreadsheet, close the popup and go to Add-ons >If you encounter any issues, review the setup and check whether you havefollowed all the steps.
google-dcm-bulk-trafficking	**DCM Bulk Trafficking Tool**	An example tool to perform bulk tasks using DCM API.
google-dcm-bulk-trafficking	OVERVIEW	This AppScript-based tool lets you use a Google Spreadsheet to perform bulktasks including Placements It uses DCM APIs to pull and push data to DCM.The same result could be achieved by manually creating each entities through theDCM UI, but the tool leverages the APIs and Spreadsheet functionalities toautomate the most of manual steps.In order to use this tool you need to have valid access to the **DoubleClickCampaign Manager APIs*that API in a Google Cloud Project so that you can authenticate thetool  see the corresponding step of Initial Setup section below .
google-dcm-bulk-trafficking	CELL FORMATTING	Some of the columns require exact format to be used
google-dcm-bulk-trafficking	CELL FORMATTING	Below you can find a listof all requirements:
google-dcm-trix-addon	Overview	DCM Trix Addon allows users to download reports from DoubleClick CampaignManager on a scheduled basis into a Google Sheets Spreadsheet
google-dcm-trix-addon	Overview	Features of thisaddon are: Go to drive.google.com and create a new spreadsheet by going to New > Copy the doc id from the URL
google-dcm-trix-addon	Overview	This is the value between the d and edit as shown in bold below: Give the spreadsheet a name  Ex: "DCM Reporting" 
google-dcm-trix-addon	Upload the files in the script using command line tool 	If you are familiar with using command line tools, you can use clasp
google-dcm-trix-addon	Upload the files in the script using command line tool 	Else go toOption  Install  clasp  as Download the github project using Change to the project directory
google-dcm-trix-addon	Upload the files in the script using command line tool 	Authenticate and allow clasp to upload files on your behalf
google-dcm-trix-addon	Upload the files in the script using command line tool 	Create a new apps script project in the spreadsheet created earlier
google-dcm-trix-addon	Upload the files in the script using command line tool 	Replace Deploy the chagnes to the apps script project
google-dcm-trix-addon	Upload the files in the script using command line tool 	Open the script editor by going to the spreadsheet window and selectingAfter completing this step, continue with  Setting upauthentication  #setting-up-authentication .
google-dcm-trix-addon	Upload files manually	 Extract the zip and open all the files in a text editor  Sublime text, Open script editor by going to the spreadsheet and going to Tools > Script Give the script a name  Ex: dcm-trix-addon 
google-dcm-trix-addon	Upload files manually	Create each individual file in the script editor with the same names as the Go to View > Show manifest file in the script editor
google-dcm-trix-addon	Upload files manually	Copy the contents ofOnce completed, move to the next section to continue the setup.
google-dcm-trix-addon	Setting up authentication	 Go to File > project properties and copy the script id
google-dcm-trix-addon	Setting up authentication	You will need this In the same script editor go to Resources > Cloud platform project and Click on the button at the top left corner of the page  three horizontal Go to APIs & Services > Dashboard Click on Enable APIS and Services at the top of the page
google-dcm-trix-addon	Setting up authentication	Search for "DCM" and click on DCM/DFA Reporting And Trafficking API
google-dcm-trix-addon	Setting up authentication	Click on Enable
google-dcm-trix-addon	Setting up authentication	Go to APIs & Services > Credentials Create new credentials by going to Create credentials -> Oauth client id -> Give it a name  Ex: dcm-trix-addon 
google-dcm-trix-addon	Setting up authentication	Under Authorized redirect URIs which is the second field in Hit 'create' Go back to the spreadsheet and refresh the document
google-dcm-trix-addon	Setting up authentication	Verify that the addon
google-dcm-trix-addon	First time run configuration	 Go to Add-ons > dcm-trix-addon > Select DCM Report
google-dcm-trix-addon	First time run configuration	You should get a popup In the popup click on Continue
google-dcm-trix-addon	First time run configuration	Select the account you want to use this addon with
google-dcm-trix-addon	First time run configuration	In the next screen, click on Advanced, scroll to the bottom and click on Review the permissions and scroll to the bottom and click on Allow
google-dcm-trix-addon	First time run configuration	Close the popup that's open in the spreadsheet and go to Add-ons > Click on Authorize and follow the steps again
google-dcm-trix-addon	First time run configuration	If all goes well, you This authentication needs to be done only the first time for each sheet
google-dcm-trix-addon	First time run configuration	Back in the spreadsheet, close the popup and go to Add-ons >If you encounter any issues, review the setup and check whether you havefollowed all the steps.
google-dcm-video-uploader	Dependencies installation	In order to install dependencies for the script, run
google-dcm-video-uploader	Before first run	The script makes use of OAuth 2.0 credentials to access DCM APIs
google-dcm-video-uploader	Before first run	Youwould need to place your credentials on a 'client_secrets.json' file in theexecution directory
google-dcm-video-uploader	Before first run	You can follow the instructions available at Inorder to perform the OAuth authentication from the command-line, you may needto execute the script with the option --noauth_local_webserver
google-dcm-video-uploader	Execution	In order to run the script, use the following command:You must provide, at least, the following arguments:write access to the advertiser and campaign where you want to add the videos.creatives will be added.the ads that were successfully createdads could not be created, you will find the reason in this fileFor a full description on how to execute the script, run
google-dcm-video-uploader	Files overview	A description of the main files part of the script follows
google-dcm-video-uploader	upload_videos.py	This is the entry point for the CLI script
google-dcm-video-uploader	upload_videos.py	It contains the argument parsing and makesuse of video_uploader.py to actually perform video upload and traffickingFor more information, please check PyDocs in upload_videos.py
google-dcm-video-uploader	video_uploader.py	This file contains an example implementation of a Python classthat helps with creating and activating targeted video ads in DCM.For more information, please check PyDocs in video_uploader.py
google-dcm_bulk_onboarding	**DCM Bulk Onboarding Tool**	An example tool to perform bulk tasks to onboard DCM accounts using DCM API.
google-dcm_bulk_onboarding	OVERVIEW	This AppScript-based tool lets you use a Google Spreadsheet to perform bulkboarding tasks including AdvertiserGroups Config IDAdditional helper tasks for these bulk creations include Permissions List It uses DCM APIs to pull and push data to DCM.The same result could be achieved by manually creating each entities through theDCM UI, but the tool leverages the APIs and Spreadsheet functionalities toautomate the most manual steps.In order to use this tool you need to have valid access to the **DoubleClickCampaign Manager APIs*that API in a Google Cloud Project so that you can generate authenticate thetool  see the corresponding step of Initial Setup section below .
google-decoupled_gaussian_process	Decoupled Gaussian process model.	**This is not an officially supported Google product.**This repository contains an implementation of the Decoupled Gaussian Processmodel that decouples the representation of mean and covariance in reproducingkernel Hilbert space.The details of the model is in the paper: _Cheng, Ching-An, and Byron Boots."Variational Inference for Gaussian Process Models with Linear Complexity."Advances in Neural Information Processing Systems
google-decoupled_gaussian_process	Decoupled Gaussian process model.	2017._Link to the paper:
google-decoupled_gaussian_process	How to use the model	This model can be used mainly in two ways:
google-decoupled_gaussian_process	Through session.run  	File decoupled_gaussian_process_example.py provides detailed steps to trainand evaluate the model by first building the graph, and then iterativelyminimizing the objective function by session.run train_step 
google-decoupled_gaussian_process	Through session.run  	In order to usethe model as a layer, you may want to embed the logic of adding bases online andhyperparameters initialization in the graph, so that no initial values forhyperparameters are needed and no need to call model.bases.add_bases   in thetrain loop anymore.
google-decoupled_gaussian_process	Through model_fn  	model_fn   is defined in decoupled_gaussian_process_model.py
google-decoupled_gaussian_process	Through model_fn  	We can use thefollowing code to create an tf.estimator.Estimator:against other models.
google-deepdream	deepdream	This repository contains IPython Notebook with sample code, complementing Google Research  blog post  about Neural Network art.See  original gallery  for more examples.You can view "dream.ipynb" directly on github, or clone the repository, install dependencies listed in the notebook and play with code locally.It'll be interesting to see what imagery people are able to generate using the described technique
google-deepdream	deepdream	If you post images to Google+, Facebook, or Twitter, be sure to tag them with  #deepdream  so other researchers can check them out too.
google-deepvariant	DeepVariant	DeepVariant is an analysis pipeline that uses a deep neural network to callgenetic variants from next-generation DNA sequencing data.
google-deepvariant	About DeepVariant	For technical details describing how DeepVariant works please see our preprint ! DeepVariant workflow  docs/DeepVariant-workflow-figure.png?raw=true "DeepVariant workflow" Briefly, we started with some of the reference genomes from  Genome in aBottle  for which there is high-quality groundtruth available  or the closest approximation currently possible 
google-deepvariant	About DeepVariant	Usingmultiple replicates of these genomes, we produced approximately one hundredmillion training examples in the form of multi-channel tensors encoding thesequencing instrument data, and then trained a TensorFlow-based imageclassification model   inception-v3  toassign genotype likelihoods from the experimental data produced by theinstrument
google-deepvariant	About DeepVariant	Read additional information on the  Google Researchblog Under the hood, DeepVariant relies on Nucleus  a library of Python and C++ codefor reading and writing data in common genomics file formats  like SAM and VCF designed for painless integration with the TensorFlow  machine learning framework.
google-deepvariant	Evaluating DeepVariant	We are delighted to see several external evaluations of the DeepVariant method.The 2016 PrecisionFDA Truth Challenge, administered by the FDA, assessed severalcommunity-submitted variant callsets on the  at the time  blinded evaluationsample, HGDeepVariant won the  Highest SNPPerformance  award in theDNAnexus  posted an extensiveevaluation of several variant calling methods, including DeepVariant, using a variety ofread sets from HG001, HG002, and HGThey have also evaluated DeepVariantunder a variety of  noisy sequencingconditions Independent evaluations of DeepVariant v0.6 from both DNAnexus  and bcbio are also available
google-deepvariant	Evaluating DeepVariant	Their analyses support our findings of improved indelaccuracy, and also include comparisons to other variant calling tools.
google-deepvariant	Support	The  Genomics team in Google Brain actively supports DeepVariant and are always interested in improving the qualityof DeepVariant
google-deepvariant	Support	If you run into an issue, please report the problem on our  Issuetracker  Make sure to add enoughdetail to your report that we can reproduce the problem and fix it
google-deepvariant	Support	We encourageincluding links to snippets of BAM/VCF/etc
google-deepvariant	Support	files that provoke the bug, ifpossible
google-deepvariant	Support	Depending on the severity of the issue we may patch DeepVariantimmediately with the fix or roll it into the next release.If you have questions about next-generation sequencing, bioinformatics, or othergeneral topics not specific to DeepVariant we recommend you post your questionto a community discussion forum such as  BioStars 
google-deepvariant	Contributing	Interested in contributing? See  CONTRIBUTING  CONTRIBUTING.md .
google-deepvariant	License	DeepVariant is licensed under the terms of the  BSD-3-Clause license  LICENSE .
google-deepvariant	Acknowledgements	DeepVariant happily makes use of many open source packages
google-deepvariant	Acknowledgements	 We'd like tospecifically call out a few key ones:
google-depan	DepAn	DepAn is a direct manipulation tool for visualization, analysis, and refactoring of dependencies in large applications.More information is available at 
google-der-ascii	DER ASCII	  DER ASCII is a small human-editable language to emit DER  Distinguished Encoding Rules or BER  Basic Encoding Rules encodings of ASN.1 structures and malformed variants of them.It provides two tools, ascii2der and der2ascii, to convert DER ASCII to abyte string and vice versa
google-der-ascii	DER ASCII	To install them, run:These tools may be used to create test inputs by taking an existing DER or BERstructure, disassembling it with der2ascii into DER ASCII, makingadjustments, and assembling back into binary with ascii2der
google-der-ascii	DER ASCII	This avoidshaving to manually fix up all the length prefixes
google-der-ascii	DER ASCII	 As a bonus, it acts as ahuman-readable view for DER structures.For the language specification and basic examples, see language.txt  /language.txt 
google-der-ascii	DER ASCII	The  samples  /samples  directory includesmore complex examples from real inputs.
google-der-ascii	Backwards compatibility	The DER ASCII language itself may be extended over time, but the intention isfor extensions to be backwards-compatible
google-der-ascii	Backwards compatibility	Specifically:  future-proof, though it is recommended to check in the generated version as  well in case of mistakes
google-der-ascii	Backwards compatibility	 formatting, or disassemble a malformed DER input in a  hopefully  more  useful form.
google-der-ascii	Disclaimer	This is not an official Google project.
google-desugar_jdk_libs	desugar_jdk_libs	This project contains a small subset of OpenJDK libraries simplified for useon older runtimes.This is not an official Google product.
google-detangle	Detangle	This is not an official Google product.Detangle automatically separates your browser into multiple browser profiles.Corporate IT can specify a list of internal sites to be opened in the mainbrowser, and all other sites  including links  will be automatically handed offto another profile.
google-detangle	Building	Bazel is required for building
google-detangle	Building	The native messaging component can be built by
google-detectorgraph	DetectorGraph: Formal C++ applications with logic/data separation, automatic dependency injection and data passing.	  DetectorGraph is a framework for writing programs in a formal graph topology.This can be used to write applications with multiple interdependent algorithms, applications' data models, general business logic or all of that combined.The framework uses a formal distinction between data  Topics  and transformations/logic  Detectors .It natively provides dependency injection, strict type-safety and provides loose coupling between Detectors by formalizing the touch points as Topics.It forces an intuitive  albeit unusual  programming paradigm that results in highly readable, maintainable & testable code.This is not an officially supported Google product.Note that the cross-reference links in this page are only rendered in the Doxygen version of the documentation  see  Building  #building  .You can also navigate the web version of the documentation hosted at 
google-detectorgraph	Usage	Applications are written as a combination of *DetectorsGraph *Evaluations
google-detectorgraph	User Guide	Below are a number of examples showcasing different aspects & usage patterns of the framework  these are in the ./examples/ folder .The library has no dependencies beyond C++ & STL  min C++0x  and was designed to be fully portable to any environment supporting those dependencies.
google-detectorgraph	Platform Implementations	The library uses abstractions for basic things like asserts & logging to allow for project & platform specific customization.The library is shipped with a basic set of implementations for those basic functions in ./platform_standalone.
google-detectorgraph	Timers / Time Integration	To enable time-aware functionality  e.g
google-detectorgraph	Timers / Time Integration	 PublishOnTimeout  @ref DetectorGraph::TimeoutPublisher ,  GetTime  @ref DetectorGraph::TimeoutPublisherService::GetTime ,  SetupPeriodicPublishing  @ref DetectorGraph::Detector::SetupPeriodicPublishing   you must provide a concrete implementation of  TimeoutPublisherService  @ref DetectorGraph::TimeoutPublisherService  and pass that to your *Detectors
google-detectorgraph	Runtime Integration	There are multiple ways of integrating  Graph  @ref DetectorGraph::Graph  into your application
google-detectorgraph	Runtime Integration	A good place to start is sub-classing  ProcessorContainer  @ref DetectorGraph::ProcessorContainer , adding: 
google-detectorgraph	Tests, Docs and Examples	The library is shipped with a bare-bones makefile that can be used to build & run all of the examples, unit tests, documentation and coverage report.
google-detectorgraph	For your project	The library is mostly header-only  only 3 core compilation units  and has a trivial compilation process
google-detectorgraph	For your project	So instead of providing a binary or a complete build system we recommend that users use their build system of choice to build the library in whatever way fits their needs better
google-detectorgraph	For your project	For examples on how to do that, please check  makefile  @ref makefile .
google-detectorgraph	Why another Graph compute framework?	DetectorGraph shares a lot of its core concepts with other frameworks based in computation graphs  e.g
google-detectorgraph	Why another Graph compute framework?	ROS, TensorFlow etc  but has also many differences.Some of its most unique features are:The DetectorGraph library had a little naming problem growing up
google-detectorgraph	Why another Graph compute framework?	From birth it came to replace nlDetectorGraph and so it pretended to be called that way
google-detectorgraph	Why another Graph compute framework?	As an adolescent it decided it wanted to be called MarkII.
google-detectorgraph	Why another Graph compute framework?	but no one cared 
google-detectorgraph	In-depth Docs & API Reference	For in depth documentation of the library,  start here  @ref core_introduction  
google-dev-on-chromeos-che	Disclaimer	This is not an official Google product, this is just a way I found to get stuff
google-dev-on-chromeos-che	Prerequsites	If you want to give your che workspaces the ability to run docker commands  say,for instance that you're developing docker images  then add editchedata/instance/config/che.properties, by replacingEdit docker-compose.yml to pick the version of Che you wish  alternatively youcan just remove the version number and always use the latest .Then run
google-dev-on-chromeos-gce-setup	Disclaimer	This is not an official Google product.
google-dev-on-chromeos-gce-setup	Basic setup	GCE Ubuntu 16 comes with curl and git and bash
google-dev-on-chromeos-gce-setup	Basic setup	 If you don't have those, add them.
google-dev-on-chromeos-gce-setup	External IP / Synamic DNS integration	Preemptable instances habe ephemeral external IPs To make it easier to use, use a dynamic DNS service To setup DuckDNS  /etc/duckdns.env
google-dev-on-chromeos-gce-setup	External IP / Synamic DNS integration	It should look like this, but with your values:Install the Docker repos and Docker, which are generally much more recent than the Ubuntu maintained docker.io package:
google-dev-on-chromeos-gce-setup	Install docker-compose	A script to just get the latest non-rc version of docker-compose:Because you're on GCE  just guessing..
google-dev-on-chromeos-gce-setup	Install docker-compose	:
google-dev-on-chromeos-gce-setup	Setup GIT	Let git know who you are:If you want to automatically shutdown the server instance so you're not charged for time you're not using:
google-dev-on-chromeos-openvpn	Overview	This is an extension of  kylemanna/openvpn  that
google-dev-on-chromeos-openvpn	Motivation	When trying to develop on a Chromebook, I didn't like three things:I find it frustratingly slow to use a full remote desktop solution.Tools exist for remote development  such as Eclipse Che  but they work best on a privateIt it very difficult to do the equivalent of setting a host file on a ChromeOS system.So I decided that the best way to accomplish this was to create an Docker image for OpenVPN that Icould run on any server I had access to  a cloud VPN, a headless machine in a bookshelf, etc , thatprovided its own DNS service.
google-dev-on-chromeos-openvpn	Project status	_This is not an official Google product._This is experimental software, not feature complete, not security reviewed, ant not ready to doanything except be a science experiment.
google-dev-on-chromeos-openvpn	How to use it	cp sample.env .env and edit it to include the right values for you.Put your master CA password in ca_master_password.txtLaunch the openvpn service:Get the client info:Find the .onc file that was generatedInstall the files on chromeos
google-dev-on-chromeos-openvpn	How to use it	Open a the  net-internals  chrome://net-internals/#chromeos If you want to specify other "host" file entries
google-dev-on-chromeos-openvpn	Why	  your connections to anyone else AND present a cert your browser will trust
google-dev-on-chromeos-openvpn	Why	I don't feel like a  password on the CA key is safe enough, given the risk
google-dev-on-chromeos-openvpn	Why	Whereas if you use a public CA to issue  the cert for your VPN, the hacker only gets to hack you VPN traffic, but not MITM all of your SSL  connections
google-dev-on-chromeos-openvpn	Why	  VPN host anyway
google-dev-on-chromeos-openvpn	Why	 the VPN server can see, the clients can see
google-dev-on-chromeos-openvpn	Why	 to be listening on port 443
google-developer.github.com	developer.github.com	This is a GitHub API resource built with  nanoc  nanoc .All submissions are welcome
google-developer.github.com	developer.github.com	To submit a change, fork this repo, commit your changes, and send us a  pull request 
google-developer.github.com	Setup	Ruby 1.9 is required to build the site.Get the nanoc gem, plus kramdown for markdown parsing:You can see the available commands with nanoc:Nanoc has  some nice documentation  to get you started
google-developer.github.com	Setup	 Though if you're mainly concerned with editing or adding content, you won't need to know much about nanoc
google-developer.github.com	Setup	nanoc : 
google-developer.github.com	Styleguide	Not sure how to structure the docs?  Here's what the structure of theAPI docs should look like:**Note**: We're using  Kramdown Markdown extensions  such as definition lists.
google-developer.github.com	JSON Responses	We specify the JSON responses in ruby so that we don't have to writethem by hand all over the docs
google-developer.github.com	JSON Responses	 You can render the JSON for a resourcelike this:Some actions return arrays
google-developer.github.com	JSON Responses	 You can modify the JSON by passing a block:You can specify terminal blocks with pre.terminal elements
google-developer.github.com	JSON Responses	 It'd benice if Markdown could do this more cleanly...This isn't a curl tutorial though, I'm not sure every API call needsto show how to access it with curl.
google-developer.github.com	Development	Nanoc compiles the site into static files living in ./output
google-developer.github.com	Development	 It'ssmart enough not to try to compile unchanged files:You can setup whatever you want to view the files
google-developer.github.com	Development	 If you have the adsfgem, however  I hope so, it was in the Gemfile , you can start Webrick:Compilation times got you down?  Use autocompile!This starts a web server too, so there's no need to run nanoc view.One thing: remember to add trailing slashes to all nanoc links!
google-devicehub	DeviceHub	_This is not an official Google product._DeviceHub is a multi-device test framework which enables you to write teststhat interact with multiple heterogeneous devices
google-devicehub	DeviceHub	The tests can run on a server as JUnit tests or on an Android device as instrumentation or UI Automator tests
google-devicehub	DeviceHub	The DeviceHub is based on a client/server architecture
google-devicehub	DeviceHub	In the middle of theDeviceHub test framework is the DevieHub server which facilitates the communications among devices
google-devicehub	DeviceHub	The tests use device clients to communicate with theDeviceHub server and send requests to other devices to perform certain actions.For Android devices, you can add custom code to provide test specific functions by extendingCustomCodeHandler provided in the device directory, these functions can be called aspart of the test logic
google-devicehub	DeviceHub	For example, imagine a test scenario where two devices are involved: abroadcaster and a receiver
google-devicehub	DeviceHub	The test is to verify that the message broadcasted by the former isreceived on the latter correctly
google-devicehub	DeviceHub	Here are the test steps: The test asks the receiver to start accept new messages
google-devicehub	DeviceHub	The test asks the broadcaster to broadcast a message
google-devicehub	DeviceHub	The test asks the receiver if it has received the expected message
google-devicehub	DeviceHub	In this scenario, you can provide two custom code to receive message and to send message
google-devicehub	DeviceHub	The test logic will be executed on the server where two devices are connected and triggers the custom code accordingly and verify the result.
google-devicehub	License	DeviceHub is licensed under the open-source  Apache 2.0 license  LICENSE .
google-devicehub	Contributing	Please  see the guidelines for contributing  CONTRIBUTING.md  before creatingpull requests.
google-devtools-driver	DevTools Driver	DevTools Driver is a Java framework for creating a WebDriver serverimplementation for any browser that supports the  DevTools Remote DebuggingProtocol  including anybrowser based on the WebKit or Blink browser engines
google-devtools-driver	DevTools Driver	Implementations for suchbrowsers can be created simply by providing a few relatively simple hookmethods, and the framework handles the rest, largely through JavaScriptinjection of  browser automationatoms  overThis project includes a WebDriver implementation for Mobile Safari on iOS
google-devtools-driver	DevTools Driver	Thisimplementation, which works for both iOS simulators and real devices, uses the iOS Device Control library  tocontrol devices
google-devtools-driver	DevTools Driver	An example of a web test controlling a remote Mobile SafariDevtools Driver can be found in  ExampleMobileSafariWebTest.java  src/com/google/devtoolsdriver/examples/ExampleMobileSafariWebTest.java .
google-devtools-driver	Installation	 Before assembling a runnable jar for a Selenium server, the iOS Device The library must then be installed into the local Maven repository: A runnable jar of a Mobile Safari capable Selenium server can be assembled Run the assembled jar found at
google-devtools-driver	License	DevTools Driver is licensed under the open-source  Apache 2.0 license  LICENSE 
google-devtools-driver	Contributing	Please  see the guidelines for contributing  CONTRIBUTING.md  before creatingpull requests
google-dicomParser	untilTag	A tag in the form xggggeeee  where gggg is the hexadecimal group number and eeee is the hexadecimal element number,e.g
google-dicomParser	untilTag	'x7fe00010'  that specifies the final tag to parse
google-dicomParser	untilTag	Any tags occurring after this in the file will be ignored.Useful for partial reading of byte streams.
google-dicomParser	vrCallback	A callback that, given a tag, will return the two-character Value Representation associated with that tag  see PS 3.5of the DICOM standard for more information 
google-dicomParser	vrCallback	It may return undefined to indicate that the VR was not provided.
google-dicomParser	inflater	A callback that given the underlying byteArray and position of the deflated buffer returns a byteArray containing theDICOM P10 header and inflated data set concatenated together.Key FeaturesBuild SystemThis project uses Webpack to build the software.---------------NodeJs Common TasksUpdate dependencies  after each pull :> npm installRunning the build:> npm run buildAutomatically running the build and unit tests after each source change:> npm run watch------------============================================While building the WADO Image Loader for  cornerstone  I couldn't find a Javascript DICOM parser that exactly metmy needs
google-dicomParser	inflater	 DICOM really isn't that hard to parse so I figured I would just make my own
google-dicomParser	inflater	 Here are some of the key things that Ireally wanted out of a DICOM library that I am hoping to deliver:_License is extremely liberal so it could be used in any type of project_DICOM is an open standard and parsing it is easy enough that it should be freely available forall types of products will help it see the widest possible adoption  which will in the end help the most patients .I will dual license it under GPL if someone asks._Only deals with parsing DICOM I am a big believer in small reusable pieces of software and loose coupling
google-dicomParser	inflater	 There is no reason totightly couple the parser with image display
google-dicomParser	inflater	 I hope that keeping this library small and simple willhelp it reach the widest adoption._Designed to work well in a browser  modern ones at least _There are some  good javascript DICOM parsing libraries  available for server development on node.js but theywon't automatically work in a browser
google-dicomParser	inflater	 I needed a library that let me easily parse WADO responses andI figured others would also prefer a simple library to do this with no dependencies.The library does make use of the  ArrayBuffer object which is widely supported except for IE  it is available on IE10+ 
google-dicomParser	inflater	 I have no current plans to add supportfor older versions of IE but would be open to contributions if someone wants to do the work._Follows modern javascript best practices_This of course means different things to different people but I have found great benefit from making suremy javascript passes  jshint  and leveraging the module pattern   I also have a great affinity to AMD modules  but I understand that not everyone wants to use them.So for this library I am shooting for simply making sure the code uses the module pattern and passes jshint._Has documentation and examples on how to use it_Do I really need to convince you that this is needed?_Does not hide the underlying data stream from you_I have used many DICOM parsing libraries over the years and most of them either hide the underlying byte streamfrom you or make it difficult to access
google-dicomParser	inflater	 There are times when you need to access the underlying bytes  it is frustrating when the library works against you
google-dicomParser	inflater	 A few examples of the need for this includeUN VR's, private attributes, encapsulated pixel data and implicit little endian transfersyntaxes  which unfortunately are still widely being used  when you don't have a complete data dictionary.This library addresses this issue by exposing the offset and length of the data portion of each element
google-dicomParser	inflater	 It also defers parsing  and type converting  the data until it is actually asked to do so
google-dicomParser	inflater	So what you get from a parse is basically a set of pointers to where the data for each element is in thebyte stream and then you call the function you want to extract the type you want
google-dicomParser	inflater	 An awesome sideeffect of this is that you don't need a data dictionary to parse a file even if it uses implicitlittle endian
google-dicomParser	inflater	 It also turns out that parsing this way is very fast as it avoids doing unneeded type conversions.Note that you cannot 100% reliably parse sequence elements in an implicit little endiantransfer syntax without a data dictionary
google-dicomParser	inflater	 I therefore *stronglysyntaxes whenever possible
google-dicomParser	inflater	 Fortunately most Image Archives should be able to give you an explicittransfer syntax encoding of your sop instance even if it received it in implicit little endian.Note that WADO's default transfer syntax is explicit little endian so one would assume that anImage Archive supporting WADO would have a good data dictionary management system.Initially I wasn't going to support parsing of implicit data at all but decided to mainly forconvenience  and the fact that many of my test data sets are in little endian transfer syntax and I am toolazy to convert them to explicit transfer syntax ._Does not require a data dictionary_As a client, you usually you know which elements you want to access and know what type they are so designing aclient oriented parser around a data dictionary is adding unnecessary complexity, especially if you can stick toexplicit transfer syntaxes
google-dicomParser	inflater	 I also believe it is the the server's responsibility to provide the client safe and easily digestable data  i.e
google-dicomParser	inflater	explicit transfer syntaxes 
google-dicomParser	inflater	 A server typically supportsmany types of clients so it makes sense to centralize data dictionary management in one place ratherthan burden each client with it.Data dictionaries are not required for most client use cases anyway so I decided not to support it in this libraryat all
google-dicomParser	inflater	 For those use cases that do require a data dictionary, you can layer it on top of this library
google-dicomParser	inflater	 An exampleof doing so is provided in the live examples
google-dicomParser	inflater	 If you do want to know the VR, request the instance in anexplicit transfer syntax and you can have it
google-dicomParser	inflater	 If your Image Archive can't do this for you, get a new one _Decodes individual elements "on demand" See above, this is related to not requiring a data dictionary
google-dicomParser	inflater	 Usually you know exactly what elements you needand what their types are
google-dicomParser	inflater	 The only time this is not the case is when you are building a DICOM Dump utility oryou can't get an explicit transfer syntax and have one of those problematic elements that can be either OB or OW  and youcan _usually_ figure out which one it is without the VR anyway _Code guards against corrupt or invalid data streams by sanity checking lengths and offsets_Even though you would expect an Image Archive to _never_ send you data that isn't 100% DICOM compliant,that is not a bet I would make
google-dicomParser	inflater	 As I like to say who ship software that creates bytes streams that violate the DICOM standard
google-dicomParser	inflater	 Regardless, it is goodpractice to never trust data from another system _Does not depend on any external dependencies Sort of addressed above as maximizing adoption requires that the library minimize the burden on its users
google-dicomParser	inflater	 I didfind a few interesting libraries that were targeted at making it easier and safer to parse byte streams butthey just seemed like overkill so I decided to do it all in one to keep it as simple as it could be
google-dicomParser	inflater	 In generalI am a big fan of building complex systems from lots of smaller simpler pieces
google-dicomParser	inflater	 Some goodreferences on this include the  microjs site  and the cujo.js manifseto _Has unit tests_I generally feel that units tests are _often_ a waste of time for front end development
google-dicomParser	inflater	 Where unit tests do make senseis code that is decoupled from the user interface  TDD  on this project and had unit testscovering ~ 80% of the code paths passing before I even tried to load my first real DICOM file
google-dicomParser	inflater	 Before I wrotethis library, I did a quick prototype without unit tests that actually took me much less time writing tests takes time...
google-dicomParser	inflater	  So in the end I don't think it saved me much time getting to a first release,but I am hoping it will pay for itself in the long run  especially if this library receives wide adoption .I also know that some people out there won't even look at it unless it has good test coverage.Interesting note here the standard difficult to understand in these areas and didn't want to waste my time building tests that were notcorrect
google-dicomParser	inflater	 I ended up making these work by throwing a variety of data sets at it and fixing the issues that I found.Getting this working took about 3x longer than everything else combined so perhaps it would have been faster if I hadused TDD on this part._Code is easy to understand_In my experience, writing code that is easy to understand is *far more importanttests for that code
google-dicomParser	inflater	 The reason is that when a developer needs to fix or enhance a piece of code, they _almost never_start with the unit tests or documentation If some other developer is looking at your code, you probably made a mistake really blew it
google-dicomParser	inflater	 In either case, you should have mercy on them in advance and make their unenviable task of fixingor extending your code the best it can be
google-dicomParser	inflater	 Some principles I try to follow include:better than writing comments in the source fileharder it is to remember what you are looking atYou can find out more about this by googling for "self documenting code"============Copyright 2016 Chris Hafey  chafey@gmail.com  mailto:chafey@gmail.com  license-image :  license-url : LICENSE npm-url :  npm-version-image :  npm-downloads-image :  travis-url :  travis-image :  coverage-url :  coverage-image : 
google-diff-match-patch	Reference	Although each language port of Diff Match Patch uses the same API, there are some language-specific notes.
google-diff-match-patch	Algorithms	This library implements  Myer's diff algorithm  which is generally considered to be the best general-purpose diff
google-diff-match-patch	Algorithms	A layer of  pre-diff speedups and post-diff cleanups  surround the diff algorithm, improving both performance and output quality.This library also implements a  Bitap matching algorithm  at the heart of a  flexible matching and patching strategy 
google-differentiable-atomistic-potentials	#+AUTHOR: John Kitchin	This is not an official Google product.
google-differentiable-atomistic-potentials	#+BEGIN_EXPORT html	The first demonstration of this approach is for the Lennard Jones potential, which is fully implemented in TensorFlow to compute energies, forces and stress of periodic atomic systems containing one kind of chemical element
google-differentiable-atomistic-potentials	#+BEGIN_EXPORT html	The potential is trainable from a database of reference data, e.g
google-differentiable-atomistic-potentials	#+BEGIN_EXPORT html	density functional theory calculations
google-differentiable-atomistic-potentials	#+BEGIN_EXPORT html	An example is illustrated in   ./docs/dap.tf.lennardjones.org  .
google-differentiable-atomistic-potentials	#+BEGIN_SRC sh	git clone cd differentiable-atomistic-potentialspip install --user -e .Here are a few of the AD toolkits that are currently around.See   ./requirements.txt   for a list of required Python packages.
google-digitalassetlinks	#Digital Asset Links	Digital Asset Links is a collection of data formats and protocols to managesecurely verified relationships between online assets such as web sites, socialmedia profiles, email addresses or mobile apps.See  digitalassetlinks.org  for a user-friendlyintroduction to Digital Asset Links
google-digitalassetlinks	#Digital Asset Links	 each other.
google-dimsum	Background	Dimsum is a portable C++  SIMD  library,that is heavily influenced by the C++ standard library proposal P0214 Currently, the library does not implement P0214, but its ultimate state is astandard conforming implementation.During the implementation, we examined all the differences our our intendedinterfaces and P0214, and provided a feedback proposal P0820 Due to prioritization, Dimsum does not currently implement the following listof features from P0214, including but not limited to:in the namespace "dimsum" and namespace "dimsum::x86"
google-dimsum	Background	The extra operations in"dimsum" include many "horizontal" operations like shuffle, zip, and reduce-add;the extra operations in "x86" provides some x86-specific semantics, with nativeimplementations on x86 and emulations on other architectures.
google-dimsum	Documentation	Refer to standard proposals for designs and public interfaces.For the implementation, all the public interfaces should be documented in comments.
google-dimsum	Status	The above mentioned proposals are not part of the standard yet, nor is thisimplementation fully conforming to the proposals
google-dimsum	Status	Any part of the API is subjectto change, without providing a fixing tool.Some functionalities are with strawman implementations, with non-optimalperformance, due to prioritization.
google-dimsum	Requirements	Build system:The following sub-architectures are planed to be supported:in the future:The project is header-only, therefore no build is needed.For testing, use "CC=clang bazel test --copt='...' <>" to run the unit tests.For example:the toolchains support cross compilation:
google-dimsum	Fuzzing	Link dimsum\_fuzz against fuzz engines like libFuzzer, then run the result TODO  Add it to  OSS-Fuzz 
google-dl_bounds	Deep Learning Complexity Measure Experiments	This is the code that compares various complexity measures for deep neuralnetworks, recently proposed in the literature.Evaluation relies on three tools:bin/mnist_demo.sh showcases an examples of evaluation workflow.
google-dnae	DNAE 	A data integration framework built on top of Google Marketing Platform  fkaDoubleClick  APIs and Google Cloud Platform.
google-dnae	OVERVIEW	DNAE implements an ETL-like framework that can extract data from the GoogleMarketing Platform  formerly DoubleClick  platforms  DBM, DCM, DS , transformit as necessary and load transformed data onto Google Cloud Storage and BigTaking advantage of the built-in BigQuery connector, Google DataStudio can beused as visualization tool.The framework is modular and can implement multiple "services" to providedifferent kind of ETL flows and data insights.Please note that this is not an officially supported Google product.
google-dnae	INITIAL SETUP OF A DNAE PROJECT	Note: the following steps illustrate how to set up your DNAE project using theincluded setup scripts
google-dnae	INITIAL SETUP OF A DNAE PROJECT	Feel free to customize your setup installing thenecessary files manually.
google-dnae	More info about a DNAE service	A typical DNAE-based service folder will include:
google-dnae	DNAE libraries and folders	The standard DNAE setup has:
google-dnsmasq_exporter	dnsmasq exporter	  dnsmasq_exporter is an exporter for  Prometheus allowing you to monitor/alert on the number of DHCP leases and various DNSThe minimum required version of dnsmasq is 2.69, which added support forquerying the statistics via DNS.See also the “cache statistics” section inThis is not an official Google product.
google-dnsmasq_exporter	Installation	Place /etc/systemd/system/dnsmasq_exporter.service, then enable and start theservice using:
google-docker-explorer	Docker Explorer	This project helps a forensics analyst explore offline Docker filesystems.
google-docker-explorer	Overview	When analyzing a system where a Docker container has been compromised, it canbe useful to have the same view of the filesystem as the container's.Docker uses layered backend filesystems like AuFS or OverlayFS.Each layer is actually stored on the host's filesystem as multiple folders, andsome JSON files are used by Docker to know what is what;
google-docker-explorer	Usage	For the forensicator, this usually goes:find the interesting container IDmount the container's filesystem in log2timeline.py /tmp/container.plaso /mnt/aufs
google-docker-explorer	List the running containers	On the live host:On the live host:
google-docker-explorer	find ID of your running container:	docker ps
google-docker-explorer	create image  snapshot  from container filesystem	docker commit 12345678904b5 mysnapshot
google-docker-explorer	explore this filesystem using bash  for example 	docker run -t -i mysnapshot /bin/bashOn a disk image mounted in
google-docker-explorer	de.py -r /tmp/ mount 7b02fb3e8a665a63e32b909af5babb7d6ba0b64e10003b2d9534c7d5f2af8966 /tmp/test	mount -t aufs -o ro,br=/tmp/docker/aufs/diff/b16a494082bba0091e572b58ff80af1b7b5d28737a3eedbe01e73cd7f4e01d23=ro+wh none /tmp/testmount -t aufs -o ro,remount,append:/tmp/docker/aufs/diff/b16a494082bba0091e572b58ff80af1b7b5d28737a3eedbe01e73cd7f4e01d23-init=ro+wh none /tmp/testmount -t aufs -o ro,remount,append:/tmp/docker/aufs/diff/d1c54c46d331de21587a16397e8bd95bdbb1015e1a04797c76de128107da83ae=ro+wh none /tmp/testDo you want to mount this container Id: /tmp/docker/aufs/diff/b16a494082bba0091e572b58ff80af1b7b5d28737a3eedbe01e73cd7f4e01d23 on /tmp/test?root@test-VirtualBox:~# ls /tmp/testbin  dev  etc  home  proc  root  sys  tmp  usr  var
google-docker-explorer	List the available images	On the live host:On the live host:If on your Ubuntu system you get the errors:
google-docopt-scripts	docopt-scripts	This tool provides a framework for invoking a collection of bash scriptsthrough a single command line interface
google-docopt-scripts	docopt-scripts	Its purpose is to ease the developmentof these scripts with well-formed usage semantics from docopt  and collect them into a single place for easyThe tool itself can be built into an executable with a name of your choice, andindividual scripts are invoked as subcommands of that executable
google-docopt-scripts	docopt-scripts	 For example,if you build the tool to have the name ak, then a script called launch-qemucan be invoked as follows:Individual scripts can be spread across the file system and the tool willcoalesce them based on the value of an $_SCRIPTS_PATH environmentvariable  e.g
google-docopt-scripts	docopt-scripts	$AK_SCRIPTS_PATH 
google-docopt-scripts	docopt-scripts	 This environment variable  as well as anyothers  can be set in a special .config file in the users homedirectory  e.g
google-docopt-scripts	docopt-scripts	~/.akconfig 
google-docopt-scripts	docopt-scripts	 Putting variables in this file  as opposed toyour standard ~/.bashrc keeps them from being set on a system wide basis andonly available during the running of this tool.Scripts are written with the following naming convention so that they can sitalong other files in the $_SCRIPTS_PATH:When invoked, they are called as:Instructions on how to write these scripts is forthcoming
google-docopt-scripts	docopt-scripts	For a  very  simpleexample, see the print-scripts-path.sh script in the scripts folder of the------------This installation requires Go >= 1.5.As part of this, Go requires you to set thevalue of the GOPATH environment variable in order to download and install thirdparty packages during go compilation
google-docopt-scripts	docopt-scripts	Your GOPATH should remain set so thatinstalled scripts can make use of Go as well
google-docopt-scripts	docopt-scripts	Please add the following to your.bashrc file  or equivalent .After that, just...Clone the repoRun make EXEC= installFollow the onscreen instructions-----------**This is not an official Google product**
google-domaintest	Domain Test	**Note**: In the links throughout this documentation, we use the internationalized domain name domaintest.みんな
google-domaintest	Domain Test	In links, GitHub improperly encodes this as domaintest.%E3%81%BF%E3%82%93%E3%81%AA
google-domaintest	Domain Test	Domain names should not be URL-encoded
google-domaintest	Domain Test	 This is exactly the type of issue that the Domain Test tool is intended to catch
google-domaintest	Domain Test	This bug breaks the hyperlinks in this documentation for users of Firefox, Internet Explorer, and Safari; we've reported the issue to GitHub
google-domaintest	Domain Test	In the meantime, affected users can test the examples by copying and pasting the on-screen text.
google-domaintest	Overview	Domain Test is a tool designed to help developers test their applications for compatibility with new top-level domains  TLDs 
google-domaintest	Overview	Developed by Google and launched in a partnership between Google Registry and Ausregistry, CentralNic, Donuts, RightSide, and Uniregistry, Domain Test is an open source project available under the Apache 2 license and can be used across 145 new TLDs
google-domaintest	Overview	It is freely available for use and modification.In 2011, the Internet Committee for Assigned Names and Numbers  ICANN  approved a new gTLD program, where applicants could apply to own and operate new gTLDs
google-domaintest	Overview	A total of 1,930 applications were filed, and beginning in 2013, ICANN began delegating new gTLDs to the root DNS zone
google-domaintest	Overview	These gTLDs have a series of characteristics, such as string length and the use of non-Latin scripts, that can cause bugs in software
google-domaintest	Overview	Domain Test helps developers identify and fix these problems.This repository contains the documentation and code for Domain Test
google-domaintest	Overview	For clarity, the documentation uses the term “new TLDs” to refer to the universe of new generic top-level domains  gTLDs , new country-code top-level domains  ccTLDs , and internationalized domain names  IDNs 
google-domaintest	Overview	The Domain Test service runs on AppEngine and is available for any developer to use
google-domaintest	Overview	The syntax examples in this documentation use the domaintest.みんな domain name
google-domaintest	Overview	However, depending on what type of new TLD you want to test, you can substitute any of the strings in the  Domain Test TLDs  #domain-test-tlds  section of this documentation.
google-domaintest	HTTP Testing API	You can use the HTTP Testing API to construct an HTTP GET or POST request that results in a predictable server response
google-domaintest	HTTP Testing API	By observing your application's handling of the server’s response, you can determine whether the application making the HTTP call works properly with new TLDs
google-domaintest	HTTP Testing API	GET requests should use the following syntax:POST requests can mix parameters between the query string, like GET, and the POST body
google-domaintest	HTTP Testing API	Both multipart/form-data and application/x-www-form-urlencoded are supported, and the postpayload parameter does not interpret the POST body at all.The HTTP Testing API supports Cross-Origin Resource Sharing on all requests, including support for preflight
google-domaintest	HTTP Testing API	This means that you can test AJAX requests to new TLDs from JavaScript running on any page.
google-domaintest	ECHO	The echo command instructs the Domain Test service to echo a response based on the parameters you specify
google-domaintest	ECHO	You can construct an ECHO command with one or more of the parameters below.The request below will return a 302 redirect to .The request below will return a 302 redirect to  after sleeping for 10 seconds.
google-domaintest	STASH	The stash command instructs the Domain Test service to stash a response to the parameters specified in the request for later retrieval
google-domaintest	STASH	It uses the same parameters as the echo command
google-domaintest	STASH	A stashed payload is truncated after 10K.For example, the request below will stash the string 'stashed-narwhal'.The Domain Test service responds to stash requests with a temp URL in the form below, which can be used later to retrieve the stashed response.A single temp URL is available for use for 5 minutes after it's been generated, and it can be used once
google-domaintest	STASH	Note that stashed data is stored in memory and should be considered highly ephemeral
google-domaintest	STASH	Under some circumstances it may be lost even before the stated expiration time, in which case you should re-stash and try again.
google-domaintest	TOKEN	Alternatively, you can use the URL below if you want to pre-generate a token *beforeIf you’ve pre-generated a token prior to stashing a request, you can assign a stash command to your pre-generated token using the token parameter:A single pre-generated token can be used an unlimited number of times within one hour of generation.
google-domaintest	Security Considerations	By design, the Domain Test service is highly insecure
google-domaintest	Security Considerations	You should consider any data sent to the service to be public and should not stash or email anything other than test data
google-domaintest	Security Considerations	It is trivial to execute arbitrary JavaScript within the domaintest.みんな origin, both directly via /echo and stored via /stash, so it is crucial that there not be anything private within the same domain that is worth stealing
google-domaintest	Security Considerations	For this reason, there is no content on the domains listed below other than the Domain Test service.You should think carefully before running the service on your own domain, since it opens an XSS vector against any other content on the domain
google-domaintest	Security Considerations	In addition, since stored XSS attacks can live beyond the lifetime of a stash  for example, by manipulating the HTML5 Application Cache , running the service on a domain name means that the domain name in question will *always
google-domaintest	Testing Client Software	Suppose you’ve developed an RSS reader and want to know whether it’ll work with feeds that are served off of a new TLD
google-domaintest	Testing Client Software	You can use the HTTP Testing API to craft a URL that returns an RSS feed
google-domaintest	Testing Client Software	Here's an example using GET: In practice, it may be easier to prepare a smaller URL by using /stash with the postpayload parameter
google-domaintest	Testing Client Software	You can take this URL and plug it into your app
google-domaintest	Testing Client Software	If your app works properly --
google-domaintest	Testing Webhooks	You can use the /stash endpoint to test webhooks
google-domaintest	Testing Webhooks	Suppose you are testing a service that posts the weather to a URL of your choosing every few minutes
google-domaintest	Testing Webhooks	You can go to the /token endpoint on domaintest.みんな and get a token that you can use with /stash
google-domaintest	Testing Webhooks	Then you give the weather service a URL that looks like this:This will cause the Domain Test server to save whatever gets POSTed to this URL and make it available here:You can then poll this URL until there is something there to see
google-domaintest	Testing Webhooks	If the service successfully posted the weather to this new TLD's "webhook" then you will be able to see it
google-domaintest	Testing Webhooks	If nothing shows up, even after the weather should have been sent, you've probably found a bug!
google-domaintest	Other Things to Try	By combining the various parameters of /stash and /echo, you can make the Domain Test service mimic almost any kind of server
google-domaintest	Other Things to Try	Here are some things to try:
google-domaintest	Installation Instructions	If you are the registry operator of one or more TLDs, and you wish to configure an instance of domaintest for your TLD s , follow these instructions:Delegate the domain domaintest.yourtld to yourself for every applicable TLD.Set the domains' nameservers to ns1.google.com, ns2.google.com, ns3.google.com, and ns4.google.com.Send an email to crr-tech@google.com with a subject line of "New Domaintest domains" and include a list of all domaintest domains that you just created.Wait up to a few weeks for the new sites to go live.
google-domaintest	Discussion	The discussion forum for this project is hosted on Google Groups:  domain-test@googlegroups.com 
google-domaintest	Domain Test TLDs	The Domain Test tool is available on the following TLDs, thanks to a partnership between Google Registry and Ausregistry, CentralNic, Dominion, Donuts, DotClub, RightSide, The American Bible Society, Top Level Spectrum, and Uniregistry
google-domaintest	Domain Test TLDs	Registries that are interested in adding TLDs to the program can email the Google Registry at crr-tech@google.com.domaintest.academy  domaintest.actor  domaintest.ads  domaintest.agency  domaintest.airforce  domaintest.app  domaintest.archi  domaintest.army  domaintest.associates  domaintest.attorney  domaintest.auction  domaintest.autos  domaintest.band  domaintest.bar  domaintest.bargains  domaintest.bible  domaintest.bike  domaintest.bio  domaintest.blackfriday  domaintest.boats  domaintest.boutique  domaintest.build  domaintest.builders  domaintest.bzh  domaintest.cab  domaintest.camera  domaintest.camp  domaintest.capital  domaintest.cards  domaintest.care  domaintest.careers  domaintest.cash  domaintest.catering  domaintest.center  domaintest.cheap  domaintest.christmas  domaintest.cleaning  domaintest.clinic  domaintest.clothing  domaintest.codes  domaintest.coffee  domaintest.community  domaintest.company  domaintest.computer  domaintest.condos  domaintest.construction  domaintest.consulting  domaintest.contractors  domaintest.cool  domaintest.cruises  domaintest.dance  domaintest.dating  domaintest.degree  domaintest.democrat  domaintest.dental  domaintest.dentist  domaintest.diamonds  domaintest.directory  domaintest.discount  domaintest.domains  domaintest.education  domaintest.email  domaintest.engineer  domaintest.engineering  domaintest.enterprises  domaintest.equipment  domaintest.estate  domaintest.events  domaintest.exchange  domaintest.expert  domaintest.exposed  domaintest.fail  domaintest.family  domaintest.farm  domaintest.financial  domaintest.fish  domaintest.fitness  domaintest.flights  domaintest.florist  domaintest.foo  domaintest.forsale  domaintest.forum  domaintest.foundation  domaintest.fund  domaintest.furniture  domaintest.futbol  domaintest.gallery  domaintest.gives  domaintest.glass  domaintest.graphics  domaintest.gripe  domaintest.guitars  domaintest.guru  domaintest.haus  domaintest.holdings  domaintest.holiday  domaintest.homes  domaintest.host  domaintest.house  domaintest.immobilien  domaintest.ink  domaintest.institute  domaintest.international  domaintest.investments  domaintest.kaufen  domaintest.kitchen  domaintest.land  domaintest.lawyer  domaintest.lease  domaintest.lighting  domaintest.limited  domaintest.limo  domaintest.link  domaintest.live  domaintest.maison  domaintest.management  domaintest.market  domaintest.marketing  domaintest.media  domaintest.moda  domaintest.mortgage  domaintest.motorcycles  domaintest.navy  domaintest.news  domaintest.ninja  domaintest.page  domaintest.partners  domaintest.photography  domaintest.photos  domaintest.pics  domaintest.pictures  domaintest.pid  domaintest.plumbing  domaintest.press  domaintest.productions  domaintest.properties  domaintest.pub  domaintest.realty  domaintest.recipes  domaintest.rehab  domaintest.reisen  domaintest.rentals  domaintest.repair  domaintest.report  domaintest.republican  domaintest.rest  domaintest.reviews  domaintest.rip  domaintest.rocks  domaintest.sale  domaintest.schule  domaintest.services  domaintest.shoes  domaintest.singles  domaintest.ski  domaintest.social  domaintest.software  domaintest.solar  domaintest.solutions  domaintest.studio  domaintest.support  domaintest.surgery  domaintest.systems  domaintest.tax  domaintest.technology  domaintest.tienda  domaintest.tips  domaintest.today  domaintest.town  domaintest.toys  domaintest.training  domaintest.university  domaintest.vacations  domaintest.ventures  domaintest.vet  domaintest.viajes  domaintest.video  domaintest.villas  domaintest.vision  domaintest.voyage  domaintest.watch  domaintest.website  domaintest.wiki  domaintest.works  domaintest.wtf  domaintest.xyz  domaintest.yachts  domaintest.zone  domaintest.みんな  domaintestclub.club  اختبارنطاق.شبكة  
google-domaintest	Legal	Domain Test is an open source project available under the Apache 2 license
google-domaintest	Legal	Use of the Domain Test service is subject to Google’s Terms of Service and Privacy Policy
google-domaintest	Legal	 Learn more  
google-domato	A DOM fuzzer	Written and maintained by Ivan Fratric, Copyright 2017 Google Inc
google-domato	A DOM fuzzer	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-domato	Usage	To generate a single .html sample run:python generator.py To generate multiple samples with a single call run:python generator.py --output_dir  --no_of_files The generated samples will be placed in the specified directory and will be named as fuzz-&lt;number&gt;.html, e.g
google-domato	Usage	fuzz-1.html, fuzz-2.html etc
google-domato	Usage	Generating multiple samples is faster because the input grammar files need to be loaded and parsed only once.
google-domato	Code organization	generator.py contains the main script
google-domato	Code organization	It uses grammar.py as a library and contains additional helper code for DOM fuzzing.grammar.py contains the generation engine that is mostly application-agnostic and can thus be used in other  i.e
google-domato	Code organization	non-DOM  generation-based fuzzers
google-domato	Code organization	As it can be used as a library, its usage is described in a separate section below..txt files contain grammar definitions
google-domato	Code organization	There are 3 main files, html.txt, css.txt and js.txt which contain HTML, CSS and JavaScript grammars, respectively
google-domato	Code organization	These root grammar files may include content from other files.
google-domato	Using the generation engine and writing grammars	To use the generation engine with a custom grammar, you can use the following python code:from grammar import Grammarmy_grammar = Grammar  my_grammar.parse_from_file 'input_file.txt' result_string = my_grammar.generate_symbol 'symbol_name' The following sections describe the syntax of the grammar files.
google-domato	Basic syntax	Domato is based on an engine that, given a context-free grammar in a simple format specified below, generates samples from that grammar.A grammar is described as a set of rules in the following basic format: = a mix of constants and sEach grammar rule contains a left side and the right side separated by the equal character
google-domato	Basic syntax	The left side contains a symbol, while the right side contains the details on how that symbol may be expanded
google-domato	Basic syntax	When expanding a symbol, all symbols on the right-hand side are expanded recursively while everything that is not a symbol is simply copied to the output
google-domato	Basic syntax	Note that a single rule can't span over multiple lines of the input file.Consider the following simplified example of a part of the CSS grammar:a { width:100% }b { width:100% }Note there are two rules for the 'selector' symbol
google-domato	Basic syntax	In such cases, when the generator is asked to generate a 'selector', it will select the rule to use at random
google-domato	Basic syntax	It is also possible to specify the probability of the rule using the 'p' attribute, for example:There are other attributes that can be applied to symbols in addition to the probability
google-domato	Basic syntax	Those are listed in a separate section.Consider another example for generating html samples:
google-domato	Generating programming language code	To generate programming language code, a similar syntax can be used, but there are a couple of differences
google-domato	Generating programming language code	Each line of the programming language grammar is going to correspond to the line of the output
google-domato	Generating programming language code	Because of that, the grammar syntax is going to be more free-form to allow expressing constructs in various programming languages
google-domato	Generating programming language code	Secondly, when a line is generated, in addition to outputting the line, one or more variables may be created and those variables may be reused when generating other lines
google-domato	Generating programming language code	Again, let's take a look of the simplified example:!varformat fuzzvar%05d!lineguard try {  } catch e  {}!begin lines = document.getElementById "" ;.doSomething  ;!end linesIf we instruct the engine to generate 5 lines, we may end up with something like:Everything after the first '#' character on the line is considered a comment, so for example:The grammar syntax has a way of telling the fuzzer which rules are nonrecursive and can be safe to use even if the maximum level of recursion has been reached
google-domato	Generating programming language code	This is done with the ‘nonrecursive’ attributes
google-domato	Generating programming language code	An example is given below.
google-domato	Including and importing other grammar files	In Domato, including and importing grammars are two different context.Including is simpler
google-domato	Including and importing other grammar files	You can use:Importing works a bit differently:
google-domato	Including Python code	Sometimes you might want to call custom Python code in your grammar
google-domato	Including Python code	For example, let’s say you want to use the engine to generate a http response and you want the body length to match the 'Size' header
google-domato	Including Python code	Since this is something not possible with normal grammar rules, you can include custom Python code to accomplish it like this:!begin function savesize  context 'size'  = ret_val!end function!begin function createbody  n = int context 'size'    ret_val = 'a' !end function =  = Size:  = The python functions are defined between ‘!begin function ’ and ‘!end function’ commands
google-domato	Including Python code	The functions can be called in two ways: using ‘beforeoutput’ attribute and using  symbol.By specifying the ‘beforeoutput’ attribute in some symbol, the corresponding function will be called when this symbol is expanded, just before the result of the expansion is output to the sample
google-domato	Including Python code	The expansion result will be passed to the function in the ret_val variable
google-domato	Including Python code	The function is then free to modify ret_val, store it for later use or perform any other operations.When using a special  symbol, the function  specified in a ‘function’ attribute  will be called when the symbol is encountered during language generation
google-domato	Including Python code	Any value stored by the function in ret_val will be considered the result of the expansion  ret_val gets included in the sample .Your python code has access to the following variables:The following symbols have a special meaning and should not be redefined by users:The following attributes are supported:Some of the bugs that have been found with Domato:This is not an official Google product.
google-dopamine	Dopamine	  Dopamine is a research framework for fast prototyping of reinforcement learningalgorithms
google-dopamine	Dopamine	It aims to fill the need for a small, easily grokked codebase inwhich users can freely experiment with wild ideas  speculative research .Our design principles are:In the spirit of these principles, this first version focuses on supporting thestate-of-the-art, single-GPU *Rainbowapplied to Atari 2600 game-playing   Bellemare et al., 2013  ale  .Specifically, our Rainbow agent implements the three components identified asmost important by  Hessel et al
google-dopamine	Dopamine	 rainbow :  Mnih et al., 2015  dqn  .For additional details, please see our documentation This is not an official Google product.
google-dopamine	Install via source	Installing from source allows you to modify the agents and experiments asyou please, and is likely to be the pathway of choice for long-term use.These instructions assume that you've already set up your favourite packagemanager  e.g
google-dopamine	Install via source	apt on Ubuntu, homebrew on Mac OS X , and that a C++ compileris available from the command-line  almost certainly the case if your favouritepackage manager works .The instructions below assume that you will be running Dopamine in a *virtualenvironment*
google-dopamine	Install via source	A virtual environment lets you control which dependencies areinstalled for which program; however, this step is optional and you may chooseto ignore it.Dopamine is a Tensorflow-based framework, and we recommend you also consultthe  Tensorflow documentation for additional details.Finally, these instructions are for Python 2.While Dopamine is Python 3compatible, there may be some additional steps needed during installation.
google-dopamine	Ubuntu	First set up the virtual environment:environment lives
google-dopamine	Ubuntu	The last command activates the environment.Then, install the dependencies to Dopamine:*tensorflow 1.10.1 has requirement numpy=1.13.3, but you'll havenumpy 1.15.1 which is incompatible*.Finally, download the Dopamine source, e.g.First set up the virtual environment:environment lives
google-dopamine	Ubuntu	The last command activates the environment.Then, install the dependencies to Dopamine:*tensorflow 1.10.1 has requirement numpy=1.13.3, but you'll havenumpy 1.15.1 which is incompatible*.Finally, download the Dopamine source, e.g.You can test whether the installation was successful by running the following: dopamine/atari/train.py To run the basic DQN agent,The command-line interface will output statistics about the latest training ..
google-dopamine	Ubuntu	I0824 17:13:33.078342 140196395337472 tf_logging.py:115  gamma: 0.990000I0824 17:13:33.795608 140196395337472 tf_logging.py:115  Beginning training...Steps executed: 5903 Episode length: 1203 Return: -To get finer-grained information about the process,you can adjust the experiment parameters in dopamine/agents/dqn/configs/dqn.gin in particular by reducing Runner.training_steps and Runner.evaluation_steps,which together determine the total number of steps needed to complete aniteration
google-dopamine	Ubuntu	This is useful if you want to inspect log files or checkpoints, whichare generated at the end of each iteration.More generally, the whole of Dopamine is easily configured using the gin configuration framework 
google-dopamine	Install as a library	An easy, alternative way to install Dopamine is as a Python library:zlib  see "Install via source" above .
google-dopamine	Running tests	From the root directory, tests can be run with a command such as: Bellemare et al., *The Arcade Learning Environment: An evaluation platform forgeneral agents*
google-dopamine	Running tests	Journal of Artificial Intelligence Research, 2013
google-dopamine	Running tests	 ale  Hessel et al., *Rainbow: Combining Improvements in Deep Reinforcement Learning*.Proceedings of the AAAI Conference on Artificial Intelligence, 2018
google-dopamine	Running tests	 rainbow  Mnih et al., *Human-level Control through Deep Reinforcement Learning*
google-dopamine	Running tests	Nature,2015
google-dopamine	Running tests	 dqn  Mnih et al., *Asynchronous Methods for Deep Reinforcement Learning*
google-dopamine	Running tests	Proceedingsof the International Conference on Machine Learning, 2016
google-dopamine	Running tests	 a3c  Schaul et al., *Prioritized Experience Replay*
google-dopamine	Running tests	Proceedings of the InternationalConference on Learning Representations, 2016
google-dopamine	Running tests	 prioritized_replay 
google-dopamine	Giving credit	If you use Dopamine in your work, we ask that you cite this repository as areference
google-dopamine	Giving credit	The preferred format  authors in alphabetical order  is:Marc G
google-dopamine	Giving credit	Bellemare, Pablo Castro, Carles Gelada, Saurabh Kumar, Subhodeep Moitra
google-dopamine	Giving credit	dqn :  a3c :  prioritized_replay :  c51 :  rainbow :  iqn : 
google-dorusu-js	Dorusu-js 	  travisimg   travis  ! Code Coverage  codecovimg   codecov  travis :  travisimg :  codecov :  codecovimg : This is **not*The official Google-maintained implementation of gRPC for node.js is availableat  grpc-nodejs   
google-dorusu-js	Dorusu-js 	 Note that Google only maintains *oneimplementation of gRPC in any programming language for nodejs is focused on  grpc-nodejs   .This is an alternate implementation written in javascript by a Googler
google-dorusu-js	Dorusu-js 	It grpc-nodejs : gRPC spec : grpc interop tests :
google-dorusu-js	DESIGN SUMMARY	dorusu-js provides strongly-idiomatic client and server implementationssupporting the gRPC rpc protocol.The main governing power behind the dorusu API design is that it provideselements similar to the existing node.js  HTTP2 API   , node-http2, whichis in turn very similar to the node  HTTP API   / HTTPS API   .In part, the similarity comes from direct use of classes defined in node-http2   
google-dorusu-js	DESIGN SUMMARY	 In other cases the classes have been extended toenforce additional restrictions the  RPC Protocol    places on the use HTTP2   .The goal of the design is thateasy to learn due to its similarity to existing node.js code
google-dorusu-js	DESIGN SUMMARY	 I.e, most of theAPI should already be familiar to developers, and important new rpc features likestreaming requests and responses are available as minor deltas that are easily HTTP2 API : HTTPS API : HTTP API : RPC protocol :  HTTP2 : Express API :
google-dorusu-js	Missing Features	At this point in time, dorusu-js is missing features that  grpc-nodejs   provides, e.g,There are also other features that are planned for  grpc-nodejs    that dorusu-jsshould implement:These missing features are tracked with  issues  and triaged via single meta  tracking issue 
google-dorusu-js	Given the greeter protobuf IDL: helloworld.proto	syntax = "proto3";option java_package = "ex.grpc";package helloworld;// The greeting service definition.service Greeter {  // Sends a greeting  rpc SayHello  HelloRequest  returns  HelloReply  {}// The request message containing the user's name.message HelloRequest {  string name = 1;// The response message containing the greetingsmessage HelloReply {  string message = 1;
google-dorusu-js	Serve greetings with a server: helloworld_server.js	var protobuf = require 'dorusu/protobuf' ;var server = require 'dorusu/server' ; */function sayHello request, response  {  request.on 'data', function msg  {  } ;  request.on 'end', function   {  } ;  request.on 'error', function   {  } ;function main   {  var hellopb = protobuf.requireProto './helloworld', require ;  var app = hellopb.helloworld.Greeter.serverApp;  app.register '/helloworld/SayHello', sayHello ;  s = server.raw.createServer {  } ;  s.listen 50051 ;main  ;
google-dorusu-js	Access greetings with a client: helloworld_client.js	var protobuf = require 'dorusu/protobuf' ;function main   {  var hellopb = protobuf.requireProto './helloworld', require ;  /  var GreeterClient = hellopb.helloworld.Greeter.Client.raw;  var client = new GreeterClient {  } ;  // Call the say hello method remotely
google-dorusu-js	Access greetings with a client: helloworld_client.js	 client.sayHello {name: user}, function  resp  {  } ;main  ;
google-dorusu-js	Try it out	You can also try out the large math_server and math_client examples in this reponpm update  # install dorusu locallyexample/math_server.js &
google-dorusu-js	 same directory, another terminal window 	Try it out with much nicer log output by installing  bunyan   npm install -g bunyan # installs bunyan, may require sudo depending on how node is set up
google-dorusu-js	 from this directory 	HTTP2_LOG=info example/math_server.js | bunyan -o short &
google-dorusu-js	 same directory, another terminal 	HTTP2_LOG=info example/math_client.js | bunyan -o short nvm :  bunyan : node-http2 ::
google-dorusu-js	interop tests	_Note_ The node interop test client is tested against the node interop test server as part of the  unit tests  #unit_tests 
google-dorusu-js	interop tests	  interop-test here actual runs against  grpc-go   .
google-dorusu-js	Install the Go interop test server and client to a temporary location	npm run install-go-interop
google-dorusu-js	Run the interop tests	npm run interop-test grpc-go :
google-dorusu-js	production interop tests	npm run prod-interopnpm run bunyan-prod-interop grpc-go :
google-dorusu-js	CONTRIBUTING/REPORTING ISSUES	Contributions to this library are always welcome and highly encouraged.See the  CONTRIBUTING  documentation for more information on how to get started
google-dorusu-js	CONTRIBUTING/REPORTING ISSUES	CONTRIBUTING :
google-dotty	EFILTER Query Language	EFILTER is a general purpose query language designed to be embedded in Python applications and libraries
google-dotty	EFILTER Query Language	It supports SQL-like syntax to filter your application's data and provides a convenient way to directly search through the objects your applications manages.A second use case for EFILTER is to translate queries from one query language to another, such as from SQL to OpenIOC and so on
google-dotty	EFILTER Query Language	A basic SQL-like syntax and a POC lisp implementation are included with the language, and others are relatively simple to add.
google-dotty	Don't have SQL injections.	EFILTER supports query templates, which can interpolate unescaped strings safely.
google-dotty	Language Reference	Work in progress.
google-dotty	Protocol documentation	Work in progress.
google-dotty	Example projects	Several sample projects are provided.Copyright 2015 Google Inc
google-dotty	Example projects	All Rights ReservedLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License at   Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-dotty	Contributors	 Adam Sindelar 
google-dpy	dPy	  
google-dpy	Overview	Yes, Python is a dynamic language so dependency injection is not necessary and might seem silly..
google-dpy	Overview	but injection of components provides more than just the ability to test statically typed languages
google-dpy	Overview	It can make your code clearer, assist developers with straightforward modularization, and make testing super simple
google-dpy	Overview	Take a look at the examples below to see how your code can be transformed.
google-dpy	Examples	Below are some simple examples for using dPy
google-dpy	Examples	For a complete usage example set that alse runs, check out example.py.
google-dpy	Simple	Any argument can be turned into an injected argument.from dpy import IN, Inject, Injectabledef Go where=IN :  # Go is fully injected!  print 'Hello ' + whereInjectable.value where='World' Go    # Invokes the function 
google-dpy	Mixing	You don't have to inject all of your arguments!from dpy import IN, Inject, Injectabledef Go when, how='train', where=IN :  # Partial injection  print 'We need the %s %s, %s!' %  where, how, when Injectable.value where='California' Go 'now', how='car'   # Invokes the function 
google-dpy	Scoping	Scopes are useful when creating servers or threaded designs that revisit the same code with different data.You'll probably want to swap out injections, scoping them to a particular stack or thread.As you would hope, they use the current scope when they are requested  not the one in which they were defined .If not using scopes, it's an error to set the same injectable key more than once!from dpy import IN, Inject, Injectable, Scopedef Go where=IN :  print 'Hello ' + wheredef HandleRequest request :  Injectable.value where=request.destination   Go    # Invokes the function Singletons have the behavior you would expect; they are single to their scope branch.
google-dpy	Injection Types	There are different ways to specify injectables.from dpy import Injectable, SingletonInjectable.value foo=object   
google-dpy	In effect, the injectable foo is a singleton object.	def bar  :  """2  Provides an injectable bar
google-dpy	In effect, the injectable foo is a singleton object.	 In effect, no two injections of bar will ever be  i.e
google-dpy	In effect, the injectable foo is a singleton object.	is  the same object
google-dpy	In effect, the injectable foo is a singleton object.	 """  return object  @Singletondef cat  :  """3  Provides a singleton injectable cat
google-dpy	In effect, the injectable foo is a singleton object.	 is needed
google-dpy	In effect, the injectable foo is a singleton object.	The return value is stored and the same value is returned each time
google-dpy	In effect, the injectable foo is a singleton object.	 In effect, this is a lazily initialized version of #  """  return Object  @Injectable.named 'dog' def ProvidePitbull  :  """Provides an injectable dog
google-dpy	In effect, the injectable foo is a singleton object.	 the injectable key has been explicity set to 
google-dpy	Modules?	Injection modules? We don't need no stinking injection modules.In dPy, Python modules serve as our injection modules
google-dpy	Modules?	Provide whatever you want in your regular ol' module using the methods above and when you want to switch out the implementation, you can just switch which module you import.Of course, you can also setup injectables behind conditionals if you like.Modules may import their own dependencies or you might prefer to defer importing all your dependencies in a "main" module  or other organization 
google-dpy	Modules?	As long as all the dependencies are established at runtime, there's no problem.Testing is quite simple in dPy
google-dpy	Modules?	The only concept dPy has of modules is as regular Python modules
google-dpy	Modules?	There are no special injection modules
google-dpy	Modules?	For a full, working example test, check out example_test.py.In the normal mode, injections are automatically passed in for you to things labeled Inject or Injectable.In test mode, this functionality is turned off!Only normal arguments, or _specifically_ test injections may be used in test.@Injectable.value 'bar', 'cat' def Foo bar=IN : print len bar  Foo    # Normally, this prints 3
google-dpy	In test mode, this would raise an exception about expecting injection to occur.	Foo bar='test'   # In test mode  and normal mode , this prints
google-dpy	Enable test mode	Enabling test mode is one call in your test.It may not be turned off once enabled, so feel free to put it at the top level of your test module.You might need to create special test injections depending on how you've structured your code.Setting them up is straight-forward:
google-dpy	Things injected should be injected.	This prevents having to setup injections for test.Injecting objects that are themselves injected is not required but alleviates the need to setup injections for test which may be confusing.
google-dpy	Don't rely on injections for test.	It's best not to have to setup test injections
google-dpy	Don't rely on injections for test.	You should only need to use it when private methods are injected or call other injectable functions/constructors
google-dpy	Don't rely on injections for test.	In general, you should stick to injecting public methods
google-dpy	Don't rely on injections for test.	If you are using a lot of injections for test, it may be a sign of bad program design.
google-dpy	Don't inject too much.	Dependency injection should be easy, not stressful
google-dpy	Don't inject too much.	It's not a license for spaghetti code
google-dpy	Don't inject too much.	Treat injections as called constructors
google-dpy	Don't inject too much.	Don't overuse them, don't overthink them
google-dpy	Don't inject too much.	Use them when they make sense
google-dpy	Don't inject too much.	Use them when they'll make testing easier
google-dpy	Don't inject too much.	Use them when they'll make your life easier, not the opposite!
google-draco	Version 1.3.0 release	===========Draco is a library for compressing and decompressing 3D geometric  meshes  and point clouds 
google-draco	Version 1.3.0 release	It is intended to improve the storage and transmission of 3DDraco was designed and built for compression efficiency and speed
google-draco	Version 1.3.0 release	The codesupports compressing points, connectivity information, texture coordinates,color information, normals, and any other generic attributes associated withgeometry
google-draco	Version 1.3.0 release	With Draco, applications using 3D graphics can be significantlysmaller without compromising visual fidelity
google-draco	Version 1.3.0 release	For users, this means apps cannow be downloaded faster, 3D graphics in the browser can load quicker, and VRand AR scenes can now be transmitted with a fraction of the bandwidth andrendered quickly.Draco is released as C++ source code that can be used to compress 3D graphicsas well as C++ and Javascript decoders for the encoded data.========For all platforms, you must first generate the project/make files and thencompile the examples.CMake BasicsTo generate project/make files for the default toolchain on your system, runcmake from a directory where you would like to generate build files, and passit the path to your Draco repository.~~~~~ bashOn Windows, the above command will produce Visual Studio project files for thenewest Visual Studio detected on the system
google-draco	Version 1.3.0 release	On Mac OS X and Linux systems,the above command will produce a makefile.To control what types of projects are generated, add the cmake command
google-draco	Version 1.3.0 release	This argument must be followed by the name of a generator.Running cmake with the --help argument will list the availablegenerators for your system.Mac OS XOn Mac OS X, run the following command to generate Xcode projects:~~~~~ bash-------On a Windows box you would run the following command to generate Visual Studio2015 projects:~~~~~ bashC:\Users\nobody> cmake path/to/draco -G "Visual Studio 14 2015"To generate 64-bit Windows Visual Studio 2015 projects:~~~~~ bashC:\Users\nobody> cmake path/to/draco -G "Visual Studio 14 2015 Win64"CMake Build ConfigurationDebugging and OptimizationUnlike Visual Studio and Xcode projects, the build configuration for makebuilds is controlled when you run cmake
google-draco	Version 1.3.0 release	The following examples demonstratevarious build configurations.Omitting the build type produces makefiles that use release build flagsby default:~~~~~ bashA makefile using release  optimized  flags is produced like this:~~~~~ bashA release build with debug info can be produced as well:~~~~~ bashAnd your standard debug build will be produced using:~~~~~ bashTo enable the use of sanitizers when the compiler in use supports them, set thesanitizer type when running CMake:~~~~~ bashGoogletest IntegrationDraco includes testing support built using Googletest
google-draco	Version 1.3.0 release	To enable Googletest unittest support the ENABLE_TESTS cmake variable must be turned on at cmakegeneration time:~~~~~ bashWhen cmake is used as shown in the above example the Draco cmake file assumesthat the Googletest source directory is a sibling of the Draco repository
google-draco	Version 1.3.0 release	Tochange the location to something else use the GTEST_SOURCE_DIR cmake variable:~~~~~ bashTo run the tests just execute draco_tests from your toolchain's build outputJavascript Encoder/DecoderThe javascript encoder and decoder can be built using the existing cmake buildfile by passing the path the Emscripten's cmake toolchain file at cmakegeneration time in the CMAKE_TOOLCHAIN_FILE variable.In addition, the EMSCRIPTEN environment variable must be set to the local pathof the parent directory of the Emscripten tools directory.~~~~~ bash
google-draco	Build the Javascript encoder and decoder.	WebAssembly DecoderThe WebAssembly decoder can be built using the existing cmake build file bypassing the path the Emscripten's cmake toolchain file at cmake generation timein the CMAKE_TOOLCHAIN_FILE variable and enabling the WASM build option.In addition, the EMSCRIPTEN environment variable must be set to the local pathof the parent directory of the Emscripten tools directory.Make sure to have the correct version of Emscripten installed for WebAssemblybuilds
google-draco	Build the Javascript encoder and decoder.	See ~~~~~ bash
google-draco	Run the Javascript wrapper through Closure.	WebAssembly Mesh Only Decoder~~~~~ bash
google-draco	cmake command line for mesh only WebAssembly decoder.	WebAssembly Point Cloud Only Decoder~~~~~ bash
google-draco	cmake command line for point cloud only WebAssembly decoder.	Android Studio Project IntegrationTo include Draco in an existing or new Android Studio project, reference itfrom the cmake file of an existing native project that has a minimum SDKversion of 18 or higher
google-draco	cmake command line for point cloud only WebAssembly decoder.	The project must support C++To add Draco to your project:  Add macro to build.gradle for the features you need:Native Android BuildsIt's sometimes useful to build Draco command line tools and run them directly onAndroid devices via adb.~~~~~ bash
google-draco	x86_64	After building the tools they can be moved to an android device via the use ofadb push, and then run within an adb shell instance.======Command Line ApplicationsThe default target created from the build files will be the draco_encoderand draco_decoder command line applications
google-draco	x86_64	For both applications, if yourun them without any arguments or -h, the applications will output usage andEncoding Tooldraco_encoder will read OBJ or PLY files as input, and output Draco-encodedfiles
google-draco	x86_64	We have included Stanford's  Bunny  mesh for testing
google-draco	x86_64	The basic commandline looks like this:~~~~~ bash./draco_encoder -i testdata/bun_zipper.ply -o out.drcA value of 0 for the quantization parameter will not perform any quantizationon the specified attribute
google-draco	x86_64	Any value other than 0 will quantize the inputvalues for the specified attribute to that number of bits
google-draco	x86_64	For example:~~~~~ bash./draco_encoder -i testdata/bun_zipper.ply -o out.drc -qp 14will quantize the positions to 14 bits  default for the position coordinates .In general, the more you quantize your attributes the better compression rateyou will get
google-draco	x86_64	It is up to your project to decide how much deviation it willtolerate
google-draco	x86_64	In general, most projects can set quantization values of about 14without any noticeable difference in quality.The compression level  -cl  parameter turns on/off different compression~~~~~ bash./draco_encoder -i testdata/bun_zipper.ply -o out.drc -cl 8In general, the highest setting, 10, will have the most compression butworst decompression speed
google-draco	x86_64	0 will have the least compression, but bestdecompression speed
google-draco	x86_64	The default setting is 7.Encoding Point CloudsYou can encode point cloud data with -point_cloud parameter
google-draco	x86_64	If you specify the -point_cloud parameter with amesh input file, draco_encoder will ignore the connectivity data and encodethe positions from the mesh file.~~~~~ bash./draco_encoder -point_cloud -i testdata/bun_zipper.ply -o out.drcThis command line will encode the mesh input as a point cloud, even though theinput might not produce compression that is representative of other pointclouds
google-draco	x86_64	Specifically, one can expect much better compression rates for largerand denser point clouds.Decoding Tooldraco_decoder will read Draco files as input, and output OBJ or PLY files.The basic command line looks like this:~~~~~ bash./draco_decoder -i in.drc -o out.objC++ Decoder APIIf you'd like to add decoding to your applications you will need to includethe DecodePointCloudFromBuffer   to return a decoded PointCloud object
google-draco	x86_64	For~~~~~ cppdraco::DecoderBuffer buffer;buffer.Init data.data  , data.size   ;const draco::EncodedGeometryType geom_type =if  geom_type == draco::TRIANGULAR_MESH  {  unique_ptr mesh = draco::DecodeMeshFromBuffer &buffer ;} else if  geom_type == draco::POINT_CLOUD  {  unique_ptr pc = draco::DecodePointCloudFromBuffer &buffer ;~~~~~Please see  src/draco/mesh/mesh.h  src/draco/mesh/mesh.h  for the full Mesh class interface and src/draco/point_cloud/point_cloud.h  src/draco/point_cloud/point_cloud.h  for the full PointCloud class interface.Javascript Encoder APIAPI can be used to compress mesh and point cloud
google-draco	x86_64	In order to use the encoder,you need to first create an instance of AddFloatAttributeToMesh   to add attribute data to the mesh, e.g
google-draco	x86_64	position,normal, color and texture coordinates
google-draco	x86_64	After a mesh is constructed, you couldthen use EncodeMeshToDracoBuffer   to compress the mesh
google-draco	x86_64	For example:~~~~~ jsconst mesh = {  indices : new Uint32Array indices ,  vertices : new Float32Array vertices ,  normals : new Float32Array normals const encoderModule = DracoEncoderModule  ;const encoder = new encoderModule.Encoder  ;const meshBuilder = new encoderModule.MeshBuilder  ;const dracoMesh = new encoderModule.Mesh  ;const numFaces = mesh.indices.length / 3;const numPoints = mesh.vertices.length;meshBuilder.AddFacesToMesh dracoMesh, numFaces, mesh.indices ;meshBuilder.AddFloatAttributeToMesh dracoMesh, encoderModule.POSITION,  numPoints, 3, mesh.vertices ;if  mesh.hasOwnProperty 'normals'   {  meshBuilder.AddFloatAttributeToMesh if  mesh.hasOwnProperty 'colors'   {  meshBuilder.AddFloatAttributeToMesh if  mesh.hasOwnProperty 'texcoords'   {  meshBuilder.AddFloatAttributeToMesh if  method === "edgebreaker"  {  encoder.SetEncodingMethod encoderModule.MESH_EDGEBREAKER_ENCODING ;} else if  method === "sequential"  {  encoder.SetEncodingMethod encoderModule.MESH_SEQUENTIAL_ENCODING ;const encodedData = new encoderModule.DracoInt8Array  ;// Use default encoding setting.const encodedLen = encoder.EncodeMeshToDracoBuffer dracoMesh,encoderModule.destroy dracoMesh ;encoderModule.destroy encoder ;encoderModule.destroy meshBuilder ;Please see  src/draco/javascript/emscripten/draco_web_encoder.idl  src/draco/javascript/emscripten/draco_web_encoder.idl  for the full API.Javascript Decoder APIThe Javascript decoder is located in  javascript/draco_decoder.js  javascript/draco_decoder.js 
google-draco	x86_64	TheJavascript decoder can decode mesh and point cloud
google-draco	x86_64	In order to use thedecoder, you must first create an instance of DecodeBufferToMesh   or DecodeBufferToPointCloud  , which will returna Mesh object or a point cloud
google-draco	x86_64	For example:~~~~~ js// Create the Draco decoder.const decoderModule = DracoDecoderModule  ;const buffer = new decoderModule.DecoderBuffer  ;buffer.Init byteArray, byteArray.length ;// Create a buffer to hold the encoded data.const decoder = new decoderModule.Decoder  ;const geometryType = decoder.GetEncodedGeometryType buffer ;// Decode the encoded geometry.let outputGeometry;let status;if  geometryType == decoderModule.TRIANGULAR_MESH  {  outputGeometry = new decoderModule.Mesh  ;  status = decoder.DecodeBufferToMesh buffer, outputGeometry ;} else {  outputGeometry = new decoderModule.PointCloud  ;  status = decoder.DecodeBufferToPointCloud buffer, outputGeometry ;// You must explicitly delete objects created from the DracoDecoderModule// or Decoder.decoderModule.destroy outputGeometry ;decoderModule.destroy decoder ;decoderModule.destroy buffer ;Please see  src/draco/javascript/emscripten/draco_web_decoder.idl  src/draco/javascript/emscripten/draco_web_decoder.idl  for the full API.Javascript Decoder PerformanceThe Javascript decoder is built with dynamic memory
google-draco	x86_64	This will let the decoderwork with all of the compressed data
google-draco	x86_64	But this option is not the fastest.Pre-allocating the memory sees about a 2x decoder speed improvement
google-draco	x86_64	If youknow all of your project's memory requirements, you can turn on static memoryby changing CMakeLists.txt accordingly.Metadata APIother than geometry
google-draco	x86_64	It could be used to encode any custom data along with thegeometry
google-draco	x86_64	For example, we can enable metadata functionality to encode the nameof attributes, name of sub-objects and customized information.For one mesh and point cloud, it can have one top-level geometry metadata class.The top-level metadata then can have hierarchical metadata
google-draco	x86_64	Other than that,the top-level metadata can have metadata for each attribute which is calledattribute metadata
google-draco	x86_64	The attribute metadata should be initialized with thecorrespondent attribute id within the mesh
google-draco	x86_64	The metadata API is provided bothin C++ and Javascript.For example, to add metadata in C++:~~~~~ cppdraco::PointCloud pc;// Add metadata for the geometry.std::unique_ptr metadata =  std::unique_ptr new draco::GeometryMetadata   ;metadata->AddEntryString "description", "This is an example." ;pc.AddMetadata std::move metadata  ;// Add metadata for attributes.draco::GeometryAttribute pos_att;pos_att.Init draco::GeometryAttribute::POSITION, nullptr, 3,const uint32_t pos_att_id = pc.AddAttribute pos_att, false, 0 ;std::unique_ptr pos_metadata =pos_metadata->AddEntryString "name", "position" ;// Directly add attribute metadata to geometry.// You can do this without explicitly add |GeometryMetadata| to mesh.pc.AddAttributeMetadata pos_att_id, std::move pos_metadata  ;To read metadata from a geometry in C++:~~~~~ cpp// Get metadata for the geometry.const draco::GeometryMetadata *pc_metadata = pc.GetMetadata  ;// Request metadata for a specific attribute.const draco::AttributeMetadata *requested_pos_metadata =  pc.GetAttributeMetadataByStringEntry "name", "position" ;Please see  src/draco/metadata  src/draco/metadata  and  src/draco/point_cloud  src/draco/point_cloud  for the full API.NPM Packagedoc in the folder for detailed usage.three.js Renderer ExampleHere's an  example  of a geometric compressed with Draco loaded via aJavascript decoder using the three.js renderer.Please see the  javascript/example/README.md  javascript/example/README.md  file for more information.=======For questions/comments please email If you have found an error in this library, please file an issue atPatches are encouraged, and may be submitted by forking this project andsubmitting a pull request through GitHub
google-draco	x86_64	See  CONTRIBUTING  for more detail.=======Licensed under the Apache License, Version 2.0  the "License" ; you may notuse this file except in compliance with the License
google-draco	x86_64	You may obtain a copy ofthe License atUnless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS, WITHOUTWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-draco	x86_64	See theLicense for the specific language governing permissions and limitations underthe License.========== example : meshes :  point clouds :  Bunny :  CONTRIBUTING : Bunny model from Stanford's graphic department <>
google-drone-firebase	drone-firebase	Drone plugin to deploy a project to Firebase
google-drone-firebase	drone-firebase	For the usage informationand a listing of the available options please take a look at the docs  DOCS.md .*This is not an official Google product.*If you want to contribute, see the  CONTRIBUTING page  CONTRIBUTING.md .
google-drone-firebase	Binary	Build the binary using make:Build the container using make:Run the docker container from the directory of your Firebase project:
google-dropzone-polyfill	Polyfill for the removed HTML5 dropzone attribute	This is not an official Google product.This is a polyfill intended to help sites impacted by the removal of webkitdropzone from Chromium 
google-dropzone-polyfill	Usage	If your Web application's drag-and-drop functionality works in Firefox, Edge,or any other browser that is not based on Blink or WebKit, stop reading now.You do not need this polyfill.If you're still here, the quickest way to get your site working again is todownload  lib/dropzone-polyfill.js  lib/dropzone-polyfill.js  and include it inyour site's JavaScript bundler, then call DropzonePolyfill.handleDom   afteryour DOM is ready
google-dropzone-polyfill	Usage	For example, imperative API for handling drops This polyfill is way more complex than the code you'll have to write for yourown application, due to the need of handling the entire dropzone syntax.The code needed to replace webkitdropzone can be as simple as:
google-dropzone-polyfill	Limitations	In Safari and Firefox, the polyfill is not able to obtain the MIME type ofdragged files at the time needed to implement the filters expressed by file:tokens in the dropzone attribute
google-dropzone-polyfill	Limitations	The polyfill errs on the side of falsepositives, by having any dragged file match against any file: token.For example, if a Safari user drags a HTML file over an element with adragzone attribute set to file:text/plain, the polyfill will decide that thedragged file matches the dragzone conditions
google-dropzone-polyfill	Limitations	However, the polyfill will notmatch non-file drags to the dragzone value above.On the other hand, it is worth noting that dropzone / webkitdropzone werenever implemented in Firefox so, if your application relies on these attributes,it is already broken in Firefox
google-dropzone-polyfill	Limitations	Along the same lines, the webkitdropzone inChrome was unable to match file: tokens against dragged files, until MIn conclusion, if you wish to accept file drags in a portable manner, you needto use the imperative API for handling drops 
google-ds-trix-addon	DS Trix Addon	_Disclaimer: This is not an official Google product._
google-ds-trix-addon	Overview	DS Trix Addon is an addon for Google Sheets which allows you to sync Web QueryReports from DoubleClick Search directly into a Google Sheets spreadsheet
google-ds-trix-addon	Overview	Touse this addon, you will need to have access to  DoubleClickSearch The addon has the following features:You can use additional tabs in the same spreadsheet to create a dashboard basedon your reports.
google-ds-trix-addon	Installation	 Download all the files in this repository to your computer
google-ds-trix-addon	Installation	Open  Google Drive  in a browser Create a new spreadsheet using New > Google Sheets
google-ds-trix-addon	Installation	Give your spreadsheet a name by clicking on the title at the top
google-ds-trix-addon	Installation	Open the script editor by going to Tools > Script Editor ..
google-ds-trix-addon	Installation	Give your script a name  Ex: DS Trix Addon 
google-ds-trix-addon	Installation	You should have the file Code.gs open in the editor
google-ds-trix-addon	Installation	On your computer, Copy the contents of the entire file into the script editor, replacing Press ctrl/cmd-s or go to File > Save to save the file
google-ds-trix-addon	Installation	You will need to add all the remaining source files to the same project The final step is to configure OAuth so that the addon can access your Web Now we can start using the Addon
google-ds-trix-addon	Installation	Close the script editor and refresh the When using for the first time, you will see dialogs asking for When setting up authentication, you may see a message that says This app
google-dualhttp	The dual-http Solution	Render your page with cached data,then fetch up-to-date data from server and update the page.This solution contains both frontend code and backend code.It works in the following way:It is a special header that both the http request and the response carrythat makes it possible for us to detect whether the response comes from cache,because the backend always responses with the exact x-echo valueas the request has
google-dualhttp	The dual-http Solution	Example:First request:Gets a response:Noting the difference of the x-echo values,the frontend realizes that the response must be from browser cache.It then issues a second request immediately:Because of max-age=0, the browser cache gets bypassed.The server gets the request and has to respond.This time x-echo values match.
google-dualhttp	Usage	This solution supports AngularJS as frontend frameworkand django as backend framework
google-dualhttp	Usage	More framework supports are on the way.
google-dynamic-form	How to build	Check it out from GitHub.Download npm dependencies.
google-earthenterprise	Earth Enterprise  ! Chat on Slack    ! build  	Earth Enterprise is the open source release of Google Earth Enterprise, a geospatial application which provides the ability to build and host custom 3D globes and 2D maps
google-earthenterprise	Earth Enterprise  ! Chat on Slack    ! build  	 Earth Enterprise does not provide a private version of Google imagery that's currently available in Google Maps or Earth.The application suite consists of three core components:
google-earthenterprise	Releases	 Release 5.2.3 Earth Enterprise Fusion & Server currently run on 64-bit versions of the following operating systems:
google-earthenterprise	Installation	Refer to the  Install Instructions  for instructions on installing Fusion or Earth Server
google-earthenterprise	Installation	 Please note that you must have a successful build of the source before proceeding with the install.
google-easy-grid	easy-grid for React	***This is not an official Google product.***easy-grid is a React component factory that provides a declarative layout mechanism for utilizing  CSS grid layouts  It uses ASCII layout descriptions to generate layout components that arrange child components according to the defined grid.																														
google-easy-grid	Prerequisites	Make sure you have the  npm package manager  installed on your development machine.
google-easy-grid	Installing	Clone the git repository to a local directory:To play around with the library, make changes to the  examples.js  React app and re-run npm run examples.
google-easy-grid	Running the tests	To use the library in a production environment, simply run:easy-grid exports a grid factory method:The exported grid method is used to create layout components based on an ASCII representations of the desired layout grid
google-easy-grid	Running the tests	For instance:const TwoByTwoLayout = grid1fr A1fr A~~~defines a React component, TwoByTwoLayout, that will distribute it's child elements along a two by two grid
google-easy-grid	Running the tests	element "A" will take up the entire grid, while element "B" will overlap element "A" and take up the right half of the grid
google-easy-grid	Running the tests	The two rows will each have the same height, namely half the height of the parent element
google-easy-grid	Running the tests	Likewise, the two columns will each have the same width, or half the width of the parent component.
google-easy-grid	Grid Definition Syntax	Grids are defined by a back-tick    string
google-easy-grid	Grid Definition Syntax	Spaces and new-lines are non-trivial as they are used to parse the grid definition from the string.Row and column header definitions use the syntax defined for  grid-template-rows  **Type**Flex*Length
google-easy-grid	Column Headers	The first line of the string is a space-delimited definition of **column headers**
google-easy-grid	Column Headers	A component can be defined by only using column headers
google-easy-grid	Column Headers	For instance,defines a ColumnsOnly component that will arrange its children in 3 columns
google-easy-grid	Column Headers	The first and last column will be half the size of the middle column.
google-easy-grid	Row Headers	Each line after the first line defines a new row in the grid
google-easy-grid	Row Headers	The first element in the space-deilimited row definition defines the height of that row, and is called the **row header**
google-easy-grid	Row Headers	However, similar to column-only grid definitions, row-only grid defintions can be created by only specifying row headers on each new line
google-easy-grid	Row Headers	For instance,defines a RowsOnly component that will give each of its three child components heights of 10 pixels, 50 pixels and 100 pixels respectively.
google-easy-grid	Grid Areas	Using a combination of column headers and row headers, a grid is defined
google-easy-grid	Grid Areas	The cells of the grid should be used to define **grid areas**
google-easy-grid	Grid Areas	Grid areas are continuous square areas defined by an arbitrary identifier being placed in a **grid cell**
google-easy-grid	Grid Areas	For example, the following grid defines two grid areas, one denoted by "A" and one denoted by "B".Grid area defintions use commas to separate multiple overlapping grid areas identifiers in a given grid cell.
google-easy-grid	Overlap	Grid areas can overlap, as seen in the example above
google-easy-grid	Overlap	This overlap defines a z-ordering
google-easy-grid	Overlap	When rendered, an area will be drawn on top of any area it overlaps
google-easy-grid	Overlap	**Grid areas are alphabetically ordered
google-easy-grid	Overlap	Later areas will be rendered on top of earlier ones.*
google-easy-grid	Empty Cells	Empty grid cells can be denoted by ..
google-easy-grid	Empty Cells	For instance,defines a SpacerGrid component that has a single grid area with a 10px border around it.
google-easy-grid	Grid Component	As mentioned above, the result of calling the grid factory method with a grid definition is a React component
google-easy-grid	Grid Component	The returned component has the following expectations:					Grid components can also be styled via the className property
google-easy-grid	Grid Component	If your project is using  styled components  the returned grid component can also be styled using the styled method:	background-color: red;
google-easy-grid	Built With	Please read  CONTRIBUTING.md  for details on our code of conduct, and the process for submitting pull requests to us.
google-easy-grid	License	This project is licensed under the Apache 2 License 
google-easy-gwt-mock	Easy GWT Mock  #	_Easy GWT Mock_ is an EasyMock-like mocking framework for  Google Web Toolkit  which allows the creation of mock objects within GWTTestCase
google-easy-gwt-mock	Easy GWT Mock  #	Feature and syntax-wise it is a lot like  EasyMock  However, there are three main differences:
google-easy-gwt-mock	Integrating _Easy GWT Mock_ in Your Project ##	Checkout the sources and executeThat's it! You are ready to use _Easy GWT Mock_.
google-easy-gwt-mock	Create Your First Mock ##	Let’s get started! Imagine, you want to mock the following type  in this case, an interface :ctrl.expect mock.add 2, 3  .andReturn 5 .once  ;// Like in EasyMock, once   is the default so you can leave it out:ctrl.expect mock.add 1, 1  .andReturn 2 ;ctrl.expect mock.add 4, 2  .andReturn 6 .anyTimes  ;ctrl.expect mock.add 6, 2  .andReturn 8 .times 2 ;ctrl.expect mock.add 2, 1  .andReturn 3 .times 4, 6 ;// Use expectLastCall   for void methods:mock.doSomething "Hello" ;ctrl.expectLastCall  .atLeastOnce  ;// chaining expectations is also possible:ctrl.expect mock.add 4, 2  .andReturn 6 .andReturn 3 ;// ..
google-easy-gwt-mock	Create Your First Mock ##	is equivalent to:ctrl.expect mock.add 4, 2  .andReturn 6 ;ctrl.expect mock.add 4, 2  .andReturn 3 ;ctrl.replay  ;// ..
google-easy-gwt-mock	Create Your First Mock ##	 interact with the mock ctrl.verify  ;That’s it! If you want to learn more about the semantic of anyTimes  , expectLastCall  , once  , etc
google-easy-gwt-mock	Create Your First Mock ##	see the  EasyMock documentation 
google-easy-gwt-mock	Using Argument Matchers ##	Sometimes you do not want to specify the exact value of an argument
google-easy-gwt-mock	Using Argument Matchers ##	That is where argument matchers are useful
google-easy-gwt-mock	Using Argument Matchers ##	Use argument matchers to specify that you expect an argument to be within a certain range:Have a lock at the MocksControl interface to learn which argument matchers are currently available
google-easy-gwt-mock	Using Argument Matchers ##	If there is no matcher that fits your use case, then fear not because you can create your own matcher!
google-easy-gwt-mock	Create Your Own Argument Matcher ##	Create a class that implements the public class IsOdd implements ArgumentMatcher {  }  }
google-easy-gwt-mock	Capture Arguments for Later Use ##	Sometimes you want to hold on to an argument passed to a mock method
google-easy-gwt-mock	Capture Arguments for Later Use ##	You can do that with captures
google-easy-gwt-mock	Capture Arguments for Later Use ##	Just create a Capture addend = new Capture;mock.add ctrl.captureInt addend , ctrl.eq 4  ;// do something with the mockaddend.getFirstValue  ; // returns the first value capturedaddend.getLastValue  ;  // returns the last value capturedaddend.getValues  ;
google-easy-gwt-mock	Throwing Exceptions ##	You can throw an exception as a reaction to a mock method call by using 
google-easy-gwt-mock	Calling onSuccess   or onFailure   ##	Asynchronous callbacks are quite common in GWT applications If your callback object does not implement the AsyncCallback interface, use the more generic Answer described in the next section to invoke your callback.
google-easy-gwt-mock	More Sophisticated Responses ##	Sometimes you actually want to do something more sophisticated than just returning a value or throwing an exception
google-easy-gwt-mock	More Sophisticated Responses ##	For example, you might want to call a callback in reaction to a method call
google-easy-gwt-mock	More Sophisticated Responses ##	You can do that and much more with the help of Caution: Using the method’s arguments within an Answer is not refactoring-safe!Word of advice: If your callback implements GWT’s AsyncCallback interface you should not use Answer and instead use the easier way described in the previous section.
google-easy-gwt-mock	Nice Mocks ##	Mocks throw an exception in response to an unexpected method call as default behavior
google-easy-gwt-mock	Nice Mocks ##	However, there are situations where you want a “nice” mock that returns appropriate default values  {{0}}}, 
google-easy-gwt-mock	Object’s equal  , hasCode   and toString   methods ##	You cannot mock the following basic methods of java.lang.Object: equals  , toString  , hashCode  
google-easy-gwt-mock	Object’s equal  , hasCode   and toString   methods ##	For your convenience, we have provided a default implementation for those methods
google-easy-gwt-mock	Object’s equal  , hasCode   and toString   methods ##	This makes it easier to add mocks to collections which might make an arbitrary amount of equals   and hashCode   calls to the mock
google-easy-gwt-mock	Object’s equal  , hasCode   and toString   methods ##	The default toString   implementation makes it easy for exceptions to display a string representation of the mock.
google-easy-gwt-mock	Limited Class Mocking  coming soon  ##	The main focus of _Easy GWT Mock_ is on mocking interfaces
google-easy-gwt-mock	Limited Class Mocking  coming soon  ##	Class mocking is somewhat limited because due to the way GWT and Java work the mock is actually a subclass of the class to mock
google-easy-gwt-mock	Limited Class Mocking  coming soon  ##	Please keep the following limitations in mind when mocking classes:
google-easy-gwt-mock	Frequently Asked Questions  FAQ  ##	**_Where should I put the interface extending MocksControl that defines which classes I want to mock?_**As you can see in the tests for the framework I usually implement the interface as an inner type right inside the test classes where I need the mocks
google-easy-gwt-mock	Frequently Asked Questions  FAQ  ##	That way, I end up with one interface per test class that only contains the mocks I need for that class
google-easy-gwt-mock	Frequently Asked Questions  FAQ  ##	Other people have suggested to have just one interface for all your tests which includes all classes you want to mock.
google-easy-gwt-mock	Differences between EasyMock and _Easy GWT Mock_ ##	Here is an  incomplete  list of the differences between _Easy GWT Mock_ and EasyMock:_Easy GWT Mock_ has some special GWT related features which are not part of EasyMock:The following features are available in EasyMock, but they are not  yet  implemented in _Easy GWT Mock_:Special thanks to the guys who created  EasyMock 
google-easybundler	EasyBundler	EasyBundler is a library to simplify converting state objects into Bundles for Android applications.This repository is also a demonstration of simple annotation processing for Android libraries.
google-easybundler	Download	In order to use EasyBundler you will need to add a compile dependency for the API as wellas an annotationProcessor dependency for the compiler:First, define a simple state class in your application and annotate it with @BundlerClass:@BundlerClasspublic class MyState {There are a few important requirements for a state object to work with EasyBundler:public final class MyStateBundler {  public static Bundle toBundle MyState object  {  }  }You can use the Bundler class directly in your application, but it's even easier to usethe helper methods provided by EasyBundler.For example to serialize an object to Bundle, use the EasyBundler.toBundle Object  method.And to turn that Bundle back into an object, use the EasyBundler.fromBundle Bundle, Class method
google-easybundler	Download	Both of these methods will fail if there is no generated Bundler class available.If you are passing objects through Intents, you can use the EasyBundler.putExtra Intent, Object and EasyBundler.fromIntent Intent, Class  methods to quickly add objects to and retrieve objectsfrom an Intent.
google-easybundler	Is EasyBundler efficient?	EasyBundler does most of the heavy lifting at compile time to generate the Bundler classes,so bundling and unbundling objects should be very fast due to the limited use of reflection atruntime
google-easybundler	Is EasyBundler efficient?	If you want to maximize efficiency by eliminating all reflection, use the Bundler classesdirectly rather than the EasyBundler helper methods  which have to do a Class lookup atruntime to find the Bundler classes .
google-easybundler	Can I customize how EasyBundler serializes and deserializes?	Not yet! But if you have a use case that is blocked by the lack of customization please open an Issue so we can discuss it.
google-easybundler	Does EasyBundler support inheritance?	No, the current version of EasyBundler only looks at properties of the annotated class, not itsparent class es .
google-easybundler	Publishing	To install the library to your mavenLocal   repository, run:
google-easypki	API	 ! godoc  For the latest API:API below pkg/ has been rewritten to allow extensibility in terms of PKIstorage and better readability.If you used the legacy API that was only writing files to disk, a tag has beenapplied so you can still import it:Current implementation of the CLI uses the local store and uses a structurecompatible with openssl, so you are not restrained.
google-easypki	Get the CLI:	go get github.com/google/easypki/cmd/easypki
google-easypki	env variables.	export PKI_ROOT=/tmp/pkiexport PKI_ORGANIZATION="Acme Inc."export PKI_ORGANIZATIONAL_UNIT=ITexport PKI_COUNTRY=USexport PKI_LOCALITY="Agloe"export PKI_PROVINCE="New York"mkdir $PKI_ROOT
google-easypki	Create the root CA:	easypki create --filename root --ca "Acme Inc
google-easypki	Create the root CA:	Certificate Authority"
google-easypki	Create a server certificate for blog.acme.com and www.acme.com:	easypki create --ca-name root --dns blog.acme.com --dns www.acme.com www.acme.com
google-easypki	Create an intermediate CA:	easypki create --ca-name root --filename intermediate --intermediate "Acme Inc
google-easypki	Create a wildcard certificate for internal use, signed by the intermediate ca:	easypki create --ca-name intermediate --dns "*.internal.acme.com" "*.internal.acme.com"
google-easypki	Create a client certificate:	easypki create --ca-name intermediate --client --email bob@acme.com bob@acme.com
google-easypki	Revoke the www certificate.	easypki revoke $PKI_ROOT/root/certs/www.acme.com.crt
google-easypki	Generate a CRL expiring in 1 day  PEM Output on stdout :	easypki crl --ca-name root --expire 1You will find the generated certificates in $PKI_ROOT/ca_name/certs/ andprivate keys in $PKI_ROOT/ca_name/keys/For more info about available flags, checkout out the help easypki -h.
google-easypki	Disclaimer	This is not an official Google product.
google-eclipse2017	Install gerrit's hooks to ensure that pushes go to code review.	curl -Lo $ git rev-parse --git-dir /hooks/commit-msg chmod +x $ git rev-parse --git-dir /hooks/commit-msggit config remote.origin.push refs/heads/*:refs/for/*sudo apt-get install docker-engine
google-eclipse2017	Install nvm	curl -osource $HOME/.bashrc
google-eclipse2017	install node.js v6	nvm install 6npm install
google-eclipse2017	Create a local_dev secret for HTTPS	./scripts/run create_secret local-dev
google-eclipse2017	Create a dev secret for HTTPS	./scripts/run create_secret dev to add yourself to the docker group
google-eclipse2017	Create a dev secret for HTTPS	note, you must completely log out of your current session for group changes toapply
google-eclipse2017	Create a dev secret for HTTPS	 This includes exiting your entire window session
google-eclipse2017	Create a dev secret for HTTPS	**If building/deploying for/to a new Google Cloud project**Every developer should create a Google Cloud project with an id of the form"eclipse-2017-dev-$USER"
google-eclipse2017	Create a dev secret for HTTPS	 Starting at  in thetop blue bar, click your current project and select "Create Project".Set the GCLOUD_PROJ variable to this id:"Oauth consent screen" tab and set the product name to $GCLOUD_PROJ
google-eclipse2017	Create a dev secret for HTTPS	 Click"Create Credentials" and select "API Key"
google-eclipse2017	Create a dev secret for HTTPS	 Make Next, click "CreateCredentials" again, and select "OAuth Client ID"
google-eclipse2017	Create a dev secret for HTTPS	 Select "Web application";fill the Name field with "Eclipse 2017 Dev $USER"
google-eclipse2017	Create a dev secret for HTTPS	 Add the following redirectURIs: Next, create a service account the gcloud project you wish to deploy to this: Google Cloud Console > IAM & Admin > Service Accounts > Create ServiceAccount
google-eclipse2017	Create a dev secret for HTTPS	Assign the role Project > Editor  TODO: is this the correct role?  tothe service account
google-eclipse2017	Create a dev secret for HTTPS	Select to furnish a new private key in JSON format andcreate the service account
google-eclipse2017	Create a dev secret for HTTPS	This will download a JSON key file to your downloadsfolder
google-eclipse2017	Create a dev secret for HTTPS	Rename this file to service_account_\.json  choosing the env withwhich you want to associate this particular gcloud project  and move it to theeclipse2017/conf directory.Create a google cloud storage bucket to store photos
google-eclipse2017	Create a dev secret for HTTPS	Google Could Console >Storage > Create Bucket
google-eclipse2017	Create a dev secret for HTTPS	Name your bucket GCLOUD_PROJ-photos
google-eclipse2017	Create a dev secret for HTTPS	Assign your bucketthe standard storage class and location United States.Set your gcloud project:bug, you will need to visit  beforeyou can do this
google-eclipse2017	Create a dev secret for HTTPS	You will see a loading wheel telling you that GKE isinitializing
google-eclipse2017	Create a dev secret for HTTPS	Once this loading is complete, you are ready to create yourcluster as described below.Create a container engine cluster
google-eclipse2017	Create a dev secret for HTTPS	*Important: cluster must be named eclipse*env to which you wish to deploy
google-eclipse2017	Create a dev secret for HTTPS	These files need to contain 4 module levelconstants specific to the gcloud project you are associating with env  definedin scripts/run :*Note: the local-dev environment should only be used when you are planning torun the profile or upload-server containers on your local machine
google-eclipse2017	Create a dev secret for HTTPS	This optioncurrently builds the project using the same configuration as the dev option,EXCEPT it adds an additional nginx server to emulate the cloud load balancer'sTLS termination behavior, i.e
google-eclipse2017	Create a dev secret for HTTPS	it turns HTTPS requests into HTTP requests andforwards them to the profile/upload-server nginx servers*You also need to install the service_account.json  from creating a serviceaccount in the Cloud Console  file to connect to Cloud Storage and CloudDatastore
google-eclipse2017	Create a dev secret for HTTPS	This contains secret keys and therefore will not be checked intosource control
google-eclipse2017	Create a dev secret for HTTPS	The file should be named conf/service_account_.json, where is the environment type  local-dev/dev, test, prod  of the Cloud projectyou are deploying to.**To run the application locally*
google-eclipse2017	Take down the local-dev environment again	The "nginx-lb-emulator" is a fake Cloud Load Balancer; it is available on yourworkstation at  and   If there are anyother processes binding to those ports, the container will fail.**To deploy**profile and upload services
google-eclipse2017	Take down the local-dev environment again	You can monitor the status of your deployment asfollows the app should be visible online:access the  Kubernetes console  as well as use the kubectl command lineGKE should respawn your containers with the new images.fully redeploy.To run all tests, from the project root directory * Note: before running thiscommand you will have to build for dev so that the necessary environmentspecific files are generated/moved to the correct locations *:
google-eddystone	Eddystone	Eddystone is a protocol specification that defines a Bluetooth low energy  BLE  message format for proximity beacon messages
google-eddystone	Eddystone	It describes several different frame types that may be used individually or in combinations to create beacons that can be used for a variety of applications.Announced in April 2016,  Eddystone-EID  eddystone-eid   Ephemeral ID  is a new frame type that defines a cryptographically secure method of configuring a beacon to broadcast information that only authorized people may decrypt
google-eddystone	Eddystone	It includes support for a  secure transmission  eddystone-tlm/tlm-encrypted.md  of the TLM  Telemetry  information.
google-eddystone	Design Goals	The design of Eddystone has been driven by several key goals:The common frame PDU types and the individual service data byte layouts forthe Eddystone frame formats are documented in the Eddystone Protocol Specification  protocol-specification.md .
google-eddystone	Configuration Service	Eddystone defines a  GATT configuration service  configuration-service/  to enable interoperability between hardware manufacturers and application developers
google-eddystone	Configuration Service	It allows the beacon to report its capabilities to apps, and for the beacon's broadcast data to be reconfigured
google-eddystone	Configuration Service	This service is also necessary for secure configuration and registration as an Eddystone-EID beacon.
google-eddystone	Tools and Code Samples	We have a variety of tools and code samples to assist developers and implementors in working with Eddystone devices.
google-edf	EDF+ Parser library	This package provides a simple, correct, and idiomatic library for parsing EDF+  files in the Go language.This is not an official Google product.
google-effcee	Effcee	   "Linux and OSX Build Status" Effcee is a C++ library for stateful pattern matching of strings,inspired by LLVM's  FileCheck  FileCheck  command.The following is from  examples/main.cc  examples/main.cc :For more examples, see the matching testsin  effcee/match_test.cc  effcee/match_test.cc .
google-effcee	Status	Effcee is a **work in progress**.What works:Effcee is licensed under terms of the  Apache 2.0 license  LICENSE 
google-effcee	Status	 If youare interested in contributing to this project, please see CONTRIBUTING.md  CONTRIBUTING.md .This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google
google-effcee	Status	 That may change if Effcee gainscontributions from others
google-effcee	Status	 See the  CONTRIBUTING.md  CONTRIBUTING.md  filefor more information
google-effcee	Status	See also the  AUTHORS  AUTHORS  and CONTRIBUTORS  CONTRIBUTORS  files.
google-effcee	File organization	Effcee depends on the  RE2  RE2  regular expression library.Effcee tests depend on  Googletest  Googletest  and  Python  Python .In the following sections, $SOURCE_DIR is the directory containing theEffcee source code.
google-effcee	Getting and building Effcee	1  Check out the source code:2  Ensure you have the requisite tools -3  Decide where to place the build output
google-effcee	Getting and building Effcee	In the following steps, we'll call it4a  Build and test with Ninja on Linux or Windows: Skip building threaded unit tests due to Googletest bug 606 the $BUILD_DIR/effcee/ directory.The default behavior on MSVC is to link with the static CRT
google-effcee	Getting and building Effcee	If you would liketo change this behavior -DEFFCEE_ENABLE_SHARED_CRT may be passed on thecmake configure line.
google-effcee	Tests	By default, Effcee registers two tests with ctest:You can disable Effcee's tests by using -DEFFCEE_BUILD_TESTING=OFF atconfiguration time:suggest limiting ctest to tests with prefix effcee:Alternately, you can turn off RE2 tests entirely by using-DRE2_BUILD_TESTING=OFF at configuration time:For building, testing, and profiling Effcee, the following tools should beinstalled regardless of your OS:On Windows, the following tools should be installed and available on your path:
google-effcee	Build options	Third party source locations:  the third_party directory, and if the previous two variables are not set.Compilation options:We track bugs using GitHub - the project's GitHub page 
google-effcee	References	 FileCheck :  RE2 :  Googletest :  CMake :  Python :  MinGW : 
google-election-au-2016	Australian Election 2016 Application	See LICENSE for usage and distribution restrictions.
google-election-au-2016	Summary	In 2016 there was a national election in Australia, this application was used toshow the current state of the nation, where it was possible to vote, and oncevoting had closed the live results as they came in.It consists of three main components:A dart-based client  under dart_frontend 
google-election-au-2016	Summary	This is an Angular2 applicationA go-based server  under go_backend 
google-election-au-2016	Summary	This was responsible for serving the Not Included : A utility that read various data sources  predominantly theThe live version of this website is visible at: 
google-election-au-2016	Dependencies	You'll need:   the dart frontend  ./dart_frontend/web/index.html .Please also ensure you comply with the various  licenses   ./LICENSE .
google-election-au-2016	Running Locally 	To run the frontend client against an existing backend:You can edit  dart_frontend/lib/conf/config_debug.yaml   dart_frontend/lib/conf/config_debug.yaml  to modify pub serve's backend.
google-election-au-2016	Deployment to Appengine	To deploy to appengine, ensure the cloned project is associated with an appengine project  normally done via Once that's done, you should be able run make install.
google-election-au-2016	Examples of the Raw API	The following REST requests show how the Go App Engine hosted API can beused to make queries against the shape data that is used to show electorateson the map.
google-election-au-2016	Which electorates are in this viewport?	_Note_: For readability, allowEncodedPolylineFeatureCollection in  go_backend/http.go   go_backend/http.go  was set to false for generating this output.The application otherwise sends an  encoded polyline  JSON response, to reduce payload size.The client can work with either formats.
google-embiggen-disk	embiggen-disk	The **embiggen-disk*any necessary layers below it: an optional LVM LV and PV, and an MBR or GPTpartition table.
google-embiggen-disk	Example	other Linux architectures.
google-embiggen-disk	Disclaimer	This is not an officially supported Google product.Audit the code and/or snapshot your disk before use if you're worried about losing data.
google-eme_logger	The EME Call and Event Logger Extension #	The EME Logger extension logs all Encrypted Media Extension  EME  calls andEvents
google-eme_logger	The EME Call and Event Logger Extension #	The log can be viewed in the javascript console, a separate browser pageor a downloaded file
google-eme_logger	The EME Call and Event Logger Extension #	EME Specification Just want to try it out? Install the EME Logger from  Chrome Web Store 
google-eme_logger	EME Formatters ##	Formatters can be used with the EME Logger extension
google-eme_logger	EME Formatters ##	Formatters are separateextensions that provide a class for key system-specific custom formatting ofdata from the calls and events
google-eme_logger	EME Formatters ##	Formatters should use \n for line breaks.This extension will convert these to  and preserve spaces when generatingTo register a message formatter:Write a class that implements isKeySystemSupported keySystem  and theAppend an instance of the class to document.emeFormatters.For example:function SomeSystemFormatter   {  this.isKeySystemSupported = function  keySystem  {  }  this.formatUpdateCall = function  response  {  }  this.formatmessage = function  message  {  }  this.formatwebkitkeymessage = function  message  {  }  this.formatAddKeyCall = function  key  {  }if  !document.emeFormatters   document.emeFormatters =   ;document.emeFormatters.push new SomeSystemFormatter ;
google-emoji-scavenger-hunt	👾 Emoji Scavenger Hunt 👾	Emoji Scavenger Hunt is an experimental web based game that makes use of TensorFlow.js to identify objects seen by your webcam or mobile camera in the browser
google-emoji-scavenger-hunt	👾 Emoji Scavenger Hunt 👾	We show you emojis 🍌 ⏰ ☕️ 📱 and you have to find those objects in the real world before your timer runs out 🏆 👍.Learn more about the experiment and try it for yourself at  g.co/emojiscavengerhunt 
google-emoji-scavenger-hunt	Development	In order to start local development we also require the installation of the  Google Cloud SDK  and associated  App Engine Components  These are used for the local webserver and pushing to app engine for static site hosting.Once you have both installed you can run the local development server with:When building assets for production use:
google-emoji-scavenger-hunt	Build your own model	You can build your own image recognition model by running a Docker container.Dockerfiles are in training directory.Prepare images for training by dividing them into directories for each labelname that you want to train.For example: the directory structure for training *catfollows assuming image data is stored under data/images.running the Docker container.data/saved_model_web directory: TensorFlow.js converter You can build your own game using your own custom image recognition model by replacingthe corresponding files under the dist/model/ directory with the newly generated ones.You also need to update src/js/scavenger_classes.ts in order to update thelabel outputs from the custom model with human-readable strings.Update the game logic in src/js/game.ts if needed.
google-emoji-scavenger-hunt	Using GPU	You can boost the training speed by utilizing your GPU.If you want to use the GPU for training, install nvidia-docker  and run:
google-emoji-scavenger-hunt	License	Copyright 2018 Google LLCLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-emoji-scavenger-hunt	Credits	This is an experiment and collaboration between Google Brand Studio and the  PAIR  teams at Google.
google-emoji-scavenger-hunt	Final Thoughts	This is not an official Google product
google-emoji-scavenger-hunt	Final Thoughts	We will do our best to support and maintain this experiment but your mileage may vary.We encourage open sourcing projects as a way of learning from each other
google-emoji-scavenger-hunt	Final Thoughts	Please respect our and other creators’ rights, including copyright and trademark rights when present, when sharing these works and creating derivative work.If you want more info on Google's policy, you can find that  here 
google-encrypted-bigquery-client	encrypted-bigquery-client	The encrypted BigQuery client is an experimental extension of the BigQuery  client
google-encrypted-bigquery-client	encrypted-bigquery-client	Itoffers client-side encryption for a subset of query types
google-encrypted-bigquery-client	encrypted-bigquery-client	Currentlyit is implemented in Python.Sample data and query examples is available in our  tutorial  tutorial.md .
google-enjarify	Introduction	Enjarify is a tool for translating Dalvik bytecode to equivalent Java bytecode
google-enjarify	Introduction	This allows Java analysis tools to analyze Android applications.
google-enjarify	Usage and installation	Enjarify is a pure python 3 application, so you can just git clone and run it
google-enjarify	Usage and installation	To run it directly, assuming you are in the top directory of the repository, you can just doFor normal use, you'll probably want to use the wrapper scripts and set it up on your path.
google-enjarify	Linux	For convenience, a wrapper shell script is provided, enjarify.sh
google-enjarify	Linux	This will try to use Pypy if available, since it is faster than CPython
google-enjarify	Linux	If you want to be able to call Enjarify from anywhere, you can create a symlink from somewhere on your PATH, such as ~/bin
google-enjarify	Linux	To do this, assuming you are inside the top level of the repository,
google-enjarify	Windows	A wrapper batch script, enjarify.bat, is provided
google-enjarify	Windows	To be able to call it from anywhere, just add the root directory of the repository to your PATH
google-enjarify	Windows	The batch script will always invoke python3 as interpreter
google-enjarify	Windows	If you want to use pypy, just edit the script.
google-enjarify	Usage	Assuming you set up the script on your path correctly, you can call it from anywhere by just typing enjarify, e.g.The most basic form of usage is to just specify an apk file or dex file as input
google-enjarify	Usage	If you specify a multidex apk, Enjarify will automatically translate all of the dex files and output the results in a single combined jar
google-enjarify	Usage	If you specify a dex file, only that dex file will be translated
google-enjarify	Usage	E.g
google-enjarify	Usage	assuming you manually extracted the dex files you could doThe default output file is  inputname -enjarify.jar in the current directory
google-enjarify	Usage	To specify the filename for the output explicitly, pass the -o or --output option.By default, Enjarify will refuse to overwrite the output file if it already exists
google-enjarify	Usage	To overwrite the output, pass the -f or --force option.
google-enjarify	Why not dex2jar?	Dex2jar is an older tool that also tries to translate Dalvik to Java bytecode
google-enjarify	Why not dex2jar?	It works reasonable well most of the time, but a lot of obscure features or edge cases will cause it to fail or even silently produce incorrect results
google-enjarify	Why not dex2jar?	By contrast, Enjarify is designed to work in as many cases as possible, even for code where Dex2jar would fail
google-enjarify	Why not dex2jar?	Among other things, Enjarify correctly handles unicode class names, constants used as multiple types, implicit casts, exception handlers jumping into normal control flow, classes that reference too many constants, very long methods, exception handlers after a catchall handler, and static initial values of the wrong type.
google-enjarify	Limitations	Enjarify does not currently translate optional metadata such as sourcefile attributes, line numbers, and annotations.Enjarify tries hard to successfully translate as many classes as possible, but there are some potential cases where it is simply not possible due to limitations in Android, Java, or both
google-enjarify	Limitations	Luckily, this only happens in contrived circumstances, so it shouldn't be a problem in practice.
google-enjarify	Performance tips	PyPy is much faster than CPython
google-enjarify	Performance tips	To install PyPy, see  Make sure you get PyPy3 rather than regular PyPy
google-enjarify	Performance tips	The Linux wrapper script will automatically use the command pypy3 if available
google-enjarify	Performance tips	On Windows, you'll need to edit the wrapper script yourself.By default, Enjarify runs optimizations on the bytecode which make it more readable for humans  copy propagation, unused value removal, etc
google-enjarify	Performance tips	If you don't need this, you can speed things up by disabling the optimizations with the --fast option
google-enjarify	Performance tips	Note that in the very rare case where a class is too big to fit in a classfile without optimization, Enjarify will automatically retry it with all optimizations enabled, so this option does not affect the number of classes that are successfully translated.
google-enjarify	Disclaimer	This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-enum_class.dart	Enum Classes for Dart	Enum Classes are now available from built_value 
google-episodes.dart	Using Episodes	Add the episodes package to your pubspec.yaml file, selecting a version rangethat works with your version of the SDK
google-episodes.dart	Using Episodes	For example:packages:episodes/episodes.dart
google-episodes.dart	Using Episodes	This library exposes the Episodes class,which contains methods you can use to instrument your code.You can call mark   to mark points in time, or call measure   to recordintervals between two such points
google-episodes.dart	Using Episodes	You can later extract the results as a graphicaltimeline in HTML, as HTML tables, or you can send them to a listener viaThere is an associated Reporter class for listening to the window.postMessagenotifications
google-episodes.dart	Using Episodes	This can be customized in suitable ways
google-episodes.dart	Using Episodes	For example, the defaultcase is like the original episodes library; there is also a  YahooBoomerang  boomerang  compatible reporter available.
google-episodes.dart	A note about versions	This package follows  semantic versioning  semver 
google-episodes.dart	A note about versions	Prior to 1.0, wefollow a similar scheme to semantic versioning
google-episodes.dart	A note about versions	 We treat the 'patch' number asthe 'minor' version, and use + as a patch
google-episodes.dart	A note about versions	So a change from 0.3.0 to 0.3.0+1 isa non-breaking change, but a change from 0.3.0 to 0.3.1 is considered a breakingchange
google-episodes.dart	A note about versions	Additionally we try to match the minor version with the currentmilestone from the Dart SDK
google-episodes.dart	A note about versions	The first release of episodes is versioned as 0.3.0because it was developed under the first M3 release of the Dart SDK
google-episodes.dart	A note about versions	If Dart M4has breaking changes, our library at that point will jump to version 0
google-episodes.dart	A note about versions	episodes :  boomerang :  semver : 
google-epr	Entry Point Regulation Prototype Chrome Extension	This prototype Chrome extension allows for the implementation of Entry Point Regulation  EPR  on a given web site
google-epr	Entry Point Regulation Prototype Chrome Extension	 Sites with regulated entry points limit their exposure to reflected cross-site scripting vulnerabilities and cross-site request forgery.Disclaimer: This is not an official Google product.
google-epr	EPR Implementation for Web Sites	To EPR-enable a site, three steps are required:1  List out valid site entry points in a manifest file  /epr-manifest.json 
google-epr	EPR Implementation for Web Sites	 Once installed in Chrome at the client, the EPR Chrome extension is responsible for enforcing the rules specified in a site's EPR manifest
google-epr	EPR Implementation for Web Sites	 Currently EPR manifests are specified for a given fully qualified domain name
google-epr	EPR Implementation for Web Sites	  In the future, this may be extended to allow different paths on a domain to have individually maintained manifests
google-epr	EPR Implementation for Web Sites	2  Serve the following HTTP response header from the domain:3  Install the EPR prototype Chrome extension on client browsers.
google-epr	Example EPR Manifest	The background.js file contains a hardcoded example manifest, complete with comments
google-epr	Example EPR Manifest	  See eprDataStatic
google-epr	Example EPR Manifest	  The epr-manifest.json file contains the same manifest, just without comments
google-epr	Example EPR Manifest	 Edit epr-manifest.json as you'd like and host it at the root.
google-epr	More Information	EPR blog post: EPR Google Group: See background.js for a list of TODOs for future improvements to the EPR Chrome extension.
google-error-prone	Error Prone	Error Prone is a static analysis tool for Java that catches common programmingmistakes at compile-time.Our documentation is at  errorprone.info Error Prone works with  Bazel  Maven   Ant  and Gradle  See our  installationinstructions  for details.
google-error-prone	Developing Error Prone	Developing and building Error Prone is documented on the wiki 
google-escapevelocity	EscapeVelocity summary	EscapeVelocity is a templating engine that can be used from Java
google-escapevelocity	EscapeVelocity summary	It is a reimplementation of a subset offunctionality from  Apache Velocity This is not an official Google product.For a fuller explanation of Velocity's functioning, see its User Guide If EscapeVelocity successfully produces a result from a template evaluation, that result should bethe exact same string that Velocity produces
google-escapevelocity	EscapeVelocity summary	If not, that is a bug.EscapeVelocity has no facilities for HTML escaping and it is not appropriate for producingHTML output that might include portions of untrusted input
google-escapevelocity	EscapeVelocity summary	SpacesFor the most part, spaces and newlines in the template are preserved exactly in the output.To avoid unwanted newlines, you may end up using ## comments
google-escapevelocity	EscapeVelocity summary	In the #foreach example abovewe had this:result is this:in the output of the spaces in #foreach  $product in $allProducts  or #if  $foreach.hasNext .Spaces are also ignored inside references, such as $indexme  $i   or $callme  $i , $j  .If you are concerned about the detailed formatting of the text from the template, you may want topost-process it
google-escapevelocity	EscapeVelocity summary	For example, if it is Java code, you could use a formatter such as google-java-format  Then you shouldn't have toworry about extraneous spaces
google-escapevelocity	EscapeVelocity summary	VelocityHacks :  AutoValue : 
google-eslint-closure	Closure Linter	 Google JavaScript style guide Check out the  **demo page** 
google-eslint-closure	Google Style Guide Specific Features	  goog.scope function   {  var noIndent = 2;  } ;    goog.provide 'my.module' ;  goog.require 'other.module' ;    /*  my.module.foo = 2;   Google JavaScript style guide  forthe rest of the rules.
google-eslint-closure	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-eslint-closure	Developing	Pull requests are always welcome
google-eslint-closure	Developing	 To get started,install  Bazel  Google's open-source build system,and  Yarn  an NPM replacement.A typical development flow looks like this: make develop to download dependencies from NPM and to link the projects together
google-eslint-closure	Developing	make test to ensure everything works first
google-eslint-closure	Developing	Add a feature or fix a bug
google-eslint-closure	Developing	make test git commit git push
google-eslint-config-google	eslint-config-google   	> ESLint  shareable config  for the  Google JavaScript style guide  ES2015+ version  
google-eslint-config-google	Installation	Once the eslint-config-google package is installed, you can use it by specifying google in the  extends  section of your  ESLint configuration There are several rules in the  eslint:recommended ruleset  that Google style is not opinionated about that you might want to enforce in your project.To use Google style in conjunction with ESLint's recommended rule set, extend them both, making sure to list google last:
google-eslint-config-google	License	Apache-2 © Google
google-etc2comp	Etc2Comp 	Etc2Comp is a command line tool that converts textures  e.g
google-etc2comp	Etc2Comp 	bitmaps into the  ETC2 format
google-etc2comp	Etc2Comp 	The tool is built with a focus on encoding performanceto reduce the amount of time required to compile asset heavy applications aswell as reduce overall application size.This repo provides source code that can be compiled into a binary
google-etc2comp	Etc2Comp 	Thebinary can then be used to convert textures to the ETC2 format.Important: This is not an official Google product
google-etc2comp	Etc2Comp 	It is an experimentallibrary published as-is
google-etc2comp	Etc2Comp 	Please see the CONTRIBUTORS.md file for informationabout questions or issues.
google-etc2comp	Setup	This project uses  CMake  to generate platform-specificbuild files:Refer to each platform's setup section to setup your environment and buildan Etc2Comp binary
google-etc2comp	Setup	Then skip to the usage section of this page for examplesof how to use the library.
google-etc2comp	Setup for OS X	 build tested on this config:  OS X 10.9.5 i7 16GB RAM  Xcode 5.1.1  cmake 3.2.3already installed on your development machine
google-etc2comp	Setup for OS X	Open a *Terminal Run mkdir build_xcode Run cd build_xcode Run cmake -G Xcode ../ Open *Xcode Open the Product menu and choose Build For -> Running
google-etc2comp	Setup for OS X	Once the build succeeds the binary located at build_xcode/EtcTool/Debug/EtcToolcan be executed.Xcode EtcTool ‘Run’ preferencesnote: if the build_xcode/EtcTest.xcodeproj is manually deleted then some Xcode preferences will need to be set by hand after cmake is run  these prefs are retained across cmake updates if the .xcodeproj is not deleted/removed Set the active scheme to ‘EtcTool’Edit the schemeSelect option ‘Run EtcTool’, then tab ‘Arguments’
google-etc2comp	Setup for OS X	Add this launch argument: ‘-argfile ../../EtcTool/args.txt’Select tab ‘Options’ and set a custom working directory to: ‘$ SRCROOT /Build_Xcode/EtcTool’
google-etc2comp	SetUp for Windows	Open a *TerminalRun mkdir build_vsRun cd build_vsRun CMAKE, noting what build version you need, and pointing to the parent directory as the source root;  For VS 2015 : cmake -G "Visual Studio 14 2015 Win64" ../  NOTE: To see what supported Visual Studio outputs there are, run cmake -Gopen the 'EtcTest' solutionmake the 'EtcTool' project the start up project  optional  in the project properties, under 'Debugging ->command arguments' add the argfile textfile thats included in the EtcTool directory
google-etc2comp	SetUp for Windows	example: -argfile C:\etc2\EtcTool\Args.txt
google-etc2comp	Setup For Linux	The Linux build was tested on this config:  Ubuntu desktop 14.04  gcc/g++ 4.8  cmake 2.8.12.2Verify linux has cmake and C++-11 capable g++ installedOpen shellRun mkdir build_linuxRun cd build_linuxRun cmake ../Run makenavigate to the newly created EtcTool directory cd EtcToolrun the executable: ./EtcTool -argfile ../../EtcTool/args.txtSkip to the Usage section for more information about using the
google-etc2comp	Command Line Usage	EtcTool can be run from the command line with the following usage:The encoder will use an array of RGBA floats read from the source_image to create an ETC1 or ETC2 encoded image in encoded_image
google-etc2comp	Command Line Usage	 The RGBA floats should be in the range  0:1 .	-mipmaps or -m 	-mipwrap or -w "analysis_folder"  e.g
google-etc2comp	Command Line Usage	../analysis/kodim05 
google-etc2comp	Command Line Usage	 within the analysis_folder, a folder will be created with a name of the current date/time  e.g
google-etc2comp	Command Line Usage	20151204_153306 
google-etc2comp	Command Line Usage	 this date/time folder is used to compare encodings of the same texture over time
google-etc2comp	Command Line Usage	 within the date/time folder is a text file with several encoding stats and a 2x png image showing the encoding mode for each 4x4 block.will dictate what error analysis is used in the comparison.to apply during the encoding.RMS error using RGB components that are weighted by A
google-etc2comp	Command Line Usage	 "rgbx" calculates RMS error using RGBA components, where A is treated as an additional data channel, instead of as alpha
google-etc2comp	Command Line Usage	 "rec709" is similar to "rgba", except the RGB components are also weighted according to Rec "numeric" calculates RMS error using unweighted RGBA components
google-etc2comp	Command Line Usage	 "normalize" calculates error based on dot product and vector length for RGB and RMS error for A.source image
google-etc2comp	Command Line Usage	 The mipmaps are generated with a lanczos3 filter using edge clamping.If the mipmaps option is not specified no mipmaps are created.are "x", "y" and "xy" which specify wrapping in x only, y only or x and y respectively.The default options are clamping in both x and y.Note: Path names can use slashes or backslashes
google-etc2comp	Command Line Usage	 The tool will convert the slashes to the appropriate polarity for the current platform.
google-etc2comp	API	The library supports two different APIs class-based and a class-based API.main   in EtcTool.cpp contains an example of both APIs.The Encode   method now returns an EncodingStatus that contains bit flags forreporting various warnings and flags encountered when encoding.
google-etc2comp	Copyright	Copyright 2015 Etc2Comp Authors.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-eventid-js	Monotonically increasing per machine, globally unique eventids	 ! Greenkeeper badge   ! CircleCI  circle-image   circle-url  ! Dependencies  david-image   david-url  ! Known Vulnerabilities  snyk-image   snyk-url ***Note: This is not an official Google product.***An eventId uniquely identifies an event across a network of services
google-eventid-js	Monotonically increasing per machine, globally unique eventids	It isglobally unique, and is monotically increasing locally
google-eventid-js	Monotonically increasing per machine, globally unique eventids	This makes eventidsuseful for lexically comparable identifiers for events in a distributed system.This can be used instead of timestamps – JavaScript timestamps only havemillisecond resolution making them unsuitable for the purpose of buildingmonotonically increasing local ids.const EventId = require 'eventid' ;// Instantiate a generator.const eventId = new EventId  ;// Generate a globally unique identifier.const id1 = eventId.new  ; // -> "..........37qqNkj4K24ulWyeuWxpZh"// Use the same generator to get monotonically increasing local ids.const id2 = eventId.new  ; // -> "..........77qqNkj4K24ulWyeuWxpZh"// You can lexicographically compare the ids.assert id1  true// Another instance will use a different guidconst another = new EventId  ;const id3 = another.new  ; // -> "..........5rkLYOc5W8ZAHAmVSyrixJ" circle-image :  circle-url :  david-image :  david-url :  snyk-image :  snyk-url : 
google-extra-keyboards-for-chrome-os	Extra Keyboards for Chrome OS	A collection of extra keyboard layouts and input methods for Chrome OS
google-extra-keyboards-for-chrome-os	Extra Keyboards for Chrome OS	Eachdirectory is its own Chrome extension.
google-extra-keyboards-for-chrome-os	GitHub	Go to chrome://extensions.Click on "Load unpacked extensions...".Pick the directory containing the manifest for the extension you want toLogout and then login again
google-extra-keyboards-for-chrome-os	GitHub	 This may not be necessary
google-extra-keyboards-for-chrome-os	GitHub	Go to chrome://settings/languages.Add the relevant language, e.g
google-extra-keyboards-for-chrome-os	GitHub	French for the bepo keyboard layout.Select the relevant keyboard layout and input method.Optionally, remove any keyboard layouts or input methods that are no longer
google-extra-keyboards-for-chrome-os	Chrome Web Store	Several of the extensions are available on the  Chrome Web Store Note that the version on the webstore may not be as up-to-date as on GitHub.Press Ctrl + Shift + Space to cycle through the enabled keyboard languages.Type away…Ctrl + Space to toggle between the most recently used keyboard languages.
google-ezgantt	ezGantt	View a Google Spreadsheet as a Gantt ChartezGantt uses public Google Chart and Google Drive JavaScript APIs, so the same users who can view the Spreadsheet can see the Gantt chart.To try it, go to To use it yourself, make a copy of the demo sheet and start adding tasks!
google-ezgantt	ezgantt.apspot.com	gcloud app deploy -q --project ezgantt --version 1 --verbosity=info app.yaml> "I think ezgantt is a great tool for small-medium projects, > it's easy to learn  took me minutes to get a good chart  and maintain."
google-ezgantt	References	* * * 
google-fancy-regex	fancy-regex	A Rust library for compiling and matching regular expressions
google-fancy-regex	fancy-regex	It uses a hybridregex implementation designed to support a relatively rich set of features.In particular, it uses backtracking to implement "fancy" features such aslook-around and backtracking, which are not supported in purelyNFA-based implementations  exemplified by RE2  and implemented in Rust in the regex  crate 
google-fancy-regex	fancy-regex	! crate   ! build status   ! codecov  A goal is to be as efficient as possible
google-fancy-regex	fancy-regex	For a given regex, the NFAimplementation has asymptotic running time linear in the length of theinput, while in the general case a backtracking implementation hasexponential blowup
google-fancy-regex	fancy-regex	An example given in  Static Analysis for RegularExpression Exponential Runtime via SubstructuralLogics  is:doubles for each additional repeat of 'ab'.Thus, many proponents advocate  a purely NFA nondeterministic finite automaton  based approach
google-fancy-regex	fancy-regex	Even so,backreferences and look-around do add richness to regexes, and theyare commonly used in applications such as syntax highlighting for texteditors
google-fancy-regex	fancy-regex	In particular, TextMate's  syntaxdefinitions based on the  Oniguruma backtracking engine, are now used in a number of other populareditors, including Sublime Text and Atom
google-fancy-regex	fancy-regex	These syntax definitionsroutinely use backreferences and look-around
google-fancy-regex	fancy-regex	For example, thefollowing regex captures a single-line Rust raw string:a backtracking implementation handles it efficiently.This package is one of the first that handles both cases well
google-fancy-regex	fancy-regex	Theexponential blowup case above is run in 258ns
google-fancy-regex	fancy-regex	Thus, it should be avery appealing alternative for applications that require both richnessand performance.
google-fancy-regex	A warning about worst-case performance	NFA-based approaches give strong guarantees about worst-caseperformance
google-fancy-regex	A warning about worst-case performance	For regexes that contain "fancy" features such asbackreferences and look-around, this module gives no correspondingguarantee
google-fancy-regex	A warning about worst-case performance	If an attacker can control the regular expressions thatwill be matched against, they will be able to successfully mount adenial-of-service attack
google-fancy-regex	A warning about worst-case performance	Be warned.See  PERFORMANCE.md  PERFORMANCE.md  for some examples.
google-fancy-regex	A hybrid approach	One workable approach is to detect the presence of "fancy" features,and choose either an NFA implementation or a backtracker depending onwhether they are used.However, this module attempts to be more fine-grained
google-fancy-regex	A hybrid approach	Instead, itimplements a true hybrid approach
google-fancy-regex	A hybrid approach	In essence, it is a backtracking VM as well explained in  Regular Expression Matching: the VirtualMachine Approach  inwhich one of the "instructions" in the VM delegates to an inner NFAimplementation  in Rust, the regex crate, though a similar approachwould certainly be possible using RE2 or the Go regexp  package 
google-fancy-regex	A hybrid approach	Then there's ananalysis which decides for each subexpression whether it is "hard", orcan be delegated to the NFA matcher
google-fancy-regex	A hybrid approach	At the moment, it is eager, anddelegates as much as possible to the NFA engine.
google-fancy-regex	Theory	** This section is written in a somewhat informal style; I hope toexpand on it **The fundamental idea is that it's a backtracking VM like PCRE, but asmuch as possible it delegates to an "inner" RE engine like RE2  inthis case, the Rust one 
google-fancy-regex	Theory	For the sublanguage not using fancyfeatures, the library becomes a thin wrapper.Otherwise, you do an analysis to figure out what you can delegate andwhat you have to backtrack
google-fancy-regex	Theory	I was thinking it might be tricky, butit's actually quite simple
google-fancy-regex	Theory	The first phase, you just label eachsubexpression as "hard"  groups that get referenced in a backref,look-around, etc , and bubble that up
google-fancy-regex	Theory	You also do a little extraanalysis, mostly determining whether an expression has constant matchlength, and the minimum length.The second phase is top down, and you carry a context, also a booleanindicating whether it's "hard" or not
google-fancy-regex	Theory	Intuitively, a hard context isone in which the match length will affect future backtracking.If the subexpression is easy and the context is easy, generate aninstruction in the VM that delegates to the inner NFA implementation.Otherwise, generate VM code as in a backtracking engine
google-fancy-regex	Theory	Mostexpression nodes are pretty straightforward; the only interesting caseis concat  a sequence of subexpressions .Even that one is not terribly complex
google-fancy-regex	Theory	First, determine a prefix ofeasy nodes of constant match length  this won't affect backtracking,so safe to delegate to NFA 
google-fancy-regex	Theory	Then, if your context is easy, determinea suffix of easy nodes
google-fancy-regex	Theory	Both of these delegate to NFA
google-fancy-regex	Theory	For the ones inbetween, recursively compile
google-fancy-regex	Theory	In an easy context, the last of thesealso gets an easy context; everything else is generated in a hardcontext
google-fancy-regex	Theory	So, conceptually, hard context flows from right to left, andfrom parents to children.
google-fancy-regex	Current status	Still in development, though the basic ideas are in place
google-fancy-regex	Current status	Currently,the following features are missing:Many thanks to  Andrew Gallant  forstimulating conversations that inspired this approach, as well as forcreating the excellent regex crate.
google-fancy-regex	Authors	The main author is Raph Levien.
google-fancy-regex	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-fancy-regex	Contributions	Please see CONTRIBUTIONS.md formore details.
google-fancy-regex	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.
google-fast-simple-lcsk	Fast and simple algorithms for computing both LCSk and LCSk+	  This repository contains an implementation of the algorithms for computing LCSk and LCSk+, described in  1 .
google-fast-simple-lcsk	Dependencies	For compiling the library, it is necessary to have C++11 compatible compiler.
google-fast-simple-lcsk	References	 1  Filip Pavetic, Ivan Katanic, Gustav Matula, Goran Zuzic, Mile Sikic: _Fast and simple algorithms for computing both LCSk and LCSk+_, 3    
google-fastboot-mobile	Fastboot Mobile	Android library for sending fastboot commands from an Android device to a device running fastboot.***Only supports fastboot over USB On-The-Go  OTG  connections.******This is NOT an officially supported Google product.***
google-fastboot-mobile	Connect to a Fastboot Device	// typealias DeviceId = StringFastbootDeviceManager.addFastbootDeviceManagerListener FastbootDeviceManager.connectToDevice /
google-favcolor-android	FavColor Android client	Android app which is a FavColor client; FavColor is a demo app for a variety of identity technologies, including OAuth 2, OpenID COnnect, and Persona.This generates two APKs, called “FavColor” and “FC + GitKit”
google-favcolor-android	FavColor Android client	 The former uses pure OpenID Connect tokens for authentication to talk to the server and only works with Google accounts
google-favcolor-android	FavColor Android client	 The latter uses the Google Identity Toolkit libraries and allows sign-in via Facebook, Yahoo, or Google, or with an email address and password.
google-favcolor-android	Setup	I just pushed the Eclipse project directory
google-favcolor-android	Setup	 If you’re using IntelliJ or something, sorry.There are dependencies on three library projects: the AmbilWarna color picker, the Identity Toolkit SDK, and the Identity-Toolkit Facebook SDK shim.
google-favcolor-server	FavColor server	A demo app for a variety of identity technologies, including OAuth 2, OpenID COnnect, and Persona.
google-favcolor-server	favcolor.net	Integrates with the Google, Microsoft, Facebook, and Mozilla Persona IDPs
google-favcolor-server	favcolor.net	 Mostly OAuth 2.0-based, except for Facebook is subtly incompatible and Personais something completely different.
google-favcolor-server	favcolor.net/gat	Integrates with the Google “Identity Toolkit” software, which takes care of all the user management stuff, including passwords, recovery, and federation with lots of IDPs.
google-favcolor-server	components	This is the server side of the code, a Ruby/Sinatra thing which uses filesystem storage with some help from memcached.Also, there’s an Android client at  and an iOS client at 
google-fchan-go	fchan: Fast Channels in Go	This package contains implementations of fast and scalable channels in Go.Implementation is in bench.go is very rudimentary, and modifying the source may be necessarydepending on what you want to run; that will change in the future
google-fchan-go	fchan: Fast Channels in Go	 For detailson the algorithm, check out the writeup directory, it includes a pdf and thepandoc markdown used to generate it
google-fchan-go	fchan: Fast Channels in Go	**This is a proof of concept only**
google-fchan-go	fchan: Fast Channels in Go	This code should *notproduction
google-fchan-go	fchan: Fast Channels in Go	 Comments, criticisms and bugs are all welcome!
google-fchan-go	Disclaimer	This is not an official Google product.
google-ffcc	Fast Fourier Color Constancy Matlab Toolbox	The Fast Fourier Color Constancy  FFCC  Matlab Toolbox includes the followingEither add this to the path manually or place it inside the root /ffcc/
google-ffcc	Training & Cross Validation	The following section discusses training and cross validation.
google-ffcc	Preparation and Folder Structure	The training folder structure should look similar to the following:The script will parse down the subfolders and look for *.png and *.txt files,which corresponds to the linear thumbnail and the color of global illuminant.This data has been provided for the Gehler-Shi dataset, alongside a scriptfor generating this data "from scratch"  see /ffcc/data/ .
google-ffcc	Linear Thumbnail	The PNG file is usually a small resolution thumbnail with linear data afterblack level removed
google-ffcc	Linear Thumbnail	This is very important since this assumption enables shiftinvariance
google-ffcc	Linear Thumbnail	This PNG file needs to match to the format of your imaging pipeline
google-ffcc	Global Illuminant	The text file descibes the color of the global illuminant
google-ffcc	Global Illuminant	It looks like this:as follows:$$where \\ z =  1/R_{gain}, 1/G_{gain}, 1/B_{gain} \\ .
google-ffcc	Project Folder	To allow FFCC Toolbox to support wide range of projects, we separate out thecore algorithms from the project specific implementations
google-ffcc	Project Folder	The project specificimplementations are placed under projects/ folder.The following scripts all take as input the string of some project name, whichmust correspond exactly to a folder in projects/, and which must prefix allfilenames in the projects/ subfolder.
google-ffcc	Tuning and cross-validation	Tune   performs coordinate descent over hyperparameters, and can also be used tosanity-check the current hyperparameter set as a diagnostic
google-ffcc	Tuning and cross-validation	A side effect oftuning/cross-validation is that it will produce a set of error metrics, of thefollowing form:second element is a surface statistic on that error metric
google-ffcc	Tuning and cross-validation	Please seeCrossValidate.m and ErrorMetrics.m for detailed descriptions.An angular_err less than 2 degrees is not perceptible, and vonmisses_nll isis measured in negative-nats for an individual training point
google-ffcc	Tuning and cross-validation	If the error ismore than 2 degrees, you might consider:  file to be used in later training and tuning, as described in Tune  
google-ffcc	Tuning and cross-validation	Tuning  may be slow, so consider running it overnight or for several days
google-ffcc	Tuning and cross-validation	 group.You can read further tuning description in Tune.m or CrossValidate.m
google-ffcc	Training	Once Tune   is producing reasonable cross-validation results, use Train  to train a final model which will be written to disk
google-ffcc	Training	See Train   for details.
google-ffcc	Visualization	Visualize   provides visualizing and testing functinality
google-ffcc	Visualization	Given a project name,It will do all necessary training  or cross-validation  and produce avisualization for each image
google-ffcc	Visualization	If the project uses cross-validation, then eachimage is evaluated using the model that did not include that image in itstraining fold
google-ffcc	Visualization	If the project uses training/test splits, then all images areevaluated using the model trained on the training set.If params.TRAINING.DUMP_EXHAUSTIVE_VISUALIZATIONis set to true, this script will dump an extensive set of images and filesdescribing the output of the model, which can be useful for debugging.See CrossValidate   for details.
google-ffn	Flood-Filling Networks	Flood-Filling Networks  FFNs  are a class of neural networks designed forinstance segmentation of complex and large shapes, particularly in volumeEM datasets of brain tissue.For more details, see the related publications: *  * This is not an official Google product.
google-ffn	Installation	No installation is required, but please ensure that the following dependenciesare available on your system:versions listed above, and equipped with a Tesla P100 GPU.
google-ffn	Training	FFN networks can be trained with the train.py script, which expects aTFRecord file of coordinates at which to sample data from input volumes.
google-ffn	Sample data	We provide a sample coordinate file for the FIB-25 validation1 volumeincluded in third_party
google-ffn	Sample data	Due to its size, that file is hosted inGoogle Cloud Storage
google-ffn	Sample data	If you haven't used it before, you will need toinstall the Google Cloud SDK and set it up with:There are two scripts to generate training coordinate files fora labeled dataset stored in HDF5 files: build_coordinates.py.compute_partitions.py transforms the label volume into an intermediatevolume where the value of every voxel A corresponds to the quantizedfraction of voxels labeled identically to A within a subvolume ofradius lom_radius centered at A
google-ffn	Sample data	lom_radius should normally beset to  fov_size // 2  + deltas  where fov_size and deltas areFFN model settings 
google-ffn	Sample data	Every such quantized fraction is called a *partition*.Sample invocation:to produce a TFRecord file of coordinates in which every partition isrepresented approximately equally frequently
google-ffn	Sample data	Sample invocation:Once the coordinate files are ready, you can start training the FFN with:computationally expensive processes
google-ffn	Sample data	We recommend a GPU-equipped machinefor best results, particularly when using the FFN interactively in a Jupyternotebook
google-ffn	Sample data	Training the FFN as configured above requires a GPU with 12 GB of RAM.You can reduce the batch size, model depth, fov_size, or number of features inthe convolutional layers to reduce the memory usage.
google-ffn	Inference	We provide two examples of how to run inference with a trained FFN model.For a non-interactive setting, you can use the run_inference.py script:contain a segmentation map and quantized probability maps, respectively.In Python, you can load the segmentation as follows:For the training2 volume, segmentation takes ~7 min with a P100 GPU.For an interactive setting, check out ffn_inference_demo.ipynb
google-ffn	Inference	This Jupyternotebook shows how to segment a single object with an explicitly definedseed and visualize the results while inference is running.Both examples are configured to use a 3d convstack FFN model trained on thevalidation1 volume of the FIB-25 dataset from the FlyEM project at Janelia.
google-fhir	FHIR protocol buffers	This repository contains a Google implementation of protocol buffers forFHIR
google-fhir	FHIR protocol buffers	This is not an officially supported Google product.To build this repository, install  bazel  and then runsee our  blog post  Support for C++, Go, and Python is coming soon
google-fhir	FHIR protocol buffers	You can post questions and feedback in this  web forum 
google-filament	Filament	        Filament is a real-time physically based rendering engine for Android, Linux, macOS and Windows.This rendering engine was designed to be as small as possible and as efficient as possibleon Android.Filament is currently used in the Sceneform  library both at runtime onAndroid devices and as the renderer inside the Android Studio plugin.
google-filament	Download	 Download Filament releases  to access stable builds.If you prefer to live on the edge, you can download continuous builds directly:  This document explains the math and reasoning behind most of our decisions
google-filament	Download	This document is a  good introduction to PBR for graphics programmers
google-filament	Download	 to use the material compiler matc and how to write custom materials.
google-filament	Samples	Here are a few sample materials rendered with Filament:! Brushed copper  docs/images/samples/brushed_copper_2.png ! Chess set  docs/images/samples/chess1.png ! Environment lighting  docs/images/samples/spheres.png ! Material 1  docs/images/samples/material_01.png ! Material 2  docs/images/samples/material_02.png ! Material 3  docs/images/samples/material_03.png ! Material 4  docs/images/samples/material_04.png ! Material 6  docs/images/samples/material_06.png ! Material 7  docs/images/samples/material_07.png ! Material 8  docs/images/samples/material_08.png 
google-filament	APIs	Many other features have been either prototyped or planned:
google-filament	Prerequisites	To build Filament, you must first install the following tools:section below.To build Filament for Android you must also install the following:Make sure the environment variable ANDROID_HOME points to the location of your Android SDK.By default our build system will attempt to compile the Java bindings
google-filament	Prerequisites	To do so, the environmentvariable JAVA_HOME should point to the location of your JDK.When building for WebGL, you'll also need to set EMSDK
google-filament	Prerequisites	See  WebAssembly  #WebAssembly .
google-filament	IDE	We recommend using CLion to develop for Filament
google-filament	IDE	Simply open the root directory's CMakeList.txtin CLion to obtain a usable project.
google-filament	Easy build	The easiest way to build Filament for Android is to use -p android flag
google-filament	Easy build	For instance to build the release target:
google-filament	Disabling Java builds	By default our build system will attempt to compile the Java bindings
google-filament	Disabling Java builds	If you wish to skip thiscompilation step simply pass the -j flag to build.sh:
google-filament	Linux	Make sure you've installed the following dependencies:extra parameter to cmake:solution is to use update-alternatives to both change the default compiler, and point to aspecific version of clang:
google-filament	macOS	To compile Filament you must have the most recent version of Xcode installed and you need tomake sure the command line tools are setup by running:properly set
google-filament	macOS	If it doesn't already point to the appropriate JDK, you can simply add the followingto your .profile:The following instructions have been tested on a machine running Windows They should take youfrom a machine with only the operating system to a machine able to build and run Filament.Google employees require additional steps which can be found here  go/filawin Install the following components:Create a working directory:Create the msBuild project:Check out the output and make sure Clang for Windows frontend was found
google-filament	macOS	You should see a lineshowing the following ouput.You are now ready to build:Run it:
google-filament	Building with Ninja on Windows	Alternatively, you can use  Ninja  to build for Windows
google-filament	Building with Ninja on Windows	An MSVCinstallation is still necessary.First, install the dependencies listed under  Windows  #Windows  as well as Ninja
google-filament	Building with Ninja on Windows	Then open up aVS2015 x64 Native Tools terminal as before
google-filament	Building with Ninja on Windows	Create a build directory inside Filament and run thefollowing CMake command:
google-filament	Running a simple test	To confirm Filament was properly built, run the following command from the build directory:Before building Filament for Android, make sure to build Filament for your host
google-filament	Running a simple test	Some of thehost tools are required to successfully build for Android.Filament can be built for the following architectures:foremost for arm64-v8a.
google-filament	Linux toolchain	Then invoke CMake in a build directory of your choice, sibling of filament's directory:to build the Android Studio projects located in filament/android
google-filament	Linux toolchain	After install, the librarybinaries should be found in out/android-release/filament/lib/x86.
google-filament	AAR	Before you attempt to build the AAR, make sure you've compiled and installed the native librariesas explained in the sections above
google-filament	AAR	You must have the following ABIs built inAAR is a universal AAR that contains all supported build targets:Alternatively you can build the AAR from the command line by executing the following theandroid/filament-android directory:the CMake install prefix used in the previous steps .
google-filament	Using Filament's AAR	Create a new module in your project and select _Import .JAR or .AAR Package_ when prompted
google-filament	Using Filament's AAR	Makesure to add the newly created module as a dependency to your application.If you do not wish to include all supported ABIs, make sure to create the appropriate flavors inyour Gradle build file
google-filament	Using Filament's AAR	For example:As an experimental feature, the core Filament library can be cross-compiled to WebAssembly fromeither macOS or Linux
google-filament	Using Filament's AAR	To get started, do the following only once:After this you can invoke our standard build script with -p webgl.
google-filament	Running the samples	The samples/ directory contains several examples of how to use Filament with SDLSome of the samples accept FBX/OBJ meshes while others rely on the filamesh file format
google-filament	Running the samples	Togenerate a filamesh  file from an FBX/OBJ asset, run the filamesh tool ./tools/filamesh/filamesh in your build directory :in your build directory 
google-filament	Running the samples	These sample apps expect a path to a directory containing the RGBM filesfor the IBL
google-filament	Running the samples	To generate an IBL simply use this command:file
google-filament	Running the samples	The environment map can be an equirectangular projection, a horizontal cross, a verticalcross, or a list of cubemap faces  horizontal or vertical .cmgen will automatically create a directory based on the name of the source environment map
google-filament	Running the samples	Inthe example above, the final directory will be ./ibls/my_ibl/
google-filament	Running the samples	This directory should contain thepre-filtered environment map  one file per cubemap face and per mip level , the environment maptexture for the skybox and a text file containing the spherical harmonics for indirect diffuseIf you prefer a blurred background, run cmgen with this flag: --extract-blur=0.5
google-filament	Running the samples	The numericalvalue is the desired roughness between 0 and 
google-filament	Native Linux, macOS and Windows	You must create an Engine, a Renderer and a SwapChain
google-filament	Native Linux, macOS and Windows	The SwapChain is created from anative window pointer  an NSView on macOS or a HDC on Windows for instance :CameraSceneview->setCamera camera ;view->setScene scene ;Renderables are added to the scene:by matc: materials documentation  ./docs/Materials.md.html .To render, simply pass the View to the Renderer:in the samples/ directory
google-filament	Native Linux, macOS and Windows	These samples are all based on samples/app/ which contains the codethat creates a native window with SDL2 and initializes the Filament engine, renderer and views.
google-filament	Java on Linux, macOS and Windows	After building Filament, you can use filament-java.jar and its companion filament-jni nativelibrary to use Filament in desktop Java applications.You must always first initialize Filament by calling Filament.init  .You can use Filament either with AWT or Swing, using respectively a FilamentPanel.Following the steps above  how to use Filament from native code , create an Renderer, but instead of calling beginFrame and endFrame on the renderer itself, callthese methods on FilamentCanvas or FilamentPanel.
google-filament	Android	You must always first initialize Filament by calling Filament.init  .Rendering with Filament on Android is similar to rendering from native code  the APIs are largelythe same across languages 
google-filament	Android	You can render into a createSwapChain method
google-filament	Android	This allows you to render to a SurfaceTexture, a TextureView ora SurfaceView
google-filament	Android	To make things easier we provide an Android specific API called UiHelper in thepackage com.google.android.filament.android
google-filament	Android	All you need to do is set a render callback on thehelper and attach your SurfaceView or TextureView to it
google-filament	Android	You are still responsible forcreating the swap chain in the onNativeWindowChanged   callback.
google-filament	Generating C++ documentation	To generate the documentation you must first install doxygen, then run the following commands:
google-filament	Dependencies	One of our design goals is that Filament itself should have no dependencies or as few dependenciesas possible
google-filament	Dependencies	The current external dependencies of the runtime library include:
google-filament	How to make contributions	Please read and follow the steps in  CONTRIBUTING.md  /CONTRIBUTING.md 
google-filament	How to make contributions	Make sure you arefamiliar with the  code style  /CODE_STYLE.md 
google-filament	License	Please see  LICENSE  /LICENSE .
google-filament	Disclaimer	This is not an officially supported Google product.
google-file-system-stress-testing	**Summary**	A  monkey test  tool framework that can be used to stress test POSIX filesystems
google-file-system-stress-testing	**Summary**	There is a library of common filesystem operations  open,mmap, etc 
google-file-system-stress-testing	**Summary**	And a small framework library that does some housekeeping  like tracking open FDs 
google-file-system-stress-testing	**Summary**	Some  example tools  are provided.Reading the  monkey test  overview, would help you understand the goals of this project.
google-file-system-stress-testing	**Objectives**	Develop a new  monkey test  tool that will meet these objectives:
google-file-system-stress-testing	**Operational Pool**	Split the monkey tool into two parts: one tool uses entropy to generate a file system operation list and another tool that replays this pre-generated operation list.Using pre-generated operation lists is a win due to the future improvements this technique enables:
google-files.dart	Status	This package is deprecated
google-files.dart	Status	For a more full-featured replacement, see package:file  or similar.
google-files.dart	Overview	This package defines filesystem APIs that can be implemented for differentenvironments such as dart:io, Chrome Apps, or network filesystems.The API includes FileSystem, File and Directory classes with interfacessimilar to those in dart:io, excluding synchronous operations and constructors.All File and Directory implementations should not have public constructors,and instances should only be retreived via a FileSystem instance
google-files.dart	Overview	This ensuresthat code that uses the interfaces defined here can work with any implementations.
google-firing-range	What is Firing Range?	Firing Range is a test bed for web application security scanners,providing synthetic, wide coverage for an array of vulnerabilities.It can be deployed as a Google App Engine application
google-firing-range	What is Firing Range?	A public instanceis running at 
google-firing-range	Local installation instructions	ant runserverThe application then will be run locally at 
google-firing-range	License information	See the LICENSE file.
google-firmata.py	Overview	Firmata.py presents an easy-to-use API for the firmata wire protocol commonly used with arduino boards
google-firmata.py	Overview	Firmata.py implements the entire protocol  including things like the Capabilities query and I2C .Firmata.py is licensed under the Apache License, a copy of which is present in the LICENSE file included in this distribution.
google-flatbuffers	Integration	For applications on Google Play that integrate this tool, usage is tracked.This tracking is done automatically using the embedded version string **flatbuffer_version_string** , and helps us continue to optimize it
google-flatbuffers	Integration	Aside fromconsuming a few extra bytes in your application binary, it shouldn't affectyour application at all
google-flatbuffers	Integration	 We use this information to let us know if FlatBuffersis useful and if we should continue to invest in it
google-flatbuffers	Integration	Since this is opensource, you are free to remove the version string but we would appreciate ifyou would leave it in.
google-flatui	Welcome to FlatUI!	FlatUI is a immediate mode C++ GUI library for games and graphical applications.Go to our  landing page    to browse our documentation.FlatUI aims to be a simple, efficient and easy to use way to add menus, HUDs    and any kind of other UI to your game or graphical application,and provide unicode & i18n aware font-rendering.FlatUI can be built for many different systems  Android, Windows, OS X, Linux ,see docs/html/index.html.FlatUI integrates with our other game development libraries, primarily FPLBase   .Discuss FlatUI with other developers and users on the FlatUI Google Group   
google-flatui	Welcome to FlatUI!	File issues on the  FlatUI Issues Tracker   or post your questions to  stackoverflow.com    with a mention of**Important**: FlatUI uses submodules to reference other components it dependsupon so download the source using:~~~**Changes**: Please see  the release notes  ./release_notes.md  for a list of changes.For applications on Google Play that integrate this tool, usage is tracked.This tracking is done automatically using the embedded version string FlatUiVersion , and helps us continue to optimize it
google-flatui	Welcome to FlatUI!	Aside fromconsuming a few extra bytes in your application binary, it shouldn't affectyour application at all
google-flatui	Welcome to FlatUI!	 We use this information to let us know if FlatUIis useful and if we should continue to invest in it
google-flatui	Welcome to FlatUI!	Since this is opensource, you are free to remove the version string but we would appreciate ifyou would leave it in
google-flatui	Welcome to FlatUI!	  FlatUI Issues Tracker :   landing page :   HUDs : 
google-fleetspeak	Fleetspeak	     ! Go Report Card  Fleetspeak is a framework for communicating with a fleet of machines, with afocus on security monitoring and basic administrative use cases
google-fleetspeak	Fleetspeak	 It is asubproject of  GRR  andcan be seen as an effort to modularizing and modernizing its communication
google-fleetspeak	Status	We have this code working internally as part of our GRR installation
google-fleetspeak	Status	Over thenext weeks to months we will be organizing our open source development process,building out installation processes and otherwise preparing for broader externaluse, both as part of GRR and for other uses.
google-fleetspeak	Getting Started	On linux, assuming a recent version of the go development environment  testedwith 1.9, probably requires at least 1.8  and virtualenv, the following sequenceof commands will build and test this pre-release:
google-fleetspeak	Required golang dependencies:	go get \  github.com/go-sql-driver/mysql \  github.com/golang/glog \  github.com/golang/protobuf/proto \  github.com/kolide/osquery-go \  github.com/mattn/go-sqlite3 \  github.com/pires/go-proxyproto \  golang.org/x/sys \  golang.org/x/time/rate \  google.golang.org/grpc
google-fleetspeak	This package:	go get github.com/google/fleetspeak
google-fleetspeak	Assuming default $GOPATH:	cd ~/go/src/github.com/google/fleetspeak
google-fleetspeak	and this ensures they are set up in a known way.	virtualenv venvsource venv/bin/activatepip install -e .
google-fleetspeak	variables are set. Otherwise it will be skipped.	export MYSQL_TEST_USER=export MYSQL_TEST_PASS=   # will assume null password if unset.export MYSQL_TEST_ADDR=
google-fleetspeak	Build and test the release:	source venv/bin/activatecd fleetspeakSTRICT=true ./build.shOnce built, you can take a look at the files and instructions in our demo directory 
google-fleetspeak	DISCLAIMER	While the code presented here is in some sense feature complete, much of it isbarely tested or documented, and breaking changes are still possible.Therefore, please consider this a preview release while the dust settles.Suggestions and pull requests are very much appreciated.
google-flexbox-layout	FlexboxLayout	  ! Circle CI     ! Download   FlexboxLayout is a library project which brings the similar capabilities of CSS Flexible Box Layout Module  to Android.
google-flexbox-layout	Installation	Add the following dependency to your build.gradle file:There are two ways of using Flexbox in your layout
google-flexbox-layout	FlexboxLayout 	The first one is xmlOr from code like:FlexboxLayout flexboxLayout =  FlexboxLayout  findViewById R.id.flexbox_layout ;flexboxLayout.setFlexDirection FlexDirection.ROW ;View view = flexboxLayout.getChildAt 0 ;FlexboxLayout.LayoutParams lp =  FlexboxLayout.LayoutParams  view.getLayoutParams  ;lp.order = -1;lp.flexGrow = 2;view.setLayoutParams lp ;
google-flexbox-layout	FlexboxLayoutManager  within RecyclerView 	The second one is FlexboxLayoutManager that can be used within RecyclerView.for reuse for the views that are appearing as the user scrolls instead of inflating every individual view,which consumes much less memory especially when the number of items contained in the Flexbox container is large.! FlexboxLayoutManager in action  /assets/flexbox-layoutmanager.gif 
google-flexbox-layout	Supported attributes/features comparison	Due to some characteristics of RecyclerView, some Flexbox attributes are not available/not implementedto the FlexboxLayoutManager.Here is a quick overview of the attributes/features comparison between the two implementations.|Attribute / Feature|FlexboxLayout| FlexboxLayoutManager  RecyclerView || ------|flexDirection|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||flexWrap|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png   except wrap_reverse ||justifyContent|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||alignItems|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||alignContent|! Check  /assets/pngs/check_green_small.png | |layout_order|! Check  /assets/pngs/check_green_small.png | |layout_flexGrow|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||layout_flexShrink|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||layout_alignSelf|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||layout_flexBasisPercent|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||layout_ min/max Width|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||layout_ min/max Height|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||layout_wrapBefore|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||Divider|! Check  /assets/pngs/check_green_small.png |! Check  /assets/pngs/check_green_small.png ||View recycling| |Scrolling| *1 |! Check  /assets/pngs/check_green_small.png |*1 Partially possible by wrapping it with ScrollView
google-flexbox-layout	Supported attributes/features comparison	But it isn't likely to work with a large set
google-flexbox-layout	Attributes for the FlexboxLayout:	  spaces between flex lines or flex items, you may see unexpected spaces
google-flexbox-layout	Attributes for the FlexboxLayout:	Please avoid using these  at the same time
google-flexbox-layout	Attributes for the FlexboxLayout:	 xml      xml  <com.google.android.flexbox.FlexboxLayout xmlns:android=""  
google-flexbox-layout	Attributes for the children of a FlexboxLayout	  layout XML
google-flexbox-layout	Attributes for the children of a FlexboxLayout	If not specified, 1 is set as a default value
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 If a flex item has a positive layout_flexGrow value, the item will take up the remaining  space in the flex line
google-flexbox-layout	Attributes for the children of a FlexboxLayout	If multiple flex items in the same flex line have positive layout_flexGrow  values, the remaining free space is distributed depending on the proportion of their declared  layout_flexGrow value
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 Similar to the layout_weight attribute in the LinearLayout   If not specified, 0 is set as a default value
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 If not specified, 1 is set as a default value
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 alignItems in the parent, but if this is set to other than  auto, the cross axis alignment is overridden for this child
google-flexbox-layout	Attributes for the children of a FlexboxLayout	Possible values are:  fraction against the parent main size
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 If this value is set, the length specified from layout_width   or layout_height  is overridden by the calculated value from this attribute
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 This attribute is only effective when the parent's length is definite  MeasureSpec mode is  MeasureSpec.EXACTLY 
google-flexbox-layout	Attributes for the children of a FlexboxLayout	The default value is -1, which means not set
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 flexDirection attribute as to which attribute imposes the size constraint along the  main axis  regardless of the layout_flexShrink attribute
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 flexDirection attribute as to which attribute imposes the size constraint along the  main axis  regardless of the layout_flexGrow attribute
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 flex item, the item will become the first item of a flex line
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 A wrapping happens  regardless of the flex items being processed in the previous flex line   This attribute is ignored if the flex_wrap attribute is set to nowrap
google-flexbox-layout	Attributes for the children of a FlexboxLayout	 The equivalent attribute isn't defined in the original CSS Flexible Box Module  specification, but having this attribute is useful for Android developers
google-flexbox-layout	Attributes for the children of a FlexboxLayout	For example, to flatten  the layouts when building a grid-like layout or for a situation where developers want  to put a new flex line to make a semantic difference from the previous one, etc.
google-flexbox-layout	Known differences from the original CSS specification	This library tries to achieve the same capabilities of the original Flexible Box specification  as much as possible,but due to some reasons such as the way specifying attributes can't be the same betweenCSS and Android XML, there are some known differences from the original specification
google-flexbox-layout	Known differences from the original CSS specification	1  There is no  flex-flow equivalent attribute 2  There is no  flex  equivalent attribute 3  layout_flexBasisPercent is introduced instead of   flexBasis   values such as 1em, 10px, and content as strings as well as percentage values such as  10% and 30%
google-flexbox-layout	Known differences from the original CSS specification	layout_flexBasisPercent only accepts percentage values
google-flexbox-layout	Known differences from the original CSS specification	 However, specifying initial fixed width values can be done by specifying width  or height  values in  layout_width  or layout_height, varies depending on the flexDirection 
google-flexbox-layout	Known differences from the original CSS specification	Also, the same  effect can be done by specifying "wrap_content" in layout_width  or layout_height  if  developers want to achieve the same effect as 'content'
google-flexbox-layout	Known differences from the original CSS specification	Thus, layout_flexBasisPercent only  accepts percentage values, which can't be done through layout_width  or layout_height  for  simplicity
google-flexbox-layout	Known differences from the original CSS specification	4  layout_wrapBefore is introduced
google-flexbox-layout	Known differences from the original CSS specification	 more control over when a wrapping happens.
google-flexbox-layout	Xamarin Binding	Xamarin binding is now available on  NuGet  thanks to  @btripp 
google-flexbox-layout	Flexbox Playground demo app	The 
google-flexbox-layout	Cat gallery demo app	The 
google-flexbox-layout	How to make contributions	Please read and follow the steps in  CONTRIBUTING.md  /CONTRIBUTING.md 
google-flexbox-layout	License	Please see  LICENSE  /LICENSE 
google-flogger	What is it?	Flogger is a  fluent  logging APIfor Java
google-flogger	What is it?	It supports a wide variety of features, and has ** many benefits *Come for more self-documenting log statements:While some users prefer "fluency" as a style, this is not what the argument forFlogger rests on
google-flogger	What is it?	Flogger offers these key, concrete advantages over otherlogging APIs:
google-flogger	Yet another logging API?	The field of open-source Java logging APIs is already extremely crowded, so whyadd another?To paraphrase Douglas Adams "Google's codebase is big
google-flogger	Yet another logging API?	Really big
google-flogger	Yet another logging API?	You justwon’t believe how vastly hugely  mind-bogglinglybig it is"
google-flogger	Yet another logging API?	Inevitably this resulted in many different debug logging APIs being usedthroughout the Java codebase, each with its own benefits and issues
google-flogger	Yet another logging API?	Developerswere forced to switch between APIs as they worked on different projects, anddifferences between APIs caused confusion and bugs.Flogger is the result of an attempt to create a unified logging API, suitablefor the vast majority of Java projects in Google.For something of this magnitude it would have been preferable to use anexisting logging API, rather than creating and maintaining our own
google-flogger	Yet another logging API?	However, theJava Core Libraries Team  i.e
google-flogger	Yet another logging API?	Guava maintainers  concluded that Flogger was notslightly better than the alternatives, but much better.By switching the majority of Java code in Google to use Flogger, many thousandsof bugs have been fixed and the cost to developers of learning new logging APIsas they move through the codebase has been eliminated
google-flogger	Yet another logging API?	Flogger is now the solerecommended Java logging API within Google.
google-flogger	Add the dependencies on Flogger	All code that uses flogger should depend on> Note: the dependency on flogger-system-backend is only required to beincluded when the binary is run
google-flogger	Add the dependencies on Flogger	If you have a modularized build, you caninclude this dependency by the root module that builds your app/binary, and canbe runtime scope.
google-flogger	More information	Flogger was designed and implemented by David Beaumont, with invaluable helpfrom the Java Core Libraries Team and many other Googlers.If you interested in a deeper dive into the rationale behind Flogger's API,please see  Anatomy of an API  anatomy 
google-flogger	More information	backend :  effectively free :  extensibility :  FluentLogger :  many benefits :  performance :  readability : 
google-flutter-data	REPLACE_ME	A library for Flutter developers
google-flutter-data	REPLACE_ME	It is awesome.
google-flutter-data	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-flutter-data	Features and bugs	tracker : 
google-flutter-desktop-embedding	Desktop Embedding for Flutter	This purpose of this project is to support buildingapplications that use  Flutter on Windows, macOS, and Linux.It consists of libraries that implement  Flutter's embeddingAPI handling drawing and mouse/keyboard input, as well asoptional plugins to access other native platform functionality.
google-flutter-desktop-embedding	Setting Up	The tooling and build infrastructure for this project requires that you havea Flutter tree in the same parent directory as the clone of this project:containing flutter-desktop-embedding, containing a path to the Flutter tree touse, if you prefer not to have the Flutter tree next to
google-flutter-desktop-embedding	Repository Structure	Each supported platform has a top-level directory named for the platform.Within that directory is a library directory containing the core embeddinglibrary, and an example directory containing an example application using it.See the README file in the directory corresponding to your platform for moreIn addition, there is:  plugins  See the   README  plugins/README.md  for details
google-flutter-desktop-embedding	Repository Structure	 some functionality similar to the flutter tool may be added.
google-flutter-desktop-embedding	Flutter Application Requirements	Because desktop platforms are not supported Flutter targets, existing Flutterapplications are likely to require slight modifications to run.
google-flutter-desktop-embedding	Target Platform Override	Most applications will need to override the target platform for the applicationto one of the supported values in order to avoid 'Unknown platform' exceptions.This should be done as early as possible.In the simplest case, where the code will only run on desktop and the behaviorshould be consistent on all platforms, you can hard-code a single target:import 'package:flutter/foundation.dart' ..
google-flutter-desktop-embedding	Target Platform Override	void main   {  debugDefaultTargetPlatformOverride = TargetPlatform.fuchsia;   ..
google-flutter-desktop-embedding	Target Platform Override	If the code needs to run on both mobile and desktop, or you want differentbehavior on different desktop platforms, you can conditionalize on Platform.For example, the line in main   above could be replaced with a call to:appearance of the widgets, but also the expectations Flutter will have forwhat is available on the platform, such as fonts.
google-flutter-desktop-embedding	Fonts	Flutter applications may default to fonts that are standard for the targetplatform, but unavailable on desktop
google-flutter-desktop-embedding	Fonts	For instance, if the target platform isTargetPlatform.iOS the Material library will default to San Francisco, whichis available on macOS but not Linux or Windows.Most applications will need to set the font  e.g., via ThemeData  basedon the host platform, or set a specific font that is bundled with theapplication
google-flutter-desktop-embedding	Fonts	The example application demonstrates using and bundling Robotoon all platforms.Symptoms of missing fonts can include text failing to display, console loggingabout failure to load fonts, or in some cases crashes.
google-flutter-desktop-embedding	Feedback and Discussion	For bug reports and specific feature requests, you can file GitHub issues
google-flutter-desktop-embedding	Feedback and Discussion	Forgeneral discussion and questions there's a  project mailinglist When submitting issues related to build errors or other bugs, please make sureto include the git hash of the Flutter checkout you are using
google-flutter-desktop-embedding	Feedback and Discussion	This will helpspeed up the debugging process.
google-flutter-desktop-embedding	Caveats	  for Flutter's official stance on desktop development
google-flutter-desktop-embedding	Caveats	 is very different from the Flutter model, where the native application  projects are created automatically
google-flutter-desktop-embedding	Caveats	This may change in the future, but for now  there is no equivalent to flutter create
google-flutter-desktop-embedding	Caveats	 and event processing
google-flutter-desktop-embedding	Caveats	If the feature you need isn't there, file a feature  request, or  write a plugin  plugins/README.md#writing-your-own-plugins !
google-flutter.plugins	Flutter plugins	  This repository contains the source code for Flutter plugins that aredeveloped by Google but not by the core Flutter team.Check the packages directory for all plugins.Flutter plugins enable access to platform-specific APIs
google-flutter.plugins	Flutter plugins	For more informationabout plugins, and how to use them, see  These plugins are also available on pub 
google-flutter.plugins	Issues	Please file any issues, bugs, or feature requests in the  thisrepo 
google-flutter.plugins	Contributing	If you wish to contribute a new plugin, please see the documentation for developing packages  and platform channels  Once your pluginis ready you can  publish to the  pub repository If you wish to contribute a change to any of the existing plugins in this repo,please review our  contribution guide and send a  pull request 
google-flutter.widgets	Flutter widgets	  This repository contains the source code for various Flutter widgets that aredeveloped by Google but not by the core Flutter team.
google-flutter.widgets	Issues	Please file any issues, bugs, or feature requests in the  thisrepo 
google-flutter.widgets	Contributing	If you wish to contribute a change to any of the existing widgets in this repo,please review our  contribution guide and send a  pull request 
google-flutter_flux	flutter_flux	> A Dart app architecture library with uni-directional data flow inspired by  RefluxJS  and Facebook's  Flux This is an experimental package and does not have official support from theFlutter team
google-flutter_flux	flutter_flux	However, feedback is most welcome!
google-flutter_flux	Overview	! flux-diagram flutter_flux implements a uni-directional data flow pattern comprised of Actions, Stores, and StoreWatchers.It is based on  w_flux  but modified to use Flutter instead of React.
google-flutter_flux	Action	An Action is a command that can be dispatched  with an optional data payload  and listened to.In flutter_flux, Actions are the sole driver of application state change
google-flutter_flux	Action	Widgets and other objects dispatch Actions in response to user interaction with the rendered view
google-flutter_flux	Action	Stores listen for these Action dispatches and mutate their internal data inresponse, taking the Action payload into account as appropriate.import 'package:flutter_flux/flutter_flux.dart';// define an actionfinal Action displayString = new Action  ;// dispatch the action with a payloaddisplayString 'somePayload' ;// listen for action dispatchesdisplayString.listen _displayAlert ;_displayAlert String payload  {  print payload ;They return a Future that completes after all registered Action listeners complete
google-flutter_flux	Action	 It's NOT generally recommended touse this feature within normal app code, but it is quite useful in unit test code.
google-flutter_flux	Store	A Store is a repository and manager of app state
google-flutter_flux	Store	The base Store class provided by flutter_flux should be extended to fitthe needs of your app and its data
google-flutter_flux	Store	App state may be spread across many independent stores depending on the complexityof the app and your desired app architecture.By convention, a Store's internal data cannot be mutated directly
google-flutter_flux	Store	Instead, Store data is mutated internally inresponse to Action dispatches
google-flutter_flux	Store	Stores should otherwise be considered read-only, publicly exposing relevant data ONLYvia getter methods
google-flutter_flux	Store	 This limited data access ensures that the integrity of the uni-directional data flow is maintained.A StoreWatchers listen to Stores, typically triggering re-rendering of UI elements based on the updated Store data.import 'package:flutter_flux/flutter_flux.dart';class RandomColorStore extends Store {  String _backgroundColor = 'gray';  String get backgroundColor => _backgroundColor;  RandomColorActions _actions;  }  }// verbose syntaxactions.incrementCounter.listen _handleAction ;_handleAction payload  {  }// equivalent terse syntaxtriggerOnAction actions.incrementCounter,  payload  => counter += payload ;
google-flutter_flux	Examples	Simple examples of flutter_flux usage can be found in the example directory
google-flutter_flux	Examples	The example  README  example/README.md includes instructions for building / running them.
google-flutter_flux	External Consumption	flutter_flux implements a uni-directional data flow within an isolated application or code module
google-flutter_flux	External Consumption	If flutter_flux is used as theinternal architecture of a library, this internal data flow should be considered when defining the external API.
google-font-go	font-go	This is a port of  to the Go programmingThere are two implementations, using fixed and floating point math
google-font-go	font-go	The fixedpoint implementation benchmarks 1.3 to 1.4 times faster on GOARCH=amd64, butmay have rendering artifacts above 1024 ppem
google-font-go	font-go	It uses mostly int32 math,although some int64 and float32 math is used for numerical accuracy.You can visually inspect rasterization by running:To run the benchmarks with and without SIMD assembler:The main author is Nigel Tao.
google-font-go	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-font-go	Contributions	Please see CONTRIBUTIONS.md for more
google-font-go	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-font-rs	font-rs	This is a font renderer written  mostly  in pure, safe Rust
google-font-rs	font-rs	There is an optionalSIMD module for cumulative sum, currently written in C SSE3 intrinsics.The current state of the code is quite rough
google-font-rs	font-rs	The code isn't well organized,and it's basically not ready for prime time
google-font-rs	font-rs	However, it runs well enough torun benchmarks, and those benchmarks suggest extremely promising performancecompared with Freetype and freetype-go  the loose port of Freetype to Go .The rasterizer is basically very similar in design to libart  except thatvectors are drawn immediately into the buffer, rather than sorted and storedin intermediate form, and that the buffer for rasterization is a dense arrayrather than a sparse data structure
google-font-rs	font-rs	The main motivation for the latter is toavoid branch misprediction and to better exploit data parallelism, both validtrends in optimization since libart was originally written.It's worth comparing the algorithm with that in Anti-Grain Geometry The original libart algorithm was also inspiration for the current antialiasedrenderer in Freetype
google-font-rs	font-rs	All these renderers share many common features,particularly computation of exact subpixel areas and an integration stepto determine winding number  and convert to pixel value , but differ in detailssuch as data structures to represent the vectors and the buffer.The parsing of TrueType glyph data is done in pull-parser style, as iteratorsover the lower-level data
google-font-rs	font-rs	This technique basically avoids allocating anymemory for representation of points and quadratic Beziers.
google-font-rs	Authors	The main author is Raph Levien.
google-font-rs	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-font-rs	Contributions	Please see CONTRIBUTIONS.md formore details.
google-font-rs	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.
google-fonts	Google Fonts Files	This project contains the binary font files served by Google Fonts: The top level directories indicate the license of all files found within them.Subdirectories are named according to the family name of the fonts within
google-fonts	Google Fonts Files	Each family subdirectory contains the  .ttf font files served by Google Fonts, plus a METADATA.pb file with metadata for the family, and a DESCRIPTION.en_us.html with a description of the family in US English.Also,  /designers  designers  contains a list of the Google+ pages for the fonts' designers.
google-fonts	Bug reports and improvement requests	If you find a problem with a font file or have a request for future development of a font project, please  create a new issue in this project's issue tracker 
google-fonts	Self Host Fonts Available From Google Fonts	Since all the fonts available here are licensed with permission to redistribute, subject to the license terms, you can self-host.For help doing this, see <>
google-fonts	Download All Google Fonts	You can download all Google Fonts in a simple ZIP snapshot  over 300MB  from <>
google-fonts	Sync With Git	You can also sync the collection with git so that you can update by only fetching what has changed.To learn how to use git, Github provides  illustrated guides  and a  youtube channel  and a  learning game that takes just 15 minutes  Free, open source git applications are available for  Windows  and  Mac OS X 
google-fonts	Licensing	It is important to always read the license for every font that you use.Each font family directory contains the appropriate license file for the fonts in that directory
google-fonts	Licensing	The fonts files themselves also contain licensing and authorship metadata.Most of the fonts in the collection use the SIL Open Font License, v1.Some fonts use the Apache 2 license
google-fonts	Licensing	The Ubuntu fonts use the Ubuntu Font License v1.The SIL Open Font License has an option for copyright holders to include a Reserved Font Name requirement, and this option is used with some of the fonts
google-fonts	Licensing	If you modify those fonts, please take care of this important detail.
google-fonts	Source Files	Source files for each family are often available from the designer, or fromWhen customizing or remixing fonts, please do contact the designers to understand what they might need in order to include your improvements.Most of all: Enjoy the fonts!– The Google Fonts team, 2015-06-18
google-fpc	Fixed-point Calculator	This program takes a range  min, max  and precision and calculates constants and information to be used in code performing calculations in this range using fixed-point integer math.This is not an official Google product.
google-fpc	Also, check this out:	fpc has an expression evaluator built in to allow simple expressions!
google-fplbase	Welcome to FPLBase!	FPLBase is a low level rendering / input / asset management cross-platform C++library
google-fplbase	Welcome to FPLBase!	Go to our  landing page    to browse our documentation.FPLBase aims to take the grunt work out of getting games or graphicalapplications up and running.FPLBase can be built for many different systems  Android, Windows, OS X, Linux, iOS ,see docs/html/index.html.Discuss FPLBase with other developers and users on the FPLBase Google Group   
google-fplbase	Welcome to FPLBase!	File issues on the  FPLBase Issues Tracker   or post your questions to  stackoverflow.com    with a mention ofFor applications on Google Play that integrate this tool, usage is tracked.This tracking is done automatically using the embedded version string FplBaseVersion , and helps us continue to optimize it
google-fplbase	Welcome to FPLBase!	Aside fromconsuming a few extra bytes in your application binary, it shouldn't affectyour application at all
google-fplbase	Welcome to FPLBase!	 We use this information to let us know if FPLBaseis useful and if we should continue to invest in it
google-fplbase	Welcome to FPLBase!	Since this is opensource, you are free to remove the version string but we would appreciate ifyou would leave it in
google-fplbase	Welcome to FPLBase!	  FPLBase Issues Tracker :   landing page : 
google-fplutil	fplutil	fplutil is a set of small libraries and tools that can be useful whendeveloping applications for Android and other platforms.Goto fplutil's  landing page    for documentation.**Important**: fplutil uses submodules to reference other components it dependsupon so to download the source use:To contribute to this project see  CONTRIBUTING   .For applications on Google Play that integrate these libraries, usage istracked
google-fplutil	fplutil	 This tracking is done automatically using the embedded version string kFplUtilVersionString 
google-fplutil	fplutil	Aside from consuming a few extra bytes in yourapplication binary, it shouldn't affect your application at all
google-fplutil	fplutil	We use thisinformation to let us know if fplutil libraries are useful and if we shouldcontinue to invest in them
google-fplutil	fplutil	Since this is open source, you are free to removethe version string but we would appreciate if you would leave it in
google-fplutil	fplutil	  Linux :   fplutil Google Group :   stackoverflow.com :   Hello World :
google-freebase-wikidata-converter	Wikidata related tools	They are in the wikidata directory.
google-freebase-wikidata-converter	Convert Wikidata JSON dump into TSV	Download  latest Wikidata JSON dump There are two TSV creation scripts:Run hhvm tsv-property-stat.php FILE.tsv
google-freebase-wikidata-converter	Mapping between Freebase topic and Wikidata items tools	They are in the mapping directory.
google-freebase-wikidata-converter	from Wikidata TSV file	Run python wikidata2pairs.py WIKIDATA_TSV_FILE.tsv MAPPING_FILE.pairs
google-freebase-wikidata-converter	from Samsung mapping	Download  latest Samsung mapping Run python samsung2pairs.py SAMSUNG_MAPPING.nt MAPPING_FILE.pairs
google-freebase-wikidata-converter	doing reconciliation based on shared ids	Creates a mapping based on Freebase keys and Wikidata external ids.Run hhvm freebase-wikidata-reconciliation-keys.php WIKIDATA_TSV_FILE FREEBASE_FACTS.nt MAPPING_FILE.pairs
google-freebase-wikidata-converter	Main conversion tools	They are in the convert directory.
google-freebase-wikidata-converter	Split Freebase dump	Create smaller dumps from the big freebase dumpDownload  the latest freebase dump Execute python explode-dump.py freebase-rdf-latest.gz FITERED_FACTS_FILE.nt TYPES_FILE.tsv LABELS_FILE.tsvYou could replace some of the output files by /dev/null if you do not care about them.
google-freebase-wikidata-converter	Main conversion script	Create Wikidata statement from Freebase dump.Warning running this script requires a lot of RAM  something like 20GB with HHVM .It has some dependences managed using  Composer To install them do the usual curl -sS  | php then hhvm composer.phar install.Run hhvm convert.php FILTERED_FACTS_FILE.nt REFERENCES_FILE.tsv MAPPINGS_DIRECTORY OUTPUT_DIRECTORYThis scripts creates in the output directory:It use as mapping between Freebase topics and Wikidata items all the .pairs files contained in the MAPPINGS_DIRECTORY
google-freebase-wikidata-converter	Main conversion script	It use them in alphabetic order and, when there is a conflict, overrides the mapping
google-freebase-wikidata-converter	Main conversion script	So, you should order your mappings by increasing quality.If the mapping directory contains a file wikidata-redirects.tsv in the format FROM_QID\tTARGET_QID\n it is used to resolve Wikidata redirections.The references file is not released
google-freebase-wikidata-converter	Main conversion script	To run the script without it, just replace it with /dev/null.To create 
google-freebase-wikidata-converter	Filter statements	Allows to filter TSV files
google-freebase-wikidata-converter	Filter statements	Example of use case: filter statements already in Wikidata.This script also removes duplicate statements.Run python filter.py STATEMENTS.tsv STATEMENTS_TO_FILTER.nt STATEMENT_AFTER_FILTER.nt STATEMENT_FILTERED.nt
google-freebase-wikidata-converter	Missing labels	Creates labels from Freebase when they are missing in Wikidata
google-freebase-wikidata-converter	Missing labels	For details of the conversion of the language codes, see the source code
google-freebase-wikidata-converter	Missing labels	It uses the mapping directory in the same way as convert.php.Run hhvm labels.php WIKIDATA_DUMP.json FREEBASE_LABELS_FILE.tsv MAPPINGS_DIRECTORY OUTPUT_DIRECTORYThis scripts creates in the output directory:Compares Wikidata and Freebase content in order to suggest additional mapping between Freebase and Wikidata properties
google-freebase-wikidata-converter	Missing labels	Only works for properties which domain is topic and range is topic or string
google-freebase-wikidata-converter	Missing labels	It uses the mapping directory in the same way as convert.php.Run hhvm properties-statistical-mapping.php WIKIDATA_TSV.tsv FREEBASE_FACTS_FILE.nt MAPPINGS_DIRECTORY OUTPUT_CSV_FILE.csv
google-freebase-wikidata-converter	Import statement	Small very hacky script to import TSV encoded statement into Wikidata
google-freebase-wikidata-converter	Import statement	Warning: contains some Freebase specific code!Run python import-statements.py MY_TSV_FILE.tsv
google-fscrypt	fscrypt  ! GitHub version  	     ! GoDoc   ! Go Report Card   ! License  fscrypt is a high-level tool for the management of Linux filesystem encryption This tool manages metadata, key generation, key wrapping, PAM integration, andprovides a uniform interface for creating and modifying encrypted directories.For a small low-level tool that directly sets policies, see fscryptctl To use fscrypt, you must have a filesystem with encryption enabled and akernel that supports reading/writing from that filesystem
google-fscrypt	fscrypt  ! GitHub version  	Currently, ext4  F2FS  and UBIFS  support Linux filesystemencryption
google-fscrypt	fscrypt  ! GitHub version  	Ext4 has supported Linux filesystem encryption since v4.1  F2FS added support in v4.2  and UBIFS added support in v4.10  Other filesystemsmay add support for native encryption in the future
google-fscrypt	fscrypt  ! GitHub version  	Filesystems mayadditionally require certain kernel configuration options to be set to usenative encryption.Most of the testing for fscrypt has been done with ext4 filesystems
google-fscrypt	fscrypt  ! GitHub version  	However,the kernel uses a common userspace interface, so this tool should work with allexisting and future filesystems which support encryption
google-fscrypt	fscrypt  ! GitHub version  	If there is a problemusing fscrypt with other filesystems, please open an issue.
google-fscrypt	Other encryption solutions	It is important to distinguish Linux filesystem encryption from two otherencryption solutions:  eCryptfs  and dm-crypt Currently, dm-crypt encrypts an entire block device with a single master key.dm-crypt can be used with or without fscrypt
google-fscrypt	Other encryption solutions	All filesystem data  including allfilesystem metadata  is encrypted with this single key when using dm-crypt,while fscrypt only encrypts the filenames and file contents in a specifieddirectory
google-fscrypt	Other encryption solutions	Note that using both dm-crypt and fscrypt simultaneously will givethe protections and benefits of both; however, this may cause a decrease inyour performance, as file contents are encrypted twice.One example of a reasonable setup could involve using dm-crypt with a TPM orSecure boot key, while using fscrypt for the contents of a home directory
google-fscrypt	Other encryption solutions	Thiswould still encrypt the entire drive, but would also tie the encryption of auser's personal documents to their passphrase.On the other hand, eCryptfs is another form of filesystem encryption on Linux;it encrypts a filesystem directory with some key or passphrase
google-fscrypt	Other encryption solutions	eCryptfs sits ontop of an existing filesystem
google-fscrypt	Other encryption solutions	This makes eCryptfs an alternative choice if yourfilesystem or kernel does not support native filesystem encryption.Also note that fscrypt does not support or setup either eCryptfs or dm-crypt.For these tools, use ecryptfs-utils  foreCryptfs or  cryptsetup  for dm-crypt.
google-fscrypt	Features	fscrypt is intended to improve upon the work in e4crypt  by providing amore managed environment and handling more functionality in thebackground
google-fscrypt	Features	fscrypt has a  design document  specifyingthe full architecture of fscrypt.Briefly, fscrypt deals with protectors and policies
google-fscrypt	Features	Protectors represent somesecret or information used to protect the confidentiality of your data
google-fscrypt	Features	Thethree currently supported protector types are:Your login passphrase, through  PAM A custom passphraseA raw key fileThese protectors are mutable, so the information can change without needing toupdate any of your encrypted directories.Policies represent the actual key passed to the kernel
google-fscrypt	Features	This "policy key" isimmutable and policies are  usually  applied to a single directory
google-fscrypt	Features	Protectorsthen protect policies, so that having one of the protectors for a policy isenough to get the policy key and access the data
google-fscrypt	Features	Which protectors protect apolicy can also be changed
google-fscrypt	Features	This allows a user to change how a directory isprotected without needing to reencrypt the directory's contents.Concretely, fscrypt contains the following functionality:information about each of the commands.
google-fscrypt	Building and Installing	fscrypt has a minimal set of build dependencies:Once all the dependencies are installed, you can get the repository by running:Running make in $GOPATH/src/github.com/google/fscrypt builds theexecutable  fscrypt  and PAM module  pam-fscrypt.so  in the bin/directory
google-fscrypt	Building and Installing	Use make bin/fscrypt or make bin/pam_fscrypt.soto build only one.Running pam-fscrypt to /lib/security
google-fscrypt	Building and Installing	Use make install-bin or make install-pamto install only one.See the Makefile for instructions on how to customize the build  e.g
google-fscrypt	Building and Installing	installingto a custom location, using different build flags, building a static binary,etc ..
google-fscrypt	Building and Installing	Alternatively, if you only want to install the fscrypt binary to 
google-fscrypt	Runtime Dependencies	fscrypt has very few runtime dependencies:
google-fscrypt	Setting up the PAM module	Note that to make use of the installed PAM module, your PAM configuration files in /etc/pam.d must be modified to add fscrypt.
google-fscrypt	Automatic setup on Ubuntu	fscrypt automatically installs the PAM config file pam_fscrypt/config to /usr/share/pam-configs/fscrypt
google-fscrypt	Automatic setup on Ubuntu	This file containsreasonable defaults for the PAM module
google-fscrypt	Automatic setup on Ubuntu	To automatically apply these changes,run sudo pam-auth-update and follow the on-screen instructions.
google-fscrypt	Manual setup	The fscrypt PAM module implements the Auth, Session, and Password types The Password functionality of after pam_unix.so in /etc/pam.d/common-password or similar.The Auth and Session functionality of lock_policies option locks the directories protected with the user's loginpassphrase when the last session ends
google-fscrypt	Manual setup	The drop_caches option tells fscrypt toclear the filesystem caches when the last session closes, ensuring all thelocked data is inaccessible
google-fscrypt	Manual setup	All the types also support the debug option whichprints additional debug information to the syslog.
google-fscrypt	Note about stability	fscrypt follows  semantic versioning  As such, all versionsbelow 1.0.0 should be considered development versions
google-fscrypt	Note about stability	This means noguarantees are make about the stability of APIs or formats of config files
google-fscrypt	Note about stability	Asthe on-disk metadata structures use Protocol Buffers  we don't expect to breakbackwards compatibility for metadata, but we give no guarantees.
google-fscrypt	Example Usage	All these examples assume we have ext4 filesystems mounted at /mnt/disk which both support encryption and that /mnt/disk containsdirectories we want to encrypt.
google-fscrypt	Check which directories on our system support encryption	>>>>> fscrypt status2 filesystem s  on this system support encryption/
google-fscrypt	Create the global configuration file. Nothing else needs root.	>>>>> sudo fscrypt setupCreate "/etc/fscrypt.conf"?  Y/n  yCustomizing passphrase hashing difficulty for this system...Created global config file at "/etc/fscrypt.conf".
google-fscrypt	Start using fscrypt with our filesystem	>>>>> fscrypt setup /mnt/diskMetadata directories created at "/mnt/disk/.fscrypt".Filesystem "/mnt/disk"  /dev/sdb  ready for use with ext4 encryption.
google-fscrypt	Initialize encryption on a new empty directory	>>>>> mkdir /mnt/disk/dir1>>>>> fscrypt encrypt /mnt/disk/dir1Should we create a new protector?  Y/n  yYour data can be protected with one of the following sources:1 2 3 Enter the source number for the new protector  2 Enter a name for the new protector: Super SecretEnter custom passphrase for protector "Super Secret":Confirm passphrase:"/mnt/disk/dir1" is now encrypted, unlocked, and ready for use.
google-fscrypt	We can see this created one policy and one protector for this directory	>>>>> fscrypt status /mnt/diskext4 filesystem "/mnt/disk" has 1 protector s  and 1 policy ies 7626382168311a9d  No7626382168311a9d  Yes
google-fscrypt	Locking and unlocking a directory	As noted in the troubleshooting below, we  as of now  have to unmount afilesystem after purging its keys to clear the necessary caches.
google-fscrypt	Write a file to our encrypted directory.	>>>>> echo "Hello World" > /mnt/disk/dir1/secret.txt>>>>> fscrypt status /mnt/disk/dir1"/mnt/disk/dir1" is encrypted with fscrypt.Policy:   16382f282d7b29eeUnlocked: YesProtected with 1 protector s :7626382168311a9d  No
google-fscrypt	Purging, unmounting, and remounting a filesystem locks all the files.	>>>>> fscrypt purge /mnt/diskWARNING: This may make data encrypted with fscrypt inaccessible.Purge all policy keys from "/mnt/disk"  this will lock all encrypted directories   y/N  yAll keys purged for "/mnt/disk".Filesystem "/mnt/disk" should now be unmounted.>>>>> umount /mnt/disk>>>>> mount /mnt/disk>>>>> fscrypt status /mnt/disk/dir1"/mnt/disk/dir1" is encrypted with fscrypt.Policy:   16382f282d7b29eeUnlocked: NoProtected with 1 protector s :7626382168311a9d  No
google-fscrypt	Now the filenames and file contents are inaccessible	>>>>> ls /mnt/disk/dir1>>>>> cat /mnt/disk/dir1/u,k20l9HrtrizDjh0zGkw2dTfBkX4T0ZDUlsOhBLl4Pcat: /mnt/disk/dir1/u,k20l9HrtrizDjh0zGkw2dTfBkX4T0ZDUlsOhBLl4P: Required key not available
google-fscrypt	Unlocking the directory makes the contents available	>>>>> fscrypt unlock /mnt/disk/dir1Enter custom passphrase for protector "Super Secret":"/mnt/disk/dir1" is now unlocked and ready for use.>>>>> fscrypt status /mnt/disk/dir1"/mnt/disk/dir1" is encrypted with fscrypt.Policy:   16382f282d7b29eeUnlocked: YesProtected with 1 protector s :7626382168311a9d  No>>>>> cat /mnt/disk/dir1/secret.txtHello World
google-fscrypt	Protecting a directory with your login passphrase	As noted above and in the troubleshooting below, fscrypt cannot  yet  detectwhen your login passphrase changes
google-fscrypt	Protecting a directory with your login passphrase	So if you protect a directory with yourlogin passphrase, you may have to do additional work when you change your system
google-fscrypt	Login passphrases also require that fscrypt is setup on the root directory	>>>>> sudo fscrypt setup /Filesystem "/"  /dev/dm-1  ready for use with ext4 encryption.
google-fscrypt	Select your login passphrase as the desired source.	>>>>> mkdir /mnt/disk/dir2>>>>> fscrypt encrypt /mnt/disk/dir2Should we create a new protector?  Y/n  yYour data can be protected with one of the following sources:1 2 3 Enter the source number for the new protector  2 Enter login passphrase for joerichey:"/mnt/disk/dir2" is now encrypted, unlocked, and ready for use.
google-fscrypt	Note that the login protector actually sits on the root filesystem	>>>>> fscrypt status /mnt/disk/dir2"/mnt/disk/dir2" is encrypted with fscrypt.Policy:   fe1c92009abc1cffUnlocked: YesProtected with 1 protector s :6891f0a901f0065e  Yes  /   login protector for joerichey>>>>> fscrypt status /mnt/diskext4 filesystem "/mnt/disk" has 3 protector s  and 3 policy ies 7626382168311a9d  No6891f0a901f0065e  Yes  /   login protector for joerichey16382f282d7b29ee  Yesfe1c92009abc1cff  Yes>>>>> fscrypt status /ext4 filesystem "/" has 1 protector s  and 0 policy ies 6891f0a901f0065e  No
google-fscrypt	First we have to figure out which protector we wish to change.	>>>>> fscrypt status /mnt/disk/dir1"/mnt/disk/dir1" is encrypted with fscrypt.Policy:   16382f282d7b29eeUnlocked: YesProtected with 1 protector s :7626382168311a9d  No
google-fscrypt	Now specify the protector directly to the metadata command	>>>>> fscrypt metadata change-passphrase --protector=/mnt/disk:7626382168311a9dEnter old custom passphrase for protector "Super Secret":Enter new custom passphrase for protector "Super Secret":Confirm passphrase:Passphrase for protector 7626382168311a9d successfully changed.
google-fscrypt	Using a raw key protector	fscrypt also supports protectors which use raw key files as the user-providedsecret
google-fscrypt	Using a raw key protector	These key files must be exactly 32 bytes long and contain the raw binarydata of the key
google-fscrypt	Using a raw key protector	Obviously, make sure to store the key file securely  and not inthe directory you are encrypting with it 
google-fscrypt	Using a raw key protector	If generating the keys on Linux makesure you are aware of how randomness works  and some common myths 
google-fscrypt	Generate a 256-bit key file	>>>>> head --bytes=32 /dev/urandom > secret.key
google-fscrypt	could also use fscrypt encrypt --key=secret.key to achieve the same thing.	>>>>> fscrypt metadata create protector /mnt/diskCreate new protector on "/mnt/disk"  Y/n  yYour data can be protected with one of the following sources:1 2 3 Enter the source number for the new protector  2 Enter a name for the new protector: SkeletonEnter key file for protector "Skeleton": secret.keyProtector 2c75f519b9c9959d created on filesystem "/mnt/disk".>>>>> fscrypt status /mnt/diskext4 filesystem "/mnt/disk" has 3 protectors and 3 policies7626382168311a9d  No2c75f519b9c9959d  No6891f0a901f0065e  Yes  /   login protector for joerichey16382f282d7b29ee  Yesfe1c92009abc1cff  Yes
google-fscrypt	Finally, we could apply this key to a directory	>>>>> mkdir /mnt/disk/dir3>>>>> fscrypt encrypt /mnt/disk/dir3 --protector=/mnt/disk:2c75f519b9c9959dEnter key file for protector "Skeleton": secret.key"/mnt/disk/dir3" is now encrypted, unlocked, and ready for use.
google-fscrypt	Using multiple protectors for a policy	fscrypt supports the idea of of protecting a single directory with multipleprotectors
google-fscrypt	Using multiple protectors for a policy	This means having access to any of the protectors is sufficient todecrypt the directory
google-fscrypt	Using multiple protectors for a policy	This is useful for sharing data or setting up accesscontrol systems.
google-fscrypt	Add an existing protector to the policy for some directory	>>>>> fscrypt status /mnt/diskext4 filesystem "/mnt/disk" has 3 protectors and 3 policies7626382168311a9d  No2c75f519b9c9959d  No6891f0a901f0065e  Yes  /   login protector for joericheyd03fb894584a4318  No16382f282d7b29ee  Nofe1c92009abc1cff  No>>>>> fscrypt status /mnt/disk/dir1"/mnt/disk/dir1" is encrypted with fscrypt.Policy:   16382f282d7b29eeUnlocked: NoProtected with 1 protector:7626382168311a9d  No>>>>> fscrypt metadata add-protector-to-policy --protector=/mnt/disk:2c75f519b9c9959d --policy=/mnt/disk:16382f282d7b29eeWARNING: All files using this policy will be accessible with this protector!!Protect policy 16382f282d7b29ee with protector 2c75f519b9c9959d?  Y/n Enter key file for protector "Skeleton": secret.keyEnter custom passphrase for protector "Super Secret":Protector 2c75f519b9c9959d now protecting policy 16382f282d7b29ee.>>>>> fscrypt status /mnt/disk/dir1"/mnt/disk/dir1" is encrypted with fscrypt.Policy:   16382f282d7b29eeUnlocked: NoProtected with 2 protectors:7626382168311a9d  No2c75f519b9c9959d  No
google-fscrypt	Now the unlock command will prompt for which protector we want to use	>>>>> fscrypt unlock /mnt/disk/dir1The available protectors are:0 1 Enter the number of protector to use: 1Enter key file for protector "Skeleton": secret.key"/mnt/disk/dir1" is now unlocked and ready for use.
google-fscrypt	The protector can also be removed from the policy  if it is not the only one 	>>>>> fscrypt metadata remove-protector-from-policy --protector=/mnt/disk:2c75f519b9c9959d --policy=/mnt/disk:16382f282d7b29eeWARNING: All files using this policy will NO LONGER be accessible with this protector!!Stop protecting policy 16382f282d7b29ee with protector 2c75f519b9c9959d?  y/N  yProtector 2c75f519b9c9959d no longer protecting policy 16382f282d7b29ee.
google-fscrypt	Contributing	We would love to accept your contributions to fscrypt
google-fscrypt	Contributing	See the CONTRIBUTING.mdfile for more information about signing the CLA and submitting a pull request.
google-fscrypt	Troubleshooting	In general, if you are encountering issues with fscrypt, open an issue  following theguidelines in CONTRIBUTING.md
google-fscrypt	Troubleshooting	We will try our best to help.
google-fscrypt	I changed my login passphrase, now all my directories are inaccessible	The PAM module provided by fscrypt  pam_fscrypt.so  should automaticallydetect changes to a user's login passphrase so that they can still access theirencrypted directories
google-fscrypt	I changed my login passphrase, now all my directories are inaccessible	However, sometimes the login passphrase can becomedesynchronized from a user's login protector
google-fscrypt	I changed my login passphrase, now all my directories are inaccessible	This usually happens when the PAMpassphrase is managed by an external system, if the PAM module is not installed,or if the PAM module is not properly configured.To fix your login protector, you first should find the appropriate protector IDby running 
google-fscrypt	Directories using my login passphrase are not automatically unlocking.	Either the PAM module is not installed correctly, or your login passphrasechanged and things got out of sync
google-fscrypt	Directories using my login passphrase are not automatically unlocking.	Another reason that these directories mightnot unlock is if your session starts without password authentication
google-fscrypt	Directories using my login passphrase are not automatically unlocking.	The mostcommon case of this is public-key ssh login.To trigger a password authentication event, run su $ whoami  -c exit.
google-fscrypt	Getting "encryption not enabled" on an ext4 filesystem.	Getting this error on an ext4 system usually means the filesystem has not beensetup for encryption
google-fscrypt	Getting "encryption not enabled" on an ext4 filesystem.	The only other way to get this error is if filesystemencryption has been explictly disabled in the kernel config.__IMPORTANT:__ Before enabling encryption on an ext4 filesystem __ALL__ of thefollowing should be true:To turn on encryption for your filesystem, runHowever, it requires GRUB 2.02  __NOT__ the 2.02 beta  to be installed as thebootloader
google-fscrypt	Getting "encryption not enabled" on an ext4 filesystem.	As this version was released in April 2017, most systems __WILLFAIL TO BOOT__ with an ext4 encrypted boot directory
google-fscrypt	Getting "encryption not enabled" on an ext4 filesystem.	Note that this is onlyrelevant to systems without a seperate boot partition
google-fscrypt	Getting "encryption not enabled" on an ext4 filesystem.	Sytems with /boot ona different partition than the one being encrypted  including all UEFI systems are not effected by this.
google-fscrypt	Legal	Copyright 2017 Google Inc
google-fscrypt	Legal	under the Apache 2.0 License  see theLICENSE file for more information.Author: Joe Richey This is not an official Google product.
google-fscryptctl	fscryptctl	fscryptctl is a low-level tool written in C that handles raw keys and managespolicies for  Linux filesystem encryption  Fora tool that presents a higher level interface and manages metadata, keygeneration, key wrapping, PAM integration, and passphrase hashing, see fscrypt To use fscryptctl, you must have a filesystem with encryption enabled and akernel that supports reading/writing from that filesystem
google-fscryptctl	fscryptctl	Currently, ext4  F2FS  and UBIFS  support Linux filesystemencryption
google-fscryptctl	fscryptctl	Ext4 has supported Linux filesystem encryption since v4.1  F2FS added support in v4.2  and UBIFS added support in v4.10  Note that onlycertain configurations of the Linux kernel enable encryption, and otherfilesystems may add support for encryption.Most of the testing for fscrypt has been done with ext4 filesystems
google-fscryptctl	fscryptctl	However,the kernel uses a common userspace interface, so this tool should work with allexisting and future filesystems which support encryption
google-fscryptctl	fscryptctl	If there is a problemusing fscrypt with other filesystems, please open an issue.
google-fscryptctl	Other encryption solutions	It is important to distinguish Linux filesystem encryption from two otherencryption solutions:  eCryptfs  and dm-crypt Currently, dm-crypt encrypts an entire block device with a single master key
google-fscryptctl	Other encryption solutions	Ifyou do not need the fine-grained controls of fscryptctl or want to fullyencrypt your filesystem metadata, dm-crypt could be a simpler choice.On the other hand, eCryptfs is another form of filesystem encryption on Linux;it encrypts a filesystem directory with some key or passphrase
google-fscryptctl	Other encryption solutions	eCryptfs sits ontop of an existing filesystem
google-fscryptctl	Other encryption solutions	This make eCryptfs an alternative choice if yourfilesystem or kernel does not support Linux filesystem encryption or you do notwant to modify your existing filesystem.Also note that fscryptctl does not support or setup either eCryptfs ordm-crypt
google-fscryptctl	Other encryption solutions	For these tools, use ecryptfs-utils  foreCryptfs or  cryptsetup  for dm-crypt.
google-fscryptctl	Features	This tool aims to improve upon the work in e4crypt  with fscryptctlproviding a smaller and simpler interface
google-fscryptctl	Features	It only supports the minimalfunctionality required to use filesystem encryption
google-fscryptctl	Features	 It supports the followingGet the source by running make and a C compiler.
google-fscryptctl	Running and Installing	fscryptctl is a standalone binary, so it just needs to have support forfilesystem encryption and for the keyctl   and add_key   syscalls to exist,which they will be available on any kernel which supports filesystem encryption.Run fscryptctl --help to see the full usage and description of the availablecommands and flags
google-fscryptctl	Running and Installing	Installing the tool just requires placing it in your path orrunning sudo make install  set DESTDIR to install to a custom locations .
google-fscryptctl	Make a random 512-bit key and store it in a file	> dd if=/dev/urandom of=key.data count=64 bs=1
google-fscryptctl	Get the descriptor for the key	> ./fscryptctl get_descriptor  ./fscryptctl insert_key --ext4  keyctl showSession Keyring 827244259 --alswrv  416424 65534  keyring: _uid_ses.416424 111054036 --alswrv  416424 65534   \_ keyring: _uid.416424 227138126 --alsw-v  416424  5000   \_ logon: ext4:cd8c77009a9a3e6d
google-fscryptctl	Remove the key from the keyring	> keyctl unlink 227138126
google-fscryptctl	Make a test directory on a filesystem that supports encryption	> mkdir /mnt/disks/encrypted/test
google-fscryptctl	Setup an encryption policy on that directory	> ./fscryptctl set_policy cd8c77009a9a3e6d /mnt/disks/encrypted/test> ./fscryptctl get_policy /mnt/disks/encrypted/testEncryption policy for /mnt/disks/encrypted/test:
google-fscryptctl	We cannot create files in the directory without the key	> echo "Hello World!" > /mnt/disks/encrypted/test/foo.txtAn error occurred while redirecting file '/mnt/disks/encrypted/test/foo.txt'open: No such file or directory> ./fscryptctl insert_key --ext4  echo "Hello World!" > /mnt/disks/encrypted/test/foo.txt> ls -lA /mnt/disks/encrypted/test/total 4> cat /mnt/disks/encrypted/test/foo.txtHello World!
google-fscryptctl	Now we remove the key, remount the filesystem, and see the encrypted data	> keyctl showSession Keyring1047869403 --alswrv   1001  1002  keyring: _ses 967765418 --alswrv   1001 65534   \_ keyring: _uid.10011009690551 --alsw-v   1001  1002   \_ logon: ext4:cd8c77009a9a3e6d> keyctl unlink 10096905511 links removed> umount /mnt/disks/encrypted> mount /mnt/disks/encrypted> ls -lA /mnt/disks/encrypted/test/total 4> cat /mnt/disks/encrypted/test/wnJP+VX33Y6OSbN08+,jtQXK9yMHm8CFcI64CxDFPxLcat: /mnt/disks/encrypted/test/wnJP+VX33Y6OSbN08+,jtQXK9yMHm8CFcI64CxDFPxL: Required key not available
google-fscryptctl	Reinserting the key restores access to the data	> ./fscryptctl insert_key --ext4  ls -lA /mnt/disks/encrypted/test/total 4> cat /mnt/disks/encrypted/test/foo.txtHello World!
google-fscryptctl	Contributing	We would love to accept your contributions to fscryptctl
google-fscryptctl	Contributing	See theCONTRIBUTING.md file for more information about singing the CLA and submittinga pull request.
google-fscryptctl	Getting "filesystem encryption has been disabled" on an ext4 filesystem.	Getting this error on an ext4 system usually means the filesystem has not beensetup for encryption
google-fscryptctl	Getting "filesystem encryption has been disabled" on an ext4 filesystem.	To setup a filesystem to support encryption, first checkthat your block size is equal to your page size by comparing the outputs ofgetconf PAGE_SIZE and tune2fs -l /dev/device | grep 'Block size'
google-fscryptctl	Getting "filesystem encryption has been disabled" on an ext4 filesystem.	If theseare not the same, DO NOT ENABLE ENCRYPTION.To turn on the encryption feature flag for your filesystem, runThis command may require root privileges
google-fscryptctl	Getting "filesystem encryption has been disabled" on an ext4 filesystem.	Once the flag is enabled, olderkernels may not be able to mount the filesystem
google-fscryptctl	Getting "filesystem encryption has been disabled" on an ext4 filesystem.	Note that there was a bug in anolder kernel version that allowed encryption policies to be set on ext4filesystems without enabling this encryption feature flag.
google-fscryptctl	Files are still visible in plaintext after encryption key is removed.	This is an issue with how the Linux kernel implements filesystem encryption
google-fscryptctl	Files are still visible in plaintext after encryption key is removed.	Theplaintext is still cached even after the key is removed
google-fscryptctl	Files are still visible in plaintext after encryption key is removed.	To clear these cachesafter removing the appropriate key, either unmount and remount the filesystem,or run:There used to be kernel functionality to "lock" files after their keys had beenremoved
google-fscryptctl	Files are still visible in plaintext after encryption key is removed.	However,  this was removed because the implementation was insecure and buggy.
google-fscryptctl	Legal	Copyright 2017 Google Inc
google-fscryptctl	Legal	under the Apache 2.0 License  see theLICENSE file for more information.Author: Joe Richey This is not an official Google product.
google-functional-objc	Functional operators for Objective-C	An Objective-C library of functional operators, derived from NSDictionary, NSOrderedSet, and NSSet.
google-functional-objc	Filter	Loops over a collection and returns an array that contains elements that meet aReturns the first element in the collection that satisfies a condition.Similar to  map  #map , but can also flatten a collection of collections.Invokes a block on each element of the collection in the same order as a for-inLoops over a collection and applies the same operation to each element in theCombines all items in a collection to create a single value.Creates an array of pairs built from the two input collections.
google-functional-objc	CocoaPods	Add the following to your Podfile:
google-functional-objc	Carthage	Add the following to your Cartfile:
google-functional-objc	Import	Import the umbrella header as:
google-functions-demo	Prerequisites	A gmail accountBilling enabled in the GCP ConsoleA Walmart Open API keyNode.js, npm and Firebase CLI installed
google-functions-demo	Setting up	Using the Firebase Console  create a new projectUpgrade the pricing plan to Blaze  Pay as you go Log into the Firebase CLIIn the terminal, navigate to the root of this repositoryInitialize the Firebase Functionscd functionsEdit the walmartAPI.js file and update the WALMART_API_KEY constant with your keyDeploy the functionsIn the Firebase Console, use the Database Rules to make the database publicIn the Firebase Console, go through the "Add Firebase to your iOS App" wizardEnter "com.github.davidair.FunctionsDemo" as the iOS Bundle IDDownload GoogleService-Info.plistIn the FunctionsDemo directory, run "pod install"Open FunctionsDemo.xcworkspaceDrag the GoogleService-Info.plist downloaded in step 12 into the projectYou should be able to run the demo in the simulator
google-functionsimsearch	FunctionSimSearch	FunctionSimSearch similarity search over CFGs extracted from disassemblies.
google-functionsimsearch	Getting started for the lazy  using Docker 	Make sure you have Docker installed
google-functionsimsearch	Getting started for the lazy  using Docker 	Then do:The last command should dump the disassembly of ./elf_file to stdout.
google-functionsimsearch	Getting Started for the less lazy  build from source 	These instructions will get you a copy of the project up and running on yourlocal machine for development and testing purposes.
google-functionsimsearch	Prerequisites	This code has a few external dependencies
google-functionsimsearch	Prerequisites	The dependencies are:You should be able to build on a Debian stretch machine by running the followingbash script in the directory where you checked out everything:
google-functionsimsearch	#!/bin/bash	source_dir=$ pwd 
google-functionsimsearch	Install gtest and gflags. It's a bit fidgety, but works:	sudo apt-get install libgtest-dev libgflags-dev libz-dev libelf-dev cmake g++sudo apt-get install libboost-system-dev libboost-date-time-dev libboost-thread-devcd /usr/src/gtestsudo cmake CMakeListssudo makesudo cp *.a /usr/lib
google-functionsimsearch	Now get and the other dependencies	cd $source_dirmkdir third_partycd third_party
google-functionsimsearch	Download Dyninst.	wget tar xvf ./v9.3.2.tar.gz
google-functionsimsearch	Download PicoSHA, pe-parse, SPII and the C++ JSON library.	git clone git clone git clone mkdir jsonmkdir json/srccd json/srcwget  cd ../..
google-functionsimsearch	Build PE-Parse.	cd pe-parsecmake ./CMakeLists.txtmake -j8cd ..
google-functionsimsearch	Build SPII.	cd spiicmake ./CMakeLists.txtmake -j8sudo make installcd ..
google-functionsimsearch	Build Dyninst	cd dyninst-9.3.2cmake ./CMakeLists.txtmake -j8sudo make installsudo ldconfigcd ..
google-functionsimsearch	Finally build functionsimsearch tools	cd ..make -j8This should build the relevant executables to try
google-functionsimsearch	Finally build functionsimsearch tools	On Debian stretch and later,you may have to add '-fPIC' into the pe-parse CMakeLists.txt to make sure yourgenerated library supports being relocated.
google-functionsimsearch	Running the tests	You can run the tests by doing:will not work.Also be aware that a fair number of the tests are pretty expensive to run, andexpect the full testsuite to eat all your CPU for a few minutes; the suite ofslow tests may keep your computer busy for hours.
google-functionsimsearch	Running the tools	At the moment, the following executables will be built  in alphabetical order :
google-functionsimsearch	addfunctionstoindex	calculate the SimHash for each such function and add it to the search index file.
google-functionsimsearch	addsinglefunctiontoindex	at the specified address and at it to the search index
google-functionsimsearch	addsinglefunctiontoindex	Incurs the full cost ofdisassembling the entire executable, so use with care.
google-functionsimsearch	createfunctionindex	first command you want to run.
google-functionsimsearch	disassemble	file can either be a 32-bit/64-bit ELF, or a 32-bit PE file
google-functionsimsearch	disassemble	Adding supportfor 64-bit PE is easy and will be done soon.
google-functionsimsearch	dumpfunctionindex	| HashID | SimHash First Part | SimHash Second Part | Executable ID | Address || -----|  ..
google-functionsimsearch	dumpfunctionindex	  |   ...
google-functionsimsearch	dumpfunctionindexinfo	is left, how many functions are indexed etc.Example output:
google-functionsimsearch	dumpsinglefunctionfeatures	IDs of the features that will be used for the SimHash calculation to stdout.You will probably not need this command unless you experiment with the machinelearning features in the codebase.
google-functionsimsearch	evalsimhashweights	to the tutorial about weight learning for details.
google-functionsimsearch	functionfingerprints	 verbose  is set to "false", this tool will simply dump the SimHash hashesof the functions in the specified executable to stdout, in the format:features that enter the SimHash calculation, so the output will look like:mode is used to create training data for the machine learning components.
google-functionsimsearch	graphhashes	disassembled function to stdout
google-functionsimsearch	graphhashes	These hashes encode **only*structure and completely ignore any mnemonics; as such they are not very usefulon small graphs.
google-functionsimsearch	growfunctionindex	be dynamically resized, so when one nears being full, it is a good idea togrow it.
google-functionsimsearch	matchfunctionsfromindex	basic blocks, retrieve the top-10 most similar functions from the search index.Each match must be at least 90% similar.
google-functionsimsearch	trainsimhashweights	the specified data directory, trains for 500 iterations  using LBFGS , and thenwrites the resulting weights to the specified file.
google-functionsimsearch	End-to-end tutorial: How to build an index of vulnerable functions to scan for	Let's assume that weights have been trained already, and placed in a filecalled "trained_weights_500.txt"
google-functionsimsearch	Create a new index file.	bin/createfunctionindex --index="./trained.index"
google-functionsimsearch	Grow the index to be 2 gigs in size.	bin/growfunctionindex --index="./trained.index" --size_to_grow=2048
google-functionsimsearch	Add DLLs with interesting functions to the search index.	for dll in $ find -iname \*.dll ; do \  bin/addfunctionstoindex -format=PE -index=,/trained.index -weights=./trained_weights_500.txt --input $ pwd /$dll; done
google-functionsimsearch	Add ELFs with interesting functions to the search index.	 ..
google-functionsimsearch	Add ELFs with interesting functions to the search index.	At this point, we can start scanning a given new executable for any of thefunctions in the search index.bin/matchfunctionsfromindex -format=PE -index=./trained.index -input=../bin/libpng-1.6.26_msvc14/libpng16.dll -weights=./trained_weights_500.txtsr/local/google/home/thomasdullien/Desktop/sources/functionsimsearch/trained_weights_500.txt  !  Executable id is 66d4ebee347438de !  Loaded search index, starting disassembly
google-functionsimsearch	Add ELFs with interesting functions to the search index.	!  Done disassembling, beginning search
google-functionsimsearch	Add ELFs with interesting functions to the search index.	!   289/882  !   289/882  !   289/882  !   289/882  !   289/882  ..
google-functionsimsearch	Add ELFs with interesting functions to the search index.	While this is nice and fine, all we get is the source executable ID and theaddress of the function we matched to
google-functionsimsearch	Add ELFs with interesting functions to the search index.	In order to make sense of this, we needto make sure there is a file called "./trained.index.metadata" in the samedirectory as the index file.This file should contain simple space-delimited lines of the format:The last field indicates whether the function is known to be vulnerable or not.Re-running our matching command above now yields much more useful output:
google-functionsimsearch	End-to-end tutorial: Training weights prior to building an index of vulnerable functions	How does one train weights prior to building a search index? We need a coupleof ingredients:  predictive value.In order to generate labelled datasets, the usual process involves compiling thesame codebase with many different compilers and compiler settings
google-functionsimsearch	End-to-end tutorial: Training weights prior to building an index of vulnerable functions	In an idealworld, we would have something like Compiler Explorer; in the meantime, peoplewill have to build things themselves.
google-functionsimsearch	Generating input data	Input data currently consists of three text files:Generating these files from the unrar executables is somewhat involved -to extract the function names from debug information, convert between differentcompiler conventions on how to demangle their names, and finally match the oneswe can match by identical name
google-functionsimsearch	Generating input data	For the moment, simply use the below shell script;run it from ./bin after having built everything.Generate bashcd ./testdatachmod +x ./generate_test_data.shThe script creates two directories: /tmp/train/validation_data
google-functionsimsearch	Generating input data	Both directories will contain the files describedabove, all of them generated from the unrar executables
google-functionsimsearch	Generating input data	The set of functionsappearing in the training data should be disjoint from the set of functionsappearing in the validation data.Note that the shell script is grossly inefficient
google-functionsimsearch	Generating input data	Rewriting this hack in C++would be a great thing for a contributor to do :- .
google-functionsimsearch	Running the training code	In order to launch the training itself, simply do:bin/trainsimhashweights -data=/tmp/train/training_data/ -train_steps=500 -weights=./trained_weights_500.txtThis should launch the training process and nicely max out all the cores you havein your machine
google-functionsimsearch	Running the training code	Unfortunately, there is no GPU-accelerated training yet, so oddsare you will have to wait a few hours until the training is done.The resulting weights will be written to the specified output file.
google-functionsimsearch	Running the validation code	After we have arun a training iteration, we need to check whether the trainingactually did anything useful
google-functionsimsearch	Running the validation code	Run the following command line to see what theeffects of the new weights are on the validation set:bin/evalsimhashweights -data=/tmp/train/training_data/ -weights=./trained_weights_500.txtRunning this command will output data for 4 histograms  ideally visualized usingGNUplot , and the differences between the mean distances preAttraction mean trained: 1.6483634587e+01Attraction mean untrained: 2.3003175379e+01Repulsion mean trained: 3.1962383977e+01Repulsion mean untrained: 2.8451636541e+01As we can see here, the average distance between two identical pairs was loweredto 16.5 bits from 23.0 bits, and the average distance for non-identical pairswas increased to 32 bits from 28.5 bits prior to training.Drawing histograms from the data can be done as follows  assuming you have pipedthe output to /tmp/evaldata :cat /tmp/evaldata | grep -v  a-z  > /tmp/evalgnuplot> set multiplot layout 2, 1 title "Premultiplot> plot '/tmp/eval' index 1 with lines title "Repulsion pre-train", '/tmp/eval' index 3 with lines title "Repulsion post-train"multiplot> plot '/tmp/eval' index 0 with lines title "Attraction pre-train", '/tmp/eval' index 2 with lines title "Attraction post-train"multiplot> unset multiplot
google-functionsimsearch	Compiling the same debian package with many compilers/settings	For all experiments with this codebase, it is often useful to be able to compilea given codebase with a number of different compilers and compiler settings
google-functionsimsearch	Compiling the same debian package with many compilers/settings	Thisis often complicated, though, by various Makefiles and build scripts ignoringflags provided to them by debuild, or alternatively, by clang ignoring all butthe last -Ox argument
google-functionsimsearch	Compiling the same debian package with many compilers/settings	The following is a quick guide on how to rebuild a givenDebian package with a number of different compiler settings.following command:directory=$ pwd|rev|cut -d"/" -f1|rev ; for config in $ ls ~/.config/gcc-wrapper/ ; do config=$ echo $config|rev|cut -d"/" -f1|rev ; DEB_BUILD_OPTIONS="nostrip" debuild --set-envvar=GCC_PROFIL=$config -b -us -uc -j36; cd ..; mkdir $ echo $directory .$config; mv ./*.deb $ echo $directory .$config; cd $directory; doneThis should take every compiler configuration that you have in your gcc-wrapperdirectory, and rebuild the package with this compiler configuration
google-functionsimsearch	Compiling the same debian package with many compilers/settings	The resultswill be placed in the corresponding subdirectory.Once this is done, you can run the following command to gather all the .so's inthe packages, label them properly, and put them in the right directory:This project is licensed under the Apache 2.0 License 
google-fury	Fury config management	 ! license    ! Travis     ! api  Fury is a very opinionated configuration management tool, operating ina similar space to Puppet, Chef, Ansible, Saltstack and the like
google-fury	Fury config management	It'snot at all production-ready, you should never use it.I wrote it because I have strange  opinions  README.opinions.md  aboutwhat my ideal config management system would be, and why I think allexisting systems are getting it fundamentally wrong
google-fury	Fury config management	It's veryunlikely that I'm correct, but exploring the depths of my wrongness isentertaining, and might result in something that _I_ at least likeThis is not an official Google project, if you hadn't guessed by now.
google-fuzzer-test-suite	fuzzer-test-suite	This is a set of tests  benchmarks  for fuzzing engines  fuzzers .The goal of this project is to have a set of fuzzing benchmarks derived from real-lifelibraries that have interesting bugs, hard-to-find code paths, or otherchallenges for bug finding tools.In addition, this project provides a fuzzing engine comparison framework  engine-comparison/  to execute A/B tests betweendifferent fuzzing configurations.The current version supports  libFuzzer  and AFL   In future versions we may supportother fuzzing engines.
google-fuzzer-test-suite	See also	See  CONTRIBUTING  CONTRIBUTING  first
google-fuzzer-test-suite	See also	If you want to add one more benchmark to the test suite,simply mimic one of the existing benchmarks and send the pull request
google-fuzzer-test-suite	Disclaimer	This is not an official Google product.
google-gae-secure-scaffold-python	Introduction	This contains a boilerplate AppEngine application meant to provide a securebase on which to build additional functionality
google-gae-secure-scaffold-python	Introduction	 Structure:and compiled by Google's Closure Compiler  detailed below in the dependenciessection .The scaffold provides the following basic security guarantees by default througha set of base classes found in src/base/handlers.py
google-gae-secure-scaffold-python	Introduction	 These handlers:Set assorted security headers  Strict-Transport-Security, X-Frame-Options,Prevent the XSS-prone construction of HTML via string concatenation byTest for the presence of headers that guarantee requests to Cron orVerify XSRF tokens by default on authenticated requests using any verb otherIn addition to the protections above, the scaffold monkey patches assorted APIsthat use insecure or dangerous defaults  see src/base/api_fixer.py .Obviously no framework is perfect, and the flexibility of Python offers manyways for a motivated developer to circumvent the protections offered
google-gae-secure-scaffold-python	Introduction	 Underthe assumption that developers are not malicious, using the scaffold shouldcentralize many security mechanisms, provide safe defaults, and structure thecode in a way that facilitates security review.Sample implementations can be found in src/handlers.py
google-gae-secure-scaffold-python	Introduction	 These demonstratebasic functionality, and should be removed / replaced by code specific toyour application.
google-gae-secure-scaffold-python	Prerequisites	--- git submodule init git submodule update cd closure-compiler cd ../closure-templates && mvn && cd .
google-gae-secure-scaffold-python	Prerequisites	npm install mkdir $HOME/bin; cd $HOME/bin npm install grunt-cli export PATH=$HOME/bin/node_modules/grunt-cli/bin:$PATHTo install dependencies for unit testing:sudo pip install unittest2
google-gae-secure-scaffold-python	Testing	To run unit tests:python run_tests.py ~/bin/google_appengine src
google-gae-secure-scaffold-python	Local Development	To run the development appserver locally:grunt appengine:run:appNote that the development appserver will be running on a snapshot of codeat the time you run it
google-gae-secure-scaffold-python	Local Development	 If you make changes, you can run the various Grunttasks in order to propagate them to the local appserver
google-gae-secure-scaffold-python	Local Development	 For instance,grunt copy will refresh the source code  local and third party , static files,and templates
google-gae-secure-scaffold-python	Local Development	 grunt closureSoys and/or grunt closureBuilder will rebuildthe templates or your provided Javascript and the updated versions will bewritten in the output directory.
google-gae-secure-scaffold-python	Deployment	To deploy to AppEngine:grunt appengine:update:app --appid=Specifying --appid= will override any value set in config.json
google-gae-secure-scaffold-python	Deployment	 You maymodify the config.json file to avoid having to pass this parameter onevery invocation.
google-gae-secure-scaffold-python	Notes	out/static/app.js
google-gae-secure-scaffold-python	Notes	 Included in this compilation pass is the the output ofthe closureSoys:js task  intermediate artifacts: out/generated/js/\*.js .Closure Templates that you provide are also compiled using the Python backend,and are available using the constants.CLOSURE template strategy  the default .The generated source code is stored in out/generated/\*.py
google-gae-secure-scaffold-python	Notes	 To use them,pass the callable template as the first argument to render  , and a dictionarycontaining the template values as the second argument, e.g.:The out/base/foo.py .
google-gapid	GAPID: Graphics API Debugger	 ! GoDoc   ! Gitter  
google-gapid	Downloads	** Download the latest version of GAPID here
google-gapid	Documentation	** User documentation can be found here
google-gapid	About	GAPID is a collection of tools that allows you to inspect, tweak and replay calls from an application to a graphics driver.GAPID can trace any Android  debuggable application  or if you have root access to the device any application can be traced.GAPID can also trace any desktop Vulkan application
google-gapid	About	       
google-gapid	Building	**See  Building GAPID  BUILDING.md .**
google-gapid	Running the client	After building GAPID, you can run the client from /bazel-bin/pkg/gapid.
google-gapid	Project Structure	GAPID consists of the following sub-components:
google-gapid	 gapii  gapii : Graphics API Interceptor	A layer that sits between the application / game and the GPU driver, recording all the calls and memory accesses.
google-gapid	 gapis  gapis : Graphics API Server	A process that analyses capture streams reporting incorrect API usage, processes the data for replay on various target devices, and provides an RPC interface to the client.
google-gapid	 gapir  gapir : Graphics API Replay daemon	A stack-based VM used to playback capture files, imitating the original application’s / game's calls to the GPU driver
google-gapid	 gapir  gapir : Graphics API Replay daemon	Supports read-back of any buffer / framebuffer, and provides profiling functionality.
google-gapid	 gapic  gapic : Graphics API Client	The frontend user interface application
google-gapid	 gapic  gapic : Graphics API Client	Provides visual inspection of the capture data, memory, resources, and frame-buffer content.
google-gapid	 gapil  gapil : Graphics API Language	A new domain specific language to describe a graphics API in its entirety
google-gapid	 gapil  gapil : Graphics API Language	Combined with our template system to generate huge parts of the interceptor, server and replay systems.
google-gcm	Google Cloud Messaging	Google Cloud Messaging  GCM  is a service that lets developers send data fromservers to users' devices, and receive messages from devices on the sameconnection
google-gcm	Google Cloud Messaging	The service provides a simple, lightweight mechanism that serverscan use to tell mobile applications to contact the server directly to fetchupdated application user data
google-gcm	Google Cloud Messaging	The GCM service handles all aspects of queueingof messages and delivery to client applications running on target devices.This project contains client libraries and samples to help developers interfacewith and explore the Google Cloud Messaging APIs.For more information on GCM, including an overview and integrationinstructions, see  Cloud Messaging For help getting started with GCM, see the GCM Quickstart for Android or the  GCM Quickstart for iOS 
google-gcm	License	Copyright 2015 Google, Inc.Licensed to the Apache Software Foundation  ASF  under one or more contributorlicense agreements
google-gcm	License	 See the NOTICE file distributed with this work foradditional information regarding copyright ownership
google-gcm	License	 The ASF licenses thisfile to you under the Apache License, Version 2.0  the "License" ; you may notuse this file except in compliance with the License
google-gcm	License	 You may obtain a copy ofthe License atdistributed under the License is distributed on an "AS IS" BASIS, WITHOUTWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-gcm	License	 See theLicense for the specific language governing permissions and limitations underthe License.
google-gdata-java-client	Description	Older Google Data  GData  APIs use XML as their underlying format, but most Google APIs have released newer versions of their APIs based on JSON
google-gdata-java-client	Description	You should migrate your code to use the new API infrastructure that is based on JSON
google-gdata-java-client	Description	Likewise, if you have an existing application that uses the GData Java client library, you need to update your code to use the  Google APIs Client Library for Java  as described on the  migration  page.We have stopped actively developing the GData Java client library, and the following table shows the GData status of relevant Google APIs:We have stopped actively developing the GData Java client library
google-gdata-java-client	Description	Forinformation about the GData status of relevant Google APIs, see the  GData APIDirectory **Android support:*
google-gdata-java-client	Download	 Source  Samples 
google-gdata-objectivec-client	Google Data APIs Objective-C Client Library #	**Project site***Discussion group*The  Google data APIs  provide asimple protocol for reading and writing data on the web
google-gdata-objectivec-client	Google Data APIs Objective-C Client Library #	 Many Google servicesprovide a Google data API.This library is for Google **XML APIs**
google-gdata-objectivec-client	Google Data APIs Objective-C Client Library #	For **JSON APIs,* Google APIs Client Library for Objective-C for REST Each of the following Google services provides a Google Data API supported bythis library:This library should **no longer*library, a Mac OS X framework, and source code that make it easy to access datathrough Google Data APIs.**To get started*look at the  overview slides read the  introduction and study the  example applications **If you have a problem*Data Objective-C Client Library, please join the discussion group or submit an  issue **Externally-included projects**The library includes code from the separate projects GTM HTTP Fetcher  and GTM OAuth 2 Other useful classes for Mac and iPhone developers are available in the Google Toolbox for Mac 
google-gemmlowp	gemmlowp: a small self-contained low-precision GEMM library	  This is not a full linear algebra library, only a GEMM library: it only doesgeneral matrix multiplication  "GEMM" .The meaning of "low precision" is detailed in this document: doc/low-precision.md  doc/low-precision.md Some of the general design is explained in  doc/design.md  doc/design.md .
google-gemmlowp	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-gemmlowp	Mailing list	gemmlowp-related discussion, about either development or usage, is welcome onthis Google Group  mailing list / forum :Should be portable to any platform with some C++11 and POSIX support, while wehave optional optimized code paths for specific architectures.
google-gemmlowp	Architecture-specific optimized code paths	We have some optimized code paths for specific instruction sets
google-gemmlowp	Architecture-specific optimized code paths	Some arewritten in inline assembly, some are written in C++ using intrinsics
google-gemmlowp	Architecture-specific optimized code paths	Both GCCand Clang are supported.Current optimized code paths:otherwise gemmlowp will use slow reference code
google-gemmlowp	Architecture-specific optimized code paths	Bazel users can compile byrunning bazel build --copt=-msse4.1 //gemmlowp:all
google-gemmlowp	Architecture-specific optimized code paths	The compiled binary shouldwork on all Intel CPUs since 2008  including low power microarchitectures  aswell as AMD CPUs since Please note when compiling binaries that don't need to be distributed, it'sgenerally a better idea to pass -march=native to the compiler
google-gemmlowp	Architecture-specific optimized code paths	That flagimplies -msse4.1 flag, along with others that might be helpful
google-gemmlowp	Architecture-specific optimized code paths	This of courseassumes the host machine supports those instructions
google-gemmlowp	Architecture-specific optimized code paths	Bazel users should preferto run bazel build --config=opt //gemmlowp:all instead.Details of what it takes to make an efficient port of gemmlowp, namely writing asuitable GEMM kernel and accompanying packing code, are explained in this file: doc/kernel.md  doc/kernel.md .
google-gemmlowp	The gemmlowp public interface	gemmlowp's main public interface is in the public/ subdirectory.This is a headers-only library, so there is nothing to link to.Usage documentation, and comments on the deprecation status of each public entrypoint, may be found in  doc/public.md  doc/public.md  .A full, self-contained usage example, showing how to quantize float matrices andperform a quantized matrix multiplication approximating a float matrixmultiplication, is given in doc/quantization_example.cc  doc/quantization_example.cc .
google-gemmlowp	Old EightBitIntGemm legacy deprecated interface	The eight_bit_int_gemm/ subdirectory contains an alternate interface thatshould be considered purely legacy, deprecated, and going to be removed at somepoint in the future.
google-gemmlowp	Building by manually invoking your compiler	Because gemmlowp is so simple, working with it involves only single-command-linecompiler invocations
google-gemmlowp	Building by manually invoking your compiler	Therefore we expect that most people working with gemmlowpwill either manually invoke their compiler, or write their own rules for theirown preferred build system.Keep in mind  previous section  that gemmlowp itself is a pure-headers-onlylibrary so there is nothing to build.For a Android gemmlowp development workflow, the scripts/ directory contains ascript to build and run a program on an Android device:That being said, we also maintain a Bazel BUILD system as part of gemmlowp
google-gemmlowp	Building by manually invoking your compiler	Itsusage is not mandatory at all and is only one possible way that gemmlowplibraries and tests may be built
google-gemmlowp	Building by manually invoking your compiler	If you are interested, Bazel's home page is And you can get started with using Bazel to build gemmlowptargets by first creating an empty WORKSPACE file in a parent directory, for
google-gemmlowp	Testing by manually building and running tests	The test/ directory contains unit tests
google-gemmlowp	Testing by manually building and running tests	The primary unit test iscompiler/linker:Android device:compiler, and expects source files  and optionally, cflags  as command-lineparameters
google-gemmlowp	Testing by manually building and running tests	To build and run the above-mentioned main unit test, first set CXXAlternatively, you can use Bazel to build and run tests
google-gemmlowp	Testing by manually building and running tests	See the Bazelinstruction in the above section on building
google-gemmlowp	Testing by manually building and running tests	Once your Bazel workspace is setup, you can for instance do:If you're having trouble finding the compiler, follow these instructions tobuild a standalone toolchain:Here's an example of setting up Clang 3.5:support NEON assembly
google-gemmlowp	Testing by manually building and running tests	The benchmark build process will issue a warning ifsupport isn't detected, and you should make sure you're using a compiler likearm-linux-androideabi-g++ that does include NEON.
google-gemmlowp	Benchmarking	The main benchmark iswith assertions disabled  -DNDEBUG .For example, the benchmark can be built and run on an Android device by doing:profiling instrumentation  which makes it slower  and will dump profiles
google-gemmlowp	Benchmarking	Seenext section on profiling.
google-gemmlowp	Profiling	The profiling/ subdirectory offers a very simple, naive, inaccurate,non-interrupting sampling profiler that only requires pthreads  no signals .It relies on source code being instrumented with pseudo-stack labels
google-gemmlowp	Profiling	Seeprofiling/instrumentation.h
google-gemmlowp	Profiling	A full example of using this profiler is given inthe top comment of profiling/profiler.h.
google-gemmlowp	Contributing	Contribution-related discussion is always welcome on the gemmlowp mailing list see above .We try to keep a current list of TODO items in the todo/ directory.Prospective contributors are welcome to pick one to work on, and communicateabout it on the gemmlowp mailing list.Details of the contributing process, including legalese, are in CONTRIBUTING.
google-gemmlowp	Performance goals	Our performance goals differ from typical GEMM performance goals in thefollowing ways: We care not only about speed, but also about minimizing power usage
google-gemmlowp	Performance goals	We Most GEMMs are optimized primarily for large dense matrix sizes  >= 1000 .
google-generativemloncloud	Generative Machine Learning on the Cloud	This tool uses the  Google Cloud Machine LearningAPI  and  Tensorflow Generative Machine Learning on the Cloud is a cloud based tool to aid ingenerative art and synthetic image generation
google-generativemloncloud	Generative Machine Learning on the Cloud	The end to end system designallows a user to have a custom dataset of images to train a VariationalAutoencoder Generative Adversarial Network  VAE-GAN  model on Cloud ML
google-generativemloncloud	Generative Machine Learning on the Cloud	Fromhere, their model is deployed to the cloud, where they can input an embedding tohave synthetic images generated from their dataset or input an image to get anembedding vector.
google-generativemloncloud	Pre-steps:	  Install Tensorflow 
google-generativemloncloud	How To: Run a Training Job	A training job will train the VAE-GAN on your own training data!Important: You will be using billable components of the Cloud Platform and willincur charges when running a training job
google-generativemloncloud	How To: Run a Training Job	cd into the data directory of the source code you just cloned
google-generativemloncloud	How To: Run a Training Job	Make sure to Run the training script \ Monitor your training job using the TensorBoard you started or the Cloud
google-generativemloncloud	How To: Create and Deploy Model	Now that we have a trained model saved on GCS, lets deploy it on Cloud ML! cd into the data directory of the source code
google-generativemloncloud	How To: Create and Deploy Model	Run create model script  if you don't know your job name, use the -l flag  \ Look at your deployed model on the cloud dashboard under Cloud ML Engine!
google-generativemloncloud	How To: Run an Inference Job	Now that we have a deployed model trained with your own data, we can use it togenerate new samples
google-generativemloncloud	How To: Run an Inference Job	Generate an Image! Embedding to Image generation Image to Embedding generation
google-generativemloncloud	Acknowledgements	Huge shoutout to this awesome DCGAN  After much trial error,the architecture from this network was the one that produced the greatestgenerative results and ended up as the network architecture in the final versionof this tool.
google-generativemloncloud	Disclaimer	This is not an official Google product.
google-generator-goro	generator-goro Overview	This boilerplate is intended to jumpstart creation of marketing websites on Goro that use AngularJS.
google-generator-goro	Usage	Install generator-goro:Make a new directory then cd into it:and answer the questions.
google-generator-goro	Writing JavaScript	Please be sure your Javascript follows the  Google Javascript  and  Google AngularJS  style guides
google-generator-goro	Writing JavaScript	Google doesn't write Angular the same way it is shown on the external AngularJS site.Using AngularJS in Goro is some what tricky due to the usage of the Closure Compiler
google-generator-goro	Writing JavaScript	But most of this is resolved for you with the boilerplate
google-generator-goro	Writing JavaScript	Read the Goro documentation on using AngularJS with Goro for more info.Easily debug changes in your site by appending ?debug=1 to your goro preview url
google-generator-goro	Writing JavaScript	This will use the uncompiled js and make it easier to debug.
google-generator-goro	More About Yeoman	To learn more about Yeoman check out the  Getting Started Guide  Yeoman also heaviliy relies on  Grunt  and  Bower  
google-generator-goro	License	Apache 2.0
google-genomics-protos	Genomics protos	This project contains protocol buffer definitions for working withgenomics data
google-genomics-protos	Genomics protos	 These definitions are based on thegoogle.genomics.v1.* protos from googleapis  but with theAPI-specific pieces removed.For convenience, this package also contains pre-compiled Python versions ofthe protobufs which can be installed using pip via the instructions below.
google-genomics-protos	License	This code is licensed under the terms of the  Apache license  LICENSE .
google-genomics-protos	Disclaimer	You are welcome to use the .proto files directly
google-genomics-protos	Disclaimer	For Python specifically,we provide pre-compiled files that can be installed via pip.Optional but recommended: start a virtualenvThe *_pb2 files are generated as follows:
google-geovelo	Geodetic Velocities Visualization	! Geodetic Velocities Visualization Screenshot  screenshot.png This visualization renders Global Navigation Satellite System  GNSS  positiontime series data on top of an interactive Google Map.By manipulating the magnification level and the timespan, you can see how theEarth has moved over time.
google-geovelo	Setup	To use Google Maps, you need a browser API key.Follow these instructions to Get a Key/Authentication Once you have your API key, open up the Paste in your API key and save the file.
google-geovelo	Usage	To use this visualization, first you'll need to produce or acquire a GNSS dataThe visualization expects to find a file named beacon-data.json in the data/directory
google-geovelo	Usage	See the README file there for details on the format.Once you have a data file, dowload this source code and serve the contents
google-geovelo	Usage	Ifyou have Python installed, you can use its SimpleHTTPServer to see thisworking locally.
google-geovelo	Disclaimer	This is not an official Google product.
google-gfw-deployments	GFW-Deployments	Looking for deprecated scripts and tools?   Deprecated Branch 
google-gfw-toolkit	Deprecation Notice	Users of gfw-toolkit,The team at Google responsible for gfw-toolkit want to provide you with a 30 day notice that the repository  google/gfw-toolkit  will be deprecated on 11/14/
google-gfw-toolkit	What does this mean?	The github project will be deprecated and Google will discontinue support for gfw-toolkit.
google-gfw-toolkit	Why are you doing this?	The reason Google first created these tools was to address a need when there were limited alternatives in the market
google-gfw-toolkit	Why are you doing this?	Today there are options available that are better supported and in many cases provide an improved experience.
google-gfw-toolkit	What are the alternative options?	We recommend switching to use  Google Apps Manager  as the functionality provided by gfw-toolkit is well supported by Google Apps Manager and can offer an improved benefit over it.Here's an  example on key management with GAM We thank you for your support and use of the tool, we hope it was useful! 
google-ggrc-core	Requirements	The following software is required to stand up a GGRC-Core development|--------------------------------------------------|------------------------------------------|| Docker | Docker compose | A tool for defining multi-container apps |**NOTE for Windows/OSX users:* docker toolbox 
google-ggrc-core	Quick Start	Getting started with GGRC-Core development should be fast and easy once youhave Docker up and running
google-ggrc-core	Quick Start	Here are the steps:**NOTE for Windows/OSX users:*step fails, try running docker-compose build  See  Reprovisioning a Docker container  #reprovisioning-a-docker-container  below for more .If apt-get fails to install anything  for example Could not resolve 'archive.ubuntu.com' , try  this  #dns-issues ._NOTE: Because Docker shared volumes do not have permission mappings, you shouldnot use git and other file-creating commands from inside the container, as thesefiles will be owned by root and may disrupt future git usage on the host
google-ggrc-core	Launching GGRC as Stand-alone Flask	Most development is done in a stand-alone flask
google-ggrc-core	Launching GGRC as Stand-alone Flask	We strive to make getting upand running as simple as possible; to that end, launching the application isWe strive to make getting up and running as simple as possible; to that end,launching the application in the Google App Engine SDK environment is simple:requirements
google-ggrc-core	Launching GGRC as Stand-alone Flask	You can generate the YAML file with:The application will be accessible via this URL: <>If you're running the Google App Engine SDK, the App Engine management consolewill be available via this URL: <>
google-ggrc-core	Launching GGRC as Stand-alone Flask	You can log in asuser@example.com with admin rights and setup other users later.
google-ggrc-core	Accessing MySQL query logs	If using the docker-compose.yml file, the mysql query logs are enabledby default and can be monitored with:Tests are your friend! Keep them running, keep them updated.
google-ggrc-core	For JavaScript tests:	manually by running build_assets.
google-ggrc-core	For Python tests:	For better usage of unit tests, you can use sniffer inside the test/unit folder.This will run the tests on each file update.Up docker containers, prepare and launch dev server:Then you can run Selenium tests on your machine: you can set these env variables and cmd options in IDE To run Selenium tests inside docker container you can do:The quick start above gives a glimpse into the GGRC development environment.It's worth noting where there is automation in GGRC, and where there isn't.Often the lack of automation support for a step is intentional
google-ggrc-core	For Python tests:	Let's exploreeach step in detail.
google-ggrc-core	Git Submodules in GGRC	GGRC makes use of some external tools for  Sass templates and JavaScript form handling
google-ggrc-core	Git Submodules in GGRC	In order to have the relevantrepositories checked out as Git sub modules the following command must beissued in the project directory:To reprovision a docker container run the following:Remove files that are not in the repository e.g
google-ggrc-core	Git Submodules in GGRC	Python cache:Because Docker provisioning is done with Dockerfile which can not modify content of a shared volume, you need to enter the container and run one more step to finish the provisioningSince GGRC uses Webpack to bundle JavaScript and Sass Templates, the sources need to be compiled.This has been automated via a script available in $PATH in the virtualyou could use this command:Example test data can be loaded with the following command:After syncing your local clone of GGRC-Core you may experience a failure whentrying to run the application due to a change  usually an addition  to theThere are three primary classes of requirements for GGRC-Core: Submodules,Python requirements and other provision stepsThere are two pip requirements files: a runtime requirements file,src/requirements.txt, for application package dependencies and adevelopment requirements file, src/requirements-dev.txt, for additionaldevelopment-time package dependencies
google-ggrc-core	Git Submodules in GGRC	The runtime requirements are deployedwith the application while the development requirements are only used in thedevelopment environment  largely for testing purposes .Most requirements changes should be in either src/requirements-dev.txt and would manifest as module import failures.
google-ggrc-core	DNS issues	Sometimes build fails due to Could not resolve 'archive.ubuntu.com'.Solution 1:On the host find out the primary and secondary DNS server addresses:NOTE: For older versions of nmcli, one should replace the first part of thecommand above with nmcli device list  tested with nmcli version 0.9.8.8 .Using these addresses, create a file Solution 2:Please check the  Official documentation  on this.
google-ggrc-core	IOError: Can not access file in context: //src/packages	Latest Docker  at least Docker version 18.01.0-ce, build 03596f51b1  tries toresolve our symlinks in the project directory  which we use to storedependencies installed from inside the container  on the host machine.A workaround for this is to create the corresponding directories on the hostmachine as a placeholder so the symlinks aren't considered broken:
google-ggrc-core	Environment Variables	GGRC uses this environment variable to define which module s  within
google-ggrc-core	Details About VM File Structure	docker-compose build installs several Debian packages globally within theVM
google-ggrc-core	Details About VM File Structure	All other project data is contained within two directories, specified byenvironment variables  and defined in /home/vagrant/.bashrc .Points at root directory of the Git repository, and is automaticallydetected if not present.Points at a directory containing tmp and opt directories
google-ggrc-core	Details About VM File Structure	If notdefined, DEV_PREFIX defaults to the value of PREFIX
google-ggrc-core	Details About VM File Structure	 In the VM,it is defined to /vagrant-dev to avoid slowdown caused by the sharedfilesystem at /vagrant
google-ggrc-core	Changes to Requirements Files	The first thing to try to resolve issues due to missing prerequisites is torun the following command from within the project directory in the hostoperating system:required by the application as well as any new development packageTo manually update the requirements, you can log in to docker container and runA change in the git sub modules required by the project could also lead to errors, particularly in the front-end HTML portion of the application
google-ggrc-core	Changes to Requirements Files	The solution is to update the submodules:requirements of GGRC, it may also be necessary to rebuild the Sass and otherweb assets:Copyright  C  2013-2018 Google Inc.Licensed under the  Apache 2.0 license  see the LICENSE file .
google-gif-for-cli	Installation	Requires Python 3  with setuptools and pip , zlib, libjpeg, and ffmpeg, other dependencies are installed by setup.py.
google-gif-for-cli	Install dependencies:	Your Python environment may need these installation tools:
google-gif-for-cli	Install gif-for-cli:	Install from PyPI:Or download this repo and run:The gif-for-cli command will likely be installed into ~/.local/bin or similar, you may need to put that directory in your $PATH by adding this to your .profile:
google-gif-for-cli	File/URL	Executing as a Python module is also supported:
google-gif-for-cli	Query  Tenor's GIF API  tenor-gif-api 	Queries to Tenor's GIF API can also be performed:
google-gif-for-cli	Change max width/height	The default number of rows and columns may be too large and result in line wrapping
google-gif-for-cli	Change max width/height	If you know your terminal size, you can control the output size with the following options:Set to current terminal size:Note: Generated ASCII art is cached based on the number of rows and columns, so running that command after resizing your terminal window will likely result in the ASCII Art being regenerated.
google-gif-for-cli	Loop forever	Use CTRL + c to exit.
google-gif-for-cli	Export/Share	Want to share your generated ASCII Art outside a CLI env  e.g
google-gif-for-cli	Export/Share	social media ?
google-gif-for-cli	Help	See more generation/display options:
google-gif-for-cli	About Tenor	Tenor is the API that delivers the most relevant GIFs for any application, anywhere in the world
google-gif-for-cli	About Tenor	We are the preferred choice for communication products of all types and the fastest growing GIF service on the market.Check out our API Docs:    tenor-gif-api 
google-gif-for-cli	Testing	With coverage:
google-gif-for-cli	Development	To reuse the shared Git hooks in this repo, run:
google-gif-for-cli	Troubleshooting	If you get an error like the following:Chances are gif-for-cli was installed in a location not on your PATH
google-gif-for-cli	Troubleshooting	This can happen if running gif-for-cli in your .bashrc, but it was installed into ~/.local/bin, and that directory hasn't been added to your PATH
google-gif-for-cli	Troubleshooting	You can either specify the full path to gif-for-cli to run it, or add its location to your $PATH.
google-gif-for-cli	Module Usage	To add gifs to your cli tool include gif-for-cli import and call execute.import osimport sysfrom gif_for_cli.execute import executeexecute os.environ,
google-gif-for-cli	Disclaimer	This is not an officially supported Google product
google-gif-for-cli	Disclaimer	tenor-home :  tenor-gif-api : 
google-gin-config	Gin	Gin provides a lightweight configuration framework for Python, based ondependency injection
google-gin-config	Gin	Functions or classes can be decorated with@gin.configurable, allowing default parameter values to be supplied from aconfig file  or passed via the command line  using a simple but powerful syntax.This removes the need to define and maintain configuration objects  e.g.protos , or write boilerplate parameter plumbing and factory code, while oftendramatically expanding a project's flexibility and configurability.Gin is particularly well suited for machine learning experiments  e.g
google-gin-config	Gin	usingTensorFlow , which tend to have many parameters, often nested in complex ways.**Authors**: Dan Holtmann-Rice, Sergio Guadarrama, Nathan SilbermanThis is not an official Google product.
google-gin-config	Table of Contents	 TOC 
google-gin-config	Basic usage	This section provides a high-level overview of Gin's main features, orderedroughly from "basic" to "advanced"
google-gin-config	Basic usage	More details on these and other features canbe found in the  user guide 
google-gin-config	Basic usage	user guide : 
google-gin-config	Setup	Install Gin with pip:At its most basic, Gin can be seen as a way of providing or changing defaultvalues for function or constructor parameters
google-gin-config	Setup	To make a function's parameters"configurable", Gin provides the gin.configurable decorator:values are supported as value  numbers, strings, lists, tuples, dicts 
google-gin-config	Setup	Oncethe config file has been parsed by Gin  gin.parse_config_file , any futurecalls to dnn will use the Gin-specified value for layer_sizes  unless avalue is explicitly provided by the caller .Classes can also be marked as configurable, in which case the configurationapplies to constructor parameters:@gin.configurableclass DNN object :  # Constructor parameters become configurable
google-gin-config	Setup	 def __init__ self,Within a config file, the class name is used when binding values to constructorgin.configurable decorator and a call to one of Gin's parsing functions.
google-gin-config	Passing functions, classes, and instances  "configurable references" 	In addition to accepting Python literal values, Gin also supports passing otherGin-configurable functions or classes
google-gin-config	Passing functions, classes, and instances  "configurable references" 	In the example above, we might want tochange the activation_fn parameter
google-gin-config	Passing functions, classes, and instances  "configurable references" 	If we have registered, say tf.nn.tanhwith Gin  see  registering external functions  external configurables  , we canpass it to activation_fn by referring to it as @tanh  or @tf.nn.tanh :references work for classes as well:class constructor
google-gin-config	Passing functions, classes, and instances  "configurable references" 	Gin supports "evaluating" configurable references via the@name   syntax
google-gin-config	Passing functions, classes, and instances  "configurable references" 	For example, say we wanted to use the class form of DNN fromabove  which implements __call__ to "behave" like a function  in the followingPython code:parameters must be provided via Gin
google-gin-config	Passing functions, classes, and instances  "configurable references" 	The call to the function or constructortakes place *just beforepassed, In the above example, this would be just before build_model is called.The result is not cached, so a new DNN instance will be constructed for eachcall to build_model
google-gin-config	Passing functions, classes, and instances  "configurable references" 	external configurables : 
google-gin-config	Configuring the same function in different ways  "scopes" 	What happens if we want to configure the same function in different ways? Forinstance, imagine we're building a GAN, where we might have a "generator"network and a "discriminator" network
google-gin-config	Configuring the same function in different ways  "scopes" 	We'd like to use the dnn function aboveto construct both, but with different parameters:set of bindings for a given function or class
google-gin-config	Configuring the same function in different ways  "scopes" 	In both bindings and references,the "scope name" precedes the function name, separated by a "scope_name/function_name :
google-gin-config	Inside "config.gin"	run_training.train_input_fn = @train/input_fnrun_training.eval_input_fn = @eval/input_fninput_fn.batch_size = 64  # Shared by both train and eval...train/input_fn.file_pattern = ...eval/input_fn.file_pattern = ...run_training.estimator = @tf.estimator.Estimator  tf.estimator.Estimator.model_fn = @build_model_fn  build_model_fn.network_fn = @dnndnn.layer_sizes =  1024, 512, 256 build_model_fn.loss_fn = @tf.losses.sparse_softmax_cross_entropybuild_model_fn.optimize_loss_fn = @optimize_lossoptimize_loss.optimizer_cls = @tf.train.MomentumOptimizerMomentumOptimizer.momentum = 0.9optimize_loss.learning_rate = 0.01Note that it is straightforward to switch between different network functions,optimizers, datasets, loss functions, etc
google-gin-config	Inside "config.gin"	via different config files.
google-gin-config	Full hierarchical configuration	The greatest degree of flexibility and configurability in a project is achievedby writing small modular functions and "wiring them up" hierarchically via possibly scoped  references
google-gin-config	Full hierarchical configuration	For example, this code sketches a generic trainingsetup that could be used with the tf.estimator.Estimator API:@gin.configurabledef build_model_fn network_fn, loss_fn, optimize_loss_fn :  def model_fn features, labels :  return model_fndef optimize_loss loss, optimizer_cls, learning_rate :  optimizer = optimizer_cls learning_rate   return optimizer.minimize loss def input_fn file_pattern, batch_size, ..
google-gin-config	Full hierarchical configuration	:  ...def run_training train_input_fn, eval_input_fn, estimator, steps=1000 :  estimator.train train_input_fn, steps=steps   estimator.evaluate eval_input_fn   ...In conjunction with suitable  external configurables  to register TensorFlowfunctions/classes  e.g., Estimator and various optimizers , this could beconfigured as follows:
google-gin-config	Additional features	Additional features described in more detail in the  user guide  include: macros :  imports :  includes :  TensorBoard integration :  modules : 
google-gin-config	Best practices	At a high level, we recommend using the minimal feature set required to achieveyour project's desired degree of configurability
google-gin-config	Best practices	Many projects may onlyrequire the features outlined in sections 2 or 3 above
google-gin-config	Best practices	Extreme configurabilitycomes at some cost to understandability, and the tradeoff should be carefullyevaluated for a given project.Gin is still in alpha development and some corner-case behaviors may bechanged in backwards-incompatible ways
google-gin-config	Best practices	We recommend the following bestIn short, use Gin responsibly : 
google-gin-config	Syntax quick reference	A quick reference for syntax unique to Gin  which otherwise supportsnon-control-flow Python syntax, including literal values and linecontinuations 
google-gin-config	Syntax quick reference	Note that where function and class names are used, these mayinclude a dotted module name prefix  some.module.function_name 
google-gin-config	Syntax quick reference	     
google-git-appraise-eclipse	Google Appraise Eclipse Plugin	Git Appraise is a code review system that uses git-notes as a data store
google-git-appraise-eclipse	Google Appraise Eclipse Plugin	The Google Appraise Eclipse Plugin supports an Appraise-based code reveiw workflow inside Eclipse
google-git-appraise-eclipse	Google Appraise Eclipse Plugin	It is implemented as a Mylyn Task Repository connector and leverages the Egit plugin.
google-git-appraise-eclipse	Screenshots	Displaying a single review, with details and highlighted diffs for the changed files:! Displaying a single review  ./doc/screenshots/Review-Display.png?raw=true Adding an inline comment to the current review:! Adding an inline comment  /doc/screenshots/New-Line-Comment-Menu.png?raw=true Displaying the comments in a review:! Displaying the comments in a review  /doc/screenshots/Review-Display-With-Comments.png?raw=true 
google-git-appraise-eclipse	Prerequisites	Note that the Appraise workflow model expects you to request a review from a working branch, and the Eclipse Plugin assumes that you currently have that branch checked out
google-git-appraise-eclipse	Prerequisites	 You can confirm this by looking at the project node name in the Package Explorer
google-git-appraise-eclipse	Prerequisites	The code review workflow for Appraise in Eclipse is based around Mylyn's task activation model.Releases will be tagged in the repository and an announcement will be made on our Github page
google-git-appraise-eclipse	Prerequisites	We have no strict timetable but aim to do this every three months or whenever a more urgent need arises.
google-git-appraise-eclipse	Roadmap	Import the following projects into Eclipse:To build the update site archive  site/target/site_assembly.zip :mvn packagePlease send pull requests.
google-git-appraise-web	Git-Appraise Web UI	This repository contains a read-only web UI for git-appraise reviews.
google-git-appraise-web	Try it now	You can see a live demo of the UI running  here 
google-git-appraise-web	Disclaimer	This is not an official Google product.
google-git-appraise-web	Prerequisites	Building requires the Go tools and GNU Make
google-git-appraise-web	Prerequisites	Running the built binary requires the git command line tool.
google-git-appraise-web	Building the source code	Assuming you have the  Go tools installed  runthe following command:
google-git-appraise-web	Manual steps	Assuming you have not run the above command, first checkout the code from the git repo:Build the binary:
google-git-appraise-web	Running the application	Binary is placed into ${GOPATH}/bin:The tool requires that it be started in a directory that contains at least one git repo, and it shows thereviews from every git repo under that directory.The UI is a webserver which defaults to listening on port To use a different port, pass it as an argument to the "--port" flag:
google-git-appraise	Distributed Code Review For Git	  This repo contains a command line tool for performing code reviews on git
google-git-appraise	Overview	This tool is a *distributedBy "distributed", we mean that code reviews are stored inside of the repositoryas git objects
google-git-appraise	Overview	Every developer on your team has their own copy of the reviewhistory that they can push or pull
google-git-appraise	Overview	When pulling, updates from the remoterepo are automatically merged by the tool.This design removes the need for any sort of server-side setup
google-git-appraise	Overview	As a result,this tool can work with any git hosting provider, and the only setup requiredis installing the client on your workstation.
google-git-appraise	Installation	Assuming you have the  Go tools installed  runthe following command:Then, either make sure that ${GOPATH}/bin is in your PATH, or explicitly add the"appraise" git alias by running the following command.
google-git-appraise	Requirements	This tool expects to run in an environment with the following attributes: The git command line tool is installed, and included in the PATH
google-git-appraise	Requirements	The tool is run from within a git repo
google-git-appraise	Requirements	The git command line tool is configured with the credentials it needs to
google-git-appraise	Usage	Requesting a code review:Pushing code reviews to a remote:Pulling code reviews from a remote:Listing open code reviews:Showing the status of the current review, including comments:Showing the diff of a review:Commenting on a review:Accepting the changes in a review:Submitting the current review:A more detailed getting started doc is available  here  docs/tutorial.md .
google-git-appraise	Metadata	The code review data is stored in  git-notes using the formats described below
google-git-appraise	Metadata	Each item stored is written as a singleline of JSON, and is written with at most one such item per line
google-git-appraise	Metadata	This allowsthe git notes to be automatically merged using the "cat\_sort\_uniq" strategy.Since these notes are not in a human-friendly form, all of the refs used totrack them start with the prefix "refs/notes/devtools"
google-git-appraise	Metadata	This helps make itclear that these are meant to be read and written by automated tools.When a field named "v" appears in one of these notes, it is used to denotethe version of the metadata format being used
google-git-appraise	Metadata	If that field is missing, thenit defaults to the value 0, which corresponds to this initial version of the
google-git-appraise	Code Review Requests	Code review requests are stored in the "refs/notes/devtools/reviews" ref, andannotate the first revision in a review
google-git-appraise	Code Review Requests	They must conform to the request schema  schema/request.json .If there are multiple requests for a single commit, then they are sorted bytimestamp and the final request is treated as the current one
google-git-appraise	Code Review Requests	This sortingshould be done in a stable manner, so that if there are multiple requestswith the same timestamp, then the last such request in the note is treatedas the current one.This design allows a user to update a review request by re-running thegit appraise request command.
google-git-appraise	Continuous Integration Status	Continuous integration build and test results are stored in the"refs/notes/devtools/ci" ref, and annotate the revision that was built andtested
google-git-appraise	Continuous Integration Status	They must conform to the  ci schema  schema/ci.json .
google-git-appraise	Robot Comments	Robot comments are comments generated by static analysis tools
google-git-appraise	Robot Comments	These arestored in the "refs/notes/devtools/analyses" ref, and annotate the revision.They must conform to the  analysis schema  schema/analysis.json .
google-git-appraise	Review Comments	Review comments are comments that were written by a person rather than by amachine
google-git-appraise	Review Comments	These are stored in the "refs/notes/devtools/discuss" ref, andannotate the first revision in the review
google-git-appraise	Review Comments	They must conform to the comment schema  schema/comment.json .
google-git-appraise	Libraries	Please see  the CONTRIBUTING file  CONTRIBUTING.md  for information on contributing to Git Appraise.
google-git-phabricator-mirror	Git/Phabricator Mirror	This repo contains code that automatically mirrors source code metadata betweengit-notes and Phabricator.
google-git-phabricator-mirror	Setup	This tool expects to run in an environment with the following attributes: The "arcanist" command line tool is installed and included in the PATH
google-git-phabricator-mirror	Setup	A ".arcrc" file is located where arcanist will find it, specifies a URL for The current working directory contains a clone of every git repo that needs The git command line tool is installed, and included in the PATH
google-git-phabricator-mirror	Setup	The git command line tool is configured with the credentials it needs to The "mysql" command line tool is installed, and has been preconfigured with
google-git-phabricator-mirror	Installation	Assuming you have the  Go tools installed  run the following command:
google-git-phabricator-mirror	Metadata	The source code metadata is stored in git-notes, using the formats described here 
google-git-presubmit-linter	Git Presubmit Linter	Git Presubmit Linter is a project which contains a variety of QOL toolsto help developers maintain high-quality, consistent commits intheir projects.The project contains a collection of shell scripts which can beconfigured and run during a pre-submit task
google-git-presubmit-linter	Git Presubmit Linter	The scripts will reportpotential issues found in the commit.This is not an officially supported Google product.
google-git-presubmit-linter	Get Started	You can easily include this project into your CI system whenit runs:There are many rules that are available in the rules/ directory.Each can be accessed in a shell script by piping a string into thescript and providing additional parameters.Each rule will either complete without issue or return an errorcode
google-git-presubmit-linter	Get Started	In a presubmit script, you can set errors to exit thescript early.set -e
google-git-presubmit-linter	Verb Tense	This rule is used to verify that a commit message is written in agiven verb tense, such as present tense or past tense.git log -1 --pretty=%B | ./rules/verb-tense.sh If the commit message starts with a present tense verb, like:"**Adds new field**"The script succeeds
google-git-presubmit-linter	Verb Tense	However, if it is in a different tense like below,the script will exit early with a non-zero status."**I have added a new field**"This supports present, imperative, and past tense verbs.
google-git-presubmit-linter	No Second Line	This rule verifies that the second line in a commit message isempty, a common style in git.git log -1 --pretty=%B | ./rules/no-second-line.shThe script succeeds if the second line of the commit message isempty, and it fails otherwise with a non-zero status.
google-git-presubmit-linter	Line Length	This rule verifies that every line in a commit message or in thecode diff is under a certain line length
google-git-presubmit-linter	Line Length	Style guides oftenwant code to be a maximum length per line, and git commitmessages are typically short as well.It can be used by passing a string and including the maximumgit diff HEAD~1 --pretty=%B | ./rules/line-length.sh **Note**: Git diffs will add in additional spacing to each line.To verify the line length, you will need to add 2 to your maximum,eg
google-git-presubmit-linter	Line Length	A style guide with 80 characters max per line should use 82.
google-git-presubmit-linter	First Line Length	Sometimes you may only want to check the length of the first line ofa message only, or may want a different maximum
google-git-presubmit-linter	First Line Length	This can be implementedby piping your commit message into the rule using head.git log -1 --pretty=%B | head -n1 | ./rules/line-length.sh 
google-git-presubmit-linter	Contains String	This rule verifies that a certain string appears in a commit message.Style guides may require developers to include a description of a test,or an issue number.It can be used by including the string you want to identify
google-git-presubmit-linter	Contains String	This scriptwill pass if the string is exactly matched anywhere on any line of thegit log -1 --pretty=%B | ./rules/has-string.sh To require contributors to mention tests, you can use:git log -1 --pretty=%B | ./rules/has-string.sh "Test:"
google-git-presubmit-linter	Searching for edited files	If you want to check whether a certain file has been modified such as aCHANGELOG file, you can instead run:git diff HEAD~1 --name-only | ./rules/has-string.sh "CHANGELOG"
google-git-presubmit-linter	Contains Pattern	Sometimes simple string matching is not enough
google-git-presubmit-linter	Contains Pattern	This rule will checkevery line for the instance of a regular expression.git log -1 --pretty=%B | head -n1 | ./rules/has-pattern.sh If a style guide requires commit messages to start with a capitalletter, you can use:git log -1 --pretty=%B | head -n1 | ./rules/has-pattern.sh "^ A-Z "
google-git-presubmit-linter	Does not contain string	Style guides may ban the use of certain notes that developers put intocode such as "TODO", "FIXME", "NOTE", etc
google-git-presubmit-linter	Does not contain string	This rule will check each lineand exit with a non-zero status if a given string is found.git log -1 --pretty=%B | ./rules/block-string.sh 
google-git-presubmit-linter	Trailing Whitespace	This rule verifies that no changed line has any trailing whitespace.Style guides may require this to be removed.git diff HEAD~1 --pretty=%B | ./rules/trailing-whitespace.sh
google-git-presubmit-linter	Tools	This repo also contains tools to be run during a presubmit task
google-git-presubmit-linter	Tools	These donot verify the git metadata or other project details, but can produceuseful artifacts that may be part of the presubmit process.
google-git-presubmit-linter	Changelog	This tool will generate a changelog between two points in your git history ina Markdown format, with the summary of each commit prepended by an asterisk../tools/changelog.sh v1.0.0 v1.0.1 
google-git-presubmit-linter	License	See LICENSE.
google-git-pull-request-mirror	Mirror Github Pull Requests into the git-appraise formats	This repo contains a tool to mirror pull requests metadata into the corresponding gitrepository using a feature of git called  git-notes The format written is the one defined by the git-appraise code review system  so pullrequests that are mirrored using this tool can be reviewed using git-appraise.
google-git-pull-request-mirror	Organization	There are 3 packages in this repo:
google-git-pull-request-mirror	The Batch Tool	The batch tool performs a single pass of reading all of the pull request metadata fora repo, and mirroring it into your local clone of that repo.The tool can support running unauthenticated, but will be extremely rate-limited, soit is better if you create a  personal access token with the repo scope, for it to use.This app allows users to continually update their git repositories with githubmetadata  pull requests and build statuses 
google-git-pull-request-mirror	The Batch Tool	It runs in a managed VM in anon-default module, and should expose a web interface atIt uses the app engine datastore to store its configuration.To deploy:
google-git-sync-changes	Collaborative editing for git repositories	This repository implements shared worktrees for git.This is done by storing the worktree state in the repository itself.The result is that anyone with push permissions on the repositorycan sync their local worktree with that shared worktree, and thenview and edit pending changes prior to committing them.
google-git-sync-changes	Disclaimer	This is not an official Google product.
google-git-sync-changes	Installation	To install, simply copy the git-sync-changes script to somewherein your PATH.
google-git-sync-changes	Usage	The shared worktree functionality is implemented with a new gitcommand called git-sync-changes
google-git-sync-changes	Usage	Running that command will syncpending changes between your local worktree and the shared worktree,leaving the two in the same state.The command takes two optional parameters, the remote repositorystoring the shared worktree, and the name of that tree.For example:in the remote named origin.If the worktree name is not specified, the tool will default toa worktree named after the current user and the current checked-outIf the remote is not specified, then it defaults to origin.Each invocation of the command only performs a single sync, so tokeep your worktree continuously updated, run it periodically.For instance, you could run the command in a loop with something
google-github-issue-mover	Issue Mover for GitHub	This tool make it easy to migrate issues between repos: both client side and server side code  and is hosted on  Google App Engine Managed VM For a walk through of the code and backend deployment options please read  CODE_WALKTHROUGH  CODE_WALKTHROUGH.md 
google-github-issue-mover	Usage	The tool is hosted online at  github-issue-mover.appspot.com It looks like this:
google-github-issue-mover	How to use	You can copy paste full GitHub URLs
google-github-issue-mover	How to use	For instance you can copy pasteinto the "Issue to Move" text field
google-github-issue-mover	How to use	It will get automatically transformed to the _short_ GitHub URL:The tool will extract some information about the issue if it's accessible to your user:You can do the same for the "Destination Repo" text field and copy paste:It will get automatically transformed to the _short_ GitHub URL for repos:and some information will get extracted as well:Once existing issue and repo have been set you can start the move process:This will create a new issue which is a copy of the original one, with mentions of every users who commented on the bug
google-github-issue-mover	How to use	The two issues will also references themselves:
google-github-issue-mover	Disclaimer	Even though a lot of contributors are working for Google this is not an official Google Product.This is an open-source sample application written in Dart and runable on Google App Engine and Google Compute Engine with a running test instance hosted on App Engine.
google-github-issue-mover	License	 Apache 2.0  LICENSE Copyright 2014 Google Inc
google-github-owners-bot	Github Owners Bot	A web service that suggests approvers for a GitHub pull request based on OWNERSfiles and enforces reviews by OWNERS as a GitHub status check.
google-github-owners-bot	Deploying	This web server assumes it is running on Google Compute Engine  GCE .A few Environment Variables need to be setup on the GCE start-up script
google-github-owners-bot	Deploying	See gce/startup-script.sh 
google-github-owners-bot	GITHUB_ACCESS_TOKEN	To Generate a GITHUB_ACCESS_TOKEN see  creating an access token article Access Token will need public_repo and repo:status scopes.
google-github-owners-bot	GitHub Webhook events	This is not an official Google product.
google-gitiles	Gitiles 	Gitiles is a simple repository browser for Git repositories, built on JGit
google-gitiles	Gitiles 	Itsguiding principle is simplicity: it has no formal access controls, no writeaccess, no fancy Javascript, etc.Gitiles automatically renders *.md Markdown files into HTML for simplifieddocumentation
google-gitiles	Gitiles 	Refer to the  Markdown documentation  /Documentation/markdown.md for details.
google-gitiles	Configuration	Gitiles is configurable in a git-style configuration file namedgitiles.config
google-gitiles	Configuration	Refer to the  configuration documentation  /Documentation/config.md for details.
google-gitiles	Bugs	Use the  issue tracker at github  tofile bugs.
google-gitiles	Contributing to Gitiles	Please refer to the  Developer Guide  /Documentation/developer-guide.md .
google-gitprotocolio	gitprotocolio	A Git protocol parser written in Go.This is more like an experimental project to better understand the protocol.This is not an official Google product  i.e
google-gitprotocolio	gitprotocolio	a 20% project .
google-gitprotocolio	Background	Git protocol is defined in Documentation/technical/pack-protocol.txt This is not a complete definition
google-gitprotocolio	Background	Also, a transport specific spec Documentation/technical/http-protocol.txt is not complete
google-gitprotocolio	Background	This project was started so that these upstream protocol specbecomes more accurate
google-gitprotocolio	Background	To verify the written syntax is accurate, this projectincludes a Git protocol parser written in Go, and have end-to-end test suites.This makes it easy to write a test case for Git client
google-gitprotocolio	Background	Currently the test casesare run against the canonical Git implementation, but this can be extended torun against JGit, etc.
google-gitprotocolio	Background	Also it makes it easy to test an attack case
google-gitprotocolio	Background	With thislibrary, one can write an attack case like git-bomb  against Git protocol by producinga request that is usually not produced by a sane Git client
google-gitprotocolio	Background	Protocol propertiescan also be checked
google-gitprotocolio	Background	For example, it's possible to write a test to check validrequest/response's prefixes are not a valid request/response
google-gitprotocolio	Background	This propertymakes sure a client won't process an incomplete response thinking it's complete.
google-gjstest	Example #	Below is an example of a basic test for a class called UserInfo, which acceptsa database lookup function in its constructor.function UserInfoTest   {  // Each test function gets its own instance of UserInfoTest, so tests can  // use instance variables to store state that doesn't affect other tests
google-gjstest	Example #	 // There's no need to write a tearDown method, unless you modify global  // state
google-gjstest	Example #	 //  // Create an instance of the class under test here, giving it a mock  // function that we also keep a reference to below
google-gjstest	Example #	 this.getInfoFromDb_ = createMockFunction  ;  this.userInfo_ = new UserInfo this.getInfoFromDb_ ;registerTestSuite UserInfoTest ;addTest UserInfoTest, function formatsUSPhoneNumber   {  // Expect a call to the database function with the argument 0xdeadbeef
google-gjstest	Example #	When  // the call is received, return the supplied string
google-gjstest	Example #	 expectCall this.getInfoFromDb_  0xdeadbeef   expectEq ' 650  253-0000', this.userInfo_.getPhoneForId 0xdeadbeef  ;} ;addTest UserInfoTest, function returnsLastNameFirst   {  expectCall this.getInfoFromDb_  0xdeadbeef   expectEq 'Doe, John', this.userInfo_.getNameForId 0xdeadbeef  ;} ;The test's output is clean and readable:
google-gjstest	Getting Started #	See  Installing    for information about installing Google JS Test on yoursystem
google-gjstest	Getting Started #	Once you've done so,  Getting started  started  will take you through anend to end example of using Google JS Test
google-gjstest	Getting Started #	While writing your own tests, youcan use the  Matchers    and  Mocking    pages for reference
google-gjstest	Getting Started #	Installing :  started :  Matchers :  Mocking : 
google-glazier	Glazier	Glazier is a tool for automating the installation of the Microsoft Windowsoperating system on various device platforms.Table of contentsGlazier was created with certain principles in mind.__Text-based & Code-driven__With Glazier, imaging is configured entirely via text files
google-glazier	Glazier	This allowstechnicians to leverage source control systems to maintain and develop theirimaging platform
google-glazier	Glazier	By keeping imaging configs in source control, we gain peerreview, change history, rollback/forward, and all the other benefits normallyreserved for writing code.Reuse and templating allows for config sharing across multiple image types.Configs can be consumed by unit tests, build simulators, and other helperinfrastructure to build a robust, automated imaging pipeline.Source controlled text makes it easy to integrate configs across multiplebranches, making it easy to QA new changes before releasing them to the generalGlazier distributes all data over HTTPS, which means you can use as simple or asadvanced of a distribution platform as you need
google-glazier	Glazier	Run it from a simple free webserver or a large cloud-based CDN.Proxies make it easy to accelerate image deployment to remote sites.Glazier makes it simple to extend the installer by writing a bit of Python orPowershell code.
google-glazier	Contact	We have a public discussion list at glazier-discuss@googlegroups.com 
google-glazier	Disclaimer	This is not an official Google product.
google-glslang	Dependencies	The following steps assume a Bash shell
google-glslang	Dependencies	On Windows, that could be the Git Bashshell or some other shell of your choosing.
google-glslang	1  Check-Out this project	or wish to invoke -Os to reduce SPIR-V size from HLSL or GLSL, installspirv-tools with this:Assume the source directory is $BUILD_DIR
google-glslang	1  Check-Out this project	First ensure the build directory exists, then navigate to it:
google-glslang	for Windows:	ctest -C {Debug|Release|RelWithDebInfo|MinSizeRel}
google-glslang	"Release"  for --config  could also be "Debug", "MinSizeRel", or "RelWithDebInfo"	If using MSVC, after running CMake to configure, use theConfiguration Manager to check the INSTALL project.
google-glslang	If you need to change the GLSL grammar	The grammar in glslang/MachineIndependent/glslang.y has to be recompiled withbison if it changes, the output files are committed to the repo to avoid everydeveloper needing to have bison configured to compile the project when grammarchanges are quite infrequent
google-glslang	If you need to change the GLSL grammar	For windows you can get binaries from GnuWin32  bison-gnu-win32 .The command to rebuild is:-------Right now, there are two test harnesses existing in glslang: one is  GoogleTest  gtests/ , one is the  runtests script  Test/runtests 
google-glslang	If you need to change the GLSL grammar	The formerruns unit tests and single-shader single-threaded integration tests, whilethe latter runs multiple-shader linking tests and multi-threaded tests.
google-glslang	Running tests	The  runtests script  Test/runtests  requires compiled binaries to beinstalled into $BUILD_DIR/install
google-glslang	Running tests	Please make sure you have supplied thecorrect configuration to CMake  using -DCMAKE_INSTALL_PREFIX  when building;otherwise, you may want to modify the path in the runtests script.Running Google Test-backed tests:cd $BUILD_DIR
google-glslang	 which gives more fine-grained control like filtering :	Running runtests script-backed tests:Test results should always be included with a pull request that modifiesIf you are writing unit tests, please use the Google Test framework andplace the tests under the gtests/ directory.Integration tests are placed in the Test/ directory
google-glslang	 which gives more fine-grained control like filtering :	It contains test inputand a subdirectory baseResults/ that contains the expected results of thetests
google-glslang	 which gives more fine-grained control like filtering :	 Both the tests and baseResults/ are under source-code control.Google Test runs those integration tests by reading the test input, compilingthem, and then compare against the expected results in gtests/*.FromFile.cpp source files
google-glslang	 which gives more fine-grained control like filtering :	glslangtests provides a command-lineoption --update-mode, which, if supplied, will overwrite the golden filesunder the baseResults/ directory with real output from that invocation.For more information, please check gtests/ directory's README  gtests/README.md .For the localResults/ directory and diff them against the baseResults/.When you want to update the tracked test results, they need to becopied from localResults/ to baseResults/
google-glslang	 which gives more fine-grained control like filtering :	 This can be done bythe bump shell script.You can add your own private list of tests, not tracked publicly, by usinglocaltestlist to list non-tracked tests
google-glslang	 which gives more fine-grained control like filtering :	 This is automatically readby runtests and included in the diff and bump process.Programmatic InterfacesAnother piece of software can programmatically translate shaders to an ASTusing one of two different interfaces:
google-glslang	C++ Class Interface  new, preferred 	This interface is in roughly the last 1/3 of ShaderLang.h
google-glslang	C++ Class Interface  new, preferred 	 It is in theglslang namespace and contains the following.const charconst charbool InitializeProcess  ;void FinalizeProcess  ;class TShaderclass TProgramSee ShaderLang.h and the usage of it in StandAlone/StandAlone.cpp for more
google-glslang	C Functional Interface  orignal 	This interface is in roughly the first 2/3 of ShaderLang.h, and referred toas the Sh*   interface, as all the entry points start Sh.The Sh*   interface takes a "compiler" call-back object, which it calls afterbuilding call back that is passed the AST and can then execute a backend on it.The following is a simplified resulting run-time call stack:warning/error and other options for controlling compilation.Basic Internal Operation  in MachineIndependent/Scan.cpp
google-glslang	C Functional Interface  orignal 	 There is currently no use of flex
google-glslang	C Functional Interface  orignal 	 the back-end; the intermediate representation stands on its own
google-glslang	C Functional Interface  orignal 	 The tree is built by the grammar productions, many of which are  offloaded into ParseHelper.cpp, and by Intermediate.cpp
google-glslang	C Functional Interface  orignal 	 original program, and to have efficient transfer of the result from  parsing to the back-end
google-glslang	C Functional Interface  orignal 	 In the AST, constants are propogated and  folded, and a very small amount of dead code is eliminated
google-glslang	C Functional Interface  orignal 	 lists all global symbols
google-glslang	C Functional Interface  orignal 	 object code representation
google-glslang	C Functional Interface  orignal 	 There is an example of how to do this  in MachineIndependent/intermOut.cpp
google-glslang	C Functional Interface  orignal 	 of individual container/contents just few cycles and deallocation free
google-glslang	C Functional Interface  orignal 	 This pool is popped after the AST is made and processed
google-glslang	C Functional Interface  orignal 	cmake :  python :  bison :  googletest :  bison-gnu-win32 :  master-tot-release : 
google-gnd-android	Ground for Android	Ground is a map-centric data collection platform for occasionallyconnected devices.This is not an officially supported Google product; it is currentlybeing developed by volunteers on a best-effort basis.The project is currently undergoing major architectural and UI changes.Please check back periodically for updates
google-gnd-android	Ground for Android	The stable demo version isin branch  prototype 
google-gnd-android	Add Google Maps API Key s 	Create google_maps_api.xml files in gnd/src/debug/res/values andgnd/src/release/res/values, replacing API_KEY with debug and release Google MapsAPI keys:registered with package name com.google.android.gnd in:Create a new Firebase project at:
google-gnd-cloud	Ground Cloud Components	Ground is a free, map-centric data collection platform for occasionally connected devices.This is not an officially supported Google product, and it is currently under development on best-effort basis
google-gnd-cloud	Ground Cloud Components	Please check back periodically for updates.This repo contains three main components, each in their own respective subdirectories:
google-gnxi	Summary	_Note_: These tools are intended for testing and as reference implementation of the protocol.These instructions will get you a copy of the project up and running on your local machine for development and testing purposes
google-gnxi	Summary	See Docker for instructions on how to test against network equipment.
google-gnxi	Prerequisites	Install __go__ in your system  Requires golang1.7+.
google-gnxi	Clone	Clone the project to your __go__ source folder:
google-gnxi	Running	To run the binaries: FAUCET  currently includes a  Dockerfile  to setup the environment that facilitates testing these tools against network equipment.
google-go-cloud	The Go Cloud Project	_Write once, run on any cloud ☁️_   travis  ! godoc   godoc The Go Cloud Project is an initiative that will allow application developers toseamlessly deploy cloud applications on any combination of cloud providers
google-go-cloud	The Go Cloud Project	Itdoes this by providing stable, idiomatic interfaces for common uses like storageand databases
google-go-cloud	The Go Cloud Project	Think database/sql for cloud products.A key part of the project is to also provide a code generator called Wire  Itcreates human-readable code that only imports the cloud SDKs for providers youuse
google-go-cloud	The Go Cloud Project	This allows Go Cloud to grow to support any number of cloud providers,without increasing compile times or binary sizes, and avoiding any side effectsfrom init   functions.Imagine writing this to read from blob storage  like Google Cloud Storage orS3 :of cloud-specific authorization, tracing, SDKs and all the other code requiredto make an application portable across cloud platforms
google-go-cloud	The Go Cloud Project	travis :  godoc : 
google-go-cloud	Installation instructions	compile but are not supported.
google-go-cloud	Samples	 samples/tutorial  tutorial  shows how to get started with the project byusing blob storage
google-go-cloud	Samples	samples/guestbook  guestbook  contains an example guestbook application  justlike it's 1999!  that can be run locally, on Google Cloud Platform or on AmazonWeb Services
google-go-cloud	Samples	The instructions take about 5 minutes to follow if runninglocally
google-go-cloud	Samples	If you want to see the guestbook app running on cloud resources, itwill take about 30 minutes to follow, and uses  Terraform to automatically provision the resources needed
google-go-cloud	Samples	tutorial :  guestbook : 
google-go-cloud	Project status	**This project is in alpha and is not yet suitable for production.**While in alpha, the API is subject to breaking changes.
google-go-cloud	Current features	Go Cloud provides generic APIs for:
google-go-cloud	Contributing	Thank you for your interest in contributing to Go Cloud! :heart:Everyone is welcome to contribute to Go Cloud, whether it's in the form of code,documentation, bug reports, feature requests, or anything else
google-go-cloud	Contributing	We encourage youto experiment with Go Cloud and make contributions to help evolve it to meetyour needs!The GitHub repository at  google/go-cloud  go-cloud  currently contains Google Cloud Platform  gcp  and  Amazon Web Services  aws  implementations asexamples to prove everything is working
google-go-cloud	Contributing	Unfortunately, we cannot support everycloud provider directly from the project.If you create a repository that implements the Go Cloud interfaces for othercloud providers, let us know!We would be happy to link to it here and give you a heads-up before making anybreaking changes.See  the contributing guide  ./CONTRIBUTING.md  for more details
google-go-cloud	Contributing	go-cloud :  gcp :  aws : 
google-go-cloud	Code of Conduct	This project is covered by a  Code of Conduct  ./CODE_OF_CONDUCT.md .
google-go-cmp	Package for equality of Go values	 ! GoDoc   godoc    travis This package is intended to be a more powerful and safer alternative toreflect.DeepEqual for comparing whether two values are semantically equal.The primary features of cmp are:  For example, an equality function may report floats as equal so long as they  are within some tolerance of each other
google-go-cmp	Package for equality of Go values	 that they define
google-go-cmp	Package for equality of Go values	 values, much like reflect.DeepEqual
google-go-cmp	Package for equality of Go values	Unlike reflect.DeepEqual, unexported  fields are not compared by default; they result in panics unless suppressed  by using an Ignore option  see cmpopts.IgnoreUnexported  or explicitly  compared using the AllowUnexported option.See the  GoDoc documentation  godoc  for more information.This is not an official Google product
google-go-cmp	Package for equality of Go values	godoc :  travis : 
google-go-cmp	Install	BSD  license : 
google-go-containerregistry	go-containerregistry	   ! GoDoc   ! Go Report Card   ! Code Coverage  
google-go-containerregistry	Introduction	This is a golang library for working with container registries
google-go-containerregistry	Introduction	It's largely based on the  Python library of the same name  but more hip and uses GitHub as the source of truth.
google-go-containerregistry	Tools	This repo hosts three tools built on top of the library.
google-go-containerregistry	ko	 ko  cmd/ko/README.md  is a tool for building and deploying golang applications to kubernetes.
google-go-containerregistry	crane	 crane  cmd/crane/doc/crane.md  is a tool for interacting with remote images and registries.
google-go-containerregistry	gcrane	 gcrane  cmd/gcrane/README.md  is a variant of crane that has richer output forthe ls subcommand and some basic garbage collection support.
google-go-github	go-github #	    ! Test Coverage    ! Discuss at go-github@googlegroups.com  go-github is a Go client library for accessing the  GitHub API v3   .go-github requires Go version 1.8 or greater.If you're interested in using the  GraphQL API v4   , the recommended library is shurcooL/githubv4   .
google-go-github	Usage ##	access different parts of the GitHub API
google-go-github	Usage ##	For example:client := github.NewClient nil // list all organizations for user "willnorris"orgs, _, err := client.Organizations.List context.Background  , "willnorris", nil Some API methods have optional parameters that can be passed
google-go-github	Usage ##	For example:client := github.NewClient nil // list public repositories for org "github"opt := &github.RepositoryListByOrgOptions{Type: "public"}repos, _, err := client.Repositories.ListByOrg context.Background  , "github", opt The services of a client divide the API into logical chunks and correspond tothe structure of the GitHub API documentation atNOTE: Using the  context  package, one can easilypass cancelation signals and deadlines to various services of the client forhandling a request
google-go-github	Usage ##	In case there is no context available, then context.Background  can be used as a starting point.For more sample code snippets, head over to the example  directory.
google-go-github	Authentication ###	The go-github library does not directly handle authentication
google-go-github	Authentication ###	Instead, whencreating a new client, pass an http.Client
google-go-github	Authentication ###	If you have an OAuth2 access token  for example, a  personalAPI token    , you can use it with the oauth2 library using:import "golang.org/x/oauth2"func main   {	ctx := context.Background  	ts := oauth2.StaticTokenSource 		&oauth2.Token{AccessToken: "..
google-go-github	Authentication ###	your access token ..."},	 	tc := oauth2.NewClient ctx, ts 	client := github.NewClient tc 	// list all repositories for the authenticated user	repos, _, err := client.Repositories.List ctx, "", nil Note that when using an authenticated Client, all calls made by the client willinclude the specified OAuth token
google-go-github	Authentication ###	Therefore, authenticated clients shouldalmost never be shared between different users.See the  oauth2 docs    for complete instructions on using that library.For API methods that require HTTP Basic Authentication, use the BasicAuthTransport GitHub Apps authentication can be provided by the  ghinstallation import "github.com/bradleyfalzon/ghinstallation"func main   {	// Wrap the shared transport for use with the integration ID 1 authenticating with installation ID 	itr, err := ghinstallation.NewKeyFromFile http.DefaultTransport, 1, 99, "2016-10-19.private-key.pem" 	if err != nil {		// Handle error.	}	// Use installation transport with client.	client := github.NewClient &http.Client{Transport: itr} 	// Use client...
google-go-github	Rate Limiting ###	GitHub imposes a rate limit on all API clients
google-go-github	Rate Limiting ###	Unauthenticated clients arelimited to 60 requests per hour, while authenticated clients can make up to5,000 requests per hour
google-go-github	Rate Limiting ###	The Search API has a custom rate limit
google-go-github	Rate Limiting ###	Unauthenticatedclients are limited to 10 requests per minute, while authenticated clientscan make up to 30 requests per minute
google-go-github	Rate Limiting ###	To receive the higher rate limit whenmaking calls that are not issued on behalf of a user,use UnauthenticatedRateLimitedTransport.The returned Response.Rate value contains the rate limit informationfrom the most recent API call
google-go-github	Rate Limiting ###	If a recent enough response isn'tavailable, you can use RateLimits to fetch the most up-to-date ratelimit data for the client.To detect an API rate limit error, you can check if its type is *github.RateLimitError:
google-go-github	Accepted Status ###	Some endpoints may return a 202 Accepted status code, meaning that theinformation required is not yet ready and was scheduled to be gathered onthe GitHub side
google-go-github	Accepted Status ###	Methods known to behave like this are documented specifyingthis behavior.To detect this condition of error, you can check if its type isThe GitHub API has good support for conditional requests which will helpprevent you from burning through your rate limit, as well as help speed up yourapplication
google-go-github	Accepted Status ###	go-github does not handle conditional requests directly, but isinstead designed to work with a caching http.Transport
google-go-github	Accepted Status ###	We recommend using for that.Learn more about GitHub conditional requests at
google-go-github	Creating and Updating Resources ###	All structs for GitHub resources use pointer values for all non-repeated fields.This allows distinguishing between unset fields and those set to a zero-value.Helper functions have been provided to easily create these pointers for string,bool, and int values
google-go-github	Creating and Updating Resources ###	For example:
google-go-github	Pagination ###	All requests for resource collections  repos, pull requests, issues, etc
google-go-github	Pagination ###	support pagination
google-go-github	Pagination ###	Pagination options are described in thegithub.Response struct.client := github.NewClient nil opt := &github.RepositoryListByOrgOptions{	ListOptions: github.ListOptions{PerPage: 10},// get all pages of resultsvar allRepos   *github.Repositoryfor {	repos, resp, err := client.Repositories.ListByOrg ctx, "github", opt 	if err != nil {		return err	}	allRepos = append allRepos, repos..
google-go-github	Pagination ###		if resp.NextPage == 0 {		break	}	opt.Page = resp.NextPageFor complete usage of go-github, see the full  package docs   
google-go-github	Pagination ###	GitHub API v3 :  oauth2 :  oauth2 docs :  personal API token :  package docs :  GraphQL API v4 :  shurcooL/githubv4 : 
google-go-github	Integration Tests ###	You can run integration tests from the test directory
google-go-github	Integration Tests ###	See the integration tests  README  test/README.md .
google-go-github	Roadmap ##	This library is being initially developed for an internal application atGoogle, so API methods will likely be implemented in the order that they areneeded by that application
google-go-github	Roadmap ##	You can track the status of implementation in this Google spreadsheet  roadmap 
google-go-github	Roadmap ##	 roadmap : 
google-go-github	Contributing ##	I would like to cover the entire GitHub API and contributions are of course always welcome
google-go-github	Contributing ##	Thecalling pattern is pretty well established, so adding new methods is relativelystraightforward
google-go-github	Contributing ##	See  CONTRIBUTING.md  CONTRIBUTING.md  for details.
google-go-github	Versioning ##	In general, go-github follows  semver  as closely as wecan for tagging releases of the package
google-go-github	Versioning ##	For self-contained libraries, theapplication of semantic versioning is relatively straightforward and generallyunderstood
google-go-github	Versioning ##	But because go-github is a client library for the GitHub API, whichitself changes behavior, and because we are typically pretty aggressive aboutimplementing preview features of the GitHub API, we've adopted the followingversioning policy:	or behavior of the API.	functionality, as well as any changes to preview functionality in the GitHub	API
google-go-github	Versioning ##	GitHub makes no guarantee about the stability of preview functionality,	so neither do we consider it a stable part of the go-github API.Preview functionality may take the form of entire methods or simply additionaldata returned from an otherwise non-preview method
google-go-github	Versioning ##	Refer to the GitHub APIdocumentation for details on preview functionality.
google-go-github	License ##	This library is distributed under the BSD-style license found in the  LICENSE  ./LICENSE 
google-go-intervals	go-intervals	go-intervals is a library for performing set operations on 1-dimensionalintervals, such as time ranges.Example usage:var tz = func   *time.Location {}  type span struct {week1 := &span{week2 := &span{week3 := &span{set := timespanset.Empty  fmt.Printf "Empty set: %s\n", set set.Insert week1.start, week3.end fmt.Printf "Week 1-3: %s\n", set set2 := timespanset.Empty  set2.Insert week2.start, week2.end set.Sub set2 fmt.Printf "Week 1-3 minus week 2: %s\n", set 
google-go-intervals	Disclaimer	This is not an official Google product.
google-go-jsonnet	go-jsonnet	  GoDoc :  GoDoc Widget :  Travis :  Travis Widget :  Coverage Status Widget :  Coverage Status : This an implementation of  Jsonnet  in pure Go
google-go-jsonnet	go-jsonnet	 It isfeature complete but is not as heavily exercised as the  Jsonnet C++implementation   Please try it out and giveThis code is known to work on Go 1.8 and above
google-go-jsonnet	go-jsonnet	We recommend always using the newest stable release of Go.
google-go-jsonnet	Build instructions	We are generating some helper classes on types by using  Do the following to regenerate these ifTo regenerate the standard library, do:
google-go-microservice-helpers	Go-Microservice-Helpers	**This is not an official Google product**A collection of handy snippets that simplify creation of GRPC servers andclients
google-go-microservice-helpers	Go-Microservice-Helpers	The provided helpers allow to create grpc endpoints with zipkindistributed tracing pre-configured; spawn http servers that serve both grpc andcommon http traffic; simplify golang crypto primitives to load EC keys.
google-go-pbmoney	go-pbmoney	This Go package contains utilities and arithmetic functions to work withGoogle’s  money.proto These utilities can be used to check validity and sign of the Money amount,as well as arithmetic operations like adding two Money messages.See  GoDoc  for packageSee  LICENSE  LICENSE  for licensing information and CONTRIBUTING.md  CONTRIBUTING.md  for contribution guidelines.This is not an official Google project.
google-go-querystring	go-querystring #	go-querystring is Go library for encoding structs into URL query parameters.**Build Status:*
google-go-querystring	Usage ##	URL using a struct that represents the URL query parameters
google-go-querystring	Usage ##	 You might do thisto enforce the type safety of your parameters, for example, as is done in the go-github    library.The query package exports a single Values   function
google-go-querystring	Usage ##	 A simple example:type Options struct {  Query   string url:"q"  ShowAll bool   url:"all"  Pageopt := Options{ "foo", true, 2 }v, _ := query.Values opt fmt.Print v.Encode    // will output: "q=foo&all=true&page=2" go-github : 
google-go-querystring	License ##	This library is distributed under the BSD-style license found in the  LICENSE  ./LICENSE 
google-go-tika	go-tika	 ! GoDoc   ! Go Report Card    go-tika is a Go client library and command line utility for accessing the  Apache Tika  Server API.go-tika requires Go version 1.8 or greater.See  the godoc  for more documentation on what resources are available.
google-go-tika	Command line client	The tika binary allows you to access the Apache Tika Server API from the command line, including downloading and starting the server in the background.To get the binary, run:If you already have a downloaded Apache Tika Server JAR, you can specify it with the -server_jar flag and it will not be re-downloaded.If you already have a running Apache Tika Server, you can use it by adding the -server_url flag and omitting the -server_jar and -download_version flags.See $GOPATH/bin/tika -h for usage instructions.
google-go-tika	License	This library is distributed under the Apache V2 License
google-go-tika	License	See the  LICENSE  ./LICENSE  file.
google-go-tika	Contributing	Please see the  CONTRIBUTING.md  ./CONTRIBUTING.md  file.
google-go-tika	Disclaimer	This is not an official Google product.
google-go-trace	Installation	To install this package, clone it under your $GOPATH/src/ directory.
google-go-trace	Usage	Package trace allows debugging programs via trace statements insertedin code
google-go-trace	Usage	Sometimes you need to see the sequence in which functions arecalled, and stepping through each manually with a debugger is not theappropriate answer
google-go-trace	Usage	If you've ever sprinkled "Printf" statementsthroughout your code to get insight into what's happenning, thispackage is strictly better: in addition to printing the messages youspecify, it denotes the structure of the stack by appropriatelyindenting them  and indenting the names of the callers , and printingtime stamps of when the trace calls occurred.Tracing is as simple as inserting a Trace statements where you want todo the tracing
google-go-trace	Usage	These statements will print all the currrent stackframes to the most recent previously traced stack frame that is on thecurrent stack.You may also pass printf-style arguments to Trace to displayinteresting state of your program:You should turn on tracing before the point in your program where youwant to trace
google-go-trace	Usage	If you want to trace a package init   function, turn iton there
google-go-trace	Usage	This function call is idempotent
google-go-trace	Usage	It is merely a shorthandfor setting Global.On:You may also turn off tracing at any point you wish:In fact, you may change many of the seetings of an active Tracerobject by modifying them directly
google-go-trace	Usage	For example, to make global traceronly trace the last reported goroutine, useWhile in most cases you'll want to use the trace.Global logger accessible directly and through the trace.Trace function , you canalso create custom Tracer objects and use them via Tracer.Trace  .Tracer is concurrency-safe
google-go-trace	Usage	When Trace   is called from a differentgoroutine than its previous call, it prints a warning about agoroutine switch
google-go-trace	Usage	Optionally, it can print just the current goroutinestack frame including frames recorded earlier  ifOnGoroutineSwitchPrintCurrentStack is set; default is false inGlobal , or print the entire history of the stack for this goroutine if OnGoroutineSwitchPrintStackHistory is set; default is true inGlobal .This is not an officially supported Google product.
google-go-webdav	Notice	This project has been deprecated, instead it is recommended you use the better supported:
google-go-webdav	Old README.md content	Implementation of a self-contained WebDAV server in Go
google-go-webdav	Old README.md content	It supports most features of RFC 4918; except for shared locks.Verified using the WebDAV litmus tests.To discuss this project, please see the  Google Group This is not an official Google product.
google-godepq	godepq	A utility for inspecting go import treesList the packages imported:Find a path between two packages:Track down how a test package is being pulled into a production binary:! example output  example.png List imported packages, searching only packages which name starts with "k8s.io/kubernetes":*Note: This is not an official Google product.*
google-goexpect	Options	All Spawn functions accept a variadic of type expect.Option , these are used for changingoptions of the Expecter.
google-goexpect	CheckDuration	The Go Expecter checks for new data every two seconds as default
google-goexpect	CheckDuration	This can be changed by usingthe CheckDuration func CheckDuration d time.Duration  Option.
google-goexpect	Verbose	The Verbose option is used to turn on/off verbose logging for Expect/Send statements.This option can be very useful when troubleshooting workflows since it will log every interactionwith the device.
google-goexpect	VerboseWriter	The VerboseWriter option can be used to change where the verbose session logs are written.Using this option will start writing verbose output to the provided io.Writer instead of the log default.See the  ExampleVerbose  code for an example of how to use this
google-goexpect	NoCheck	The Go Expecter periodically checks that the spawned process/ssh/session/telnet etc
google-goexpect	NoCheck	session is alive.This option turns that check off.
google-goexpect	DebugCheck	The DebugCheck option adds debugging to the alive Check done by the Expecter, this will start logging informationeverytime the check is run
google-goexpect	DebugCheck	Can be used for troubleshooting and debugging of Spawners.
google-goexpect	ChangeCheck	The ChangeCheck option makes it possible to replace the Spawner Check function with a brand new one.
google-goexpect	networkbit.ch	An  article  with some examples was written about goexpect on  networkbit.ch  
google-goexpect	Telnet	First we try to replicate the Telnet example from wikipedia as close as possible.+ username:+ password:+ %+ %*Error checking was omitted to keep the example short*package mainimport  	"flag"	"fmt"	"log"	"regexp"	"time"	"github.com/google/goexpect"	"github.com/google/goterm/term" const  	timeout = 10  var  	addr = flag.String "address", "", "address of telnet server" 	user = flag.String "user", "", "username to use" 	pass = flag.String "pass", "", "password to use" 	cmd  = flag.String "cmd", "", "command to run" 	userRE   = regexp.MustCompile "username:" 	passRE   = regexp.MustCompile "password:" 	promptRE = regexp.MustCompile "%"  func main   {	flag.Parse  	fmt.Println term.Bluef "Telnet 1 example"  	e, _, err := expect.Spawn fmt.Sprintf "telnet %s", *addr , -1 	if err != nil {		log.Fatal err 	}	defer e.Close  	e.Expect userRE, timeout 	e.Send *user + "\n" 	e.Expect passRE, timeout 	e.Send *pass + "\n" 	e.Expect promptRE, timeout 	e.Send *cmd + "\n" 	result, _, _ := e.Expect promptRE, timeout 	e.Send "exit\n" 	fmt.Println term.Greenf "%s: result: %s\n", *cmd, result  In essence to run and attach to a process the expect.Spawn ,  is used.The spawn returns and Expecter that can rund e.Expect and e.Send commands to match informationin the output and Send information in.*See the   example for a slightly more fleshed out version*
google-goexpect	FTP	For the FTP example we use the expect.Batch for the following interaction.+ username:+ password:+ ftp>+ ftp>+ ftp>'package mainimport  	"flag"	"fmt"	"log"	"time"	"github.com/google/goexpect"	"github.com/google/goterm/term" const  	timeout = 10  var  	addr = flag.String "address", "", "address of telnet server" 	user = flag.String "user", "", "username to use" 	pass = flag.String "pass", "", "password to use"  func main   {	flag.Parse  	fmt.Println term.Bluef "Ftp 1 example"  	e, _, err := expect.Spawn fmt.Sprintf "ftp %s", *addr , -1 	if err != nil {		log.Fatal err 	}	defer e.Close  	e.ExpectBatch   expect.Batcher{		&expect.BExp{R: "username:"},		&expect.BSnd{S: *user + "\n"},		&expect.BExp{R: "password:"},		&expect.BSnd{S: *pass + "\n"},		&expect.BExp{R: "ftp>"},		&expect.BSnd{S: "bin\n"},		&expect.BExp{R: "ftp>"},		&expect.BSnd{S: "prompt\n"},		&expect.BExp{R: "ftp>"},		&expect.BSnd{S: "mget *\n"},		&expect.BExp{R: "ftp>"},		&expect.BSnd{S: "bye\n"},	}, timeout 	fmt.Println term.Greenf "All done"  Using the expect.Batcher makes the standard Send/Expect interactions more compact and simpler to write.
google-goexpect	SSH	With the SSH login example we test out the  expect.Caser and the  Case Tags Also for this we'll use the Go Expect native  SSH Spawner instead of spawning a process.+ "Login: "+ "Password: "+ "Wrong password"+ "Login"+ "Password: "+ router#package mainimport  	"flag"	"fmt"	"log"	"regexp"	"time"	"golang.org/x/crypto/ssh"	"google.golang.org/grpc/codes"	"github.com/google/goexpect"	"github.com/google/goterm/term" const  	timeout = 10  var  	addr  = flag.String "address", "", "address of telnet server" 	user  = flag.String "user", "user", "username to use" 	pass1 = flag.String "pass1", "pass1", "password to use" 	pass2 = flag.String "pass2", "pass2", "alternate password to use"  func main   {	flag.Parse  	fmt.Println term.Bluef "SSH Example"  	sshClt, err := ssh.Dial "tcp", *addr, &ssh.ClientConfig{		User:		Auth:		HostKeyCallback: ssh.InsecureIgnoreHostKey  ,	} 	if err != nil {		log.Fatalf "ssh.Dial %q  failed: %v", *addr, err 	}	defer sshClt.Close  	e, _, err := expect.SpawnSSH sshClt, timeout 	if err != nil {		log.Fatal err 	}	defer e.Close  	e.ExpectBatch   expect.Batcher{		&expect.BCas{  expect.Caser{		}},	}, timeout 	fmt.Println term.Greenf "All done"  
google-goexpect	Generic Spawner	The Go Expect package supports adding new Spawners with the func SpawnGeneric opt *GenOptions, timeout time.Duration, opts ...Option   *GExpect,  },		},		re:		timeout: 2 	}, {		name: "Match fail",		fail: true,		re:   regexp.MustCompile "router1>" ,		srv:   Batcher{		},		timeout: 1 	}}	for _, tst := range tests {		exp, _, err := SpawnFake tst.srv, tst.timeout 		if err != nil {		}		out, _, err := exp.Expect tst.re, tst.timeout 		if got, want := err != nil, tst.fail; got != want {		}	}*Disclaimer: This is not an official Google product.*
google-gofountain	gofountain	Go implementation of various fountain codes.Luby Transform, Online codes, Raptor code.Includes many tests, libraries, and utilities.The abstraction level is "low" -encoder/decoder level functionality, without any packetizing, etc
google-gofountain	gofountain	that a full systemwould include on top of this layer.
google-goldfinch	Goldfinch: GOogLe image-search Dataset for FINe grained CHallenges	Goldfinch is a dataset for fine-grained recognition challenges
google-goldfinch	Goldfinch: GOogLe image-search Dataset for FINe grained CHallenges	It contains a list of bird, butterfly, aircraft, and dog categories with relevant Google image search and Flickr search URLs
google-goldfinch	Goldfinch: GOogLe image-search Dataset for FINe grained CHallenges	In addition, it also includes a set of active learning annotations on dog categories
google-goldfinch	Goldfinch: GOogLe image-search Dataset for FINe grained CHallenges	Goldfinch was published along with our  ECCV'16  paper  The Unreasonable Effectiveness of Noisy Data for Fine-Grained Recognition Here we list the files included in this release and their formats
google-goldfinch	Goldfinch: GOogLe image-search Dataset for FINe grained CHallenges	Where possible, we have mapped category names to freebase ids as a form of canonicalization
google-goldfinch	Goldfinch: GOogLe image-search Dataset for FINe grained CHallenges	Questions can be directed to jkrause@google.com and howardzhou@google.com.
google-goldfinch	cub_classes.txt:	For each category in the CUB dataset:
google-goldfinch	birdsnap_classes.txt:	For each category in the Birdsnap dadataset:
google-goldfinch	fgvc_classes.txt:	For each category in the FGVC-Aircraft dataset:
google-goldfinch	sdog_classes.txt:	For each category in the Stanford Dogs dataset:
google-goldfinch	bird_classes.txt:	For each category in L-Bird:
google-goldfinch	lepidoptera_classes.txt:	For each category in L-Butterfly:
google-goldfinch	dog_classes.txt:	For each category in L-Dog:
google-goldfinch	aircraft_classes.txt:	For each category in L-Aircraft:Compressed version of URL text files
google-goldfinch	aircraft_classes.txt:	Github has a 100MB file size limit
google-goldfinch	aircraft_classes.txt:	As aresult, we had to split bird_urls into 2 files: bird_urls1, bird_urls2 andcompress them separately.
google-goldfinch	lepidoptera_urls.txt.7z	For each image search image:Note that if more than one url is given, that indicates the same image is hostedat more than one url, which we provide for convenience in case one of the urlsgoes down
google-goldfinch	lepidoptera_urls.txt.7z	Where possible, we have provided links to full resolution images, butwhen not possible a link to a thumbnail is provided.
google-goldfinch	flickr_{aircraft,bird,lepidoptera}.txt:	For each image in the Flickr testing set:
google-goldfinch	sdogs_active_learning_iteration{1,2}.txt: 	Images mined from Yahoo Flickr Creative Commons 100M dataset
google-goldfinch	sdogs_active_learning_iteration{1,2}.txt: 	 Format of eachline, with values delimited by commas:Questions can be directed to jkrause@google.com and howardzhou@google.com.
google-gonids	Quick Start	Add this import line to the file you're working in:To parse a rule:
google-gonids	Miscellaneous	This is not an official Google product.
google-googet	GooGet 	  GooGet  Googet's Obviously Only a Goofy Experimental Title  is a modularpackage repository solution primarily designed for Windows
google-googet	GooGet 	This is not an official Google product.
google-googet	Build	Run build.cmd/build.sh to build GooGet for Windows
google-googet	Build	To package googet runmachine with the googet install command  assuming googet is already installed .To install on a fresh machine copy both googet.exe and the googet packageover and run:GooGet has the ability to use a conf file to change a few of the default settings.Place a file named googet.conf in the googet root.Googet supports using Google Cloud Storage as its server.set GOOREPO=%TEMP%\googet-reposet REPONAME=my_repomkdir %GOOREPO%\%REPONAME%mkdir %GOOREPO%\packagesgo run goopack/goopack.go googet.goospeccopy *.goo %GOOREPO%\packagesgo run server\gooserve.go -root %GOOREPO% -save_index %GOOREPO%\%REPONAME%\indexgsutil mb --project my-project my-googet-servergsutil rsync -r %GOOREPO% gs://my-googet-server./googet.exe addrepo gcs gs://my-googet-serverrem This command should print 'gcs: gs://my-googet-server'./googet.exec listrepos rem This command should list the googet package and any other packages in your repo./googet.exe available -sources gs://my-googet-server/Note that you must regenerate the index and re-upload it to your bucket each timeyou add or change packges.
google-google-api-cpp-client	Google API C++ Client	The current installation has only been tested on Unix/Linux systems;this release does not support Windows yet
google-google-api-cpp-client	Google API C++ Client	The following sequence ofactions should result in a turnkey build of the client libraries fromthe source code given only:
google-google-api-cpp-client	Running the Samples	See  src/samples/README.md  src/samples/README.md 
google-google-api-cpp-client	Building Clients for Other APIs	To download additional APIs specialized for individual Google Services see:and use this precise version of the apis client generator:Here's an example invocation:It should be possible to build this from existing installed libraries.However, the build scripts are not yet written to find them
google-google-api-cpp-client	Building Clients for Other APIs	For initialsupport simplicity we download and build all the dependencies in theprepare_dependencies.py script for the time being as a one-time bruteforce preparation.
google-google-api-cpp-client	Getting Help	If you have problems, questions or suggestions, contact:  The Google group at Or you may also ask questions on StackOverflow at:
google-google-api-cpp-client	Status	  portability and/or to remove unneeded pieces
google-google-api-cpp-client	Status	 forseable future
google-google-api-cpp-client	Status	Please submit suggestions as issues.
google-google-api-cpp-client	About the branches	  the generated libraries available from from google.developers.com
google-google-api-cpp-client	About the branches	On occasion  it gets aheaad of those
google-google-api-cpp-client	About the branches	It usually catches up in a few days
google-google-api-cpp-client	About the branches	 from  //cpp  
google-google-api-dotnet-client	Google APIs client Library for .NET	_If you're working with **Google Cloud Platform*
google-google-api-dotnet-client	Library Maintenance	This client library is supported but in maintenance mode only
google-google-api-dotnet-client	Library Maintenance	We are fixing necessary bugs and adding essential features to ensure this library continues to meet your needs for accessing Google APIs
google-google-api-dotnet-client	Library Maintenance	Non-critical issues will be closed
google-google-api-dotnet-client	Library Maintenance	Any issue may be reopened if it is causing ongoing problems.Please see the  FAQ  FAQ.md  for more details on what this means.
google-google-api-dotnet-client	Description ##	The Google API client library for .NET enables access to Google APIs such as Drive, YouTube, Calendar, Storage and Analytics
google-google-api-dotnet-client	Description ##	The library supports OAuth2.0 authentication
google-google-api-dotnet-client	Description ##	Strongly-typed per-API libraries are generated using Google's  Discovery API Please see the  FAQ  FAQ.md  for answers to common questions.
google-google-api-dotnet-client	Supported Frameworks	ASP.NET Core is supported through the netstandard1.3 framework target
google-google-api-dotnet-client	Supported Frameworks	However there are currently no authentication helpers or examples specific to ASP.NET Core, making authentication more difficult to use than on other platforms
google-google-api-dotnet-client	Supported Frameworks	This is being tracked in issue  #933 
google-google-api-dotnet-client	Legacy Supported Frameworks	We provide best-effort support for these platforms, but new features may not be available.
google-google-api-dotnet-client	Developer Documentation	To make it easier for you to develop with the Google APIs using the Google API client Library for .NET we have released a number of NuGet packages
google-google-api-dotnet-client	Developer Documentation	The libraries published by Google are owned by  google-apis-packages 
google-google-api-dotnet-client	API-specific Libraries	The generator that produces the source code for API-specific libraries is in ClientGenerator/
google-google-api-dotnet-client	API-specific Libraries	The most recently generated code is available in Src/Generated/, and the discovery documents from which that code was generated are in DiscoveryJson/.
google-google-api-dotnet-client	Support Forums	If you find an issue with in the client library we would appreciate you adding an issue in the  issue tracker Questions regarding usage of the client library should be posted to  stackoverflow.com   using the tag  #google-api-dotnet-client 
google-google-api-go-client	Getting Started	package mainimport  	"net/http"	"google.golang.org/api/urlshortener/v1" func main   {	svc, err := urlshortener.New http.DefaultClient 	// ..
google-google-api-go-client	Getting Started	  ! GoDoc  These are auto-generated Go libraries from the Google Discovery Service's JSON description files of the available "new style" Google APIs.Due to the auto-generated nature of this collection of libraries, complete APIs or specific versions can appear or go away without notice.As a result, you should always locally vendor any API s  that your code relies upon.These client libraries are officially supported by Google
google-google-api-go-client	Getting Started	 However, the libraries are considered complete and are in maintenance mode
google-google-api-go-client	Getting Started	This means that we will address critical bugs and security issues but will not add any new features.If you're working with Google Cloud Platform APIs such as Datastore or Pub/Sub,consider using the Cloud Client Libraries for Go instead
google-google-api-go-client	Getting Started	These are the new andidiomatic Go libraries targeted specifically at Google Cloud Platform Services.The generator itself and the code it produces are beta
google-google-api-go-client	Getting Started	Some APIs arealpha/beta, and indicated as such in the import path  e.g.,"google.golang.org/api/someapi/v1alpha" .
google-google-api-go-client	Application Default Credentials Example	Application Default Credentials provide a simplified way to obtain credentialsfor authenticating with Google APIs.The Application Default Credentials authenticate as the application itself,which make them great for working with Google Cloud APIs like Storage orDatastore
google-google-api-go-client	Application Default Credentials Example	They are the recommended form of authentication when buildingapplications that run on Google Compute Engine or Google App Engine.Default credentials are provided by the golang.org/x/oauth2/google package
google-google-api-go-client	Application Default Credentials Example	To use them, add the following import:import   func main   {If you need a oauth2.TokenSource, use the DefaultTokenSource function:
google-google-api-java-client-samples	Samples of using the  Google APIs Client Library for Java 	For a complete list of Google APIs, visit 
google-google-api-java-client	Google APIs Client Library for Java	This client library is supported but in maintenance mode only
google-google-api-java-client	Google APIs Client Library for Java	We are fixing necessary bugs andadding essential features to ensure this library continues to meet your needs for accessing GoogleAPIs
google-google-api-java-client	Google APIs Client Library for Java	Non-critical issues will be closed
google-google-api-java-client	Google APIs Client Library for Java	Any issue may be reopened if it is causing ongoing problems.If you're working with **Google Cloud Platform*consider using the  Cloud Client Libraries for Java instead
google-google-api-java-client	Google APIs Client Library for Java	These are the new and idiomatic Java libraries targeted specifically at Google CloudPlatform Services.
google-google-api-java-client	One time setup	mkdir /tmp/foo && cd /tmp/foowget unzip play-services-basement-8.3.0.aarmvn install:install-file \  -Dfile=classes.jar \  -DgroupId=com.google.android.google-play-services \  -DartifactId=google-play-services \  -Dversion=1 \  -Dpackaging=jarcd -
google-google-api-java-client	we need the google-http-java-client jar cached locally	git clone cd google-http-java-client && mvn compile && mvn install && cd ..
google-google-api-java-client	we need the google-oauth-java-client jar cached locally	git clone cd google-oauth-java-client && mvn compile && mvn install
google-google-api-java-client	Building And Testing	The Google APIs Client Library for Java is a flexible, efficient, and powerful Java client libraryfor accessing any HTTP-based API on the web, not just Google APIs.The library has the following features:To use Google's Java client libraries to call any Google API, you need two libraries:runtime library described here
google-google-api-java-client	Building And Testing	This library provides functionality common to all APIs, for example HTTP transport, error handling, authentication, JSON parsing, media download/upload, and batching
google-google-api-java-client	Building And Testing	the  generated Java library for the BigQuery API  These generated libraries include API-specific information such as the root URL, and classes that represent entities in the context of the API
google-google-api-java-client	Building And Testing	These classes are useful for making conversions between JSON objects and Java objects.To find the generated library for a Google API, visit  Google APIs Client Library for Java  The API-specific Java packages include both the core google-api-java-client and the client-specific libraries
google-google-api-java-client	Building And Testing	If you are using the old GData library, you need to migrate 
google-google-api-java-client	Developing for Android	If you are developing for Android and the Google API you want to use is included in the  Google Play Services library  you should use that library for the best performance and experience
google-google-api-java-client	Developing for Android	To access other Google APIs, you can use the Google APIs Client Library for Java, which supports  Android 4.0  Ice Cream Sandwich   or higher  
google-google-api-java-client	Other Java environments	Client Library for Java
google-google-api-java-client	Other Java environments	Here's an example that makes a call to the  Google Calendar API  OAuth 2.0  and sometimes a few lines is all you need
google-google-api-java-client	Other Java environments	For example: batching   media upload  and  media download make quick work of authenticated calls to APIs, and you do not need to worry about exchanging code for tokens
google-google-api-java-client	Other Java environments	For example: Google Play Services library  you should use that library for the best performance and experience
google-google-api-java-client	Other Java environments	To access other Google APIs, you can use the Google Client Library for Java's Android-specific helper classes, which are are well-integrated with  Android AccountManager  For example:directly from the  Downloads page  or you can use Maven or Gradle.To use Maven, add the following lines to your pom.xml file:    To use Gradle, add the following lines to your build.gradle file:This library is built on top of two common libraries, also built by Google, and also designed to work with any HTTP service on the web:
google-google-api-java-client	@Beta	Features marked with the @Beta annotation at the class or method level are subject to change
google-google-api-java-client	@Beta	Theymight be modified in any way, or even removed, in any major release
google-google-api-java-client	@Beta	You should not use beta featuresif your code is a library itself  that is, if your code is used on the CLASSPATH of users outsideyour own control .
google-google-api-java-client	Deprecations	Deprecated non-beta features will be removed eighteen months after the release in which they arefirst deprecated
google-google-api-java-client	Deprecations	You must fix your usages before this time
google-google-api-java-client	Deprecations	If you don't, any type of breakagemight result, and you are not guaranteed a compilation error.
google-google-api-javascript-client	Description	Written by Google, this compact and efficient client library provides access to Google REST APIs
google-google-api-javascript-client	Description	See below for a list of supported APIs.
google-google-api-javascript-client	Features	The JavaScript client library  supports these Google APIs The library supports  OAuth 2 authentication 
google-google-api-nodejs-client	Google APIs Node.js Client	 ! Release Level  releaselevelimg   releaselevel  ! CircleCI  circleimg   circle  ! npm version  npmimg   npm  ! Code Coverage  codecovimg   codecov  ! Downloads  downloadsimg   downloads   david-image   david-url  ! Known Vulnerabilities  snyk-image   snyk-url  Node.js  node  client library for using Google APIs
google-google-api-nodejs-client	Google APIs Node.js Client	Support for authorization and authentication with OAuth 2.0, API Keys and JWT tokens is included.The full list of supported APIs can be found  here  supported-list 
google-google-api-nodejs-client	Google APIs Node.js Client	The API endpoints are automatically generated, so if the API is not in the list, it is currently not supported by this API client library.Supported APIs are listed on the  Google APIs Explorer  apiexplorer .
google-google-api-nodejs-client	Working with Google Cloud Platform APIs?	If you're working with  Google Cloud Platform  cloudplatform  APIs such as Datastore, Cloud Storage or Pub/Sub, consider using the  @google-cloud  googlecloud  client libraries: single purpose idiomatic Node.js clients for Google Cloud Platform services.
google-google-api-nodejs-client	Installation	This library is distributed on npm
google-google-api-nodejs-client	Installation	In order to add it as a dependency, run the following command:This is a very simple example
google-google-api-nodejs-client	Installation	This creates a Blogger client and retrieves the details of a blog given the blog Id: jsconst {google} = require 'googleapis' ;// Each API may support multiple version
google-google-api-nodejs-client	Installation	With this sample, we're getting// v3 of the blogger API, and using an API key to authenticate.const blogger = google.blogger {  version: 'v3',  auth: 'YOUR API KEY'} ;const params = {  blogId: 3213900// get the blog detailsblogger.blogs.get params,  err, res  => {  if  err  {  }  console.log Instead of using callbacks you can also use promises!There are a lot of  samples  🤗  If you're trying to figure out how to use an API ..
google-google-api-nodejs-client	Installation	look there first! If there's a sample you need missing, feel free to file an  issue  bugs .
google-google-api-nodejs-client	Reference API	This library provides generated  Reference API documentation 
google-google-api-nodejs-client	Authentication and authorization	The are three primary ways to authenticate to Google APIs
google-google-api-nodejs-client	Authentication and authorization	Some service support all authentication methods, other may only support one or two.
google-google-api-nodejs-client	OAuth2 client	This client comes with an  OAuth2  oauth  client that allows you to retrieve an access token and refreshes the token and retry the request seamlessly The basics of Google's OAuth2 implementation is explained on  Google Authorization and Authentication documentation  authdocs .In the following examples, you may need a CLIENT_ID, CLIENT_SECRET and REDIRECT_URL
google-google-api-nodejs-client	OAuth2 client	You can find these pieces of information by going to the  Developer Console  devconsole , clicking your project --> APIs & auth --> credentials.For more information about OAuth2 and how it works,  see here  oauth .A complete sample application that authorizes and authenticates with the OAuth2 client is available at  samples/oauth2.js  oauthexample .
google-google-api-nodejs-client	Generating an authentication URL	To ask for permissions from a user to retrieve an access token, you redirect them to a consent page
google-google-api-nodejs-client	Generating an authentication URL	To create a consent page URL: jsconst {google} = require 'googleapis' ;const oauth2Client = new google.auth.OAuth2   YOUR_CLIENT_ID,  YOUR_CLIENT_SECRET,  YOUR_REDIRECT_URL ;// generate a url that asks permissions for Google+ and Google Calendar scopesconst scopes =    '  ' ;const url = oauth2Client.generateAuthUrl {  // 'online'  default  or 'offline'  gets refresh_token   access_type: 'offline',  scope: scopes} ;**IMPORTANT NOTE*
google-google-api-nodejs-client	Retrieve authorization code	Once a user has given permissions on the consent page, Google will redirect the page to the redirect URL you have provided with a code query parameter.
google-google-api-nodejs-client	Retrieve access token	With the code returned, you can ask for an access token as shown below:
google-google-api-nodejs-client	Handling refresh tokens	Access tokens expire
google-google-api-nodejs-client	Handling refresh tokens	This library will automatically use a refresh token to obtain a new access token if it is about to expire
google-google-api-nodejs-client	Handling refresh tokens	An easy way to make sure you always store the most recent tokens is to use the tokens event:
google-google-api-nodejs-client	Using API keys	You may need to send an API key with the request you are going to make
google-google-api-nodejs-client	Using API keys	The following uses an API key to make a request to the Google+ API service to retrieve a person's profile given a userId: jsconst {google} = require 'googleapis' ;const plus = google.plus {  version: 'v1',  auth: 'YOUR_API_KEY' // specify your API key here} ;async function main   {  const res = await plus.people.get { userId: 'me' } ;  console.log Hello ${res.data.displayName}! ;main  .catch console.error ;To learn more about API keys, please see the  documentation  usingkeys .
google-google-api-nodejs-client	Service to Service Authentication	Rather than manually creating an OAuth2 client, JWT client, or Compute client, the auth library can create the correct credential type for you, depending upon the environment your code is running under.For example, a JWT auth client will be created when your code is running on your local developer machine, and a Compute client will be created when the same code is running on a configured instance of Google Compute Engine.The code below shows how to retrieve a default credential type, depending upon the runtime environment
google-google-api-nodejs-client	Service to Service Authentication	The createScopedRequired must be called to determine when you need to pass in the scopes manually, and when they have been set for you automatically based on the configured runtime environment.async function main    {  // environment variables
google-google-api-nodejs-client	Service to Service Authentication	 const auth = await google.auth.getClient {  } ;  const project = await google.auth.getDefaultProjectId  ;  const res = await compute.zones.list { project, auth } ;  console.log res.data ;main  .catch console.error ;
google-google-api-nodejs-client	Setting global or service-level auth	You can set the auth as a global or service-level option so you don't need to specify it every request
google-google-api-nodejs-client	Setting global or service-level auth	For example, you can set auth as a global option: jsconst {google} = require 'googleapis' ;const oauth2Client = new google.auth.OAuth2   YOUR_CLIENT_ID,  YOUR_CLIENT_SECRET,  YOUR_REDIRECT_URL ;// set auth as a global defaultgoogle.options {  auth: oauth2Client} ;Instead of setting the option globally, you can also set the authentication client at the service-level: jsconst {google} = require 'googleapis' ;const oauth2Client = new google.auth.OAuth2   YOUR_CLIENT_ID,  YOUR_CLIENT_SECRET,  YOUR_REDIRECT_URL ;const drive = google.drive {  version: 'v2',  auth: oauth2Client} ;See the  Options section  options  for more information.
google-google-api-nodejs-client	Specifying request body	The body of the request is specified in the requestBody parameter object of the request
google-google-api-nodejs-client	Specifying request body	The body is specified as a JavaScript object with key/value pairs
google-google-api-nodejs-client	Specifying request body	For example, this sample creates a watcher that posts notifications to a Google Cloud Pub/Sub topic when emails are sent to a gmail account:This client supports multipart media uploads
google-google-api-nodejs-client	Specifying request body	The resource parameters are specified in the requestBody parameter object, and the media itself is specified in the media.body parameter with mime-type specified in media.mimeType.This example uploads a plain text file to Google Drive with the title "Test" and contents "Hello World"
google-google-api-nodejs-client	Specifying request body	jsconst drive = google.drive {  version: 'v3',  auth: oauth2Client} ;const res = await drive.files.create {  requestBody: {  },  media: {  }} ;You can also upload media by specifying media.body as a  Readable stream  stream 
google-google-api-nodejs-client	Specifying request body	This can allow you to upload very large files that cannot fit into memory.const fs = require 'fs' ;const drive = google.drive {  version: 'v3',  auth: oauth2Client} ;async function main   {  const res = await drive.files.create {  } ;  console.log res.data ;main  .catch console.error ;For more examples of creation and modification requests with media attachments, take a look at the samples/drive/upload.js sample.
google-google-api-nodejs-client	Request Options	For more fine-tuned control over how your API calls are made, we provide you with the ability to specify additional options that can be applied directly to the  'axios'  axios  object used in this library to make network calls to the API.You may specify additional options either in the global google object or on a service client basis
google-google-api-nodejs-client	Request Options	 The options you specify are attached to the axios object so whatever axios supports, this library supports
google-google-api-nodejs-client	Request Options	You may also specify global or per-service request parameters that will be attached to all API calls you make.A full list of supported options can be  found here  requestopts .
google-google-api-nodejs-client	Global options	You can choose default options that will be sent with each request
google-google-api-nodejs-client	Global options	These options will be used for every service instantiated by the google client
google-google-api-nodejs-client	Global options	In this example, the timeout property of AxiosRequestConfig will be set for every request:You can also specify options when creating a service client.Similar to the examples above, you can also modify the parameters used for every call of a given service:const blogger = google.blogger {  version: 'v3',  // All requests made with this service client will contain the  // blogId query parameter unless overridden in individual API calls
google-google-api-nodejs-client	Global options	 params: {  }} ;// Calls with this drive client will NOT contain the blogId query parameter.const drive = google.drive 'v3' ;
google-google-api-nodejs-client	Request-level options	You can specify an auth object to be used per request
google-google-api-nodejs-client	Request-level options	Each request also inherits the options specified at the service level and global level.For example:const {google} = require 'googleapis' ;const bigquery = google.bigquery 'v2' ;async function main   {  // environment variables
google-google-api-nodejs-client	Request-level options	 const client = await google.auth.getClient {  } ;  };  console.log res.data ;main  .catch console.error ;You can also override *axiosFor example:You can use the following environment variables to proxy HTTP and HTTPS requests:
google-google-api-nodejs-client	Getting Supported APIs	You can programatically obtain the list of supported APIs, and all available versions:
google-google-api-nodejs-client	TypeScript	This library is written in TypeScript, and provides types out of the box
google-google-api-nodejs-client	TypeScript	All classes and interfaces generated for each API are exported under the ${apiName}_${version} namespace
google-google-api-nodejs-client	TypeScript	 For example, the Drive v3 API types are are all available from the drive_v3 namespace:You can find a detailed list of breaking changes and new features in our  Release Notes  releasenotes 
google-google-api-nodejs-client	TypeScript	If you've used this library before 25.x, see our  Release Notes  releasenotes  to learn about migrating your code from 24.x.x to 25.x.x
google-google-api-nodejs-client	TypeScript	It's pretty easy : 
google-google-api-nodejs-client	License	This library is licensed under Apache 2.Full license text is available in  COPYING  copying .
google-google-api-nodejs-client	Contributing	We love contributions! Before submitting a Pull Request, it's always good to start with a new issue first
google-google-api-nodejs-client	Contributing	To learn more, see  CONTRIBUTING  contributing .
google-google-api-nodejs-client	Questions/problems?	 snyk-url :  david-image :  david-url :  npmimg :  npm :  circle :  circleimg :  releaselevel :  releaselevelimg :  supported-list :  bugs :  node :  stackoverflow :  apiexplorer :  usingkeys :  contributing :  copying :  authdocs :  axios :  requestopts :  stream :  releasenotes :  devconsole :  oauth :  oauthexample :  options :  googlecloud :  googlecloudapis :  cloudplatform :  codecovimg :  codecov :  downloadsimg :  downloads : 
google-google-api-objectivec-client-for-rest	Google APIs Client Library for Objective-C for REST #	**Project site***Discussion group*  Written by Google, this library is a flexible and efficient Objective-Cframework for accessing JSON APIs.This is the recommended library for accessing JSON-based Google APIs for iOS andMac OS X applications
google-google-api-objectivec-client-for-rest	Google APIs Client Library for Objective-C for REST #	 The library is compatible with applications built foriOS 7 and later, and Mac OS X 10.9 and later.**To get started* wiki  BuildingTheLibrary for how to add the library to a Mac or iPhone application project, it coversdirectly adding sources or using CocoaPods
google-google-api-objectivec-client-for-rest	Google APIs Client Library for Objective-C for REST #	Study the example applications Generated interfaces for Google APIs are in the GeneratedServices folder In addition to the pre generated classes included with the library, you cangenerate your own source for other services that have a discovery document by using the ServiceGenerator **If you have a problem*please join the discussion group Be sure to include http logs for requests and responses when posting questions
google-google-api-objectivec-client-for-rest	Google APIs Client Library for Objective-C for REST #	Bugs may also be submittedon the  issues list **Externally-included projects**: The library includes code from the separateprojects  GTM Session Fetcher  GTMAppAuth **Google Data APIs**: The much older library for XML-based APIs is still available Other useful classes for Mac and iOS developers are available in the Google Toolbox for Mac 
google-google-api-objectivec-client	Google APIs Client Library for Objective-C #	**Project site***Discussion group*  > ## :warning: Deprecation Notice> This library has been replaced by>  Google APIs Client Library for Objective-C For REST > New applications should use that instead; existing application should be>  updated > as soon as possible as the Google servers will eventually stop> accepting JSON-RPC requests.Written by Google, this library is a flexible and efficient Objective-Cframework for accessing JSON APIs.This is the recommended library for accessing JSON-based Google APIs for iOS andMac OS X applications
google-google-api-objectivec-client	Google APIs Client Library for Objective-C #	 The library is compatible with applications built foriOS 3 and later, and Mac OS X 10.5 and later.**To get started*the  wiki and study the example applications Generated interfaces for Google APIs are in the services folder Library changes are documented in the release notes The library may also be used without generated interfaces with JSON REST and JSON-RPC APIs.**If you have a problem*please join the discussion group Be sure to include http logs for requests and responses when posting questions
google-google-api-objectivec-client	Google APIs Client Library for Objective-C #	Bugs may also be submittedon the  issues list **Externally-included projects**: The library includes code from the separateprojects  GTM Session Fetcher  GTM OAuth 2 **Google Data APIs**: The library for older, XML-based APIs is still available Other useful classes for Mac and iOS developers are available in the Google Toolbox for Mac 
google-google-api-php-client-services	Requirements	 Google API PHP Client 
google-google-api-php-client-services	Usage in v2 of Google API PHP Client	This library will be automatically installed with the Google API PHP Client via composer
google-google-api-php-client-services	Usage in v2 of Google API PHP Client	Composer will automatically pull down a monthly tagfrom this repository.If you'd like to always be up-to-date with the latest release, rather thanwait for monthly tagged releases, request the dev-master version in composer:If you are currently using the  v1-master branch of the client library, but want to use the latest API services, you cando so by requiring this library directly into your project via the same composer command:
google-google-api-php-client	Google APIs Client Library for PHP #	The Google API Client Library enables you to work with Google APIs such as Google+, Drive, or YouTube on your server.These client libraries are officially supported by Google
google-google-api-php-client	Google APIs Client Library for PHP #	 However, the libraries are considered complete and are in maintenance mode
google-google-api-php-client	Google APIs Client Library for PHP #	This means that we will address critical bugs and security issues but will not add any new features.
google-google-api-php-client	Google Cloud Platform	For Google Cloud Platform APIs such as Datastore, Cloud Storage or Pub/Sub, we recommend using  GoogleCloudPlatform/google-cloud-php  which is under active development.
google-google-api-php-client	Installation ##	You can use **Composer*
google-google-api-php-client	Composer	The preferred method is via  composer  Follow the installation instructions  if you do not already havecomposer installed.Once composer is installed, execute the following command in your project root to install this library:If you abhor using composer, you can download the package in its entirety
google-google-api-php-client	Composer	The  Releases  page lists all stable versions
google-google-api-php-client	Composer	Download any filewith the name google-api-php-client- RELEASE_NAME .zip for a package including this library and its dependencies.Uncompress the zip file you download, and include the autoloader in your project:
google-google-api-php-client	Examples ##	See the  examples/  examples  directory for examples of the key client features
google-google-api-php-client	Examples ##	You canview them in your browser by running the php built-in web server
google-google-api-php-client	Examples ##	in the above example,  .
google-google-api-php-client	Basic Example ###	// include your composer dependenciesrequire_once 'vendor/autoload.php';$client = new Google_Client  ;$client->setApplicationName "Client_Library_Examples" ;$client->setDeveloperKey "YOUR_APP_KEY" ;$service = new Google_Service_Books $client ;$optParams = array 'filter' => 'free-ebooks' ;$results = $service->volumes->listVolumes 'Henry David Thoreau', $optParams ;foreach  $results as $item  {  echo $item 'volumeInfo'  'title' , " \n";
google-google-api-php-client	Authentication with OAuth ###	> An example of this can be seen in  examples/simple-file-upload.php  examples/simple-file-upload.php .Follow the instructions to  Create Web Application Credentials Download the JSON credentialsSet the path to these credentials using Google_Client::setAuthConfig:Set the scopes required for the API you are going to callSet your application's redirect URIIn the script handling the redirect URI, exchange the authorization code for an access token:
google-google-api-php-client	Authentication with Service Accounts ###	> An example of this can be seen in  examples/service-account.php  examples/service-account.php .Some APIs such as the  YouTube Data API  donot support service accounts
google-google-api-php-client	Authentication with Service Accounts ###	Check with the specific API documentation if APIcalls return unexpected 401 or 403 errors.Follow the instructions to  Create a Service Account Download the JSON credentialsSet the path to these credentials using the GOOGLE_APPLICATION_CREDENTIALS environment variable:Tell the Google client to use your service account credentials to authenticate:Set the scopes required for the API you are going to callIf you have delegated domain-wide access to the service account and you want to impersonate a user account, specify the email address of the user account using the method setSubject:
google-google-api-php-client	Making Requests ###	The classes used to call the API in  google-api-php-client-services  are autogenerated
google-google-api-php-client	Making Requests ###	They map directly to the JSON requests and responses found in the  APIs Explorer A JSON request to the  Datastore API  would look like this:POST }Using this library, the same call would look something like this:// create the datastore service class$datastore = new Google_Service_Datastore $client ;// build the query $query = new Google_Service_Datastore_Query    ;// build the request and response$request = new Google_Service_Datastore_RunQueryRequest  'query' => $query  ;$response = $datastore->projects->runQuery 'YOUR_DATASET_ID', $request ;However, as each property of the JSON API has a corresponding generated class, the above code could also be written like this:// create the datastore service class$datastore = new Google_Service_Datastore $client ;// build the query$request = new Google_Service_Datastore_RunQueryRequest  ;$query = new Google_Service_Datastore_Query  ;$order->setDirection 'descending' ;$property = new Google_Service_Datastore_PropertyReference  ;$property->setName 'title' ;$order->setProperty $property ;$query->setOrder  $order  ;$kind->setName 'Book' ;$query->setKinds  $kind  ;// add the query to the request and make the request$request->setQuery $query ;$response = $datastore->projects->runQuery 'YOUR_DATASET_ID', $request ;The method used is a matter of preference, but *it will be very difficult to use this library without first understanding the JSON syntax for the API*, so it is recommended to look at the  APIs Explorer  before using any of the services here.
google-google-api-php-client	Making HTTP Requests Directly ###	If Google Authentication is desired for external applications, or a Google API is not available yet in this library, HTTP requests can be made directly.The authorize method returns an authorized  Guzzle Client  so any request made using the client will contain the corresponding authorization.// create the Google client$client = new Google_Client  ;$client->useApplicationDefaultCredentials  ;$client->addScope Google_Service_Plus::PLUS_ME ;// returns a Guzzle HTTP Client$httpClient = $client->authorize  ;// make an HTTP request$response = $httpClient->get '
google-google-api-php-client	Caching ###	It is recommended to use another caching library to improve performance
google-google-api-php-client	Caching ###	This can be done by passing a  PSR-6  compatible library to the client:use League\Flysystem\Adapter\Local;use League\Flysystem\Filesystem;use Cache\Adapter\Filesystem\FilesystemCachePool;$filesystemAdapter = new Local __DIR__.'/' ;$cache = new FilesystemCachePool $filesystem ;$client->setCache $cache ;In this example we use  PHP Cache  Add this to your project with composer:When using  Refresh Tokens  or  Service Account Credentials  it may be useful to perform some action when a new access token is granted
google-google-api-php-client	Caching ###	To do this, pass a callable to the setTokenCallback method on the client:It is often very useful to debug your API calls by viewing the raw HTTP request
google-google-api-php-client	Caching ###	This library supports the use of  Charles Web Proxy  Download and run Charles, and then capture all HTTP traffic through Charles with the following code:// FOR DEBUGGING ONLY$httpClient = new GuzzleHttp\Client    ;$client = new Google_Client  ;$client->setHttpClient $httpClient ;Now all calls made by this library will appear in the Charles UI.One additional step is required in Charles to view SSL requests
google-google-api-php-client	Caching ###	Go to **Charles > Proxy > SSL Proxying Settings*
google-google-api-php-client	Service Specific Examples ###	YouTube: 
google-google-api-php-client	How Do I Contribute? ##	Please see the  contributing  CONTRIBUTING.md  page for more information
google-google-api-php-client	How Do I Contribute? ##	In particular, we love pull requests 
google-google-api-php-client	What do I do if something isn't working? ###	For support with the library the best place to ask is via the google-api-php-client tag on StackOverflow: If there is a specific bug with the library, please  file a issue  in the Github issues tracker, including an example of the failing code and any specific errors retrieved
google-google-api-php-client	What do I do if something isn't working? ###	Feature requests can also be filed, as long as they are core library requests, and not-API specific: for those, refer to the documentation for the individual APIs for the best place to file requests
google-google-api-php-client	What do I do if something isn't working? ###	Please try to provide a clear statement of the problem that the feature would address.
google-google-api-php-client	I want an example of X! ###	If X is a feature of the library, file away! If X is an example of using a specific service, the best place to go is to the teams for those specific APIs 
google-google-api-php-client	Why do you still support 5.2? ###	When we started working on the 1.0.0 branch we knew there were several fundamental issues to fix with the 0.6 releases of the library
google-google-api-php-client	Why do you still support 5.2? ###	At that time we looked at the usage of the library, and other related projects, and determined that there was still a large and active base of PHP 5.2 installs
google-google-api-php-client	Why do you still support 5.2? ###	You can see this in statistics such as the PHP versions chart in the WordPress stats:  We will keep looking at the types of usage we see, and try to take advantage of newer PHP features where possible.
google-google-api-php-client	Why does Google_..._Service have weird names? ###	The _Service classes are generally automatically generated from the API discovery documents:  Sometimes new features are added to APIs with unusual names, which can cause some unexpected or non-standard style naming in the PHP classes.
google-google-api-php-client	How do I deal with non-JSON response types? ###	Some services return XML or similar by default, rather than JSON, which is what the library supports
google-google-api-php-client	How do I deal with non-JSON response types? ###	You can request a JSON response by adding an 'alt' argument to optional params that is normally the last argument to a method call:The library strips out nulls from the objects sent to the Google APIs as its the default value of all of the uninitialized properties
google-google-api-php-client	How do I deal with non-JSON response types? ###	To work around this, set the field you want to null to Google_Model::NULL_VALUE
google-google-api-php-client	How do I deal with non-JSON response types? ###	This is a placeholder that will be replaced with a true null when sent over the wire.
google-google-api-php-client	Code Quality ##	Run the PHPUnit tests with PHPUnit
google-google-api-php-client	Code Quality ##	You can configure an API key and token in BaseTest.php to run all calls, but this will require some setup on the Google Developer Console.
google-google-api-php-client	Coding Style	To check for coding style violations, run
google-google-api-python-client	Google API Client	This is the Python client library for Google's discovery based APIs
google-google-api-python-client	Google API Client	To get started, please see the  full documentation for this library  Additionally,  dynamically generated documentation  is available for all of the APIs supported by this library.These client libraries are officially supported by Google
google-google-api-python-client	Google API Client	 However, the libraries are considered complete and are in maintenance mode
google-google-api-python-client	Google API Client	This means that we will address critical bugs and security issues but will not add any new features.
google-google-api-python-client	Google Cloud Platform	For Google Cloud Platform APIs such as Datastore, Cloud Storage or Pub/Sub, we recommend using  Cloud Client Libraries for Python  which is under active development.
google-google-api-python-client	Installation	To install, simply use pip or easy_install:
google-google-api-python-client	Python Version	Python 2.7, 3.4, 3.5, and 3.6 are fully supported and tested
google-google-api-python-client	Python Version	This library may work on later versions of 3, but we do not currently run tests against those versions.
google-google-api-python-client	Third Party Libraries and Dependencies	The following libraries will be installed when you install the client library:Please see the  contributing page  for more information
google-google-api-python-client	Third Party Libraries and Dependencies	In particular, we love pull requests 
google-google-api-ruby-client-samples	Google API Ruby Client  0.8.x  Samples	This repository contains contributed samples for version 0.8x of the ruby client  They arenot compatible with version 0.9 of the client library which uses a differentcalling style.Updated samples for version 0.9 may be found in the ruby client repository The  migration guide may also be useful in translating samples to 0.
google-google-api-ruby-client-samples	License	The samples arelicensed under Apache 2.Full license text isavailable in  LICENSE.txt  LICENSE .
google-google-api-ruby-client-samples	contributing	See  CONTRIBUTING  CONTRIBUTING.md .
google-google-api-ruby-client	Google API Client	These client libraries are officially supported by Google
google-google-api-ruby-client	Google API Client	 However, the libraries are considered complete and are in maintenance mode
google-google-api-ruby-client	Google API Client	This means that we will address critical bugs and security issues but will not add any new features.
google-google-api-ruby-client	Google Cloud Platform	For Google Cloud Platform APIs such as Datastore, Cloud Storage or Pub/Sub, we recommend using  GoogleCloudPlatform/google-cloud-ruby  which is under active development.
google-google-api-ruby-client	Migrating from 0.8.x	See  MIGRATING  MIGRATING.md  for additional details on how to migrate to the latest version.
google-google-api-ruby-client	Installation	Add this line to your application's Gemfile:gem 'google-api-client', '~> 0.11'And then execute:Or install it yourself as:
google-google-api-ruby-client	Basic usage	To use an API, include the corresponding generated file and instantiate the service
google-google-api-ruby-client	Basic usage	For example to use the Drive API:require 'google/apis/drive_v2'Drive = Google::Apis::DriveV2 # Alias the moduledrive = Drive::DriveService.newdrive.authorization = ..
google-google-api-ruby-client	Basic usage	# See Googleauth or Signet libraries
google-google-api-ruby-client	Search for files in Drive  first page only 	files = drive.list_files q: "title contains 'finances'" files.items.each do |file|  puts file.title
google-google-api-ruby-client	Upload a file	metadata = Drive::File.new title: 'My document' metadata = drive.insert_file metadata, upload_source: 'test.txt', content_type: 'text/plain' 
google-google-api-ruby-client	Download a file	drive.get_file metadata.id, download_dest: '/tmp/myfile.txt' 
google-google-api-ruby-client	Naming conventions vs JSON representation	Object properties in the ruby client use the standard ruby convention for naming -
google-google-api-ruby-client	Media	Methods that allow media operations have additional parameters to specify the upload source or download destination.For uploads, the upload_source parameter can be specified with either a path to a file, an IO stream, or StringIOFor downloads, the download_dest parameter can also be either a path to a file, an IO stream, or StringIO instance.Both uploads & downloads are resumable
google-google-api-ruby-client	Media	If an error occurs during transmission the request will be automaticallyretried from the last received byte.
google-google-api-ruby-client	Errors & Retries	Retries are disabled by default, but enabling retries is strongly encouraged
google-google-api-ruby-client	Errors & Retries	The number of retries can be configuredvia Google::Apis::RequestOptions
google-google-api-ruby-client	Errors & Retries	Any number greater than 0 will enable retries.To enable retries for all services:request options:an exponentially increasing delay on subsequent retries
google-google-api-ruby-client	Errors & Retries	If a request can not be retried or if the maximum numberof retries is exceeded, an exception is thrown.
google-google-api-ruby-client	Callbacks	A block can be specified when making calls
google-google-api-ruby-client	Callbacks	If present, the block will be called with the result or error, rather thanreturning the result from the call or raising the error
google-google-api-ruby-client	Callbacks	Example:is complete.
google-google-api-ruby-client	Paging	To fetch multiple pages of data, use the Enumerable that automatically fetches additional pages as needed.Multiple requests can be batched together into a single HTTP request to reduce overhead
google-google-api-ruby-client	Paging	Batched calls are executedin parallel and the responses processed once all results are availableHowever, some APIs support batch uploads
google-google-api-ruby-client	Paging	To upload multiple files in a batch, use the batch_upload method instead.Batch uploads should only be used when uploading multiple small files
google-google-api-ruby-client	Paging	For large files, upload files individually totake advantage of the libraries built-in resumable upload support.
google-google-api-ruby-client	Hashes	While the API will always return instances of schema classes, plain hashes are accepted in method calls forconvenience
google-google-api-ruby-client	Hashes	Hash keys must be symbols matching the attribute names on the corresponding object the hash is meantto replace
google-google-api-ruby-client	Hashes	For example:To handle JSON serialization or deserialization in the application, set skip_serialization oror skip_deserializaton options respectively
google-google-api-ruby-client	Hashes	When setting skip_serialization in a request,the body object must be a string representing the serialized JSON.When setting skip_deserialization to true, the response from the API will likewisebe a string containing the raw JSON from the server.
google-google-api-ruby-client	Authorization	 OAuth 2  is used to authorize applications
google-google-api-ruby-client	Authorization	This library usesboth  Signet  and Google Auth Library for Ruby  for OAuth 2 support.The  Google Auth Library for Ruby  provides an implementation of application default credentials  for Ruby
google-google-api-ruby-client	Authorization	It offers a simple way to get authorization credentials for use incalling Google APIs, best suited for cases when the call needs to have the same identityand authorization level for the application independent of the user
google-google-api-ruby-client	Authorization	This isthe recommended approach to authorize calls to Cloud APIs, particularly whenyou're building an application that uses Google Compute Engine.For per-user authorization, use  Signet  to obtain user authorization.
google-google-api-ruby-client	Passing authorization to requests	Authorization can be specified for the entire client, for an individual service instance, or on a per-request basis.Set authorization for all service:drive = Google::Apis::DriveV2::DriveService.newdrive.authorization = authorization
google-google-api-ruby-client	All requests made with this service will use the same authorization	Some APIs allow using an API key instead of OAuth2 tokens
google-google-api-ruby-client	All requests made with this service will use the same authorization	For these APIs, setthe key attribute of the service instance
google-google-api-ruby-client	All requests made with this service will use the same authorization	For example:require 'google/apis/translate_v2'translate = Google::Apis::TranslateV2::TranslateService.newtranslate.key = 'YOUR_API_KEY_HERE'result = translate.list_translations 'Hello world!', 'es', source: 'en' puts result.translations.first.translated_text
google-google-api-ruby-client	Authorization using environment variables	The  GoogleAuth Library for Ruby  also supports authorization viaenvironment variables if you do not want to check in developer credentialsor private keys
google-google-api-ruby-client	Authorization using environment variables	Simply set the following variables for your application:The client includes a Logger instance that can be used to capture debugging information.When running in a Rails environment, the client will default to using ::Rails.logger
google-google-api-ruby-client	Authorization using environment variables	If youprefer to use a separate logger instance for API calls, you can provide a new logger instance:To set the logging level for the client:See the  samples  for examples on how to use the client library for variousContributions for additional samples are welcome
google-google-api-ruby-client	Authorization using environment variables	See  CONTRIBUTING  CONTRIBUTING.md .
google-google-api-ruby-client	Generating APIs	For  Cloud Endpoints  or other APIs not included in the gem, ruby code can begenerated from the discovery document.To generate from a local discovery file:A URL can also be specified:
google-google-api-ruby-client	TODO	This library is licensed under Apache 2.Full license text isavailable in  LICENSE  LICENSE .
google-google-api-ruby-client	Contributing	See  CONTRIBUTING  CONTRIBUTING.md .
google-google-api-ruby-client	Support	Please  report bugs at the project on Github  Don'thesitate to  ask questions  about the client or APIson  StackOverflow 
google-google-auth-library-java	Google Auth Library	Open source authentication client library for Java
google-google-auth-library-java	Google Auth Library	  ! Maven  interfaces for Google credentialscredentials
google-google-auth-library-java	Google Auth Library	This artifacts depends on the App Engine SDKcredentials as well as utility methods to create them and to get Application Default Credentials> Note: This client is a work-in-progress, and may occasionally> make backwards-incompatible changes.
google-google-auth-library-java	Quickstart	If you are using Maven, add this to your pom.xml file  notice that you can replace
google-google-auth-library-java	google-auth-library-credentials	This artifact contains base classes and interfaces for Google credentials:authorize your applicationCredentials.getRequestMetadata URI, Executor, RequestMetadataCallback capable of signing byte arrays using the credentials associated to a Google Service Account
google-google-auth-library-java	google-auth-library-appengine	This artifact depends on the App Engine SDK  appengine-api-1.0-sdk  and should be used only byapplications running on App Engine
google-google-auth-library-java	google-auth-library-appengine	The AppEngineCredentials class allows to authorize your AppEngine application given an instance of  AppIdentityService 
google-google-auth-library-java	Application Default Credentials	This artifact contains a wide variety of credentials as well as utility methods to create them andto get Application Default Credentials.Credentials classes contained in this artifact are:directly in the request metadata to provide authorizationTo get Application Default Credentials use GoogleCredentials.getApplicationDefault HttpTransportFactory 
google-google-auth-library-java	Application Default Credentials	These methods return theApplication Default Credentials which are used to identify and authorize the whole application
google-google-auth-library-java	Application Default Credentials	Thefollowing are searched  in order  to find the Application Default Credentials:Credentials file pointed to by the GOOGLE_APPLICATION_CREDENTIALS environment variableCredentials provided by the Google Cloud SDK gcloud auth application-default login commandGoogle App Engine built-in credentialsGoogle Cloud Shell built-in credentialsGoogle Compute Engine built-in credentialsTo get Credentials from a Service Account JSON key use GoogleCredentials.fromStream InputStream or GoogleCredentials.fromStream InputStream, HttpTransportFactory 
google-google-auth-library-java	Application Default Credentials	Note that the credentials mustbe refreshed before the access token is available.Contributions to this library are always welcome and highly encouraged.See  CONTRIBUTING  CONTRIBUTING.md  documentation for more information on how to get started.Please note that this project is released with a Contributor Code of Conduct
google-google-auth-library-java	Application Default Credentials	By participating inthis project you agree to abide by its terms
google-google-auth-library-java	Application Default Credentials	See  Code of Conduct  CODE_OF_CONDUCT.md  for more
google-google-auth-library-java	License	BSD 3-Clause 
google-google-auth-library-nodejs	Google Auth Library	 ! npm version  npmimg   npm  ! CircleCI  circle-image   circle-url  ! codecov  codecov-image   codecov-url  ! Dependencies  david-dm-img   david-dm  ! Known Vulnerabilities  snyk-image   snyk-url This is Google's officially supported  node.js  node  client library for using OAuth 2.0 authorization and authentication with Google APIs.
google-google-auth-library-nodejs	Installation	This library is distributed on npm
google-google-auth-library-nodejs	Installation	To add it as a dependency, run the following command:The 1.x release includes a variety of bug fixes, new features, and breaking changes
google-google-auth-library-nodejs	Installation	Please take care, and see  the release notes  for a list of breaking changes, and the upgrade guide.
google-google-auth-library-nodejs	Ways to authenticate	This library provides a variety of ways to authenticate to your Google services.This library provides an implementation of  Application Default Credentials    for Node.js
google-google-auth-library-nodejs	Ways to authenticate	The  Application Default Credentials    provide a simple way to get authorization credentials for use in calling Google APIs.They are best suited for cases when the call needs to have the same identity and authorization level for the application independent of the user
google-google-auth-library-nodejs	Ways to authenticate	This is the recommended approach to authorize calls to Cloud APIs, particularly when you're building an application that uses Google Cloud Platform.
google-google-auth-library-nodejs	Download your Service Account Credentials JSON file	To use Application Default Credentials, You first need to download a set of JSON credentials for your project
google-google-auth-library-nodejs	Download your Service Account Credentials JSON file	Go to **APIs & Auth*> This file is your *only copy> committed with your source code, and should be stored securely.Once downloaded, store the path to this file in the GOOGLE_APPLICATION_CREDENTIALS environment variable.
google-google-auth-library-nodejs	Enable the API you want to use	Before making your API call, you must be sure the API you're calling has been enabled
google-google-auth-library-nodejs	Enable the API you want to use	Go to **APIs & Auth*
google-google-auth-library-nodejs	Choosing the correct credential type automatically	Rather than manually creating an OAuth2 client, JWT client, or Compute client, the auth library can create the correct credential type for you, depending upon the environment your code is running under.For example, a JWT auth client will be created when your code is running on your local developer machine, and a Compute client will be created when the same code is running on Google Cloud Platform
google-google-auth-library-nodejs	Choosing the correct credential type automatically	If you need a specific set of scopes, you can pass those in the form of a string or an array into the auth.getClient method.The code below shows how to retrieve a default credential type, depending upon the runtime environment.const {auth} = require 'google-auth-library' ; */async function main   {  const client = await auth.getClient {  } ;  const projectId = await auth.getDefaultProjectId  ;  const url = {projectId};  const res = await client.request { url } ;  console.log res.data ;async function getADC   {  // Acquire a client and the projectId based on the environment
google-google-auth-library-nodejs	Choosing the correct credential type automatically	This method looks  // for the GCLOUD_PROJECT and GOOGLE_APPLICATION_CREDENTIALS environment variables
google-google-auth-library-nodejs	Choosing the correct credential type automatically	 const res = await auth.getApplicationDefault  ;  let client = res.credential;  // machine
google-google-auth-library-nodejs	Choosing the correct credential type automatically	In that case, the desired scopes must be passed in manually
google-google-auth-library-nodejs	Choosing the correct credential type automatically	When the code is  // running in GCE or a Managed VM, the scopes are pulled from the GCE metadata server
google-google-auth-library-nodejs	Choosing the correct credential type automatically	 // See  for more information
google-google-auth-library-nodejs	Choosing the correct credential type automatically	 if  client.createScopedRequired && client.createScopedRequired    {  }  return {  }main  .catch console.error ;
google-google-auth-library-nodejs	OAuth2	This library comes with an  OAuth2  oauth  client that allows you to retrieve an access token and refreshes the token and retry the request seamlessly if you also provide an expiry_date and the token is expired
google-google-auth-library-nodejs	OAuth2	The basics of Google's OAuth2 implementation is explained on  Google Authorization and Authentication documentation  authdocs .In the following examples, you may need a CLIENT_ID, CLIENT_SECRET and REDIRECT_URL
google-google-auth-library-nodejs	OAuth2	You can find these pieces of information by going to the  Developer Console  devconsole , clicking your project > APIs & auth > credentials.For more information about OAuth2 and how it works,  see here  oauth .
google-google-auth-library-nodejs	A complete OAuth2 example	Let's take a look at a complete example
google-google-auth-library-nodejs	A complete OAuth2 example	jsconst {OAuth2Client} = require 'google-auth-library' ;const http = require 'http' ;const url = require 'url' ;const querystring = require 'querystring' ;const opn = require 'opn' ;// Download your OAuth2 configuration from the Googleconst keys = require './keys.json' ; */async function main   {  try {  } catch  e  {  }  process.exit  ;function getAuthenticatedClient   {  return new Promise  resolve, reject  => {  } ;main  ;
google-google-auth-library-nodejs	Handling token events	This library will automatically obtain an access_token, and automatically refresh the access_token if a refresh_token is present
google-google-auth-library-nodejs	Handling token events	 The refresh_token is only returned on the  first authorization  so if you want to make sure you store it safely
google-google-auth-library-nodejs	Handling token events	An easy way to make sure you always store the most recent tokens is to use the tokens event:const client = await auth.getClient  ;client.on 'tokens',  tokens  => {  if  tokens.refresh_token  {  }  console.log tokens.access_token ;} ;const url = 
google-google-auth-library-nodejs	Retrieve access token	With the code returned, you can ask for an access token as shown below:If you need to manually refresh the access_token associated with your OAuth2 client, ensure the call to generateAuthUrl sets the access_type to offline
google-google-auth-library-nodejs	Retrieve access token	 The refresh token will only be returned for the first authorization by the user
google-google-auth-library-nodejs	Retrieve access token	 To force consent, set the prompt property to consent:After obtaining and storing an access_token, at a later time you may want to go check the expiration date,original scopes, or audience for the token
google-google-auth-library-nodejs	Retrieve access token	 To get the token info, you can use the getTokenInfo method:// after acquiring an oAuth2Client...const tokenInfo = await oAuth2client.getTokenInfo 'my-access-token' ;// take a look at the scopes originally provisioned for the access tokenconsole.log tokenInfo.scopes ;This method will throw if the token is invalid.
google-google-auth-library-nodejs	OAuth2 with Installed Apps  Electron 	If you're authenticating with OAuth2 from an installed application  like Electron , you may not want to embed your client_secret inside of the application sources
google-google-auth-library-nodejs	OAuth2 with Installed Apps  Electron 	To work around this restriction, you can choose the iOS application type when creating your OAuth2 credentials in the  Google Developers console  devconsole :! application type  apptype If using the 
google-google-auth-library-nodejs	JSON Web Tokens	The Google Developers Console provides a .json file that you can use to configure a JWT auth client and authenticate your requests, for example when using a service account
google-google-auth-library-nodejs	JSON Web Tokens	jsconst {JWT} = require 'google-auth-library' ;const keys = require './jwt.keys.json' ;async function main   {  const client = new JWT    ;  await client.authorize  ;  const url = {keys.project_id};  const res = await client.request {url} ;  console.log res.data ;main  .catch console.error ;The parameters for the JWT auth client including how to use it with a .pem file are explained in  examples/jwt.js  examples/jwt.js .
google-google-auth-library-nodejs	Loading credentials from environment variables	Instead of loading credentials from a key file, you can also provide them using an environment variable and the GoogleAuth.fromJSON   method
google-google-auth-library-nodejs	Loading credentials from environment variables	 This is particularly convenient for systems that deploy directly from source control  Heroku, App Engine, etc .Start by exporting your credentials:Now you can create a new client from the credentials:const {auth} = require 'google-auth-library' ;// load the environment variable with our keysconst keysEnvVar = process.env 'CREDS' ;if  !keysEnvVar  {  throw new Error 'The $CREDS environment variable was not found!' ;const keys = JSON.parse keysEnvVar ;async function main   {  // load the JWT or UserRefreshClient from the keys  const client = auth.fromJSON keys ;  client.scopes =  ' ;  await client.authorize  ;  const url = {keys.project_id};  const res = await client.request {url} ;  console.log res.data ;main  .catch console.error ;
google-google-auth-library-nodejs	Using a Proxy	You can use the following environment variables to proxy HTTP and HTTPS requests:
google-google-auth-library-nodejs	Compute	If your application is running on Google Cloud Platform, you can authenticate using the default service account or by specifying a specific service account.**Note**: In most cases, you will want to use  Application Default Credentials  #choosing-the-correct-credential-type-automatically 
google-google-auth-library-nodejs	Compute	 Direct use of the Compute class is for very specific scenarios
google-google-auth-library-nodejs	Compute	jsconst {Compute} = require 'google-auth-library' ;async function main   {  const client = new Compute {  } ;  const projectId = 'your-project-id';  const url = {project_id};  const res = await client.request {url} ;  console.log res.data ;main  .catch console.error ;
google-google-auth-library-nodejs	Questions/problems?	See  CONTRIBUTING  contributing .
google-google-auth-library-nodejs	License	This library is licensed under Apache 2.Full license text is available in  LICENSE  copying 
google-google-auth-library-nodejs	License	apiexplorer :  Application Default Credentials :  apptype :  authdocs :  axios :  axiosOpts :  bugs :  circle-image :  circle-url :  codecov-image :  codecov-url :  contributing :  copying :  david-dm-img :  david-dm :  node :  npmimg :  npm :  oauth :  snyk-image :  snyk-url :  stability :  stackoverflow :  stream :  urlshort :  usingkeys :  devconsole :  oauth :  options :  gcloud :  cloudplatform : 
google-google-auth-library-php	Google Auth Library for PHP	  Homepage  Authors  CopyrightCopyright © 2015 Google, Inc
google-google-auth-library-php	Google Auth Library for PHP	 LicenseApache 2.0
google-google-auth-library-php	Description	This is Google's officially supported PHP client library for using OAuth 2.0authorization and authentication with Google APIs.
google-google-auth-library-php	Installing via Composer	The recommended way to install the google auth library is through Composer This library provides an implementation of application default credentials  application default credentials  for PHP.The Application Default Credentials provide a simple way to get authorizationcredentials for use in calling Google APIs.They are best suited for cases when the call needs to have the same identityand authorization level for the application independent of the user
google-google-auth-library-php	Installing via Composer	This isthe recommended approach to authorize calls to Cloud APIs, particularly whenyou're building an application that uses Google Compute Engine.
google-google-auth-library-php	Download your Service Account Credentials JSON file	To use Application Default Credentials, You first need to download a set ofJSON credentials for your project
google-google-auth-library-php	Download your Service Account Credentials JSON file	Go to **APIs & Auth*the  Google Developers Console  developer console  and select**Service account*> This file is your *only copy> committed with your source code, and should be stored securely.Once downloaded, store the path to this file in theGOOGLE_APPLICATION_CREDENTIALS environment variable.> Consider using .htaccess or apache configuration files as well.
google-google-auth-library-php	Enable the API you want to use	Before making your API call, you must be sure the API you're calling has beenenabled
google-google-auth-library-php	Enable the API you want to use	Go to **APIs & Auth* Google Developers Console  developer console  and enable the APIs you'd like tocall
google-google-auth-library-php	Enable the API you want to use	For the example below, you must enable the Drive API.
google-google-auth-library-php	Call the APIs	As long as you update the environment variable below to point to *yourcredentials file, the following code should output a list of your Drive files.use Google\Auth\ApplicationDefaultCredentials;use GuzzleHttp\Client;use GuzzleHttp\HandlerStack;// specify the path to your application credentialsputenv 'GOOGLE_APPLICATION_CREDENTIALS=/path/to/my/credentials.json' ;// define the scopes for your API call$scopes =  ' ;// create middleware$middleware = ApplicationDefaultCredentials::getMiddleware $scopes ;$stack = HandlerStack::create  ;$stack->push $middleware ;// create the HTTP client$client = new Client    'handler' => $stack,  'base_uri' => '  'auth' => 'google_auth'  // authorize all requests  ;// make the request$response = $client->get 'drive/v2/files' ;// show the result!print_r  string  $response->getBody   ;
google-google-auth-library-php	Guzzle 5 Compatibility	If you are using  Guzzle 5  Guzzle 5 , replace the create the HTTP Client steps with the following:// create the HTTP client$client = new Client    'base_url' => '  'auth' => 'google_auth'  // authorize all requests  ;// create subscriber$subscriber = ApplicationDefaultCredentials::getSubscriber $scopes ;$client->getEmitter  ->attach $subscriber ;
google-google-auth-library-php	License	This library is licensed under Apache 2.Full license text isavailable in  COPYING  copying .
google-google-auth-library-php	Contributing	See  CONTRIBUTING  contributing .
google-google-auth-library-php	Support	 report bugs at the project on Github  Don'thesitate to ask questions about the client or APIs on  StackOverflow  google-apis-php-client :  application default credentials :  contributing :  copying :  Guzzle :  Guzzle 5 :  developer console : 
google-google-auth-library-ruby	Google Auth Library for Ruby	  Homepage  AuthorsTim Emiola  CopyrightCopyright © 2015 Google, Inc
google-google-auth-library-ruby	Google Auth Library for Ruby	 LicenseApache 2.0 ! Gem Version      
google-google-auth-library-ruby	Description	This is Google's officially supported ruby client library for using OAuth 2.0authorization and authentication with Google APIs.
google-google-auth-library-ruby	Alpha	This library is in Alpha
google-google-auth-library-ruby	Alpha	We will make an effort to support the library, butwe reserve the right to make incompatible changes when necessary.
google-google-auth-library-ruby	Install	Be sure  is in your gem sources.For normal client usage, this is sufficient:require 'googleauth'
google-google-auth-library-ruby	Get the environment configured authorization	scopes =   'authorization = Google::Auth.get_application_default scopes 
google-google-auth-library-ruby	headers.	some_headers = {}authorization.apply some_headers 
google-google-auth-library-ruby	Application Default Credentials	This library provides an implementation of application default credentials  application default credentials  for Ruby.The Application Default Credentials provide a simple way to get authorizationcredentials for use in calling Google APIs.They are best suited for cases when the call needs to have the same identityand authorization level for the application independent of the user
google-google-auth-library-ruby	Application Default Credentials	This isthe recommended approach to authorize calls to Cloud APIs, particularly whenyou're building an application that uses Google Compute Engine.
google-google-auth-library-ruby	User Credentials	The library also provides support for requesting and storing usercredentials  3-Legged OAuth2
google-google-auth-library-ruby	User Credentials	 Two implementations are currently available,a generic authorizer useful for command line apps or custom integrations aswell as a web variant tailored toward Rack-based applications.The authorizers are intended for authorization use cases
google-google-auth-library-ruby	User Credentials	For sign-on,see  Google Identity Platform 
google-google-auth-library-ruby	Example  Web 	require 'googleauth'require 'googleauth/web_user_authorizer'require 'googleauth/stores/redis_token_store'require 'redis'client_id = Google::Auth::ClientId.from_file '/path/to/client_secrets.json' scope =  ' token_store = Google::Auth::Stores::RedisTokenStore.new redis: Redis.new authorizer = Google::Auth::WebUserAuthorizer.new   client_id, scope, token_store, '/oauth2callback' get '/authorize'  do  # NOTE: Assumes the user is already authenticated to the app  user_id = request.session 'user_id'   credentials = authorizer.get_credentials user_id, request   if credentials.nil?  end  # Credentials are valid, can call APIs  # ...get '/oauth2callback'  do  target_url = Google::Auth::WebUserAuthorizer.handle_auth_callback_deferred   redirect target_url
google-google-auth-library-ruby	Example  Command Line 	require 'googleauth'require 'googleauth/stores/file_token_store'OOB_URI = 'urn:ietf:wg:oauth:2.0:oob'scope = 'client_id = Google::Auth::ClientId.from_file '/path/to/client_secrets.json' token_store = Google::Auth::Stores::FileTokenStore.new   :file => '/path/to/tokens.yaml' authorizer = Google::Auth::UserAuthorizer.new client_id, scope, token_store credentials = authorizer.get_credentials user_id if credentials.nil?  url = authorizer.get_authorization_url base_url: OOB_URI    puts "Open #{url} in your browser and enter the resulting code:"  code = gets  credentials = authorizer.get_and_store_credentials_from_code 
google-google-auth-library-ruby	Example  Service Account 	scope = 'authorizer = Google::Auth::ServiceAccountCredentials.make_creds   json_key_io: File.open '/path/to/service_account_json_key.json' ,  scope: scope 
google-google-auth-library-ruby	Example  Environment Variables 	Authorizers require a storage instance to manage long term persistence ofaccess and refresh tokens
google-google-auth-library-ruby	Example  Environment Variables 	Two storage implementations are included: token_store.rb  lib/googleauth/token_store.rb  for additional details.
google-google-auth-library-ruby	Supported Ruby Versions	This library is currently supported on Ruby 1.9+.However, Ruby 2.4 or later is strongly recommended, as earlier releases havereached or are nearing end-of-life
google-google-auth-library-ruby	Supported Ruby Versions	After March 31, 2019, Google will provideofficial support only for Ruby versions that are considered current andsupported by Ruby Core  that is, Ruby versions that are either in normalmaintenance or in security maintenance .See  for further details.
google-google-auth-library-ruby	License	This library is licensed under Apache 2.Full license text isavailable in  COPYING  copying .
google-google-auth-library-ruby	Contributing	See  CONTRIBUTING  contributing .
google-google-auth-library-ruby	Support	 report bugs at the project on Github  Don'thesitate to ask questions about the client or APIs on  StackOverflow  google-apis-ruby-client :  application default credentials :  contributing :  copying : 
google-google-authenticator-libpam	Google Authenticator PAM module	Example PAM module demonstrating two-factor authentication
google-google-authenticator-libpam	Google Authenticator PAM module	 
google-google-authenticator-libpam	Build & install	If you don't have access to "sudo", you have to manually become "root" priorto calling "make install".
google-google-authenticator-libpam	Setting up the PAM module for your system	For highest security, make sure that both password and OTP are being requestedeven if password and/or OTP are incorrect
google-google-authenticator-libpam	Setting up the PAM module for your system	This means that *at leastof pam_google_authenticator.so should be set as required, not requisite
google-google-authenticator-libpam	Setting up the PAM module for your system	Itprobably can't hurt to have both be required, but it could depend on the restof your PAM config.If you use HOTP  counter based as opposed to time based  then add the optionno_increment_hotp to make sure the counter isn't incremented for failedAdd this line to your PAM configuration file:  auth required pam_google_authenticator.so no_increment_hotp
google-google-authenticator-libpam	Setting up a user	Run the google-authenticator binary to create a new secret key in your homedirectory
google-google-authenticator-libpam	Setting up a user	These settings will be stored in ~/.google_authenticator.If your system supports the "libqrencode" library, you will be shown a QRCodethat you can scan using the Android "Google Authenticator" application.If your system does not have this library, you can either follow the URL thatgoogle-authenticator outputs, or you have to manually enter the alphanumericsecret key into the Android "Google Authenticator" application.In either case, after you have added the key, click-and-hold until the contextmenu shows
google-google-authenticator-libpam	Setting up a user	Then check that the key's verification value matches  this featuremight not be available in all builds of the Android application .Each time you log into your system, you will now be prompted for your TOTP code time based one-time-password  or HOTP  counter-based , depending on optionsgiven to google-authenticator, after having entered your normal user id andyour normal UNIX account password.During the initial roll-out process, you might find that not all users havecreated a secret key yet
google-google-authenticator-libpam	Setting up a user	If you would still like them to be able to login, you can pass the "nullok" option on the module's command line:  auth required pam_google_authenticator.so nullok
google-google-authenticator-libpam	Encrypted home directories	If your system encrypts home directories until after your users entered theirpassword, you either have to re-arrange the entries in the PAM configurationfile to decrypt the home directory prior to asking for the OTP code, oryou have to store the secret file in a non-standard location:  auth required pam_google_authenticator.so secret=/var/unencrypted-home/${USER}/.google_authenticatorwould be a possible choice
google-google-authenticator-libpam	Encrypted home directories	Make sure to set appropriate permissions
google-google-authenticator-libpam	Encrypted home directories	You alsohave to tell your users to manually move their .google_authenticator file tothis location.In addition to "${USER}", the ${HOME} as short-hands for the user's home directory.When using the secret= option, you might want to also set the user=option
google-google-authenticator-libpam	Encrypted home directories	The latter forces the PAM module to switch to a dedicated hard-codeduser id prior to doing any file operations
google-google-authenticator-libpam	Encrypted home directories	When using the user= option, youmust not include "~" or "${HOME}" in the filename.The user= option can also be useful if you want to authenticate users who donot have traditional UNIX accounts on your system.
google-google-authenticator-libpam	secret=/path/to/secret/file	See "encrypted home directories", above.
google-google-authenticator-libpam	authtok_prompt=prompt	Overrides default token prompt
google-google-authenticator-libpam	authtok_prompt=prompt	If you want to include spaces in the prompt,wrap the whole argument in square brackets:  auth required pam_google_authenticator.so  authtok_prompt=Your secret token:  
google-google-authenticator-libpam	user=some-user	Force the PAM module to switch to a hard-coded user id prior to doing any fileoperations
google-google-authenticator-libpam	user=some-user	Commonly used with secret=.
google-google-authenticator-libpam	no_strict_owner	DANGEROUS OPTION!By default the PAM module requires that the secrets file must be owned the userlogging in  or if user= is specified, owned by that user 
google-google-authenticator-libpam	no_strict_owner	This optiondisables that check.This option can be used to allow daemons not running as root to still handleconfiguration files not owned by that user, for example owned by the users
google-google-authenticator-libpam	allowed_perm=0nnn	DANGEROUS OPTION!By default, the PAM module requires the secrets file to be readable only by theowner of the file  mode 0600 by default 
google-google-authenticator-libpam	allowed_perm=0nnn	In situations where the module is usedin a non-default configuration, an administrator may need more lenient filepermissions, or a specific setting for their use case.
google-google-authenticator-libpam	debug	Enable more verbose log messages in syslog.
google-google-authenticator-libpam	try_first_pass / use_first_pass / forward_pass	Some PAM clients cannot prompt the user for more than just the password
google-google-authenticator-libpam	try_first_pass / use_first_pass / forward_pass	Towork around this problem, this PAM module supports stacking
google-google-authenticator-libpam	try_first_pass / use_first_pass / forward_pass	If you pass theforward_pass option, the pam_google_authenticator module queries the userfor both the system password and the verification code in a single prompt.It then forwards the system password to the next PAM module, which will haveto be configured with the use_first_pass option.In turn, use_first_pass and try_first_pass options
google-google-authenticator-libpam	try_first_pass / use_first_pass / forward_pass	But most users would not needto set those on the pam_google_authenticator.
google-google-authenticator-libpam	noskewadj	If you discover that your TOTP code never works, this is most commonly theresult of the clock on your server being different from the one on your Androiddevice
google-google-authenticator-libpam	noskewadj	The PAM module makes an attempt to compensate for time skew
google-google-authenticator-libpam	noskewadj	You canteach it about the amount of skew that you are experiencing, by trying to logit three times in a row
google-google-authenticator-libpam	noskewadj	Make sure you always wait 30s  but not longer , sothat you get three distinct TOTP codes.Some administrators prefer that time skew isn't adjusted automatically, asdoing so results in a slightly less secure system configuration
google-google-authenticator-libpam	noskewadj	If you wantto disable it, you can do so on the module command line:  auth required pam_google_authenticator.so noskewadj
google-google-authenticator-libpam	no_increment_hotp	Don't increment the counter for failed HOTP attempts
google-google-authenticator-libpam	no_increment_hotp	 Normally you should setthis so failed password attempts by an attacker without a token don't lock outthe authorized user.
google-google-authenticator-libpam	nullok	Allow users to log in without OTP, if they haven't set up OTP yet.
google-google-authenticator-libpam	echo_verification_code	By default, the PAM module does not echo the verification code when it isentered by the user
google-google-authenticator-libpam	echo_verification_code	In some situations, the administrator might prefer adifferent behavior
google-google-authenticator-libpam	echo_verification_code	Pass the echo_verification_code option to the modulein order to enable echoing.If you would like verification codes that are counter based instead oftimebased, use the google-authenticator binary to generate a secret key inyour home directory with the proper option
google-google-authenticator-libpam	echo_verification_code	 In this mode, clock skew isirrelevant and the window size option now applies to how many codes beyond thecurrent one that would be accepted, to reduce synchronization problems.
google-google-authenticator	Google Authenticator OpenSource	The Google Authenticator project includes implementations of one-time passcodegenerators for several mobile platforms
google-google-authenticator	Google Authenticator OpenSource	One-time passcodes are generated usingopen standards developed by the Initiative for Open Authentication  OATH   which is unrelated to  OAuth The pluggable authentication module  PAM  is in a separate project The Android app is in another one There is by design NO account backups in any of the apps.These apps are not on the app stores, and their code has diverged from what's inthe app stores, so patches here won't necessarily show up in those versions.These implementations support the HMAC-Based One-time Password  HOTP  algorithmspecified in  RFC 4226  and the Time-basedOne-time Password  TOTP  algorithm specifiedin  RFC 6238 Further documentation is available inthe  Wiki 
google-google-ctf	Google CTF	This repository lists most of the challenges used in the Google CTF The missing challenges are not ready to be open-sourced, or contain third-party code.Read more about the Google CTF here:
google-google-drive-proxy	About Drive Proxy	Drive Proxy is a Windows Service that streamlines communication with GoogleDrive
google-google-drive-proxy	About Drive Proxy	It is meant to facilitate the construction of tools that leverage GoogleDrive's cloud storage capacity without burdening the hard drive and network withunnecesary local copies
google-google-drive-proxy	About Drive Proxy	Drive Proxy handles authentication with Google Driveand manages the cache where the needed files reside.It uses a simple protocol to communicate with client applications over a pipe.It is currently used by the  Google Drive Shell Extension  project to provide atransparent interface between Windows Explorer and Google Drive.
google-google-drive-proxy	Supported OS	The bundled Visual Studio Solution file will work with Visual Studio 2010 andlater, and includes:  to Drive API
google-google-drive-proxy	Supported OS	 only includes Drive Proxy, it will not install Google Drive Shell Extension
google-google-drive-proxy	Supported OS	 projects.
google-google-drive-proxy	Build instructions	This github project is intended to be used as a component of your own project.Since the service needs to talk with the Google APIs, you will need to setup aGoogle API project in the Google Developers Console
google-google-drive-proxy	Build instructions	Go to: Name your project and click on “Create” Wait for the project to be created
google-google-drive-proxy	Build instructions	From the left hand side menu, click on “APIs & auth”
google-google-drive-proxy	Build instructions	From the left hand side menu, Click on “APIs” You will need to enable the “Drive API” by toggling the switch to “on” From the left hand side menu, Click on “Credentials” Click on “Create new Client ID” Select “Installed application” and click on “Configure consent screen” Fill in the details for your consent screen and click on “Save”
google-google-drive-proxy	Build instructions	A new form will be presented
google-google-drive-proxy	Build instructions	Select “Installed application” and “Other” You will be presented with a Client ID and Client Secret
google-google-drive-proxy	Build instructions	Switch to the root of the git repository and using a text editor, open You will see a line “ClientID \”
google-google-drive-proxy	Build instructions	You will see a line “ClientSecret \”
google-google-drive-proxy	Build instructions	Replace “\<Your You will see a line “CompanyPath \<Your Company here, must be a valid You can then open DriveProxy.sln and compile the Installer project.
google-google-drive-proxy	Installation instructions	Executing the installer will install the service to “%programfiles%\CompanyPath\Drive Proxy Service”.
google-google-drive-proxy	Usage	The service can not be used by itself, instead an application would use it tocommunicate with Google Drive
google-google-drive-proxy	Usage	The Google Drive Shell Extension project is anexample of such an application.
google-google-drive-proxy	Contact	For questions and answers join/view the  google-drive-proxy  Google Group.
google-google-drive-shell-extension	About Google Drive Shell Extension	Google Drive Shell Extension is a Shell Namespace Extension for MicrosoftWindows
google-google-drive-shell-extension	About Google Drive Shell Extension	It creates a virtual folder on My Computer, mirrored in the user's homedirectory, that allows the user to interact with his Google Drive accounttransparently through Windows Explorer
google-google-drive-shell-extension	About Google Drive Shell Extension	This includes "File Open" and "Browse"commands from within other Windows applications, etc
google-google-drive-shell-extension	About Google Drive Shell Extension	It connects to GoogleDrive using the Google Drive Proxy service.The main feature of the project is that syncronization is performed only asneeded
google-google-drive-shell-extension	About Google Drive Shell Extension	Instead of holding the entire contents of your Google Drive folder ondisk, it only keeps what it needs
google-google-drive-shell-extension	About Google Drive Shell Extension	When you open or copy files it will downloadthem
google-google-drive-shell-extension	About Google Drive Shell Extension	It will then upload any changes you make locally to keep the folders insync
google-google-drive-shell-extension	About Google Drive Shell Extension	This means that your content is not available while offline.
google-google-drive-shell-extension	Known Product Limitations	The Google Drive Shell Extension implementation has a few limitations that both users and administrators should be aware of
google-google-drive-shell-extension	Known Product Limitations	User actions to open a Drive document need to occur through the shell extension interface
google-google-drive-shell-extension	Known Product Limitations	If a user accesses documents outside of this method the user will not get the most updated content from Drive and saved changes will not get uploaded back to Drive.The bundled Visual Studio Solution file will work with Visual Studio 2010 andlater, and includes:  includes Google Drive Shell Extension, it will not install the Drive Proxy  service.
google-google-drive-shell-extension	Build instructions	Project dependencies:Enter the repository's directory.Update the project's submodules.Follow  google-drive-proxy's Edit Release.bat and make sure the paths to MSBuild.exe and makensis.exe areExecute Release.bat.
google-google-drive-shell-extension	Installation instructions	After building, go to the ./bin folder and execute DriveFusion.exe
google-google-drive-shell-extension	Installation instructions	This willlaunch the installer, which will automatically install both Google Drive ShellExtension and the Google Drive Proxy service to the appropriate Program Filesfolder
google-google-drive-shell-extension	Installation instructions	The only required interaction is a UAC prompt to grant admin privilege.The Google Drive Proxy service is always installed to the 32-bit Program Filesfolder, under "Google/Drive Proxy"
google-google-drive-shell-extension	Installation instructions	Google Drive Shell Extension will match yourWindows' architecture Program Files folder, under "Google/Drive Fusion".
google-google-drive-shell-extension	Usage	After installing the project, you'll find a new virtual folder in My Computer.The first time you attempt to open it, it will launch a browser window andrequest your Google Account username and password
google-google-drive-shell-extension	Usage	It will then request that youauthorize the application to access Google Drive
google-google-drive-shell-extension	Usage	Once it has authenticated yourcredentials, you will be able to view the contents of your Google Drive accountand treat it as any other folder
google-google-drive-shell-extension	Usage	You can create folders, create new files, dragand drop into and out of it, etc.
google-google-drive-shell-extension	Contact	For questions and answers join/view the  google-drive-shell-extension  Google Group.
google-google-http-java-client	Description	Written by Google, the Google HTTP Client Library for Java is a flexible, efficient, and powerfulJava library for accessing any resource on the web via HTTP
google-google-http-java-client	Description	The library has the followingjava.net.HttpURLConnection, Apache HTTP Client, or URL Fetch on Google App Engine.content
google-google-http-java-client	Description	The JSON and XML libraries are also fully pluggable, and they include support for Jackson  and Android's GSON libraries for JSON.The library supports the following Java environments:for the OAuth 2.0 and OAuth 1.0a authorization standards.access to Google APIs.This is an open-source library, and contributions are welcome.
google-google-id-token	GoogleIDToken	GoogleIDToken verifies the integrity of ID tokens generated by Google authentication servers.
google-google-id-token	Installation	Add this line to your application's Gemfile:Or install it yourself as:
google-google-id-token	Usage	GoogleIDToken currently provides a single useful class Validator, which provides a single method #check, which parses and validates the integrity of an ID Token allegedly generated by Google auth servers.Creating a new validator takes a single optional hash argument
google-google-id-token	Usage	If the hash has an entry for :x509_key, that value is taken to be a key as created by OpenSSL::X509::Certificate.new, and the token is validated using that key
google-google-id-token	Usage	 If there is no such entry, the keys are fetched from the Google certs endpoint  The certificates are cached for some time  default: 1 hour  which can be configured by adding the :expiry argument to the initialization hash  in seconds .
google-google-id-token	expiry	Expiry defines the the time  in seconds  in which the cached Google certificates are valid.x509_cert can be provided to manually define a certificate to validate the tokens.
google-google-java-format	google-java-format	google-java-format is a program that reformats Java source code to comply with Google Java Style   
google-google-java-format	google-java-format	Google Java Style : 
google-google-java-format	from the command-line	 Download the formatter and run it with:offsets  --offset , passing through to standard-out  default  or alteredin-place  --replace .To reformat changed lines in a specific patch, use google-java-format-diff.py formatting
google-google-java-format	from the command-line	This is a deliberate design decision to unify our code formatting ona single format.*
google-google-java-format	IntelliJ	A  google-java-format IntelliJplugin  is available from the pluginThe plugin will be disabled by default
google-google-java-format	IntelliJ	To enable it in the current project, goto File→Settings...→google-java-format Settings  or IntelliJIDEA→Preferences...→Other Settings→google-java-format Settings on macOS  anduncheck the Enable google-java-format checkbox
google-google-java-format	IntelliJ	 A notification will bepresented when you first open a project offering to do this for you
google-google-java-format	IntelliJ	To enable it by default in new projects, use File→Other Settings→DefaultWhen enabled, it will replace the normal Reformat Code action, which can betriggered from the Code menu or with the Ctrl-Alt-L  by default  keyboardThe import ordering is not handled by this plugin, unfortunately
google-google-java-format	IntelliJ	To fix theimport order, download the  IntelliJ Java Google Stylefile and import it into File→Settings→Editor→Code Style.
google-google-java-format	Eclipse	A  google-java-format Eclipseplugin can be downloaded from the releases page
google-google-java-format	Eclipse	Drop it into the Eclipse  drop-insfolder to activate the plugin.The plugin adds a google-java-format formatter implementation that can beconfigured in Window > Preferences > Java > Code Style > Formatter > Formatter
google-google-java-format	as a library	The formatter can be used in software which generates java to output morelegible java code
google-google-java-format	as a library	Just include the library in your maven/gradle/etc.
google-google-java-format	Building from source	Please see  the contributors guide  CONTRIBUTING.md  for details.
google-google-java-format	License	Copyright 2015 Google Inc.Licensed under the Apache License, Version 2.0  the "License" ; you may notuse this file except in compliance with the License
google-google-java-format	License	You may obtain a copy ofthe License atdistributed under the License is distributed on an "AS IS" BASIS, WITHOUTWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-google-java-format	License	See theLicense for the specific language governing permissions and limitations underthe License.
google-google-maven-parents	google-maven-parent	Parent pom.xml files used to act as shared metadata parent to  variously all or subset groups of google-owned projects.
google-google-oauth-java-client	Library maintenance	This client library is supported but in maintenance mode only
google-google-oauth-java-client	Library maintenance	We are fixing necessary bugs andadding essential features to ensure this library continues to meet your needs for accessing GoogleAPIs
google-google-oauth-java-client	Library maintenance	Non-critical issues will be closed
google-google-oauth-java-client	Library maintenance	Any issue may be reopened if it is causing ongoing
google-google-oauth-java-client	Description	Written by Google, the Google OAuth Client Library for Java is a powerful and easy-to-use Javalibrary for the OAuth 1.0a and OAuth 2.0 authorization standards
google-google-oauth-java-client	Description	The Google OAuth Client Libraryfor Java is designed to work with any OAuth service on the web, not just with Google APIs
google-google-oauth-java-client	Description	It isbuilt on the  Google HTTP Client Library for Java The library supports the following Java environments: Google APIs Client Library for Java This is an open-source library, and contributions are welcome.
google-google-p12-pem	google-p12-pem	 ! NPM Version  npm-image   npm-url   travis-image   travis-url   david-image   david-url   david-dev-image   david-dev-url  ! Known Vulnerabilities  snyk-image   snyk-url Convert Google .p12 keys to .pem keys.
google-google-p12-pem	promise style	const {getPem} = require 'google-p12-pem' ;getPem '/path/to/key.p12'   .then pem => {  }   .catch err => {  } ;
google-google-p12-pem	CLI style	 MIT  LICENSE  david-image :  david-url :  david-dev-image :  david-dev-url :  npm-image :  npm-url :  snyk-image :  snyk-url :  travis-image :  travis-url : 
google-google-toolbox-for-mac	GTM: Google Toolbox for Mac #	**Project site***Discussion group*
google-google-toolbox-for-mac	Google Toolbox for Mac #	A collection of source from different Google projects that may be of use todevelopers working other iOS or OS X projects.If you find a problem/bug or want a new feature to be included in the GoogleToolbox for Mac, please join the discussion group or submit an issue 
google-googleapps-message-recall	Deprecation Notice	Users of message-recall,The team at Google responsible for the message-recall want to provide you with a 30 day notice that the repository  google/googleapps-message-recall  will be deprecated on 11/14/
google-googleapps-message-recall	What does this mean?	The github project will be deprecated and Google will discontinue support for message-recall.
google-googleapps-message-recall	Why are you doing this?	The reason Google first created these tools was to address a need when there were limited alternatives in the market
google-googleapps-message-recall	Why are you doing this?	Today there are options available that are better supported and in many cases provide an improved experience.
google-googleapps-message-recall	What are the alternative options?	We recommend switching to use  Google Apps Manager  as the functionality provided by message-recall is well supported by Google Apps Manager and can offer an improved benefit over it.For example:We thank you for your support and use of the tool, we hope it was useful! 
google-googleapps-password-generator	Overview	Many large Google Apps customers want to allow non-SAML capable devices to login to Google Apps  iOS, IMAP, etc , however they do not want to sync their corp passwords to Google
google-googleapps-password-generator	Overview	 These customer also cannot use ASPs  appliction specific passwords  because they do not have ways to restrict how many ASPs are used by a user or how often ASPs are created.This Password Generator solution provides a self-service application customers can deploy to their end users to enable users to create a Google Apps password for the use with iOS, IMAP or other clients that require a password to be stored at Google.This project also contains examples of cross-site scripting  XSS  and cross-site request forgery  XSRF  protections implemented in an App Engine project.
google-googleapps-password-generator	Key Features	End user self-service password tool for creating Google Apps password.Automatically generate and configure iOS devicesSupport for configuring multiple iOS devices for a single userGoogle Group based access controlDetailed Reporting
google-googleapps-password-generator	Deployment	Review  setup/deploy.pdf  for detailed setup and App Engine deployment instructions.
google-googleapps-password-generator	Quick Sheet / Screen Shots	Review  setup/quicksheet.pdf  for example screen shots of the project in action.
google-googleapps-password-generator	Support	For questions and answers join/view the googleapps-password-generator Google Group 
google-googlemock	googlemock	This project has been absorbed into the  GoogleTest  project.All open googlemock issues have been moved there.
google-googletest	Google Test #	   ! Build status  **Future Plans**:This repository is a merger of the formerly separate GoogleTest andGoogleMock projects
google-googletest	Google Test #	These were so closely related that it makes sense tomaintain and release them together.Please see the project page above for more information as well as themailing list for questions, discussions, and development
google-googletest	Google Test #	 There isalso an IRC channel on  OFTC   irc.oftc.net  #gtest available
google-googletest	Google Test #	 Pleasejoin us!Getting started information for **Google Test* Google Test Primer  googletest/docs/primer.md  documentation.**Google Mock*classes
google-googletest	Google Test #	 See the separate  Google Mock documentation  googlemock/README.md .More detailed documentation for googletest  including build instructions  arein its interior  googletest/README.md  googletest/README.md  file.
google-googletest	Features ##	Google test has been used on a variety of platforms:In addition to many internal projects at Google, Google Test is also used bythe following notable projects: GTest Runner  is a Qt5 based automated test-runner and Graphical User Interface with powerful features for Windows and Linux platforms
google-googletest	Features ##	Google Test UI  is test runner that runsyour test binary, allows you to track its progress via a progress bar, anddisplays a list of test failures
google-googletest	Features ##	Clicking on one shows failure text
google-googletest	Features ##	GoogleTest UI is written in C#
google-googletest	Features ##	GTest TAP Listener  is an eventlistener for Google Test that implements the TAP protocol  for testresult output
google-googletest	Features ##	If your test runner understands TAP, you may find it useful
google-googletest	Features ##	gtest-parallel  is a test runner thatruns tests from your binary in parallel to provide significant speed-up.
google-googletest	Requirements ##	Google Test is designed to have fairly minimal requirements to buildand use with your projects, but there are some
google-googletest	Requirements ##	 Currently, we supportLinux, Windows, Mac OS X, and Cygwin
google-googletest	Requirements ##	 We will also make our besteffort to support other platforms  e.g
google-googletest	Requirements ##	Solaris, AIX, and z/OS .However, since core members of the Google Test project have no accessto these platforms, Google Test may have outstanding issues there
google-googletest	Requirements ##	 Ifyou notice any problems on your platform, please notify googletestframework@googlegroups.com  Patches for fixing them areeven more welcome!
google-googletest	Linux Requirements ###	These are the base requirements to build and use Google Test from a sourcepackage  as described below :Please read the  CONTRIBUTING.md  CONTRIBUTING.md  for details onhow to contribute to this project.Happy testing!
google-gopacket	GoPacket	This library provides packet decoding capabilities for Go.See  godoc  for more details
google-gopacket	GoPacket	  ! GoDoc  Originally forked from the gopcap project written by AndreasKrennmair  
google-gops	gops	 ! Build status   ! GoDoc  gops is a command to list and diagnose Go processes currently running on your system.For processes that starts the diagnostics agent, gops can reportadditional information such as the current stack trace, Go version, memorystats, etc.In order to start the diagnostics agent, see the  hello example  gopackage mainimport  	"log"	"time"	"github.com/google/gops/agent" func main   {	if err := agent.Listen agent.Options{} ; err != nil {		log.Fatal err 	}	time.Sleep time.Hour Otherwise, you could set GOPS_CONFIG_DIR environment variables to assign your config dir.Default, gops will use the current user's home directory AppData on windows .
google-gops	Manual	It is possible to use gops tool both in local and remote mode.Local mode requires that you start the target binary as the same user that runs gops binary.To use gops in a remote mode you need to know target's agent address.In Local mode use process's PID as a target; in Remote mode target is a host:port combination.
google-gops	Listing all processes running locally	To print all go processes, run gops without arguments:
google-gops	$gops setgc  \|\  	Sets the garbage collection target to a certain percentage.The following command sets it to 10%:gops reports the Go version the target program is built with, if you run the following:To print the runtime statistics such as number of goroutines and GOMAXPROCS.
google-gops	Pprof	gops supports CPU and heap pprof profiles
google-gops	Pprof	After reading either heap or CPU profile,it shells out to the go tool pprof and let you interatively examine the profiles.To enter the CPU profile, run:gops allows you to start the runtime tracer for 5 seconds and examine the results.
google-goterm	Get the code	go get github.com/google/goterm/termpackage mainimport    "fmt" func main   {  fmt.Println term.Blue "Hello blue world"  
google-gps-measurement-tools	GPS Measurement Tools	The GNSS Measurement Tools code is provided for you to:This code is maintained on GitHub at the following link:
google-gps-measurement-tools	Initial setup:	Extract the contents of the zip file to a directory, for example:Edit ProcessGnssMeasScript.m to add the demoFiles directory, as follows:Run ProcessGnssMeasScript.m, it will run with pre-recorded log files.
google-gps-measurement-tools	To process a log file you collected from GnssLogger:	save the log file in a directoryedit ProcessGpsMeasScript.m, specify the file name and directory pathrun ProcessGpsMeasScript.mThe code includes a function  GetNasaHourlyEphemeris.m  to read ephemerisfiles from the NASA's archive of Space Geodesy Data, It will automatically go to the ftp when you have a new log file.On some systems you need to use passive mode FTP; if this is required, see The Mathworks site for how to do it.Or  simpler : get the appropriate ephemeris file 'by hand' from the Nasa ftp site  GetNasaHourlyEphemeris.m will tell you the correct url and filename , copy the file to the directory where your log file is, and GetNasaHourlyEphemeris.m will read it from there.
google-gps-measurement-tools	For a summary of the open source GNSS Measurements Tools	See ~/gpstools/opensource/Contents.m or type 'help opensource' in matlabcommand window.
google-gps-measurement-tools	Platform specific notes:	For Windows: use \  backslash , instead of / for directories.For Mac: when installing MATLAB
google-gps-measurement-tools	Platform specific notes:	Allow Apps to be downloaded from: Mac App Store and identified developersUncompress/Unzip utility called from GetNasaHourlyEphemeris.m:The ephemeris on the Nasa ftp is Unix-compressed
google-gps-measurement-tools	Platform specific notes:	GetNasaHourlyEphemeris will automatically uncompress it, if you have the right uncompress function on your computer
google-gps-measurement-tools	Platform specific notes:	If you need to install an unzip utility, see Then search for uncompress in the GetNasaHourlyEphemeris function to find and edit the name of the unzip utility:read the uncompressed file.
google-gps-measurement-tools	GNSSLogger	Sample App that allows registering for various Android location related measurements,log the measurements to the screen and optionally to a text file and as well analyze these Version 2.0.0.0 of the GnssLogger is enhanced with the following features:Compatible with Android-O new features like AGC and multi-frequency supportIncludes weighted least square position and velocity computationsIncludes weighted least square position and velocity uncertainty computationsCompares the computed weighted least squares from raw GPS measurements vs the Kalman Filter position provided by the GPS chipset.Shows the computed weighted least square position from raw GPS measurements on Google Maps vs the Fused Location Provider reported position.Has an A-GPS control tab that allows clearing and injecting assistance dataPlots CN0 of visible satellites and as well prints the top 4 visible satellites CN0 and average valuesPerforms and plots residual analysis for both pseudorange residuals and pseudorange rate residualsEnhanced Logging both to screen and to files functionalities.This source code is supplied as an Android Studio project that can be built and runwith  Android Studio The APK is also provided for convenience.
google-gps-measurement-tools	Pseudorange Library	Position Solution Engine from Gnss Raw measurements as a dependency android library ofGnssLogger application
google-gps-measurement-tools	Pseudorange Library	Part of the dependencies concerning communicating with SUPL serverto retrieve ephemeris info has been packed in Jar for project cleanness
google-gps-measurement-tools	Pseudorange Library	To access the SUPL serverrelated code, please visit git repository of Android CTS.
google-gps-measurement-tools	Copyright Notice	Copyright 2016 Google Inc.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-gpu-emulation-stress-test	GPU Emulation Stress Test	! gpu-emulation-stree-test-image  gpu_emulation_stress_test.gif In graphics for virtual machines, one potential way to get good performance isto use the host's GPU hardware directly
google-gpu-emulation-stress-test	GPU Emulation Stress Test	This can involve the serialization ofall graphics API calls  OpenGL, Vulkan, etc  from/to guest and host, becausethe guest usually resides in a different memory address space from the host andalso the guest/host CPU ISA's often differ.Such communication channels can suffer from overhead when there are many APIcommands issued per second
google-gpu-emulation-stress-test	GPU Emulation Stress Test	 The GPU Emulation Stress Test measures theperformance of graphics virtualization in the form of an Android NDK app thatruns in the guest
google-gpu-emulation-stress-test	GPU Emulation Stress Test	It stresses the communication channel by issuing many drawcalls per second, ramping up from just a few, to thousands per second  default~1000 objects -> ~2 draw calls per object, one for shadow map writing andanother for the final color -> ~2000 draw calls per frame .The number of objects can be adjusted to observe scaling behavior
google-gpu-emulation-stress-test	GPU Emulation Stress Test	There isalso some degree of fillrate testing depending on the API level used, with theOpenGL ES 3.0 version stressing fillrate more due to more fullscreen effects:
google-gpu-mux	GPUMux	GPUMux is a scheduler for CUDA GPU python jobs.**This is not an officially supported Google product.**You let it know what GPUs to use and it will schedule tasks on them for you, always maximizingthe resources
google-gpu-mux	GPUMux	It lets your spawn tasks directly from the web browser and also permits to trackprogress, errors, logs.If the instance is rebooted or shut down, the jobs are restarted when you launch GPUMux.
google-gpu-mux	Setup	**Important**: Make sure the port you use is not open to the world since GPUMux lets you runarbitrary commands, anyone connecting to the port can run arbitrary commands
google-gpu-mux	Setup	You can verify thiseasily by checking that you cannot access GPUMux remotely without ssh port forwarding.In the folder you want to run jobs in, start GPUMux:If you're running multiple instances, you will want to forward to different local ports:Then simply point your browser to the port:
google-gpu-mux	Files	Files are saved in a locally created gpumux folder.You can see the logs of your past runs, status codes, commands
google-gpu-mux	Jobs	If you wish to, you can access your running jobs with the command screen:
google-grinder.dart	Grinder	> Dart workflows, automated.Grinder consists of a library to define project tasks  e.g
google-grinder.dart	Grinder	test, build, doc ,and a command-line tool to run them
google-grinder.dart	Grinder	! pub package     ! Build status    
google-grinder.dart	Getting Started	To start using grinder, add it to your dev_dependencies 
google-grinder.dart	Defining Tasks	Tasks are defined entirely by Dart code allowing you to take advantage ofthe whole Dart ecosystem to write and debug them
google-grinder.dart	Defining Tasks	 Task definitions residein a tool/grind.dart script
google-grinder.dart	Defining Tasks	To create a simple grinder script, run:In general, grinder scripts look something like this:import 'package:grinder/grinder.dart';main args  => grind args ;@DefaultTask 'Build the project.' build   {  log "Building..." ;@Task 'Test stuff.' @Depends build test   {  new PubApp.local 'test' .run    ;@Task 'Generate docs.' doc   {  log "Generating docs..." ;@Task 'Deploy built app.' @Depends build, test, doc deploy   {  ...Any task dependencies  see @Depends above , are run before the dependent task.Grinder contains a variety of convenience APIs for common task definitions, suchas PubApp referenced above
google-grinder.dart	Defining Tasks	 See the API Documentation  forfull details.
google-grinder.dart	Running Tasks	First install the grind executable:then use it to run desired tasks:or to run a default task  see @DefaultTask above :or to display a list of available tasks and their dependencies:You can also bypass installing grind and instead use pub run grinder.
google-grinder.dart	Passing parameters to tasks	In order to pass parameters to tasks from the command-line, you query theTaskArgs instance for your task invocation
google-grinder.dart	Passing parameters to tasks	For example:grind build --release --mode=topazYou can pass flags and options to multiple tasks
google-grinder.dart	Passing parameters to tasks	The following command-linewould pass separate flags and options to two different tasks:grind build --release generate-docs --header=small
google-grinder.dart	Disclaimer	This is not an official Google product.
google-grumpy	Grumpy: Go running Python	   ! Join the chat at   
google-grumpy	Overview	Grumpy is a Python to Go source code transcompiler and runtime that is intendedto be a near drop-in replacement for CPython 2.The key difference is that itcompiles Python source code to Go source code which is then compiled to nativecode, rather than to bytecode
google-grumpy	Overview	This means that Grumpy has no VM
google-grumpy	Overview	The compiled Gosource code is a series of calls to the Grumpy runtime, a Go library serving asimilar purpose to the Python C API  although the API is incompatible withCPython's .
google-grumpy	Things that will probably never be supported by Grumpy	exec, eval and compile: These dynamic features of CPython are notC extension modules: Grumpy has a different API and object layout than
google-grumpy	Things that Grumpy will support but doesn't yet	There are three basic categories of incomplete functionality: Language features  Builtin functions and types  Standard library C locale support: Go doesn't support locales in the same way that C does
google-grumpy	Things that Grumpy will support but doesn't yet	As such,
google-grumpy	Method 1: make run:	The simplest way to execute a Grumpy program is to use make run, which wraps ashell script called grumprun that takes Python code on stdin and builds and runsthe code under Grumpy
google-grumpy	Method 1: make run:	All of the commands below are assumed to be run from theroot directory of the Grumpy source code distribution:For more complicated programs, you'll want to compile your Python source code toGo using grumpc  the Grumpy compiler  and then build the Go code using gobuild
google-grumpy	Method 1: make run:	Since Grumpy programs are statically linked, all the modules in aprogram must be findable by the Grumpy toolchain on the GOPATH
google-grumpy	Method 1: make run:	Grumpy looks forGo packages corresponding to Python modules in the \_\_python\_\_ subdirectoryof the GOPATH
google-grumpy	Method 1: make run:	By convention, this subdirectory is also used for staging Pythonsource code, making it similar to the PYTHONPATH.The first step is to set up the shell so that the Grumpy toolchain and librariescan be found
google-grumpy	Method 1: make run:	From the root directory of the Grumpy source distribution run:"\_\_python\_\_/hello"
google-grumpy	Method 1: make run:	We can also import this module into Python programsthat are built using grumprun:Compiles the given Python code to a dummy Go package, the same way weProduces a main Go package that imports the Go package from step andExecutes go run on the main package generated in step 
google-grumpy	Developing Grumpy	There are three main components and depending on what kind of feature you'rewriting, you may need to change one or more of these.
google-grumpy	grumpc	Grumpy converts Python programs into Go programs and grumpc is the toolresponsible for parsing Python code and generating Go code from it
google-grumpy	grumpc	grumpc iswritten in Python and uses the  pythonparser module to accomplish parsing.The grumpc script itself lives at tools/grumpc
google-grumpy	grumpc	It is supported by a number ofPython modules in the compiler subdir.
google-grumpy	Grumpy Runtime	The Go code generated by grumpc performs operations on data structures thatrepresent Python objects in running Grumpy programs
google-grumpy	Grumpy Runtime	These data structures andoperations are defined in the grumpy Go library  source is in the runtimesubdir of the source distribution 
google-grumpy	Grumpy Runtime	 This runtime is analogous to the Python CAPI and many of the structures and operations defined by grumpy havecounterparts in CPython.
google-grumpy	Grumpy Standard Library	Much of the Python standard library is written in Python and thus "just works"in Grumpy
google-grumpy	Grumpy Standard Library	These parts of the standard library are copied from CPython 2.7 possibly with light modifications 
google-grumpy	Grumpy Standard Library	For licensing reasons, these files are keptin the third_party subdir.The parts of the standard library that cannot be written in pure Python, e.g.file and directory operations, are kept in the lib subdir
google-grumpy	Grumpy Standard Library	In CPython thesekinds of modules are written as C extensions
google-grumpy	Grumpy Standard Library	In Grumpy they are written inPython but they use native Go extensions to access facilities not otherwiseavailable in Python.
google-grumpy	Source Code Overview	Questions? Comments? Drop us a line at  grumpy-users@googlegroups.com or join our  Gitter channel 
google-gsocguides	Google Summer of Code Guides	This project contains the Google Summer of Code Mentor Guide and Student Guide.
google-gsocguides	Template	The template and build is based onDocumentation can be found at
google-gsocguides	Local Development	 shell
google-gsocguides	Build docker image  once 	make build-image
google-gsocguides	Run server  listens on port 4000 	make serve
google-gsocguides	Want to contribute?	Please see the  CONTRIBUTING  CONTRIBUTING.md  instructions.
google-gson	Gson	Gson is a Java library that can be used to convert Java Objects into their JSON representation
google-gson	Gson	It can also be used to convert a JSON string to an equivalent Java object.Gson can work with arbitrary Java objects including pre-existing objects that you do not have source-code of.There are a few open-source projects that can convert Java objects to JSON
google-gson	Gson	However, most of them require that you place Java annotations in your classes; something that you can not do if you do not have access to the source-code
google-gson	Gson	Most also do not fully support the use of Java Generics
google-gson	Gson	Gson considers both of these as very important design goals.
google-gson	Goals	 Gson jar downloads  are available from Maven Central
google-gson	Goals	 
google-gson	Related Content Created by Third Parties	Gson is released under the  Apache 2.0 license  LICENSE .Copyright 2008 Google Inc.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-gson	Disclaimer	This is not an officially supported Google product.
google-gsps-support-tool	Upload the file it creates to the  log analyzer 	Learn more about  troubleshooting GSPS  and about  GSPS logs and error codes This tool collects logs and information from all Domain Controllers running  G Suite Password Sync  in order to allow reviewing them all in a single place to make troubleshooting easier.It's built using VBScript for compatibility with all Windows versions, with a thin wrapper built using  AutoIt  to save it as an EXE file.
google-gtd-txt	gtd-txt: Getting Things Done in plain text	gtd-txt is a task manager designed for use with David Allen's Getting ThingsDone methodology
google-gtd-txt	gtd-txt: Getting Things Done in plain text	It's similar in spirit to the  todo.txt system, but it uses one file per project, instead of one line per action
google-gtd-txt	gtd-txt: Getting Things Done in plain text	Thisallows you to easily group notes alongside projects and actions.This is not an official Google product.
google-gtd-txt	Dependencies	You will probably need a GNU userspace
google-gtd-txt	Dependencies	In particular, you definitely need
google-gtest-parallel	gtest-parallel	_This is not an official Google product._gtest-parallel is a script that executes  GoogleTest  binaries in parallel, providing goodspeedup for single-threaded tests  on multi-core machines  and tests that do notrun at 100% CPU  on singleThe script works by listing the tests of each binary, and then executing them onworkers in separate processes
google-gtest-parallel	gtest-parallel	This works fine so long as the tests are selfcontained and do not share resources  reading data is fine, writing to the samelog file is probably not .
google-gtest-parallel	Basic Usage	_For a full list of options, see --help._This shards all enabled tests across a number of workers, defaulting to thenumber of cores in the system
google-gtest-parallel	Basic Usage	If your system uses Python 2, but you have nopython2 binary, run python gtest-parallel instead of ./gtest-parallel.To run only a select set of tests, run:This filter takes the same parameters as Google Test, so -Foo.\test exclusion as well
google-gtest-parallel	Basic Usage	This is especially useful for slow tests  that you'renot working on , or tests that may not be able to run in parallel.
google-gtest-parallel	Flakiness	Flaky tests  tests that do not deterministically pass or fail  often cause a lotof developer headache
google-gtest-parallel	Flakiness	A test that fails only 1% of the time can be very hard todetect as flaky, and even harder to convince yourself of having fixed.--workers= well above the number of available core can often cause contentionand be fruitful for detecting flaky tests as well.The above command repeats all tests inside binary1, binary2 and binary3located in out/
google-gtest-parallel	Flakiness	The tests are run 1000 times each on 128 workers  this ismore than I have cores on my machine anyways 
google-gtest-parallel	Flakiness	This can often be done and thenleft overnight if you've no initial guess to which tests are flaky and whichones aren't
google-gtest-parallel	Flakiness	When you've figured out which tests are flaky  and want to fixthem , repeat the above command with --gtest_filter= to only retry the flakytests that you are fixing.Note that repeated tests do run concurrently with themselves for efficiency, andas such they have problem writing to hard-coded files, even if they are onlyused by that single test
google-gtest-parallel	Flakiness	tmpfile   and similar library functions are oftenyour friends here.
google-gtest-parallel	Flakiness Summaries	Especially for disabled tests, you might wonder how stable a test seems beforetrying to enable it
google-gtest-parallel	Flakiness Summaries	gtest-parallel prints summaries  number of passed/failedtests  when --repeat= is used and at least one test fails
google-gtest-parallel	Flakiness Summaries	This can be used togenerate passed/failed statistics per test
google-gtest-parallel	Flakiness Summaries	If no statistics are generated thenall invocations tests are passing, congratulations!For example, to try all disabled tests and see how stable they are:Which will generate something like this at the end of the run:
google-gtest-parallel	Running Tests Within Test Cases Sequentially	Sometimes tests within a single test case use globally-shared resources hard-coded file paths, sockets, etc
google-gtest-parallel	Running Tests Within Test Cases Sequentially	 and cannot be run in parallel
google-gtest-parallel	Running Tests Within Test Cases Sequentially	Runningsuch tests in parallel will either fail or be flaky  if they happen to notoverlap during execution, they pass 
google-gtest-parallel	Running Tests Within Test Cases Sequentially	So long as these resources are only sharedwithin the same test case gtest-parallel can still provide some parallelism.For such binaries where test cases are independent, --serialize_test_cases that runs tests within the same test case sequentially.While generally not providing as much speedup as fully parallel test execution,this permits such binaries to partially benefit from parallel execution.
google-gtfs-realtime-bindings-php	PHP GTFS-realtime Language Bindings	 ! PHP version  Provides PHP classes generated from the GTFS-realtime  ProtocolBuffer specification
google-gtfs-realtime-bindings-php	PHP GTFS-realtime Language Bindings	 These classes will allow you to parse a binary ProtocolBuffer GTFS-realtime data feed into PHP objects.For bindings in other languages, see the gtfs-realtime-bindings 
google-gtfs-realtime-bindings-php	Add the Dependency	To use the gtfs-realtime-bindings-php classes in your own project, you needto first install the  Packagist Composerpackage   To doso, add a dependency in your composer.json file: ! PHP version  Then update your Composer dependencies:The following code snippet demonstrates downloading a GTFS-realtime data feedfrom a particular URL, parsing it as a FeedMessage  the root type of theGTFS-realtime schema , and iterating over the results.require_once 'vendor/autoload.php';use transit_realtime\FeedMessage;$data = file_get_contents "URL OF YOUR GTFS-REALTIME SOURCE GOES HERE" ;$feed = new FeedMessage  ;$feed->parse $data ;foreach  $feed->getEntityList   as $entity  {  if  $entity->hasTripUpdate    {  }For more details on the naming conventions for the PHP classes generated fromthe  gtfs-realtime.proto check out the  the gtfs-realtime.php source file 
google-gtfs-realtime-bindings	gtfs-realtime-bindings	Language bindings generated from the GTFS-realtime  protocolbuffer spec for popular languages.
google-gtfs-realtime-bindings	Introduction	 GTFS-realtime  is a dataformat for communicating real-time information about public transit systems.GTFS-realtime data is encoded and decoded using  ProtocolBuffers  a compact binaryrepresentation designed for fast and efficient processing
google-gtfs-realtime-bindings	Introduction	 The data schemaitself is defined in gtfs-realtime.proto To work with GTFS-realtime data, a developer would typically use thegtfs-realtime.proto schema to generate classes in the programming language oftheir choice
google-gtfs-realtime-bindings	Introduction	 These classes can then be used for constructing GTFS-realtimedata model objects and serializing them as binary data or, in the reversedirection, parsing binary data into data model objects.Because generating GTFS-realtime data model classes from thegtfs-realtime.proto schema is such a common task, but also one that sometimescauses confusion for first-time developers, this project aims to providepre-generated GTFS-realtime language bindings for a number of the most popularprogramming languages
google-gtfs-realtime-bindings	Introduction	 Where possible, these language bindings will bepublished as packages to facilitate their use in other projects.
google-gtfs-realtime-bindings	Supported Languages	We don't provide generated code for C++, use the official protoc compiler for that  from  here  or  here Are we missing your favorite language? Consider contributing:Read  CONTRIBUTING.md  CONTRIBUTING.md .Open a pull request with your language of choice
google-gtfs-realtime-bindings	Supported Languages	Please include update instructions  ideally, scripts 
google-gtfs-realtime-bindings	Supported Languages	Also, provide packaging suitable for the language ecosystem.
google-gtm-currency-rates-sync	Overview	A sheets bound Apps Script that enables maintaining an up to date GTM  GoogleTag Manager  Lookup Table variable with all the currency rates available inGoogle Finance data via sheets
google-gtm-currency-rates-sync	Overview	The resulting lookup table can be leveraged bycustom GTM variable scripts for applying currency conversion on tags data.Example: Utilising the lookup table to updating revenue data in Floodlight tagson multi-currency sites before sending them into DCM or DS.
google-gtm-currency-rates-sync	Setup instructions	Once all of this is set, you can validate that the script is running properly byrunning *runSync this will show up after saving changes and refreshing the sheet page .The Apps Script can also be extended to have it run based on time triggers 
google-gtm-currency-rates-sync	Disclaimer	This is not an official Google product.
google-gtm-http-fetcher	Google Toolbox for Mac 	**Project site***Discussion group*GTM HTTP Fetcher makes it easy for Cocoa applications to perform httpoperations
google-gtm-http-fetcher	Google Toolbox for Mac 	 The fetcher is implemented as a wrapper on NSURLConnection, so itsbehavior is asynchronous and uses operating-system settings on iOS and Mac OS X.class has been superseded by GTMSessionFetcher Features include:read the  wiki **If you have a problem**, please join the GTM discussion group or submit an  issue 
google-gtm-oauth	GTM OAuth: Google Toolbox for Mac 	**Project site***Discussion group*The Google Toolbox for Mac OAuth Controllers make it easy for Cocoaapplications to sign in to services using OAuth 1.0 for authentication andFeatures include: wiki **If you have a problem*please join the  GTM-OAuth discussion group or submit an  issue The library incorporates the GTM HTTP Fetcher project This project is for controllers for services using the OAuth 1.0 protocol.There is a separate project for  OAuth 2.0 controllers Other useful classes for OS X and iOS developers are available in the Google Toolbox for Mac 
google-gtm-oauth2	GTM OAuth 2: Google Toolbox for Mac 	**Project site***Discussion group*  The Google Toolbox for Mac OAuth 2 Controllers make it easy for Cocoaapplications to sign in to services using OAuth 2 for authentication andFeatures include:**If you have a problem*please join the GTM-OAuth 2 discussion group or submit an  issue The library incorporates the GTM Session Fetcher project There is a separate project for  OAuth 1 controllers Other useful classes for Mac and iOS developers are available in the Google Toolbox for Mac 
google-gtm-session-fetcher	Google Toolbox for Mac 	**Project site***Discussion group*  GTMSessionFetcher makes it easy for Cocoa applications to perform httpoperations
google-gtm-session-fetcher	Google Toolbox for Mac 	The fetcher is implemented as a wrapper on NSURLSession, so itsbehavior is asynchronous and uses operating-system settings on iOS and Mac OS X.Features include:
google-guava-beta-checker	Guava Beta Checker	An  Error Prone  plugin that checks for usages of  Guava  APIs that areannotated with the  @Beta  annotation
google-guava-beta-checker	Guava Beta Checker	Such APIs should _never_ be used inlibrary code that other projects may depend on; using the Beta Checker can helplibrary projects ensure that they don't use them.Example error:Using the Beta Checker requires configuring your project to build with the ErrorProne Java compiler
google-guava-beta-checker	Guava Beta Checker	By default, this enables a lot of useful checks for avariety of common bugs
google-guava-beta-checker	Guava Beta Checker	However, if you just want to use the Beta Checker, theother checks can be disabled.The usage examples below will show how to use the Beta Checker only, with notesfor what to remove if you want all checks.
google-guava-beta-checker	Maven	In pom.xml:Your build.gradle file s  should have the following things
google-guava-beta-checker	Maven	Add them to what'salready in your files as appropriate.// Add the gradle plugins that are needed for Error Prone plugin supportbuildscript {  repositories {  }  dependencies {  }repositories {  mavenCentral  apply plugin: 'java'// Enable Error Prone and APT pluginsapply plugin: 'net.ltgt.errorprone'apply plugin: 'net.ltgt.apt'dependencies {  // Add an APT dependency on the beta checker  apt 'com.google.guava:guava-beta-checker:$betaCheckerVersion'configurations.errorprone {  resolutionStrategy.force 'com.google.errorprone:error_prone_core:2.1.2'compileJava {  // Remove these compilerArgs to keep all checks enabled  options.compilerArgs +=  "-XepDisableAllChecks", "-Xep:BetaApi:ERROR" 
google-guava-beta-checker	Bazel	Bazel Java targets use the Error Prone compiler by default
google-guava-beta-checker	Bazel	To use the BetaChecker with Bazel, you'll need to add a maven_jar dependency on the BetaChecker, then create a java_plugin target for it, and finally add that targetto the plugins attribute of any Java targets it should run on.
google-guava-beta-checker	Example	You'll need a java_library for the Beta Checker
google-guava-beta-checker	Example	You can get this using generate-workspace , by running a command like:described in the documentation, put the following in third_party/BUILD:load "//:generate_workspace.bzl", "generated_java_libraries" generated_java_libraries  java_plugin  Finally, add the plugin to the plugins attribute of any Java target you wantto be checked for usages of @Beta APIs: Guava :  @Beta :  generate-workspace : 
google-guava	Guava: Google Core Libraries for Java	 ! Latest release    Guava is a set of core libraries that includes new collection types  such asmultimap and multiset , immutable collections, a graph library, functionaltypes, an in-memory cache, and APIs/utilities for concurrency, I/O, hashing,primitives, reflection, string processing, and much more!Guava comes in two flavors
google-guava	Guava: Google Core Libraries for Java	android directory : 
google-guava	Adding Guava to your build	Guava's Maven group ID is com.google.guava and its artifact ID is guava.Guava provides two different "flavors": one for use on a  Java 8+  JRE and onefor use on Android or Java 7 or by any library that wants to be compatible witheither of those
google-guava	Adding Guava to your build	These flavors are specified in the Maven version field aseither 26.0-jre or 26.0-android
google-guava	Adding Guava to your build	For more about depending onGuava, see  using Guava in your build .To add a dependency on Guava using Maven, use the following:Snapshots of Guava built from the master branch are available through Mavenusing version HEAD-jre-SNAPSHOT, or HEAD-android-SNAPSHOT for the AndroidAPIs marked with the @Beta annotation at the class or method levelare subject to change
google-guava	Adding Guava to your build	They can be modified in any way, or evenremoved, at any time
google-guava	Adding Guava to your build	If your code is a library itself  i.e
google-guava	Adding Guava to your build	it isused on the CLASSPATH of users outside your own control , you shouldnot use beta APIs, unless you  repackage  them
google-guava	Adding Guava to your build	**If yourcode is a library, we strongly recommend using the  Guava Beta Checker  toensure that you do not use any @Beta APIs!**APIs without @Beta will remain binary-compatible for the indefinitefuture
google-guava	Adding Guava to your build	 Previously, we sometimes removed such APIs after a deprecation period.The last release to remove non-@Beta APIs was Guava 21.0
google-guava	Adding Guava to your build	 Even @DeprecatedAPIs will remain  again, unless they are @Beta 
google-guava	Adding Guava to your build	We have no plans to startremoving things again, but officially, we're leaving our options open in caseof surprises  like, say, a serious security problem .Serialized forms of ALL objects are subject to change unless notedotherwise
google-guava	Adding Guava to your build	Do not persist these and assume they can be read by afuture version of the library.Our classes are not designed to protect against a malicious caller.You should not use them for communication between trusted anduntrusted code.For the mainline flavor, we unit-test the libraries using only OpenJDK 1.8 onLinux
google-guava	Adding Guava to your build	Some features, especially in com.google.common.io, may not workcorrectly in other environments
google-guava	Adding Guava to your build	For the Android flavor, our unit tests run onAPI level 15  Ice Cream Sandwich 
google-guava	Adding Guava to your build	guava-snapshot-api-docs :  guava-snapshot-api-diffs :  Guava Explained :  Guava Beta Checker :  using Guava in your build :  repackage : 
google-guetzli	Introduction	Guetzli is a JPEG encoder that aims for excellent compression density at highvisual quality
google-guetzli	Introduction	Guetzli-generated images are typically 20-30% smaller thanimages of equivalent quality generated by libjpeg
google-guetzli	Introduction	Guetzli generates onlysequential  nonprogressive  JPEGs due to faster decompression speeds they offer
google-guetzli	Introduction	 
google-guetzli	On POSIX systems	 Get a copy of the source code, either by cloning this repository, or by Install  libpng 
google-guetzli	On Windows	 Get a copy of the source code, either by cloning this repository, or by Install  Visual Studio 2015  and Install libpng using vcpkg: .\vcpkg install libpng
google-guetzli	On Windows	Cause the installed packages to be available system-wide: .\vcpkg integrate Open the Visual Studio project enclosed in the repository and build it.
google-guetzli	On macOS	To install using  Homebrew Install  Homebrew brew install guetzliTo install using the repository: Get a copy of the source code, either by cloning this repository, or by Install  Homebrew  or  MacPorts  Install libpngThere's also a  Bazel  build configuration provided
google-guetzli	On macOS	If youhave Bazel installed, you can also compile Guetzli by running bazel build -c opt //:guetzli.
google-guetzli	Using	memory per 1MPix of the input image.using about 1 minute of CPU per 1 MPix of input image.2.2**
google-guetzli	Using	Guetzli will ignore any color-profile metadata in the image.To try out Guetzli you need to  build  #building  or download  the Guetzli binary
google-guetzli	Using	Thebinary reads a PNG or JPEG image and creates an optimized JPEG image:prefer providing uncompressed input images  e.g
google-guetzli	Using	that haven't been alreadycompressed with any JPEG encoders, including Guetzli 
google-guetzli	Using	While it will work on otherimages too, results will be poorer
google-guetzli	Using	You can try compressing an enclosed  samplehigh qualityimage You can pass a --quality Q parameter to set quality in units equivalent tolibjpeg quality
google-guetzli	Using	You can also pass a --verbose flag to see a trace of encodingattempts made.Please note that JPEG images do not support alpha channel  transparency 
google-guetzli	Using	If theinput is a PNG with an alpha channel, it will be overlaid on black backgroundbefore encoding.
google-guice-aqueduct	Guice Aqueduct	Guice Aqueduct is a Guice binder to configure Chained instances to form a pipeline
google-guice-aqueduct	Guice Aqueduct	For each Chained item, next in pipeline will be set via Chained.setNext call at injection time
google-guice-aqueduct	Guice Aqueduct	For the last item in line, noOp instance configured from the constructor will be set as the next item.For example, suppose we have a Chained pipeline class:abstract class Pipeline implements Chained {  Pipeline next;  public void setNext Pipeline next  {  }class PipelineA extends Pipeline {  @Override  void process   {  }class PipelineB extends Pipeline {  @Override  void process   {  }class NoOpPipeline extends Pipeline {  @Override  void process   {  }Now, when we inject a pipeline through the following calls inside a module:Note that instead of implementing Chained.setNext, one could extend AbstractPipeline which does the same thing as what Pipeline class does in the example above.Disclaimer: This is not an official Google product.
google-gulava	Gulava	*Relational programming library for Java.*Gulava allows you to write relational predicates in Java
google-gulava	Gulava	You can writeProlog-style predicates and use them from normal Java code, seamlesslyintegrated with the magic of annotation processors.See the  GitHub wiki  for some how-tos and to get started writing your own predicates and logic value types.This repository requires  Bazel  to build,test, and run
google-gulava	Gulava	After you have set up Bazel, you can run the demo:
google-gulava	Contributing	Gulava doesn't have a particular long-term goal in mind besides exploringrelational programming
google-gulava	Contributing	Any contributions to that end are welcome! That could besomething like:MicroKanren paper: 
google-gumbo-parser	#include "gumbo.h"	int main   {  GumboOutput  // Do stuff with output->root  gumbo_destroy_output &kGumboDefaultOptions, output ;See the API documentation and sample programs for more details.A note on API/ABI compatibilityWe'll make a best effort to preserve API compatibility between releases.The initial release is a 0.9  beta  release to solicit comments from earlyadopters, but if no major problems are found with the API, a 1.0 releasewill follow shortly, and the API of that should be considered stable
google-gumbo-parser	#include "gumbo.h"	 Ifchanges are necessary, we follow  semantic versioning   .We make no such guarantees about the ABI, and it's very likely thatsubsequent versions may require a recompile of client code
google-gumbo-parser	#include "gumbo.h"	 For thisreason, we recommend NOT using Gumbo data structures throughout a program,and instead limiting them to a translation layer that picks out whateverdata is needed from the parse tree and then converts that to persistentdata structures more appropriate for the application
google-gumbo-parser	#include "gumbo.h"	 The API isstructured to encourage this use, with a single delete function for thewhole parse tree, and is not designed with mutation in mind.Python usageTo install the python bindings, make sure that theC library is installed first, and then sudo python setup.py install fromthe root of the distro
google-gumbo-parser	#include "gumbo.h"	 This installs a 'gumbo' module; pydoc gumboshould tell you about it.Recommended best-practice for Python usage is to use one of the adapters toan existing API  personally, I prefer BeautifulSoup  and write your programin terms of those
google-gumbo-parser	#include "gumbo.h"	 The raw CTypes bindings should be considered buildingblocks for higher-level libraries and rarely referenced directly.External Bindings and other wrappersThe following language bindings or other tools/wrappers are maintained byvarious contributors in other repositories: ruby-gumbo :  nokogumbo :  node-gumbo-parser :  gumbo-d :  lua-gumbo :  OCGumbo :  ObjectiveGumbo :  GumboBindings :  GumboPHP :  Gumbo.jl :  gumbo-libxml :  HTML5 parsing algorithm :  HTML5 spec :  html5lib tests :  googletest :  semantic versioning :  HTML::Gumbo : 
google-gvisor	gVisor	gVisor is a user-space kernel, written in Go, that implements a substantialportion of the Linux system surface
google-gvisor	gVisor	It includes an Open Container Initiative  OCI   oci  runtime called runsc that provides anisolation boundary between the application and the host kernel
google-gvisor	gVisor	The runscruntime integrates with Docker and Kubernetes, making it simple to run sandboxedgVisor takes a distinct approach to container sandboxing and makes a differentset of technical trade-offs compared to existing sandbox technologies, thusproviding new tools and ideas for the container security landscape.
google-gvisor	Why does gVisor exist?	Containers are not a  **sandbox**  sandbox 
google-gvisor	Why does gVisor exist?	While containers haverevolutionized how we develop, package, and deploy applications, runninguntrusted or potentially malicious code without additional isolation is not agood idea
google-gvisor	Why does gVisor exist?	The efficiency and performance gains from using a single, sharedkernel also mean that container escape is possible with a single vulnerability.gVisor is a user-space kernel for containers
google-gvisor	Why does gVisor exist?	It limits the host kernel surfaceaccessible to the application while still giving the application access to allthe features it expects
google-gvisor	Why does gVisor exist?	Unlike most kernels, gVisor does not assume or requirea fixed set of physical resources; instead, it leverages existing host kernelfunctionality and runs as a normal user-space process
google-gvisor	Why does gVisor exist?	In other words, gVisorimplements Linux by way of Linux.gVisor should not be confused with technologies and tools to harden containersagainst external threats, provide additional integrity checks, or limit thescope of access for a service
google-gvisor	Why does gVisor exist?	One should always be careful about what data ismade available to a container.
google-gvisor	How is gVisor different from other container isolation mechanisms?	Two other approaches are commonly taken to provide stronger isolation thannative containers.**Machine-level virtualization**, such as  KVM  kvm  and  Xen  xen , exposesvirtualized hardware to a guest kernel via a Virtual Machine Monitor  VMM 
google-gvisor	How is gVisor different from other container isolation mechanisms?	Thisvirtualized hardware is generally enlightened  paravirtualized  and additionalmechanisms can be used to improve the visibility between the guest and host e.g
google-gvisor	How is gVisor different from other container isolation mechanisms?	balloon drivers, paravirtualized spinlocks 
google-gvisor	How is gVisor different from other container isolation mechanisms?	Running containers indistinct virtual machines can provide great isolation, compatibility andperformance  though nested virtualization may bring challenges in this area ,but for containers it often requires additional proxies and agents, and mayrequire a larger resource footprint and slower start-up times.! Machine-level virtualization  g3doc/Machine-Virtualization.png "Machine-level virtualization" **Rule-based execution**, such as  seccomp  seccomp ,  SELinux  selinux  and AppArmor  apparmor , allows the specification of a fine-grained security policyfor an application or container
google-gvisor	How is gVisor different from other container isolation mechanisms?	These schemes typically rely on hooksimplemented inside the host kernel to enforce the rules
google-gvisor	How is gVisor different from other container isolation mechanisms?	If the surface can bemade small enough  i.e
google-gvisor	How is gVisor different from other container isolation mechanisms?	a sufficiently complete policy defined , then this is anexcellent way to sandbox applications and maintain native performance
google-gvisor	How is gVisor different from other container isolation mechanisms?	However,in practice it can be extremely difficult  if not impossible  to reliably definea policy for arbitrary, previously unknown applications, making this approachchallenging to apply universally.! Rule-based execution  g3doc/Rule-Based-Execution.png "Rule-based execution" Rule-based execution is often combined with additional layers forabove.gVisor intercepts application system calls and acts as the guest kernel, withoutthe need for translation through virtualized hardware
google-gvisor	How is gVisor different from other container isolation mechanisms?	gVisor may be thought ofas either a merged guest kernel and VMM, or as seccomp on steroids
google-gvisor	How is gVisor different from other container isolation mechanisms?	Thisarchitecture allows it to provide a flexible resource footprint  i.e
google-gvisor	How is gVisor different from other container isolation mechanisms?	one basedon threads and memory mappings, not fixed guest physical resources  while alsolowering the fixed costs of virtualization
google-gvisor	How is gVisor different from other container isolation mechanisms?	However, this comes at the price ofreduced application compatibility and higher per-system call overhead.! gVisor  g3doc/Layers.png "gVisor" On top of this, gVisor employs rule-based execution to provide defense-in-depth details below .gVisor's approach is similar to  User Mode Linux  UML   uml , although UMLvirtualizes hardware internally and thus provides a fixed resource footprint.Each of the above approaches may excel in distinct scenarios
google-gvisor	How is gVisor different from other container isolation mechanisms?	For example,machine-level virtualization will face challenges achieving high density, whilegVisor may provide poor performance for system call heavy workloads.
google-gvisor	Why Go?	gVisor was written in Go in order to avoid security pitfalls that can plaguekernels
google-gvisor	Why Go?	With Go, there are strong types, built-in bounds checks, nouninitialized variables, no use-after-free, no stack overflow, and a built-inrace detector
google-gvisor	Why Go?	 The use of Go has its challenges too, and isn't free
google-gvisor	Architecture	gVisor intercepts all system calls made by the application, and does thenecessary work to service them
google-gvisor	Architecture	Importantly, gVisor does not simply redirectapplication system calls through to the host kernel
google-gvisor	Architecture	Instead, gVisor implementsmost kernel primitives  signals, file systems, futexes, pipes, mm, etc
google-gvisor	Architecture	 and hascomplete system call handlers built on top of these primitives.Since gVisor is itself a user-space application, it will make some host systemcalls to support its operation, but much like a VMM, it will not allow theapplication to directly control the system calls it makes.
google-gvisor	File System Access	In order to provide defense-in-depth and limit the host system surface, thegVisor container runtime is normally split into two separate processes
google-gvisor	File System Access	First,the *Sentrycode and handling system calls
google-gvisor	File System Access	Second, file system operations that extendbeyond the sandbox  not internal proc or tmp files, pipes, etc
google-gvisor	File System Access	 are sent to aproxy, called a *Gofer*, via a 9P connection.! Sentry  g3doc/Sentry-Gofer.png "Sentry and Gofer" The Gofer acts as a file system proxy by opening host files on behalf of theapplication, and passing them to the Sentry process, which has no host fileaccess itself
google-gvisor	File System Access	Furthermore, the Sentry runs in an empty user namespace, and thesystem calls made by gVisor to the host are restricted using seccomp filters inorder to provide defense-in-depth.
google-gvisor	Network Access	The Sentry implements its own network stack  also written in Go  called netstack  netstack 
google-gvisor	Network Access	All aspects of the network stack are handled inside theSentry — including TCP connection state, control messages, and packet assembly —keeping it isolated from the host network stack
google-gvisor	Network Access	Data link layer packets arewritten directly to the virtual device inside the network namespace setup byDocker or Kubernetes.A network passthrough mode is also supported, but comes at the cost of reducedisolation  see below .
google-gvisor	Platforms	The Sentry requires a *platformmapping functionality
google-gvisor	Platforms	Today, gVisor supports two platforms:
google-gvisor	Performance	There are several factors influencing performance
google-gvisor	Performance	The platform choice has thelargest direct impact that varies depending on the specific workload
google-gvisor	Performance	There isno best platform: Ptrace works universally, including on VM instances, butapplications may perform at a fraction of their original levels
google-gvisor	Performance	Beyond theplatform choice, passthrough modes may be useful for improving perfomance at thecost of some isolation.
google-gvisor	Installation	These instructions will get you up-and-running sandboxed containers with gVisorand Docker.Note that gVisor can only run on x86\_64 Linux 3.17+
google-gvisor	Installation	In addition, gVisor onlysupports x86\_64 binaries inside the sandbox  i.e., it cannot run 32-bitbinaries .
google-gvisor	Download a Build	The easiest way to get {yyyy-mm-dd}/runsc.sha512**It is important to copy this binary to some place that is accessible to allusers**, since runsc executes itself as user nobody to avoid unnecessaryprivileges
google-gvisor	Download a Build	The /usr/local/bin directory is a good choice.Next, configure Docker to use runsc by adding a runtime entry to your Dockerconfiguration  /etc/docker/daemon.json 
google-gvisor	Download a Build	You may have to create this file ifit does not exist
google-gvisor	Download a Build	Also, some Docker versions also require you to specify the storage-driver field  docker-storage-driver .In the end, the file should look something like:this is done via:gVisor can run sandboxed containers in a Kubernetes cluster with cri-o, althoughthis is not recommended for production environments yet
google-gvisor	Download a Build	Follow these instructions  cri-o-k8s  to run  cri-o  cri-o  on a node in a Kubernetescluster
google-gvisor	Download a Build	Build runtime_untrusted_workload in /etc/crio/crio.conf.Any Pod without the io.kubernetes.cri-o.TrustedSandbox annotation  or with theannotation set to false  will be run with runsc.Currently, gVisor only supports Pods with a single container  not counting theever-present pause container 
google-gvisor	Download a Build	Support for multiple containers within a singlePod is coming soon.
google-gvisor	Installing from Source	gVisor currently requires x86\_64 Linux to build.
google-gvisor	Requirements	Make sure the following dependencies are installed:Clone the gVisor repo:Build and install the runsc binary.The gVisor test suite can be run with Bazel:To enable debug and system call logging, add the runtimeArgs below to yourDocker configuration  /etc/docker/daemon.json :restart the Docker daemon:with name boot will contain the strace logs from your application, which canbe useful for identifying missing or broken system calls in gVisor.
google-gvisor	Enabling network passthrough	For high-performance networking applications, you may choose to disable the userspace network stack and instead use the host network stack
google-gvisor	Enabling network passthrough	Note that this modedecreases the isolation to the host.Add the following runtimeArgs to your Docker configuration /etc/docker/daemon.json  and restart the Docker daemon:Depending on hardware and performance characteristics, you may choose to use adifferent platform
google-gvisor	Enabling network passthrough	The Ptrace platform is the default, but the KVM platform maybe specified by passing the --platform flag to runsc in your Dockerconfiguration  /etc/docker/daemon.json :
google-gvisor	Checkpoint/Restore	gVisor has the ability to checkpoint a process, save its current state in astate file, and restore into a new container using the state file
google-gvisor	Checkpoint/Restore	For moreinformation about the checkpoint and restore commands, see the checkpoint/restore readme  checkpoint-restore .
google-gvisor	Will my container work with gVisor?	gVisor implements a large portion of the Linux surface and while we strive tomake it broadly compatible, there are  and always will be  unimplementedfeatures and bugs
google-gvisor	Will my container work with gVisor?	The only real way to know if it will work is to try
google-gvisor	Will my container work with gVisor?	If youfind a container that doesn’t work and there is no known issue, please file a bug  bug  indicating the full command you used to run the image.Providing the debug logs is also helpful.
google-gvisor	What works?	The following applications/images have been tested:The following applications have been tested and may not yet work:
google-gvisor	My container runs fine with *runc	If you’re having problems running a container with runsc it’s most likely dueto a compatibility issue or a missing feature in gVisor
google-gvisor	My container runs fine with *runc	See **Debugging**,
google-gvisor	When I run my container, docker fails with flag provided but not defined: -console	You're using an old version of Docker
google-gvisor	When I run my container, docker fails with flag provided but not defined: -console	Refer to the Requirements  #requirements  section for the minimum version supported.
google-gvisor	I can’t see a file copied with docker cp or kubectl cp.	For performance reasons, gVisor caches directory contents, and therefore it maynot realize a new file was copied to a given directory
google-gvisor	I can’t see a file copied with docker cp or kubectl cp.	To invalidate the cacheand force a refresh, create a file under the directory in question and list thecontents again.This bug is tracked in  bug #4 
google-gvisor	Technical details	We plan to release a full paper with technical details and will include it herewhen available.
google-gvisor	Community	Join the  gvisor-users mailing list  gvisor-users-list  to discuss all thingsSensitive security-related questions and comments can be sent to the private gvisor-security mailing list  gvisor-security-list .
google-gvisor	Contributing	See  Contributing.md  CONTRIBUTING.md 
google-gvisor	Contributing	apparmor :  bazel :  bug :  checkpoint-restore :  cri-o-k8s :  cri-o :  docker-storage-driver :  docker :  git :  gvisor-security-list :  gvisor-users-list :  kvm :  netstack :  oci :  python :  runsc-nightly-sha :  runsc-nightly :  sandbox :  seccomp :  selinux :  uml :  xen : 
google-gwteventbinder	What is EventBinder?	GWT's EventBus is great by decoupling the components of your application, making them easy to add,modify, or remove
google-gwteventbinder	What is EventBinder?	However, using EventBus in GWT can require a lot of boilerplate in the form of implementing events, defining handler interfaces forthem, and implementing those interfaces all over your code in anonymous classes.EventBinder automates away these boring details using a strategy similar to the@UiHandler annotation defined by UiBinder.
google-gwteventbinder	How do I use it?	Easy 
google-gwteventbinder	Defining events	With EventBinder, events are just immutable value types extending GenericEvent
google-gwteventbinder	Defining events	If your event doesn't have any arguments, defining itonly takes one line:public class EmailLoadedEvent extends GenericEvent {  private final String subject;  private final String body;  }  public String getBody   { return body; }That's it GwtEvent or to define handler interfaces.
google-gwteventbinder	Registering event handlers	Event handlers are methods annotated with the UiBinder
google-gwteventbinder	Registering event handlers	Here's an example:class EmailPresenter {  interface MyEventBinder extends EventBinder {}  private final MyEventBinder eventBinder = GWT.create MyEventBinder.class ;  }  void onEmailLoaded EmailLoadedEvent event  {  }After EmailLoadedEvent is fired on the given event bus.It's possible to handle several events in one method
google-gwteventbinder	Registering event handlers	In this case you mustenumerate these event classes in handles is specified and you don't need event parameter you may omit it.class SuperEvent extends GenericEvent { }class EventOne extends SuperEvent { }class EventTwo extends SuperEvent { }class FormPresenter {  interface MyEventBinder extends EventBinder {}  private final MyEventBinder eventBinder = GWT.create MyEventBinder.class ;  }  void onEventOne EventOne event  {  }  void onEventOneAndTwo SuperEvent event  {  }  void onEventOneAndTwo2   {  }
google-gwteventbinder	Firing events	The last step is easy and doesn't require anything special from EventBinderapplication to be invoked in an undefined order
google-gwteventbinder	Firing events	That's it, you're done!
google-gwteventbinder	How do I install it?	If you're using Maven, you can add the following to your from <> and build it yourself
google-gwteventbinder	How do I install it?	Onceyou've installed EventBinder, be sure to inherit the module in your .gwt.xmlfile like this:
google-gwteventbinder	1.1.0	 1 :  2 :  3 :  4 :  5 : 
google-gwtmockito	What is GwtMockito?	Testing GWT applications using GWTTestCase can be a pain using pure Java tests, and you can't use reflection-based tools like mockingframeworks
google-gwtmockito	What is GwtMockito?	But if you've tried to test widgets using normal test cases, you'veprobably run into this error:GwtMockito solves this and other GWT-related testing problems by allowing youto call GWT.create from JUnit tests, returning  Mockito  1  mocks.
google-gwtmockito	How do I use it?	Getting started with GwtMockito using Junit 4.5+ is easy
google-gwtmockito	How do I use it?	Just annotate your testwith @RunWith GwtMockitoTestRunner.class , then any calls to GWT.createencountered will return Mockito mocks instead of throwing exceptions:populate @UiFields with Mockito mocks
google-gwtmockito	How do I use it?	Suppose you have a widget that lookslike this:public class MyWidget extends Composite {  interface MyUiBinder extends UiBinder {}  private final MyUiBinder uiBinder = GWT.create MyUiBinder.class ;  private final NumberFormatter formatter;  }  }When numberLabel with a mock object
google-gwtmockito	How do I use it?	Since @UiFields are package-visible, they can be read from your unit tests, which lets you test this widget as follows:@RunWith GwtMockitoTestRunner.class public class MyWidgetTest {  private MyWidget widget;  public void setUp   {  }  public void shouldFormatNumber   {  }Note that GwtMockito supports the @Mock annotation from Mockito, allowing standard Mockito mocks to be mixed with mocks created by GwtMockito.That's all you need to know to get started hearing about some advanced features.
google-gwtmockito	Accessing the mock returned from GWT.create	Returning mocks from GWT.create isn't very useful if you don't have any way toverify or set behaviors on them
google-gwtmockito	Accessing the mock returned from GWT.create	You can do this by annotating a field in your test with @GwtMock to return a mock stored in that field, allowing you to reference it in yourtest
google-gwtmockito	Accessing the mock returned from GWT.create	So if you have a class that looks like@RunWith GwtMockitoTestRunner.class public class MyClassTest {  @GwtMock SomeInterface mockInterface;  public void constructorShouldSetSomething   {  }
google-gwtmockito	Returning fake objects	By default, GwtMockito will return fake implementations  which don't require youto specify mock behavior  for any classes extending the following types:GwtMockito.useProviderForType Class, FakeProvider  in your setUp method
google-gwtmockito	Returning fake objects	This will cause all calls to GWT.create for the given class or its subclassesto invoke the given FakeProvider to determine what to return
google-gwtmockito	Returning fake objects	See the javadoc reference  2  for more details.
google-gwtmockito	Mocking final classes and methods	Mockito does not normally allow final classes and methods to be mocked
google-gwtmockito	Mocking final classes and methods	This poses problems in GWT since  JavaScript overlay types  3   which include Element and its subclasses  require all methods to be final
google-gwtmockito	Mocking final classes and methods	Fortunately,GwtMockito does some classloader black magic to remove all final modifiers fromclasses and interfaces, so the following test will pass:@RunWith GwtMockitoTestRunner.class public class MyTest {  @Mock Element element;  public void shouldReturnMocksFromGwtCreate   {  }As long as your test uses GwtMockitoTestRunner, it is possible to mock anyfinal methods.
google-gwtmockito	Dealing with native methods	Under normal circumstances, JUnit tests will fail with an UnsatisfiedLinkError when encountering a native JSNI method
google-gwtmockito	Dealing with native methods	GwtMockito works around this problemusing more classloader black magic to provide no-op implementations for allnative methods using the following rules:These rules allow many tests to continue to work even when calling incindentalnative methods
google-gwtmockito	Dealing with native methods	Note that this can be dangerous always returns GWTTestCase.
google-gwtmockito	Support for JUnit 3 and other tests that can't use custom runners	Though GwtMockito.initMocks directly
google-gwtmockito	Support for JUnit 3 and other tests that can't use custom runners	A test written in this style looks like this:public class MyWidgetTest extends TestCase {  public void setUp   {  }  public void tearDown   {  }  }The test must explicitly call initMocks during its setup and tearDown whenit is being teared down, or else state can leak between tests
google-gwtmockito	Support for JUnit 3 and other tests that can't use custom runners	When instantiating a widget, the test must also subclass it and override initWidgetwith a no-op implementation, or else it will fail when this method attempts tocall Javascript
google-gwtmockito	Support for JUnit 3 and other tests that can't use custom runners	Note that when testing in this way the features described in"Mocking final classes and methods" and "Dealing with native methods" won'twork methods without using GwtMockitoTestRunner.
google-gwtmockito	How do I install it?	If you're using Maven, you can add the following to your from <>
google-gwtmockito	How do I install it?	In these cases you will haveto manually install the jars for  Mockito  6  and  Javassist  7 .
google-gwtmockito	1.0.0	 2 :  3 :  4 :  5 :  6 :  7 :  8 :  9 :  10 : 
google-gxui	Linux:	In order to build GXUI on linux, you will need the following packages installed:
google-gxui	Common:	After setting up GOPATH  see  Go documentation  you can then fetch the GXUI library and its dependencies:--To build all samples run:And they will be built into GOPATH/bin.If you add GOPATH/bin to your PATH, you can simply type the name of a sample to run it
google-gxui	Common:	For example: image_viewer.---gxui code is cross platform and can be compiled using GopherJS to JavaScript, allowing it to run in browsers with WebGL support
google-gxui	Common:	To do so, you'll need the  GopherJS compiler  and some additional dependencies:--This is built into the gxfont package.Make sure to mention this font in any notices file distributed with your application.--Contributions, however small, will require the author to have signed the  Google Individual Contributor License Agreement The CLA is necessary mainly because you own the copyright to your changes, even after your contribution becomes part of our codebase, so we need your permission to use and distribute your code
google-gxui	Common:	We also need to be sure of various other things—for instance that you'll tell us if you know that your code infringes on other people's patents
google-gxui	Common:	You don't have to sign the CLA until after you've submitted your code for review and a member has approved it, but you must do it before we can put your code into our codebase
google-gxui	Common:	Before you start working on a larger contribution, you should get in touch with us first through the issue tracker with your idea so that we can help out and possibly guide you
google-gxui	Common:	Coordinating up front makes it much easier to avoid frustration later on.
google-har-sanitizer	Description	HAR files are JSON-formatted "recordings" of web traffic activity for a user's browser session, which are often used to troubleshoot web front-ends, REST APIs, authentication issues, etc
google-har-sanitizer	Description	 However, HAR files will capture everything in a web session, including passwords, sensitive form information, authentication cookies and headers, and any content embedded in HTTP requests
google-har-sanitizer	Description	 This makes HAR files extremely sensitive, and highly prone to privacy breaches if handled incorrectly.This tool aims to help mitigate these concerns by offering a simple, flexible interface to redact HAR file contents of any potentially sensitive information
google-har-sanitizer	Description	 It collects the names and values of all passwords, cookies, headers, URLQuery/POSTData/HTML-Form parameters, and embedded content mimetypes, and redacts values either already known to be sensitive, or those specified by the user
google-har-sanitizer	Description	 It currently exists as a both a client-side web tool and Flask REST API.Live version may be found at  This is NOT an official Google product 
google-har-sanitizer	Installation	 If virtual environment not already activated If desired, change static files location in config.json
google-har-sanitizer	Installation	Examples:{  "static_files": "./harsanitizer/static"  "static_files": ""Change port, debug, and other options in ./harsanitizer/harsan_api.py under:Launch Flask server:Load the Har-Sanitizer web tool by visiting "" in Chrome or Firefox  substituting '8080' with the port #, if modified .
google-har-sanitizer	Web Tool	Load HAR JSON file using 'Load HAR' button.Select names of cookies/headers/parameters/content mimetypes to scrub.Preview changes before committing, modifying scrub options as necessary.Export scrubbed HAR file once ready.
google-har-sanitizer	API Endpoint	  import json, requests  with open "har_file.har", "r"  as har_file:  url = '  headers = {"Content-Type": "application/json"}  r = requests.post url, data=json.dumps har , headers=headers   
google-har-sanitizer	TODO	Needs tests bad
google-har-sanitizer	TODO	 This should be current priority
google-har-sanitizer	TODO	 Use pytest and Jasmine.Other issues are being tracked in Github  issue tracker 
google-har-sanitizer	Contact	Garrett Anderson:Geoffrey Coulter:Copyright 2017, Google Inc.Authors: Garrett AndersonLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atUnless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License
google-hashing-demo	#Introduction	This is a sample implementation of a forthcoming C++ standard libraryproposal
google-hashing-demo	#Introduction	It is intended only for demonstration and evaluation purposes,and is not suitable for use in production systems
google-hashing-demo	#Introduction	This is not an officialGoogle product  experimental or otherwise , it is just code that happensto be owned by Google.The APIs in  std.h  std.h  and  std_impl.h  std_impl.h  are proposed forstandardization
google-hashing-demo	#Introduction	 fnv1a.h  fnv1a.h  and  farmhash.h  farmhash.h  are exampleimplementations of particular algorithms using this framework, but are notthemselves proposed for standardization
google-hashing-demo	#Introduction	 std_test.cc  std_test.cc  shows somesimple examples of the extension API for type owners, as well as the end-userAPI  which is just std::hash .The code uses some C++14 language and library features
google-hashing-demo	#Introduction	It doesn't work withlibstdc++ as of version 4.8, but it does work with libc++ 3.A CMakeLists.txt  CMakeLists.txt  is included for building the tests with CMake  Example usage:-DCMAKE_INCLUDE_PATH, respectively
google-hashing-demo	#Introduction	Similarly, the benchmarks depend on google/benchmark  This is includedas a git submodule  run git submodule init; git submodule update to setit up , or you can install the source distribution in another location,and configure that location with -Dbenchmark_src_dir.API documentation will be provided in the forthcoming paper.
google-hashtable-benchmarks	Hashtable Benchmarks	Benchmarks for comparing hashtable implementations.You can use  along with hashtable_benchmarks.ipynb to parse the generated benchmark-results.json.We would like this to turn into *thewill accept external dependencies on other hashtable libraries  assuming theyhave a compatible licence 
google-hashtable-benchmarks	Hashtable Benchmarks	 We encourage folks to improve and modify both theanalysis and the benchmarks themselves as we learn things
google-hashtable-benchmarks	Hashtable Benchmarks	 Please join thedicussion atThis is not an officially supported Google product.
google-haskell-indexer	Supported systems	Indexing hosts:
google-haskell-indexer	Stack	Download Stack from 
google-haskell-indexer	Kythe	If you want to use the Kythe frontend, download a  Kytherelease  and unpack it.If you want to install Kythe in a different location to /opt/kythe then youshould also set KYTHE_DIR to the location of the installation.
google-haskell-indexer	Protoc 3	Download the latest  Proto compiler 3release  unpack it and place thebinary in the PATH.> this.
google-haskell-indexer	Build the project	Use the following to build and run tests:To index a few packages, run:To serve the index at :possible indexing errors
google-haskell-indexer	Build the project	Also, make sure that the *.entries files are notempty
google-haskell-indexer	Build the project	If they are, it indicates that ghc_kythe_wrapper failed to index.
google-haskell-indexer	Indexing using Docker	If you plan to use the Dockerized build feature of stack, please installDocker
google-haskell-indexer	Indexing using Docker	It is also advised to set up a docker wrapper script by following theinstructions at the  stack Dockersecurity The docker image has all C library dependencies so it's possible to use it toindex the whole Stackage snapshot
google-haskell-indexer	Indexing using Docker	See stack-build-docker.sh for acomprehensive example of indexing a Stackage snapshot, and serving a Kythe
google-hdrnet	Deep Bilateral Learning for Real-Time Image Enhancements	Siggraph 2017Visit our  Project Page  Michael Gharbi Jiawen ChenJonathan T
google-hdrnet	Deep Bilateral Learning for Real-Time Image Enhancements	BarronSamuel W
google-hdrnet	Deep Bilateral Learning for Real-Time Image Enhancements	HasinoffFredo DurandMaintained by Michael Gharbi   Tested on Python 2.7, Ubuntu 14.0, gcc-4.
google-hdrnet	Disclaimer	This is not an official Google product.
google-hdrnet	Dependencies	To install the Python dependencies, run:
google-hdrnet	Build	Our network requires a custom Tensorflow operator to "slice" in the bilateral grid.To build it, run:To build the benchmarking code, run:Note that the benchmarking code requires a frozen and optimized model
google-hdrnet	Build	Usehdrnet/bin/scripts/optimize_graph.sh and hdrnet/bin/freeze.py to produce these.To build the Android demo, see dedicated section below.
google-hdrnet	Test	Run the test suite to make sure the BilateralSlice operator works correctly:
google-hdrnet	Download pretrained models	We provide a set of pretrained models
google-hdrnet	Download pretrained models	One of these is included in the repo see pretrained_models/local_laplacian_sample 
google-hdrnet	Download pretrained models	To download the rest of them
google-hdrnet	Usage	To train a model, run the following command:Look at sample_data/identity/ for a typical structure of the training data folder.You can monitor the training process using Tensorboard:To run a trained model on a novel image  or set of images , use:To prepare a model for use on mobile, freeze the graph, and optimize the network:You will need to change the ${TF_BASE} environment variable in ./hdrnet/bin/scripts/optimize_graph.shand compile the necessary tensorflow command line tools for this  automated in the script .
google-hdrnet	Android prototype	We will add it to this repo soon.
google-hdrnet	Known issues and limitations	  Apply white balance channel gains
google-hdrnet	Known issues and limitations	 Demosaic to RGB
google-hdrnet	Known issues and limitations	 Apply lens shading correction  aka vignetting correction 
google-hdrnet	Known issues and limitations	 white balance, and tone mapping performed by the Qualcomm SOC
google-hdrnet	Known issues and limitations	It results in slightly different colors than that on the test set
google-hdrnet	Known issues and limitations	If you run our HDR+ model on an sRGB input, it may produce uncanny colors.
google-hell0world-curriculum	hell0world Curriculum	This is the open source curriculum for hell0world.org classes that are taught at Heart of Los Angeles  and can also be pursued on aself-paced basis.This is not an officially supported Google product.
google-hell0world-curriculum	Projects	If you're interested in contributing to the project, please check outCONTRIBUTING.md for guidelines.
google-helloargdx	Hello AR GDX	This is a port of the hello ar sample for ARCore to libGDX.The most obvious advantage to this implemention is that thereis no requirement to use or understand OpenGL ES, which isa large barrier to creating augmented reality apps in Java.The sample shows the basics of ARCore: plane detection, anchoring objectsin space, and light estimation  coming soon 
google-helloargdx	Hello AR GDX	 In addition, it illustrateshow to use GDX to make an application and integrate non-graphical AndroidUI such as Snackbars into the activity.This is not an official Google product.I work at Google, but this specific project was created personallyas I investigated using ARCore in Java apps
google-helloargdx	Hello AR GDX	 I can't commit to maintainingor supporting this project's use.
google-helloargdx	LICENSE	Copyright 2017 Google Inc.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License at
google-helm-broker	Service Broker	This is an implementation of a service broker which runs in a Kubernetescluster and deploys Kubernetes native resources only using Helm as the reifier.This is not an official Google product.
google-helm-broker	Prerequisites	1  A  helm  tiller running in the cluster.2   Glide  installed and in your path.
google-helm-broker	Building and deploying	To install the dependencies, build the binaries, run the tests, and build the Dockerimages, run the following:where ${PROJECT_NAME} is the name of your GCP project:curl -X POST -d @  "name": "nginx",  "id": "4179E70A-4641-49D5-B395-A8ACB1419BCA",  "description": "Helm chart for running nginx",  "plans":     ,  "requires":   ,  "tags":   ,  "bindable":false__EOF__
google-helm-broker	Create an instance of it	curl -X PUT -d @  "service_id": "4179E70A-4641-49D5-B395-A8ACB1419BCA",  "plan_id":"696AD474-123F-474F-8FDB-C724C058CF03"__EOF__
google-heroku-buildpack-bazel	heroku-buildpack-bazel	Heroku buildpack for  Bazel  Currenly, only Java is supported.Bazel is an open-source build tool created by and for the engineers at Google.
google-heroku-buildpack-bazel	Default Procfile	The default This does not need to be included in your app.If you need custom JVM flags, you'll need to include a custom Procfile with your application
google-heroku-buildpack-bazel	Default Procfile	Modify the line above with the flags you want.
google-highwayhash	Quick Start	To build on a Linux or Mac platform, simply run make
google-highwayhash	Quick Start	For Windows, we providea Visual Studio 2015 project in the msvc subdirectory.Run benchmark for speed measurements
google-highwayhash	Quick Start	sip_hash_test and highwayhash_testensure the implementations return known-good values for a given set of inputs.64-bit SipHash for any CPU:64, 128 or 256 bit HighwayHash for the CPU determined by compiler flags:64, 128 or 256 bit HighwayHash for the CPU on which we're currently running:C-callable 64-bit HighwayHash for the CPU on which we're currently running:Printing a 256-bit result in a hexadecimal format similar to sha1sum:
google-highwayhash	Introduction	Hash functions are widely used, so it is desirable to increase their speed andsecurity
google-highwayhash	Introduction	This package provides two 'strong'  well-distributed andunpredictable  hash functions: a faster version of SipHash, and an even fasteralgorithm we call HighwayHash.SipHash is a fast but 'cryptographically strong' pseudo-random function byAumasson and Bernstein   .HighwayHash is a new way of mixing inputs which may inspire newcryptographically strong hashes
google-highwayhash	Introduction	Large inputs are processed at a rate of 0.24cycles per byte, and latency remains low even for small inputs
google-highwayhash	Introduction	HighwayHash isfaster than SipHash for all input sizes, with 5 times higher throughput at 1KiB
google-highwayhash	Introduction	We discuss design choices and provide statistical analysis and preliminarycryptanalysis in 
google-highwayhash	Applications	Unlike prior strong hashes, these functions are fast enough to be recommendedas safer replacements for weak hashes in many applications
google-highwayhash	Applications	The additional CPUcost appears affordable, based on profiling data indicating C++ hash functionsaccount for less than 0.25% of CPU usage.Hash-based selection of random subsets is useful for A/B experiments and similarapplications
google-highwayhash	Applications	Such random generators are idempotent  repeatable anddeterministic , which is helpful for parallel algorithms and testing
google-highwayhash	Applications	To avoidbias, it is important that the hash function be unpredictable andindistinguishable from a uniform random generator
google-highwayhash	Applications	We have verified the bitdistribution and avalanche properties of SipHash and HighwayHash.64-bit hashes are also useful for authenticating short-lived messages such asnetwork/RPC packets
google-highwayhash	Applications	This requires that the hash function withstanddifferential, length extension and other attacks
google-highwayhash	Applications	We have published a formalsecurity analysis for HighwayHash
google-highwayhash	Applications	New cryptanalysis tools may still need to bedeveloped for further analysis.Strong hashes are also important parts of methods for protecting hash tablesagainst unacceptable worst-case behavior and denial of service attacks see "hash flooding" below .128 and 256-bit hashes can be useful for verifying data integrity  checksums .
google-highwayhash	SipHash	Our SipHash implementation is a fast and portable drop-in replacement forthe reference C code
google-highwayhash	SipHash	Outputs are identical for the given test cases  messagesbetween 0 and 63 bytes .Interestingly, it is about twice as fast as a SIMD implementation using SSE4.1 This is presumably due to the lack of SIMD bit rotateinstructions prior to AVX-SipHash13 is a faster but weaker variant with one mixing round per update andthree during finalization.We also provide a data-parallel 'tree hash' variant that enables efficient SIMDwhile retaining safety guarantees
google-highwayhash	SipHash	This is about twice as fast as SipHash, butdoes not return the same results.
google-highwayhash	HighwayHash	We have devised a new way of mixing inputs with AVX2 multiply and permuteinstructions
google-highwayhash	HighwayHash	The multiplications are 32x32 -> 64 bits and therefore infeasibleto reverse
google-highwayhash	HighwayHash	Permuting equalizes the distribution of the resulting bytes.The internal state occupies four 256-bit AVX2 registers
google-highwayhash	HighwayHash	Due to limitations ofthe instruction set, the registers are partitioned into two 512-bit halves thatremain independent until the reduce phase
google-highwayhash	HighwayHash	The algorithm outputs 64 bit digestsor up to 256 bits at no extra cost.In addition to high throughput, the algorithm is designed for low finalizationcost
google-highwayhash	HighwayHash	The result is more than twice as fast as SipTreeHash.We also provide an SSE4.1 version  80% as fast for large inputs and 95% as fastfor short inputs , an implementation for VSX on POWER and a portable version 10% as fast 
google-highwayhash	HighwayHash	A third-party ARM implementation is referenced below.Statistical analyses and preliminary cryptanalysis are given in
google-highwayhash	Versioning and stability	Now that 21 months have elapsed since their initial release, we have declaredall  64/128/256 bit  variants of HighwayHash frozen, i.e
google-highwayhash	Versioning and stability	unchanging forever.SipHash and HighwayHash are 'fingerprint functions' whose input -> hashmapping will not change
google-highwayhash	Versioning and stability	This is important for applications that write hashes topersistent storage.
google-highwayhash	Speed measurements	To measure the CPU cost of a hash function, we can either create an artificial'microbenchmark'  easier to control, but probably not representative of theactual runtime , or insert instrumentation directly into an application  risksinfluencing the results through observer overhead 
google-highwayhash	Speed measurements	We provide novel variants ofboth approaches that mitigate their respective disadvantages.profiler.h uses software write-combining to stream program traces to memorywith minimal overhead
google-highwayhash	Speed measurements	These can be analyzed offline, or when memory is full,to learn how much time was spent in each  possibly nested  zone.nanobenchmark.h enables cycle-accurate measurements of very short functions.It uses CPU fences and robust statistics to minimize variability, and alsoavoids unrealistic branch prediction effects.We compile the 64-bit C++ implementations with a patched GCC 4.9 and run on asingle idle core of a Xeon E5-2690 v3 clocked at 2.6 GHz
google-highwayhash	Speed measurements	CPU cost is measuredas cycles per byte for various input sizes:---------------HighwayHashAVX2  | 7.34  | 1.81 | 1.71 | 1.04 | 0.95 | 0.24HighwayHashSSE41 | 8.00  | 2.11 | 1.75 | 1.13 | 0.96 | 0.30SipTreeHash13SipHash13SipTreeHash is slower than SipHash for small inputs because it processes blocksof 32 bytes
google-highwayhash	Speed measurements	AVX2 and SSE4.1 HighwayHash are faster than SipHash for all inputsizes due to their highly optimized handling of partial vectors.Note that previous measurements included the initialization of their input,which dramatically increased timings especially for small inputs.
google-highwayhash	CPU requirements	SipTreeHash 13  requires an AVX2-capable CPU  e.g
google-highwayhash	CPU requirements	Haswell 
google-highwayhash	CPU requirements	HighwayHashincludes a dispatcher that chooses the best available  AVX2, SSE4.1, VSX orportable  implementation at runtime, as well as a directly callable functiontemplate that can only run on the CPU for which it was built
google-highwayhash	CPU requirements	SipHash 13  andScalarSipTreeHash 13  have no particular CPU requirements.Our x86 implementations use custom vector classes with overloaded operators e.g
google-highwayhash	CPU requirements	const V4x64U a = b + c  for type-safety and improved readability vs.compiler intrinsics  e.g
google-highwayhash	CPU requirements	const __m256i a = _mm256_add_epi64 b, c  .The VSX implementation uses built-in vector types alongside Altivec intrinsics.A high-performance third-party ARM implementation is mentioned below.Our instruction_sets dispatcher avoids running newer instructions on older CPUsthat do not support them
google-highwayhash	CPU requirements	However, intrinsics, and therefore also any vectorclasses that use them, require a compiler flag that also enables the compiler togenerate code for that CPU
google-highwayhash	CPU requirements	This means the intrinsics must be placed in separatetranslation units that are compiled with the required flags
google-highwayhash	CPU requirements	It is importantthat these source files and their headers not define any inline functions,because that might break the one definition rule and cause crashes.To minimize dispatch overhead when hashes are computed often  e.g
google-highwayhash	CPU requirements	in a loop ,we can inline the hash function into its caller using templates
google-highwayhash	CPU requirements	The dispatchoverhead will only be paid once  e.g
google-highwayhash	CPU requirements	before the loop 
google-highwayhash	CPU requirements	The template mechanismalso avoids duplicating code in each CPU-specific implementation.
google-highwayhash	Defending against hash flooding	To mitigate hash flooding attacks, we need to take both the hash function andthe data structure into account.We wish to defend  web  services that utilize hash sets/maps againstdenial-of-service attacks
google-highwayhash	Defending against hash flooding	Such data structures assign attacker-controlledinput messages m to a hash table bin b by computing the hash H s, m using a hash function H seeded by s, and mapping it to a bin with somenarrowing function b = R h , discussed below.Attackers may attempt to trigger 'flooding'  excessive work in insertions orlookups  by finding multiple m that map to the same bin
google-highwayhash	Defending against hash flooding	If the attacker haslocal access, they can do far worse, so we assume the attacker can only issueremote requests
google-highwayhash	Defending against hash flooding	If the attacker is able to send large numbers of requests,they can already deny service, so we need only ensure the attacker's cost issufficiently large compared to the service's provisioning.If the hash function is 'weak', attackers can easily generate 'hash collisions' inputs mapping to the same hash values  that are independent of the seed
google-highwayhash	Defending against hash flooding	Inother words, certain input messages will cause collisions regardless of the seedvalue
google-highwayhash	Defending against hash flooding	The author of SipHash has published C++ programs to generate such'universal  key-independent  multicollisions' for CityHash and Murmur
google-highwayhash	Defending against hash flooding	Similar'differential' attacks are likely possible for any hash function consisting onlyof reversible operations  e.g
google-highwayhash	Defending against hash flooding	addition/multiplication/rotation  with a constantoperand
google-highwayhash	Defending against hash flooding	n requests with such inputs cause n^2 work for an unprotected hashtable, which is unacceptable.By contrast, 'strong' hashes such as SipHash or HighwayHash require infeasibleattacker effort to find a hash collision  an expected 2^32 guesses of m perthe birthday paradox  or recover the seed  2^63 requests 
google-highwayhash	Defending against hash flooding	These security claimsassume the seed is secret
google-highwayhash	Defending against hash flooding	It is reasonable to suppose s is initially unknownto attackers, e.g
google-highwayhash	Defending against hash flooding	generated on startup or even per-connection
google-highwayhash	Defending against hash flooding	A timing attackby Wool/Bar-Yosef recovers 13-bit seeds by testing all 8K possibilities usingmillions of requests, which takes several days  even assuming unrealistic 150 usround-trip times 
google-highwayhash	Defending against hash flooding	It appears infeasible to recover 64-bit seeds in this way.However, attackers are only looking for multiple R h  := h &  p easier for attackers to compute partial collisions where only the lower i bitsmatch
google-highwayhash	Defending against hash flooding	This can be prevented by choosing a prime p so that R h  := h % pincorporates all hash bits
google-highwayhash	Defending against hash flooding	The costly modulo operation can be avoided bymultiplying with the inverse  An interesting alternativesuggested by Kyoung Jae Seo chooses a random subset of the h bits
google-highwayhash	Defending against hash flooding	Such an Rfunction can be computed in just 3 cycles using PEXT from the BMI2 instructionset
google-highwayhash	Defending against hash flooding	This is expected to defend against SAT-solver attacks on the hash bits at aslightly lower cost than the multiplicative inverse method, and still allowspower-of-two table sizes.Summary thus far: given a strong hash function and secret seed, it appearsinfeasible for attackers to generate hash collisions because s and/or R areunknown
google-highwayhash	Defending against hash flooding	However, they can still observe the timings of data structureoperations for various m
google-highwayhash	Defending against hash flooding	With typical table sizes of 2^10 to 2^17 entries,attackers can detect some 'bin collisions'  inputs mapping to the same bin .Although this will be costly for the attacker, they can then send many instancesof such inputs, so we need to limit the resulting work for our data structure.Hash tables with separate chaining typically store bin entries in a linked list,so worst-case inputs lead to unacceptable linear-time lookup cost
google-highwayhash	Defending against hash flooding	We insteadseek optimal asymptotic worst-case complexity for each operation  insertion,deletion and lookups , which is a constant factor times the logarithm of thedata structure size
google-highwayhash	Defending against hash flooding	This naturally leads to a tree-like data structure for eachbin
google-highwayhash	Defending against hash flooding	The Java8 HashMap only replaces its linked list with trees when needed.This leads to additional cost and complexity for deciding whether a bin is alist or tree.Our first proposal  suggested by Github user funny-falcon  avoids this overheadby always storing one tree per bin
google-highwayhash	Defending against hash flooding	It may also be worthwhile to store the firstentry directly in the bin, which avoids allocating any tree nodes in the commoncase where bins are sparsely populated
google-highwayhash	Defending against hash flooding	What kind of tree should be used?Scapegoat and splay trees only offer amortized complexity guarantees, whereastreaps require an entropy source and have higher constant factors in practice.Self-balancing structures such as 2-3 or red-black trees require additionalbookkeeping information
google-highwayhash	Defending against hash flooding	We can hope to reduce rebalancing cost by realizingthat the output bits of strong H functions are uniformly distributed
google-highwayhash	Defending against hash flooding	Whenusing them as keys instead of the original message m, recent relaxed balancingschemes such as left-leaning red-black or weak AVL trees may require fewer treerotations to maintain their invariants
google-highwayhash	Defending against hash flooding	Note that H already determines thebin, so we should only use the remaining bits
google-highwayhash	Defending against hash flooding	64-bit hashes are likelysufficient for this purpose, and HighwayHash generates up to 256 bits
google-highwayhash	Defending against hash flooding	It seemsunlikely that attackers can craft inputs resulting in worst cases for both thebin index and tree key without being able to generate hash collisions, whichwould contradict the security claims of strong hashes
google-highwayhash	Defending against hash flooding	Even if they succeed, therelaxed tree balancing still guarantees an upper bound on height and thereforethe worst-case operation cost
google-highwayhash	Defending against hash flooding	For the AVL variant, the constant factors areslightly lower than for red-black trees.The second proposed approach uses augmented/de-amortized cuckoo hash tables These guarantee worst-case log n bounds for alloperations, but only if the hash function is 'indistinguishable from random' uniformly distributed regardless of the input distribution , which is claimedfor SipHash and HighwayHash but certainly not for weak hashes.Both alternatives retain good average case performance and defend againstflooding by limiting the amount of extra work an attacker can cause
google-highwayhash	Defending against hash flooding	The firstapproach guarantees an upper bound of log n additional work even if the hashfunction is compromised.In summary, a strong hash function is not, by itself, sufficient to protect achained hash table from flooding attacks
google-highwayhash	Defending against hash flooding	However, strong hash functions areimportant parts of two schemes for preventing denial of service
google-highwayhash	Defending against hash flooding	Using weak hashfunctions can slightly accelerate the best-case and average-case performance ofa service, but at the risk of greatly reduced attack costs and worst-case
google-highwayhash	Third-party implementations / bindings	Thanks to Damian Gryski and Frank Wessels for making us aware of thesethird-party implementations or bindings
google-highwayhash	Third-party implementations / bindings	Please feel free to get in touch orraise an issue and we'll add yours as well.By | Language | URLDamian Gryski | Go and x64 assembly | Lovell Fuller | node.js bindings | Vinzent Steinberg | Rust bindings | Frank Wessels & Andreas Auernhammer | Go and ARM assembly | Phil Demetriou | Python 3 bindings | 
google-highwayhash	Hashes	, updated 2017-12-29This is not an official Google product.
google-hilbert	Hilbert     ! Coverage    ! Report card    ! GoDoc    ! Libraries.io  	Go package for mapping values to and from space-filling curves, such as Hilbert  and  Peano  curves.! Image of 8 by 8 Hilbert curve  images/hilbert.png  Documentation available here *This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-hilbert	How to use	import "github.com/google/hilbert"	// Create a Hilbert curve for mapping to and from a 16 by 16 space.s, err := hilbert.NewHilbert 16 // Create a Peano curve for mapping to and from a 27 by 27 space.//s, err := hilbert.NewPeano 27 // Now map one dimension numbers in the range  0, N*N-1 , to an x,y// coordinate on the curve where both x and y are in the range  0, N-1 .x, y, err := s.Map t // Also map back from  x,y  to t.t, err := s.MapInverse x, y 
google-hilbert	Demo	The demo directory contains an example on how to draw an images of Hilbert and Peano curves, as wellas animations of varying sizes for both.Simple 8x8 Hibert curve:! 8x8 Hilbert curve image  images/hilbert.png Simple 9x9 Peano curve:! 9x9 Hilbert curve image  images/peano.png Animation of Hibert curve with N in the range 1..8:! Hilbert curve animation  images/hilbert_animation.gif Animation of Peano curve with N in the range 1..6:! Peano curve animation  images/peano_animation.gif 
google-hilbert	Licence  Apache 2 	Copyright 2015 Google Inc
google-hilbert	Licence  Apache 2 	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-homebrew-google-authenticator	Homebrew formula for Google Authenticator	Enables Google Authenticator as a two-factor authenticationfor Mac OS X ssh.for more information.> Caveat: As of August 2015 on Mac OS X El Capitan public beta clang crashes with a segfault.> A workaround is to install brew install gcc
google-homebrew-google-authenticator	Homebrew formula for Google Authenticator	There is no pre-brewed bottle for> El Capitan yet, installation can take hours.>  see 
google-homebrew-xpra	Homebrew formula for Xpra that works	Formula is written from scratch to make it harder, better, faster, stronger.
google-homebrew-xpra	Usage	Add this repo as a tap brew tap timothybasanov/xpraInstall Xpra: brew install xpra  use can use --devel for 0.15.x branch Use Xpra as you usually do: xpra attach ssh:ubuntu.local:100
google-homebrew-xpra	Development process	Clone this repo into /usr/local/Library/Tap/timothybasanov/Add as an IntelliJ projectEdit xpra.rbReinstall xpra: brew uninstall xpra ; brew install --verbose --debug --HEAD xpraI run live xpra server on a separate Ubuntu machine, here is how to debug xpra client:
google-honggfuzz	Description	A security oriented, feedback-driven, evolutionary, easy-to-use fuzzer with interesting analysis options
google-honggfuzz	Description	See  USAGE  for the description of command-line options
google-honggfuzz	Code	Honggfuzz has been used to find a few interesting security problems in major software packages; An incomplete list:The  examples directory contains code demonstrating  among others  how to use honggfuzz to find bugs in the OpenSSL library and in the  Apache HTTPD web server.
google-horenso	ほー連想：探しやすいコードで漢字直接入力	English is  here 
google-horenso	漢字直接入力のメリット	「きしゃ」など、漢字表記が多い読みを入力する場合、**長い候補リストで希望の漢字を探さなくても良いです。*
google-horenso	他の漢字直接入力システムに比べて【ほー連想】の長所	JIS x 0213の全漢字に対応する予定で、対応するとしても三打鍵を超える入力コードを必要としません。規格の全漢字を網羅しているので**極わめて特殊な文章（例：漢文）を自然に入力することが出来ます。*かな入力コードが一般のローマ字かな入力と殆んど変わりません。
google-horenso	起動方法  Windows 	 漢直Win をダウンロードして、zipを展開します。 ほー連想のテーブルファイル をダウンロードして、漢直Winのダイレクトリーにコピーします。 kanchoku.ini の、;outputUnicode=1の;を削除する必要があるかもしれません。これで、漢直Winの使い方とhrsの使い方が大体同じですが、漢直Winの場合はCaps Lockの代わりに、aを２回打って、カタカナモード・ひらがなモードのトグルができます。
google-horenso	キーボード配列を指定する	リターンを押す度にテキストをコピーしたりどこかに送信するにはCOPY_TOOLの環境変数を指定します。リターンを押すと、このCOPY_TOOLが起動されSTDINにテキストが書き込まれます。例：Mac OS Xの場合、これをpbcopyに設定すると便利です。（<>をご参照ください）
google-horenso	コードの覚え方：かな	コードは二打鍵：子音+母音になります。小文字 CAPS off にすると平仮名、大文字 CAPS on にすると片仮名になります。
google-horenso	コードの覚え方：漢字	発音とは代表的と思われる音読み、国字や音読みがない漢字は訓読みです。使用可能なキーは aiueo の母音を除けば一鍵目のキーと同じです。印刷可能な 部首鍵＋読み鍵 早わかり表 もご利用になってください。印刷可能な 部首鍵＋読み鍵 早わかり表 もご利用になってください。のどれかになりますが、ｍとｘの両方を試すのを忘れないでください。（実際のコード配当されるので、二鍵目はｒです。フルコードはurp。
google-horenso	ファイルの説明	ることができます。コードデータベース。行ごとに字と相対する入力コードがあります。コードを調べるには、このファイルを検索する方法もあります。未導入のJIS X 0213漢字も含まれていて、入力コードの代りにUCSコードポイントが明記されています。
google-hotel-ads-etl-tool	Hotel Ads ETL Tool	This repository contains a tool that provides methods to extract informationfrom the  Hotel Ads API Reports  transform it using Dataflow/Apache Beam  and insert it into BigQuery tables in Google Cloud Platform.The tool is composed of the following parts:Alternatives: If needed, the python App Engine script can be modified to runlocally on a server or another orchestration system, as it doesn't depend onApp Engine to run
google-hotel-ads-etl-tool	Hotel Ads ETL Tool	Also, the apache beam job can be run  after modifying thescript accordingly  in any managed or unmanaged Apache Beam instance.This is not an officially supported Google product.
google-hotel-ads-etl-tool	Prerequisites	Access to the Hotel Ads API
google-hotel-ads-etl-tool	Prerequisites	Follow the steps of section "Setting upA Google Cloud Platform project, to hold the scripts and the data.Enable the Cloud Storage, BigQuery and Dataflow APIs.
google-hotel-ads-etl-tool	Configuration Steps	The configuration steps will be using the google cloud console, but it can alsobe run into a local server/workstation with the google cloud sdk installed.Login to GCP using gcloudCopy the file scripts/config.sh.sample to scripts/config.sh, andmodify the latter with the appropriated values:Copy the contents of the file scripts/config.sh to the indicated section in  # TODO: PASTE HERE THE CONTENTS OF THE scripts/config.sh FILEExecute the provisioning script autoprovision.sh
google-hover	Feature Updates:	Demo Hover Menu ! Demo Hover Menu ! Demo Hover Menu Getting StartedTo get started with Hover, create a subclass of HoverMenuService to host your Hover menu
google-hover	Feature Updates:	Implement onHoverMenuLaunched Intent, HoverView  to take control of your HoverView
google-hover	Feature Updates:	You'll want to set it's HoverMenu, and also start it in the collapsed or expanded state:public class MyHoverMenuService extends HoverMenuService {
google-hover	Implement A HoverMenu	A HoverMenu is the content that appears within a HoverView
google-hover	Implement A HoverMenu	A HoverMenu is divided into an ordered list of Sections
google-hover	Implement A HoverMenu	 Each Section has a tab as well as Content that appear in your HoverView.If you want to create your own Hover Service from scratch, or if you want to experiment with a HoverView directly, you can instantiate one yourself.-----There is no built-in solution for this problem at this time
google-hover	Implement A HoverMenu	You should take care to destroy your Hover Service when the HoverView is closed
google-hover	Implement A HoverMenu	You may also want to inform the users of your app that issues with runtime permission dialogs might occur, and that those users should exit your Hover menu if problems occur.-------=======
google-hpolyc	HPolyC	For many storage encryption applications, the ciphertext must be the same size as the plaintext;generally this matches the disk sector size of either 512 or 4096 bytes
google-hpolyc	HPolyC	This means that standardapproaches like AES-GCM or RFC7539 cannot be applied
google-hpolyc	HPolyC	The standard solution is AES-XTS, butthis has two disadvantages:HPolyC uses a fast polynomial hash  Poly1305  and a fast stream cipher  XChaCha12  to builda construction which encrypts an entire sector at a time
google-hpolyc	HPolyC	Onan ARM Cortex-A7 processor, HPolyC decrypts 4096-byte messages at 14.5 cyclesper byte, over four times faster than AES-256-XTS
google-hpolyc	HPolyC	HPolyC is also a "superpseudorandom permutation" over the whole sector, which means that any change to the plaintextof the sector results in an unrecognizably different ciphertext sector and vice versa.HPolyC is published as  ePrint report 2018/720 This repository includes:
google-http2preload	http2preload	A package for manipulating  HTTP/2 preload supporting  Google App Engine for Go See for a sample usage.Docs are available on godoc.org/github.com/google/http2preload 
google-http2preload	License	 c  Google, Licensed under  Apache-2  LICENSE  license.
google-http_prefetching	HTTP prefetching experiments	**Disclaimer: This is not an official Google product.**This implements a proxy that injects prefetch hints, and a browser extensionthat prefetches pages based on received hints.
google-huproxy	HUProxy	Copyright 2017 Google Inc.This is not a Google product.HTTP S -Upgrade Proxy — Tunnel anything  but primarily SSH  over HTTP
google-huproxy	Why	The reason for not simply using a SOCKS proxy or similar is that they tend totake up an entire port, while huproxy only takes up a single URL subdirectory.There's also SSL/SSH multiplexers but they:Take over the port and front both the web server and SSH, instead of lettingHide the original client address from the web server  without someOnly allow connecting to the server itself, not treat it as a proxy jumpgate.
google-huproxy	Create user	These commands assume that HTTPS is used
google-huproxy	Create user	If not, then change "wss://"to "ws://".echo thomas:secretpassword > ~/.huproxy.pwchmod 600 ~/.huproxy.pwcat >> ~/.ssh/config << EOFHost shell.example.comssh shell.example.comOr manually with these commands:
google-hyou	Login to Google Spreadsheet with credentials	collection = hyou.login '/path/to/credentails.json' 
google-hyou	Open a spreadsheet by ID	spreadsheet = collection '1ZYeIFccacgHkL0TPfdgXiMfPCuEEWUtbhXvaB9HBDzQ' print spreadsheet.title
google-hyou	Open a worksheet in a spreadsheet by sheet name	worksheet = spreadsheet 'Sheet1' print worksheet.titleprint worksheet.rowsprint worksheet.cols
google-hyou	Worksheet objects can be accessed just like two-dimensional lists	print worksheet 1  0 print worksheet 1  1 
google-hyou	Call Worksheet.commit   to apply changes	worksheet 2  0  = 'cinamon'worksheet 2  1  = 40worksheet.commit  -------------Documentation is available atShuhei TakahashiThis library is authored by a Googler and copyrighted by Google, butis not an official Google product.-------Copyright 2015 Google Inc
google-hyou	Call Worksheet.commit   to apply changes	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-hypebot	HypeBot	HypeBot is the perfect way to add more #Hype to your chat application
google-hypebot	HypeBot	Simplyadd this bot to get #Hype.
google-hypebot	Development Guide	Want to increase #HypeQuality? Join  to get started.
google-hypebot	Running the Bot	Use bazel for building all the things
google-hypebot	Running the Bot	Installation instructions
google-hypebot	Running the Bot	Discord is our primary chat application interface
google-hypebot	Running the Bot	Create  anapplication with Discord
google-hypebot	Running the Bot	Once the application is created, click "Create A BotUser" to get a Discord Token
google-hypebot	Running the Bot	You then need admin privilegeson a server and select "Generate OAuth2 URL" to invite the bot to your server.
google-hypebot	Weather Key	HypeBot gets its weather from www.apixu.com
google-hypebot	Weather Key	 Signup  to get your key.
google-hypebot	Storage	By default, HypeBot looks for a Redis server running on localhost at the defaultport  You can pass overrides in --params to use a different location.
google-hypebot	Riot	To integrate with the Riot API, you need to  create anapplication  in order to get an API
google-hypebot	Type Annotations	HypeBot is joining the 21st century and attempting to use a new fancy typeannotation or hinting library to reduce the number of bugs that careless humansintroduce into the otherwise spotless codebase
google-hypebot	Type Annotations	As you modify existing code oradd new functionality, please use typing  Since we only supportpython3, this can be done in two easy steps
google-hypebot	Type Annotations	Add the relevant imports from the typing module into your python file Add type annotations to your function definitions
google-hypebot	Type Annotations	As an example:A few "best" practices:
google-hypebot	What about HypeParams?	Because of how HypeParams operates  specifically, creating attributesdynamically from the initialization dict , typing can't provide usefultype-checking to these objects
google-hypebot	What about HypeParams?	If you need to annotate a HypeParams instance,just use Any as per the best practices above.
google-hypebot	Legal	Hypebot is not an official Google product.
google-idaidle	idaidle	Copyright 2016-2018 Google LLCDisclaimer: This is not an official Google product  experimental or otherwise ,it is just code that happens to be owned by Google.
google-idaidle	What is it?	idaidle is a plugin for the commercial IDA Pro disassembler that warns users ifthey leave their instance idling for too long
google-idaidle	What is it?	After a predetermined amount ofidle time, the plugin first warns and later then saves the current disassemlbydatabase and closes IDA.This is useful in organizations with IDA Pro floating licenses to make surethat analysts return their license to the license server when they are doneusing it.path of your IDA SDK installation:To configure for 32-bit IDA  IDA 6.95 or lower, or IDA 7.0 "old_x86" , usethe IDA 6.95 SDK and the following commands instead:Once configured, start the build with:If all goes well, depending on your configuration, the following plugin filesare now in the build directory:| OS| ------| Linux   | idaidle.so| macOS   | idaidle.dylib| Windows | idaidle.dllNote: A 64 in anywhere in any of the filenames denotes a 64-bit addressaware plugin.
google-idaidle	Installation	To install system-wide, put the plugin binaries into the plugins folderin your IDA Pro installation
google-idaidle	Installation	Below are the default paths:| OS| ------| Linux   | /opt/ida-7.0/plugins| macOS   | /Applications/IDA Pro 7.0/idabin/plugins  || Windows | %ProgramFiles x86 %\IDA 7.0\pluginsReplace 7.0 with your actual version number.To install just for the current user, copy the files into one of thesedirectories instead:| OS| ----------| Linux/macOS | ~/.idapro/plugins| Windows
google-idaidle	Usage	As soon as a database is opened, the plugin starts to monitor idle time, i.e.the time between to consecutive UI operations
google-idaidle	Usage	By default, after six hours,a warning is printed to the output window
google-idaidle	Usage	After 12 hours, a databasesnapshot will be created and the IDA Pro instance will be closed withoutsaving
google-idaidle	Usage	This is so that the plugin does not accidentally overwrite unsavedwork or databases the analyst did not want to save.There is no configuration file, but the following command-line options are| Option| --------------------------| -OIdaIdleWarningSeconds:N | Warn the user after _N_ seconds of inactivity  || -OIdaIdleTimeoutSeconds:N | Create snapshot and close IDA afer _N_ seconds |Note: IDA only recognizes these command-line options if they come _before_ any
google-identity-aware-prober	Identity Aware Prober	Identity Aware Prober  iaprober  is a binary intended to be used as an externalserver-mode probe for use with  Cloudprober  for probing pagesbehind Google Cloud's  Identity Aware Proxy  IAP  The binary reads GCP service account credentials from a local JSON file
google-identity-aware-prober	Identity Aware Prober	That serviceaccount must have read access to the IAP-protected page.DISCLAIMER: This is not an officially supported Google product
google-identity-aware-prober	How to use iaprober	The easiest way to use iaprober is to run it alongside Cloudprober in Docker,in Google Kubernetes Engine
google-identity-aware-prober	How to use iaprober	Note: the following commands enable chargeable APIsand services on Google Cloud Platform.The following assumes you have an existing Google Cloud project.To create a new service account, follow the instructions for  creating a newaccount Grant this service account permission to access any IAP-protected page that youwant to test.To create a new Kubernetes cluster, following the instructions for  creating acluster This will also configure your local kubectl command.Download the service account's credentials as a .json file, following theinstructions at  creating and managing service accountkeys Put the credentials in a file named auth.json
google-identity-aware-prober	How to use iaprober	Upload this to your Kubernetescluster as a secret:space-separated parameters:A short-name for the page you are testingThe OAuth client-id for the IAP page
google-identity-aware-prober	How to use iaprober	This can be found on theThis file should be uploaded as a Kubernetes ConfigMap resource:Cloudprober container, and the Cloudprober container is based upon Busybox, wewon't have shared libraries available
google-identity-aware-prober	How to use iaprober	The makefile specifies the necessarybuild flags to create a static binary that will work on Busybox.project name :Add the live tag to the container image:iaprober container to gcr.io/${GOOGLE_CLOUD_PROJECT}/identity-aware-prober:liveDeploy the service and expose the Prometheus metrics port:cloudprober.yaml, and run kubectl apply -f cloudprober.yaml
google-identity-aware-prober	Running iaprober manually	If running cloudprober manually, you'll need the iaprober binary, and theservice account credentials available locally
google-identity-aware-prober	Running iaprober manually	Modify the followingcloudprober.cfg file as appropriate:For a one-off test you can run iaprober from the command line
google-identity-aware-prober	Running iaprober manually	You will need theservice account JSON credentials, the OAuth client ID of the IAP page, and the
google-identity-toolkit-go-client	Google Identity Toolkit Go client	  travisimg   travis This is the Go client library for  Google Identity Toolkit  gitkit  services.Documentation at The gitkit package provides convenient utilities for websites to integratewith the Google Identity Toolkit service.See more at To use Identity Toolkit Go client:// ClientID is the OAuth2 web client ID for your server.const clientID string = "123.apps.googleusercontent.com"var client *gitkit.Clientfunc handleSignIn w http.ResponseWriter, r *http.Request  {	// If there is no valid session, check identity tookit ID token.	ts := client.TokenFromRequest r 	token, err := client.ValidateToken context.Background  , ts,   string{clientID} 	if err != nil {		// Not a valid token
google-identity-toolkit-go-client	Google Identity Toolkit Go client	Handle error.	}	// Token is valid and it contains the user account information	// including user ID, email address, etc.	// Issue your own session cookie to finish the sign in.func main   {	// Provide configuration
google-identity-toolkit-go-client	Google Identity Toolkit Go client	gitkit.LoadConfig   can also be used to load	// the configuration from a JSON file.	config := &gitkit.Config{		WidgetURL:  "",		CookieName: "gtoken",	}	var err error	client, err = gitkit.New context.Background  , config 	if err != nil {		// Handle error.	}	// Provide HTTP handler.	http.HandleFunc "/signIn", handleSignIn 	// Start the server.	log.Fatal http.ListenAndServe ":8080", nil  The integration with Google App Engine is similar except for the contextvariable should be created from the request, i.e., go// ClientID is the OAuth2 web client ID for your server.const clientID string = "123.apps.googleusercontent.com"var client *gitkit.Clientfunc handleSignIn w http.ResponseWriter, r *http.Request  {	// If there is no valid session, check identity tookit ID token.	ts := client.TokenFromRequest r 	token, err := client.ValidateToken appengine.NewContext r , ts,   string{clientID} 	if err != nil {		// Not a valid token
google-identity-toolkit-go-client	Google Identity Toolkit Go client	Handle error.	}	// Token is valid and it contains the user account information	// including user ID, email address, etc.	// Issue your own session cookie to finish the sign in.func init   {	// Provide configuration
google-identity-toolkit-go-client	Google Identity Toolkit Go client	gitkit.LoadConfig   can also be used to load	// the configuration from a JSON file.	config := &gitkit.Config{		WidgetURL:	"",		CookieName:	"gtoken",	}	// Set the JSON key file path if running dev server in local.	if appengine.IsDevAppServer   {		config.GoogleAppCredentialsPath = googleAppCredentialsPath	}	var err error	client, err = gitkit.New context.Background  , config 	if err != nil {		// Handle error.	}	// Provide HTTP handler.	http.HandleFunc "/signIn", handleSignIn 	// Start the server.	log.Fatal http.ListenAndServe ":8080", nil  The client also provides other methods to help manage user accounts, forTo validate the token and also fetch the account information from theidentity toolkit service:To update, or delete the account information of a user:The Go client uses  Google Application Default Credentials  gadc  to accessauthentication required Identity Toolkit API
google-identity-toolkit-go-client	Google Identity Toolkit Go client	The credentials returned aredetermined by the environment the code is running in
google-identity-toolkit-go-client	Google Identity Toolkit Go client	Conditions are checked inthe following order:The environment variable GOOGLE_APPLICATION_CREDENTIALS is checked
google-identity-toolkit-go-client	Google Identity Toolkit Go client	If thisvariable is specified it should point to a file that defines the credentials.The simplest way to get a credential for this purpose is to create a serviceaccount using the Google Developers Console in the section APIs & Auth, in thesub-section Credentials
google-identity-toolkit-go-client	Google Identity Toolkit Go client	Create a service account or choose an existing one andselect Generate new JSON key
google-identity-toolkit-go-client	Google Identity Toolkit Go client	Set the environment variable to the path of theJSON file downloaded.If you have installed the Google Cloud SDK on your machine and have run thecommand gcloud auth login, your identity can be used as a proxy to test codecalling APIs from that machine.If you are running in Google App Engine production, the built-in serviceaccount associated with the application will be used.If you are running in Google Compute Engine production, the built-inservice account associated with the virtual machine instance will be used.If none of these conditions is true, an error will occur.If Application Default Credentials doesn't work for your use case, you canset GoogleAppCredentialsPath in the config to the JSON key file path
google-identity-toolkit-go-client	Google Identity Toolkit Go client	travisimg :  travis :  gitkit :  gadc : 
google-identity-toolkit-php-client	Google Identity Toolkit client library for PHP	This is the PHP client library for Google Identity Toolkit services.
google-identity-toolkit-php-client	Example Code	require_once __DIR__ 
google-identity-toolkit-php-client	Example Code	'/vendor/autoload.php';$gitkitClient = Gitkit_Client::createFromFile "gitkit-server-config.json" ;// ---$hashKey = "\x01\x02\x03";$gitkitClient->uploadUsers 'HMAC_SHA1', $hashKey, createNewUsers $hashKey  ;// --$user = $gitkitClient->validateToken "eyJhb..." ;// ---$user = $gitkitClient->getUserById "1234" ;// ---$verificationLink = $gitkitClient->getEmailVerificationLink "1234@example.com" ;// ---$iterator = $gitkitClient->getAllUsers 3 ;while  $iterator->valid    {  $user = $iterator->current  ;  // $user is a Gitkit_Account object  $iterator->next  ;// ---$gitkitClient->deleteUser '1234' ;function createNewUsers $hashKey  {  $allUsers = array  ;  $gitkitUser->setEmail "1234@example.com" ;  $gitkitUser->setUserId "1234" ;  $salt = "\05\06\07";  $password = '1111';  $gitkitUser->setSalt $salt ;  $gitkitUser->setPasswordHash hash_hmac 'sha1', $password 
google-identity-toolkit-php-client	Example Code	$salt, $hashKey, true  ;  array_push $allUsers, $gitkitUser ;  $gitkitUser->setEmail '5678@example.com' ;  $gitkitUser->setUserId '5678' ;  $salt = "\15\16\17";  $password = '5555';  $gitkitUser->setSalt $salt ;  $gitkitUser->setPasswordHash hash_hmac 'sha1', $password 
google-identity-toolkit-php-client	Example Code	$salt, $hashKey, true  ;  array_push $allUsers, $gitkitUser ;
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	Protocol buffers are a serializable format for structured data that isubiquitous at Google
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Idris is a language where types are first class valuesthat is useful for theorem proving and metaprogramming
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 This package contains apartial implementation of protocol buffers in the Idris language
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 The goal isto demonstrate how Idris is capable of advanced metaprogramming that simplifiesthe implementation of protocol buffers.Protocol buffers are a way to describe a schema for serializable data
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Theschema is called a protocol buffer "message"
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 A message describes the kind ofdata that is to be serialized, and comprises a set of fields
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Each field can bea primitive type, an enum, or another message
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 In this way protocol buffersallow the description of arbitrary data types
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Below is shown a protocolmessage describing a phone number, including an enum definition for the typeof a phone number  mobile, home or work .In most languages, protocol buffers are turned into native data types by codegeneration
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 E.g
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	in C++, the generated code for the Person class will bea C++ class with methods like set_name, name and more complex method toset nested messages like phone
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 The code is generated by a compiler thattakes protocol message descriptions like the one above, parses them and emitsgenerated C++ code.However in Idris, we can avoid generating code by considering a type ofmessage descriptors  so the Person message description would be an value withthis type 
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 This is the MessageDescriptor class
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 In the protocol buffersdocumentation this is just called a Descriptor but here it's useful to bemore consistent in naming
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 The unique property of Idris is that we candefine an inductive data type InterpMessage which has MessageDescriptor forits index space, so that InterpMessage Person is the type of messages oftype Person
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Inductive data types are similar to C++ templates but with theadvantage their arguments can be any value and that value need not even beknown at compile time.In Idris we can write generic, type safe, code for working with protocolbuffers
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 In particular we have code for serialization and deserialization toand from text form
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Serialization looks likeNote that this function is generic in that d ranges over the space ofmessage descriptors, and for each d, the type of the second argument isa message of type InterpMessage d, that is a protocol message in the formatgiven by the descriptor d
google-idris-protobuf	A partial implementation of Protocol Buffers in Idris	 Deserialization can also be done generically.
google-idris-protobuf	About this Repo	The main purpose of the repo is to demonstrate and explore some interestingapplications of Idris
google-idris-protobuf	About this Repo	 Most of the interesting applications are in the Testdirectory which contains an example descriptor Person along with someexamples of creating an instance of InterpMessage Person and some methodsto inspect properties.The PhoneType : EnumDescriptorPhoneType = MkEnumDescriptor    MkEnumValueDescriptor "MOBILE" 0,  MkEnumValueDescriptor "HOME" 1,  MkEnumValueDescriptor "WORK" 5 PhoneNumber : MessageDescriptorPhoneNumber = MkMessageDescriptor    MkFieldDescriptor Required PBString "number",  MkFieldDescriptor Optional  PBEnum PhoneType  "type" Person : MessageDescriptorPerson = MkMessageDescriptor    MkFieldDescriptor Required PBString "name",  MkFieldDescriptor Required PBInt32 "id",  MkFieldDescriptor Optional PBString "email",  MkFieldDescriptor Repeated  PBMessage PhoneNumber  "phone" Note that the MkMessage constructor accepts a heterogeneous list
google-idris-protobuf	About this Repo	 This isnot an HVect but a data type we construct in Protobuf.idr whose constructorsare Nil and  :: , but whose elements have types corresponding to thetypes of the fields given by the message descriptor.
google-idris-protobuf	Install the  Lightyear  package.	This can be done by cloning the repo by running this command from your home
google-idris-protobuf	Clone this repo and run the tests.	Clone this repo by running the following from your home directory
google-idris-protobuf	Experiment in the REPL.  	In order to load the repl with this package, first install it with the command
google-ijaas	IntelliJ as a Service	Make IntelliJ as a Java server that does autocompletion for Vim.This is not an official Google product  i.e
google-ijaas	IntelliJ as a Service	a 20% project .
google-ijaas	Installation	git clone.Import project into IntelliJ
google-ijaas	Installation	Use Gradle plugin.Run gradle buildPlugin
google-ijaas	Installation	It creates build/distributions/ijaas-*.zip at theSelect "File" menu and click "Settings..."
google-ijaas	Installation	In "Plugins" menu, click "InstallRestart IntelliJ.Add "vim" directory to your runtimepath in Vim in your own way.
google-ijaas	Development	If you want to isolate your development version and the current version, youmight need two clones
google-ijaas	Development	You can load Vim plugins conditionally by usingenvironment variables.port  see Connect to the testing IntelliJ with USE_DEV_IJAAS=1 IJAAS_PORT=5801 vim
google-ijaas	Development	Theijaas vim plugin will recognize IJAAS_PORT and use that to connect to theijaas IntelliJ plugin.
google-image-compression	#image-compression	This repository contains an image compression library that provides routinesfor converting to and from various compressed image formats, such as DXT, ETC,and PVRTC.
google-image-rebase	Docker Image Rebase	  This tool rewrites an image's manifest to replace layers in a base image withlayers in another version of that base image
google-image-rebase	Docker Image Rebase	It does so entirely with API callsto the registry, so it doesn't have to download or upload full layer blobs atany point.This can be useful if you want to produce container images with security or bugfixes in base images, without having to completely rebuild the image fromsource
google-image-rebase	Docker Image Rebase	For instance, you might not have access to the original source anymore,or you want to produce updated images without performing a full rebuild.cases
google-image-rebase	Docker Image Rebase	More details below, but caveat emptor.
google-image-rebase	Using image-rebase	For purposes of illustration, imagine you've built a container imagegcr.io/my-project/my-app:latest, containing your app, and based on some OSimage, for instance, launcher.gcr.io/google/ubuntu16_04
google-image-rebase	Using image-rebase	A vulnerability hasbeen found in the base image, and a new fixed version has been released.You could build your app image again, and its FROMlauncher.gcr.io/google/ubuntu16_04 directive would pick up the new base imagerelease, but that requires a full rebuild of your entire app from source, whichmight pull in other changes in dependencies
google-image-rebase	Using image-rebase	You just want to release thiscritical bug fix, as quickly as possible.Instead, you could use this tool to replace the vulnerable base image layers inyour image with new patched base image layers from the newly released baseimage, without needing to rebuild from source, or indeed have access to thesource at all.check that old_base is indeed the basis for original, remove old_base'slayers from original and replace them with new_base's layers, then computeand upload a new valid manifest for the image, tagged as rebased.If the image is in Google Container Registry, you can determine old_base imagedigests using gcloud alpha container images describe 
google-image-rebase	Rebase visualized	! rebase visualization  ./rebase.png 
google-image-rebase	Installing image-rebase	The tool can be installed using go get:
google-image-rebase	Rebase as a Go library	You can also use the image-rebase logic as a library in your Go program, byimporting it:
google-image-rebase	Caveats	Rebasing has no visibility into what the container image contains, or whatconstitutes a "valid" image
google-image-rebase	Caveats	As a result, it's perfectly capable of producing animage that's entirely invalid garbage
google-image-rebase	Caveats	Rebasing arbitrary layers in an image isnot a good idea.To help prevent garbage images, rebasing should only be done at a point in thelayer stack between "base" layers and "app" layers
google-image-rebase	Caveats	These should adhere to somecontract about what "base" layers can be expected to produce, and what "app"layers should expect from base layers.In the example above, for instance, we assume that the "Ubuntu" base image isadhering to some contract with downstream app layers, that it won't remove ordrastically change what it provides to the app layer
google-image-rebase	Caveats	If the new_base layersremoved some installed package, or made a breaking change to the version of somecompiler expected by the uppermost app layers, the resulting rebased image mightbe invalid.In general, it's a good practice to tag rebased images to some other tag thanthe original tag once it's determined the image is valid.There is ongoing work to standardize and advertise base image contractadherence to make rebasing safer.
google-image-rebase	Automatic Rebase Seam Detection	If an app image adheres to a strong contract with its base layers, the toolthat builds the app image can insert a hint into the image, in the form of a--new_base automatically.The form of the LABEL is:in --old_base= and --new_base=.In this way, new releases of  will automatically be consideredas --new_base for the app image, if the flags aren't passed explicitly.The image-rebase tool injects this LABEL into the --rebased image itproduces, if --new_base is passed as a tag, to aid future rebase operationson that image.Using the example above, gcr.io/my-project/my-app:rebased contains the following label:Future rebase operations can be specified with just two flags:
google-import-mailbox-to-gmail	Import .mbox files to G Suite  formerly Google Apps for Work 	This script allows G Suite admins to import mbox files in bulk for their**DISCLAIMER**: This is not an official Google product.If you want to migrate from Mozilla Thunderbird, try mail-importer You only authorize it once using a service account, and then it can import mailinto the mailboxes of all users in your domain.
google-import-mailbox-to-gmail	A. Creating and authorizing a service account for Gmail API	Go to the  Developers Console Create a new project.Click the **Enable and manage APIs*Enable the Gmail APIClick the 3-line icon  **≡**  in the top left corner of the console.Click **IAM & Admin*Click **Create service account**.Enter a name  for example, "import-mailbox"  in the **Name*Check the **Furnish a new private key*Check the **Enable G Suite Domain-wide Delegation*Click **Create**
google-import-mailbox-to-gmail	A. Creating and authorizing a service account for Gmail API	You will see a confirmation message advising that theClick **Close**.Click the **View Client ID*Copy the **Client ID*Go to  the **Manage API client access*Under **One or More API Scopes**, enter the following:Click **Authorize**.You can now use the JSON file to authorize programs to access the Gmail API"insert" and "label" scopes of all users in your G Suite domain.
google-import-mailbox-to-gmail	B. Importing mbox files using import-mailbox-to-gmail.py	**Important**: If you're planning to import mail from Apple Mail.app, see the notes below.Download the script  Download  and install Python 2.7  notOpen a **Command Prompt*Install the Google API Client Libraries for Python and their dependencies byCreate a folder for the mbox files, for example C:\mbox.Under that folder, create a folder for each of the users into which youInto each of the folders, copy the mbox files for that user
google-import-mailbox-to-gmail	B. Importing mbox files using import-mailbox-to-gmail.py	Make sure the  C:\mbox  C:\mbox\user1@domain.com  C:\mbox\user1@domain.com\Imported messages.mbox  C:\mbox\user1@domain.com\Other imported messages.mbox  C:\mbox\user2@domain.com  C:\mbox\user2@domain.com\Imported messages.mbox  C:\mbox\user2@domain.com\Other imported messages.mbox    users' mailboxes
google-import-mailbox-to-gmail	B. Importing mbox files using import-mailbox-to-gmail.py	First, migrate the mbox files into a test user, to make sure  the messages are imported correctly.To start the migration, run the following command  one line :can monitor the migration by looking at the output, and inspect errors byviewing the import-mailbox-to-gmail.log file.
google-import-mailbox-to-gmail	Options and notes	  _all_ users and _all_ mbox files 
google-in-silico-labeling	In silico labeling: Predicting fluorescent labels in unlabeled images	This is the code forIn silico labeling: Predicting fluorescent labels inunlabeled images
google-in-silico-labeling	In silico labeling: Predicting fluorescent labels in unlabeled images	It is the result of a collaboration between  Google AcceleratedScience  and two external labs: the  LeeRubin lab  at Harvard and the  StevenFinkbeiner lab  atGladstone
google-in-silico-labeling	In silico labeling: Predicting fluorescent labels in unlabeled images	See also  our blog post  and our  full dataset, including many predictions we couldn't fit in the paper  data.md .This code in this repository can be used to run training and inference of ourmodel on a single machine, and can be adapted for distributed training
google-in-silico-labeling	In silico labeling: Predicting fluorescent labels in unlabeled images	It also contains a set of weights created by trainingthe model on the data in Conditions A, B, C, and D from the paper.This README will explain how to: Restore the model from the provided checkpoint and run inference on an image Train the pre-trained model on a new dataset  Condition E .Please note, the example in this README deviates from the way transfer learning is demonstrated in the paper.In the paper, the model is trained once on all datasets, including Condition E; this is also called multi-task learning.In this guide, we're starting with a pre-trained model on Conditions A, B, C, and D, and incrementally training it on Condition E.The benefit of the latter technique is it requires less time to learn a new task, but it is likely to overfit if overtrained  see below .The model here differs from the model described in the paper in one significantway: this model does an initial linear projection to 16 features per pixel,where the model in the paper does not have this step
google-in-silico-labeling	In silico labeling: Predicting fluorescent labels in unlabeled images	This allows the model totake as input *z*-stacks with varying numbers of *zneeds to be relearned is the initial linear projection
google-in-silico-labeling	In silico labeling: Predicting fluorescent labels in unlabeled images	Here, we'll use it totake full advantage of the 26 *zhave 13 *zYou can also find the complete set of preprocessed data used for the paper,along with predictions,  here  data.md .*This is not an official Google product.*
google-in-silico-labeling	Code	The code requires Python 3 and depends on NumPy, TensorFlow, and OpenCV
google-in-silico-labeling	Code	You caninstall TensorFlow using  this guide which will also install NumPy
google-in-silico-labeling	Code	If you follow that guide you will have installedpip3 and you'll be able to install OpenCV with the command: pip3 install--upgrade opencv-python.We're using  Bazel  to build the code and run tests.Though not strictly necessary, we suggest you install it  the rest of thisREADME will assume you have it .This code has been tested in Debian 10 with TensorFlow 1.9 on a machine with 64 GB RAM.It is not optimized for memory use, and has been reported to fail with a Python MemoryError on a machine with 16 GB RAM.Based on tests with ulimit, we recommend using a machine with at least 32 GB RAM.
google-in-silico-labeling	Data	We'll work with the data sample in  data_sample.zip  Warning: 2 GB download  and a checkpoint from the pre-trained modelin  checkpoints.zip  Ifyou have  gsutil  installed, you can also use the commands:The rest of this README will assume you've downloaded and extracted thesearchives to checkpoints/ and data_sample/.
google-in-silico-labeling	Running the pre-trained model.	Training and inference are controlled by the script isl/launch.py
google-in-silico-labeling	Running the pre-trained model.	We recommendyou invoke the script with Bazel  see below , because it will handle dependencymanagement for you.The checkpoints.zip file contains parameters from a model trained onConditions A, B, C, and D
google-in-silico-labeling	Running the pre-trained model.	To run the model on a sample from Condition B, runthis command from the project root:If you get a syntax error, make sure you're using Python 3, not Python In the above: BASE_DIRECTORY is the working directory for the model
google-in-silico-labeling	Running the pre-trained model.	It will be created alsologtostderr will cause progress information to be printed to the stitch_crop_size is the size of the crop for which we'll perform infer_channel_whitelist is the list of fluorescence channels we wish toIf you run this command, you should get a target_error_panel.png that lookslike this:Each row is one of the whitelisted channels you provided; in this case it's onerow for each of the DAPI_CONFOCAL, MAP2_CONFOCAL, and NFH_CONFOCAL channels
google-in-silico-labeling	Running the pre-trained model.	The boxes with thepurple borders show the predicted images  in this case the medians of theper-pixel distributions 
google-in-silico-labeling	Running the pre-trained model.	The boxes with the teal borders show the truefluorescence images
google-in-silico-labeling	Running the pre-trained model.	The boxes with the black borders show errors, with falsepositives in orange and false negatives in blue.The script will also generate a file called  input_error_panel.png  which showsthe 26 transmitted light input images along with auto-encoding predictions anderrors
google-in-silico-labeling	Running the pre-trained model.	For this condition, there were only 13 *z*-depths, so this visualizationwill show each *z*-depth twice.
google-in-silico-labeling	Training the pre-trained model on a new dataset.	Condition E contains a cell type not previously seen by the model  human cancercells , imaged with a transmitted light modality not previously seen  DIC , andlabeled with a marker not previously seen  CellMask .We have two wells in our sample data  B2 and B3 , so let's use B2 for training and B3 for evaluation.To see how well the model can predict labels on the evaluation dataset *beforeThis should produce this target error panel:This is like the error panels above, but the first row is DAPI_CONFOCAL and the second is CELLMASK_CONFOCAL.And because we used noinfer_simplify_error_panels it includes more statistics of thepixel distribution
google-in-silico-labeling	Training the pre-trained model on a new dataset.	Previously, there was one purple-bordered box which showed themedians of the pixel distributions
google-in-silico-labeling	Training the pre-trained model on a new dataset.	Now there are four purple-bordered boxes which show,in order, the mode, median, mean, and standard deviation
google-in-silico-labeling	Training the pre-trained model on a new dataset.	There are now threeboxes with black borders, showing the same error visualization as before, butfor the mode and mean as well as the median
google-in-silico-labeling	Training the pre-trained model on a new dataset.	The white-bordered boxes are a newkind of error visualization, in which colors on the grayline between black andwhite correspond to correct predictions, orange corresponds to a false positive,and blue corresponds to a false negative
google-in-silico-labeling	Training the pre-trained model on a new dataset.	The final mango-bordered box is notinformative for this exercise.The pre-trained model hasn't seen the Condition E dataset, so we should expectits predictions to be poor
google-in-silico-labeling	Training the pre-trained model on a new dataset.	Note, however, there is some transfer of the nuclearlabel even before training.You can find the input images, consisting of a *z*-stack of 26 images, here   Warning: 100 MB download .
google-in-silico-labeling	Training	We can train the network on the Condition E data on a single machine using acommand like:By default, this uses the ADAM optimizer with a learning rate of 1e-If youwish to visualize training progress, you can run TensorBoard  on BASE_DIRECTORY:You should eventually see a training curve that looks like this:After 50,000 steps, which takes about a week on a 32-core machine, predictionson the eval data should have substantially improved.You can run this command to generate predictions:Note, we've dropped the restore_directory argument, so the model will run inference using the latest checkpoint it finds in BASE_DIRECTORY.Here's what the predictions should look like on the evaluation data:Note, there is a bug in the normalization of the DAPI_CONFOCAL channel causingit to have a reduced dynamic range in the ground-truth image
google-in-silico-labeling	Training	Comparing theinitial nuclear predictions with these, it is clear the network learned to matchthe reduced dynamic range.For reference, here's what predictions should look like on the train data:Note, if we train too long the model will eventually overfit on the train dataand predictions will worsen
google-in-silico-labeling	Training	This was not an issue in the paper, because therewe simultaneously trained on all tasks, so that each task regularized the
google-in-silico-labeling	Citing the code	If you use this code, please cite our paper:Christiansen E, Yang S, Ando D, Javaherian A, Skibinski G, Lipnick S, Mount E, O'Neil A, Shah K, Lee A, Goyal P, Fedus W, Poplin R, Esteva A, Berndl M, Rubin L, Nelson P, Finkbeiner S
google-in-silico-labeling	Citing the code	In silico labeling: Predicting fluorescent labels in unlabeled images
google-in-silico-labeling	Citing the code	Cell
google-in-silico-labeling	Citing the code	2018 Fix the tests
google-in-silico-labeling	Citing the code	Fix the DAPI_CONFOCAL normalization bug for the Condition E data
google-in-silico-labeling	Citing the code	Note: This bug was introduced after
google-inception	Inception	This repository contains a reference pre-trained network for the Inceptionmodel, complementing the Google publication.Going Deeper with Convolutions, CVPR Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.You can view "inception.ipynb" directly on GitHub, or clone therepository, install dependencies listed in the notebook and play with codeYou may also be interested in the  Multibox approach that uses the Inception architecture for object detection, alsoavailable on GitHub.Disclaimer: this is not an official Google product  experimental or otherwise .
google-incremental-dom	Overview	Incremental DOM is a library for building up DOM trees and updating them in-place when data changes
google-incremental-dom	Overview	It differs from the established virtual DOM approach in that no intermediate tree is created  the existing tree is mutated in-place 
google-incremental-dom	Overview	This approach significantly reduces memory allocation and GC thrashing for incremental updates to the DOM tree therefore increasing performance significantly in some cases.Incremental DOM is primarily intended as a compilation target for templating languages
google-incremental-dom	Overview	It could be used to implement a higher level API for human consumption
google-incremental-dom	Overview	The API was carefully designed to minimize heap allocations and where unavoidable ensure that as many objects as possible can be de-allocated by incremental GC
google-incremental-dom	Overview	One unique feature of its API is that it separates opening and closing of tags so that it is suitable as a compilation target for templating languages that allow  temporarily  unbalanced HTML in templates  e.g
google-incremental-dom	Overview	tags that are opened and closed in separate templates  and arbitrary logic for creating HTML attributes.*Think of it as ASM.dom.*
google-incremental-dom	Supported Browsers	Incremental DOM supports IE9 and above.
google-incremental-dom	Usage	HTML is expressed in Incremental DOM using the elementOpen, elementClose, elementVoid and text methods
google-incremental-dom	Usage	Consider the following example:var IncrementalDOM = require 'incremental-dom' ,function render data  {  elementVoid 'input', '',   'type', 'text'   ;  elementOpen 'div', '', null ;  elementClose 'div' ;To render or update an existing DOM node, the patch function is used:var patch = require 'incremental-dom' .patch;var data = {  text: 'Hello World!',  someCondition: truepatch myElement, function   {  render data ;} ;data.text = 'Hello World!';patch myElement, function   {  render data ;} ;
google-incremental-dom	Templating Languages and Libraries	 Check out  ECOSYSTEM.md   what others having been doing with Incremental DOM.
google-incremental-dom	Via CDN	To install the required development packages, run the following command:To run once:To build once:
google-indexable-pwa-samples	Indexable PWA	A sample ExpressJS PWA that explores and demonstrates the bestpractices for implementing a PWA in regards to indexability of content.Can be configured for 3 specific rendering modes:Install this package via npm:npm installInstall bower and the fetch polyfill to support Safari:npm install bowerbower install fetchRun the server via:node server.js
google-indexable-pwa-samples	Deploying to App Engine	Follow this link to setup your App Engine project for Node.JS:gcloud app deploy app.yamlUse app.yaml to set environment variables to override the config.js file.Example .yaml file:runtime: nodejsvm: true  AMP_MODE: disabled  RENDER_MODE: hybrid  UPDATE_MODE: json
google-indexable-pwa-samples	Configuration Patterns	Configure config.js:Recommended configuration patterns:
google-indexable-pwa-samples	Server Sample	For server-side rendering:{  "ampMode": "disabled",  "renderMode": "server",  "updateMode": "disabled",  "googleSiteVerificationToken": ""~~~~
google-indexable-pwa-samples	Client Sample	For client-side rendering.updateMode can be configured as either 'json' or 'html'.{  "ampMode": "disabled",  "renderMode": "client",  "updateMode": "json",  "googleSiteVerificationToken": ""~~~~
google-indexable-pwa-samples	Hybrid Sample	For hybrid rendering.updateMode can be configured as either 'json' or 'html'.{  "ampMode": "disabled",  "renderMode": "hybrid",  "updateMode": "json",  "googleSiteVerificationToken": ""~~~~
google-indexed-db-as-promised	indexed-db-as-promised   	 ! npm version  A thin wrapper around IndexedDB, making it much more pleasant to use byreturning Promise-likes
google-indexed-db-as-promised	indexed-db-as-promised   	Inspired by ideas in indexeddb-promised but written with the SyncPromise library to avoid issues with the transactionThis is not an official Google product.
google-indexed-db-as-promised	Installation	The APIs mirror native IndexedDB's, just returning a promise-like everywhereyou would want one.import indexedDBP from "indexed-db-as-promised";indexedDBP.open 'database', 1, {  upgrade db, { transaction, oldVersion, newVersion }  {  }} .then  db  => {  // Get the Jane's record  return db.transaction 'people' .run  tx  => {  } .then  record  => {  } .then  count  => {  } .then    => {  } ;} ;
google-indexed-db-as-promised	License	Apache 2.0
google-infact	InFact: An easy way to construct C++ objects dynamically	InFact provides an interpreter and factory for the construction ofinstances of C++ classes
google-infact	InFact: An easy way to construct C++ objects dynamically	The syntax is very much like that of C++itself, and objects may be created that wrap other objects, just likein C++
google-infact	InFact: An easy way to construct C++ objects dynamically	It supports all the common primitive types  string , as well as vectors of primitives or of Factory-constructibleobjects
google-infact	InFact: An easy way to construct C++ objects dynamically	Here's what it looks like:// Construct a cow with a required argument, its name.Cow c1 = Cow name "Bessie"  ;// Construct a second cow with a different name, and an optional age.// Also, specifying a type is optional, since InFact does type inference.c2 = Cow name "Lani Moo" , age 2  ;// Construct a human pet owner with the two cows as pets.PetOwner p = HumanPetOwner pets {c1, c2}  ;Feeding the above to InFact’s Interpreter class will construct three new objects at run-time  the referents ofc1, c2 and p  _without any new C++ code_.While being very powerful, the library is also quite lightweight: itis a simple recursive-descent parser with a single token oflook-ahead, with the entire library implemented with fewer than 1000C++ statements
google-infact	InFact: An easy way to construct C++ objects dynamically	The inspiration was the BeanShell library  for Java, whichprovides a very convenient mechanism for configuration of any Javaproject
google-infact	InFact: An easy way to construct C++ objects dynamically	Similarly, InFact can be used as an effective configurationmechansim for C++ projects
google-infact	InFact: An easy way to construct C++ objects dynamically	See the ReFr project  for an example, the default configuration file The interpreted InFact language supports _type inference_ and _namedparameters_
google-infact	InFact: An easy way to construct C++ objects dynamically	Compile-time equivalents of these two properties areavailable with the Boost Parameter library.For documentation, please visit our documentation site 
google-infra-structured-map	Usage	Document your projects in a Markdown file:
google-infra-structured-map	The Bigger Dig	This is a multi-century project to build a subway from New York to LA.Next, define the geographic features of each project in KML:maintaining your map data
google-infra-structured-map	The Bigger Dig	 It exports KML and you can even pass your KMLdownload URL to the extract below.Next, build a JSON data file for powering your interactive map.
google-inspectorspacetime	 Inspector Spacetime  4e4c540d 	Motion specs are a necessary part of the engineering process
google-inspectorspacetime	 Inspector Spacetime  4e4c540d 	It's often difficult and time consuming to deliver the data required to replicate motion on device
google-inspectorspacetime	 Inspector Spacetime  4e4c540d 	With Inspector Spacetime you can generate this data along side the reference quicktime, with just one click.> This is not an official Google product
google-inspectorspacetime	 Inspector Spacetime  4e4c540d 	Motion designers at Google just kinda like it a lot
google-inspectorspacetime	 Inspector Spacetime  4e4c540d 	Built by  Adam Plouff  8638464d .
google-inspectorspacetime	After Effects	Close After EffectsDrag the InspectorSpacetime.jsx file into Applications > Adobe After Effects  version number  > Scripts > ScriptUI PanelsFire up After Effects againNavigate to the Window menu up top
google-inspectorspacetime	After Effects	At the bottom you'll see InspectorSpacetime.jsx
google-inspectorspacetime	Basics	Select a pair or several pairs of keyframes and click the giant button
google-inspectorspacetime	Basics	Your comp will be duplicated and resized to create space for all the useful spec data to live right alongside the reference animation.A new text layer is generated with all the selected element data
google-inspectorspacetime	Basics	Raw text may be edited
google-inspectorspacetime	Basics	Enabling the expression will update style and live values.
google-inspectorspacetime	Live Text	Spec data is based on the overall transition time
google-inspectorspacetime	Live Text	Markers are placed at the time of the first and last selected keyframes as a reference for the transition time
google-inspectorspacetime	Live Text	Moving the start and end markers updates:
google-inspectorspacetime	Data output	Keyframe data output:
google-inspectorspacetime	Isolation Layer	If your comp is really busy it can be tough to clearly see what's being spec'd
google-inspectorspacetime	Isolation Layer	An isolation layer is just an adjustment layer that will grey out everything below it to get a little more focus on what you're showing.
google-inspectorspacetime	Time Counter	Created with every spec, a counter is also available as its own layer
google-inspectorspacetime	Time Counter	Create a millisecond counter with a defined start and end point
google-inspectorspacetime	Time Counter	Start the timer at the beginning of the transition to easily illustrate the global start time.
google-inspectorspacetime	Pointer	Everyone names things differently, which can lead to confusion
google-inspectorspacetime	Pointer	So draw a line from spec data to the visual element and save yourself a lot of explaining
google-inspectorspacetime	Pointer	This button will get you started, or just draw your own
google-inspectorspacetime	Pointer	Either way, it'll make your life easier.
google-inspectorspacetime	Why the dumb name?	Named after the Doctor Who parody from the underrated NBC comedy  Community  a97544c1 
google-inspectorspacetime	Why the dumb name?	It was a really great show.In**spec**tor Spacetime
google-inspectorspacetime	Why the dumb name?	It's a bad pun
google-inspectorspacetime	Why the dumb name?	But I'm a dad
google-inspectorspacetime	Why the dumb name?	I can't help it.
google-inspectorspacetime	License	Apache 2.0
google-instant-hangouts	Instant Hangouts	**Disclaimer: due to Hangouts API changes, this app is no longer supported.**Instant Hangouts lets you easily add Google+ Hangouts to any web page:! default hangout  images/default_hangout.png  Google+ Hangout Button API  isrich but requires a bit of fiddling to get details right
google-instant-hangouts	Instant Hangouts	Instant Hangouts is athin wrapper that handles a bunch of the details for you:By default we display a Hangout name and information about the participants,rather than just a button to start a new Hangout.The Google API is loaded asynchronously to keep your pages fastConfiguration is very simple: just add attributes to your .
google-instant-hangouts	How it works	You serve instanthangouts.0.1.0.js
google-instant-hangouts	How it works	Then, you put the following HTML into yourpage where you want the Hangout to appear:only need our script once:We take care of loading the script asynchronously if possible so your pagesdon't wait until they've downloaded the Google API to render.Our Javascript looks at your page and finds all elements that haveclass='instanthangouts' on them
google-instant-hangouts	How it works	We read the attributes of those tags tofigure out what arguments to pass to the Google API
google-instant-hangouts	How it works	See below for the argumentsyou can put on these elements to configure your Hangouts.Next, we insert a new class='instanthangouts'
google-instant-hangouts	How it works	We then call the Google API and pass in the argumentswe read from the element, rendering the Hangout
google-instant-hangouts	How it works	This means you can have as manyHangout controls on a page as you want.
google-instant-hangouts	Modes	We support two modes: *widget
google-instant-hangouts	Widget	Widget mode looks like this:! default hangout  images/default_hangout.png It is used by default, and can be explicitly selected by setting hangout in your HTML:end up in the same Hangout
google-instant-hangouts	Widget	Rooms are unique to the 3room_id, topic   see **Options*to values that will cause all Hangouts on a given page to have the same room,which is usually what users want.
google-instant-hangouts	Button	Button mode looks like this:! button hangout  images/button_hangout.png It can be selected with the following HTML:allows some options  like creating a Hangout on Air  that the widget does notsupport
google-instant-hangouts	Button	See **Options*You can mix buttons and widgets on the same page.
google-instant-hangouts	Options	We support the full Google+ Hangout Button API with the exception of adding Hangout apps to your page
google-instant-hangouts	Options	If you're using aHangout app, you probably want full control rather than going through an adapterlike Instant Hangouts.All options are set as HTML attributes on your tags
google-instant-hangouts	Options	All values are strings.The full list of options is:mode
google-instant-hangouts	Options	Ignored in widget mode
google-instant-hangouts	Options	See the official docs for possible values.only the value on the first  is honored.explicit, meaning no automatic processing is done and all renders must becalled via the API
google-instant-hangouts	Options	The other option is onload
google-instant-hangouts	Options	This does DOM traversal anddiscovery and is consequently slower
google-instant-hangouts	Options	parsetags is global, so only the valueon the first  is honored.default all Hangouts created with Instant Hangouts use the Instant Hangoutspublisher_id
google-instant-hangouts	Options	You can use your own if you want to be double sure that yourorganization's rooms won't overlap with another organization's  though bydefault we use the URL when constructing rooms, which in most cases will beunique to your organization .button mode
google-instant-hangouts	Options	Default is hangout
google-instant-hangouts	Options	No effect in button mode.the room_id is room_ plus the URL of the containing page
google-instant-hangouts	Options	No effect inbutton mode.value is presented to users in the Hangouts UI telling them what the Hangout isabout
google-instant-hangouts	Options	Default is Instant Hangout
google-instant-hangouts	Options	No effect in button mode.Default is 136.Default is 300.Here is a full example for the HTML you need in widget mode to set all customThis section covers development of Instant Hangouts
google-instant-hangouts	Options	You don't need to read itunless you want to contribute to the project.We use  npm  for package management and Node.js  for a development server
google-instant-hangouts	Options	You should install Node,which comes with npm, in whatever way is best on your system.Pull down the repo and install dependencies into ./node_modules withlocalhost during development because the URL is used when constructing rooms
google-instant-hangouts	Options	Ifyou use a hostname, you can bring up the test server on multiple machines andlog in with multiple accounts to do a real end-to-end test of the HangoutWe use  Grunt  to produce two files:generate new versions of these files
google-instant-hangouts	Options	You will also want to update the scripttags in this document.When developing, runtime there is a change
google-instant-hangouts	Options	This assumes you have installed grunt-cli globally,which is fairly common
google-instant-hangouts	Options	If you want to use the local version managed by InstantHangouts, instead runrunner
google-instant-hangouts	Options	To start:be run in that Chrome window
google-instant-hangouts	Options	Karma has its own file watcher and reruns testswhen either the source, tests, or index.html changes
google-instant-hangouts	Options	We use Jasmine  for our test framework.
google-intelligent_annotation_dialogs	Source code for Intelligent Annotation Dialogs	This repository contains the source code which is used to run the experiments inour ArXiv paper:The code contains third party code  np_box_ops.py  from the  Tensorflow ObjectAPI
google-intelligent_annotation_dialogs	Disclaimer	This is not an officially supported Google product.
google-intellij-cmdline-vcs-plugin	Command-line "VCS" plugin for IntelliJ IDEA	Makes calls to shell scripts to get all VCS-related job done.This allows you to write scripts to acoomodate even the strangiestVCS workflows you may encounter.
google-intellij-cmdline-vcs-plugin	Command line script	Should be placed into "/usr/local/bin/cmdline-vcs" and be executable.List of commands called from IntelliJ:
google-inverting-proxy	Inverting Proxy and Agent	This repository defines a reverse proxy that inverts the direction of trafficbetween the proxy and the backend servers.That design makes configuring and hosting backends much simpler than whatis required for traditional reverse proxies:The communication channel between the proxy and backends can be securedThe backends do not need to be exposed to incoming requests from the proxy.
google-inverting-proxy	Disclaimer	 This is not an official Google product 
google-inverting-proxy	Background	A  reverse proxy  is a server thatforwards requests to one or more backend servers.Traditionally, this has been done by configuring the reverse proxy with theaddress of each backend, and then having it send a request to a backend foreach request it receives from a client.That meant each backend had to be able to receive incoming requests from theproxy
google-inverting-proxy	Background	This implied one of two choices.Place the backend servers on a private network shared with the proxy.Place the backend servers on the public internet.The first choice requires the proxy and backends to be controlled by the samehosting provider, while the second requires the backends handle all of thesame overhead required for any internet hosting  SSL termination, protectionagainst DDoS attacks, etc .This project aims to limit the overhead of hosting a public server to justthe proxy while still allowing anyone to run a backend.The details of how this is accomplished are outlined below.
google-inverting-proxy	Design	This project defines two components:Something that we are calling the "Inverting Proxy"An agent that runs alongside a backend and forwards requests to itThe inverting proxy can be run on App Engine
google-inverting-proxy	Design	It requires incoming requests beauthenticated via the  Users API and forwards those requests to the appropriate backend, via the agent.Since neither the backend nor the agent will be accessible from the publicinternet, requests are not directly forwarded to the backend
google-inverting-proxy	Design	Instead,the direction of that traffic is inverted
google-inverting-proxy	Design	The agent sends a request to theinverting proxy, the proxy waits for incoming client requests, andthen the proxy responds to the request from the agent with those clientrequests in the response body.The agent then forwards those requests to the backend, takes the responsesthat it gets back, and sends them as a request to the inverting proxy.Finally, the inverting proxy extracts the backend's response from theagent's request and sends it as the response to the original clientAn example request flow looks like this:The important thing to note is that the request from the client  #2  matchesthe request to the backend  #4  and the response from the backend  #5  matchesthe response to the client  #7 .
google-inverting-proxy	Components	There are two components required for the inverting proxy to work:The proxy itself, which must be accessible from the public internet.The forwarding agent, which must be able to forward requests to the backend.
google-inverting-proxy	Inverting Proxy	The inverting proxy serves the same roll as a reverse proxy, but additionallyinverts the direction of traffic to the agent.We implement the inverting proxy as an App Engine app
google-inverting-proxy	Inverting Proxy	The app is written inGo and its source code is under the 'app' subdirectory.
google-inverting-proxy	Forwarding Agent	The agent receives the inverted traffic from the proxy and inverts it againbefore forwarding it to the backend
google-inverting-proxy	Forwarding Agent	This ensures that the requests from theclient match the requests to the backend and that the responses from thebackend match the responses to the client.The forwarding agent is standalone binary written in Go and its source codeis under the 'agent' subdirectory.
google-inverting-proxy	Prerequisites	First,  create a Google Cloud Platform project that will host your proxy, and ensure that you have the Google Cloud SDK  installed on your machine.
google-inverting-proxy	Setup	Save the ID of your project in the environment variable PROJECT_ID, and thenrun the commandone for agents to contact, and one that implements an API for managingproxy endpoints .
google-inverting-proxy	Registering Backends	Before you can connect a backend server to your proxy, you must use the proxy'sadmin API to create a record of that backend
google-inverting-proxy	Registering Backends	This is just a simple HTTPREST API with create, list, and delete operations
google-inverting-proxy	Registering Backends	There is no client toolprovided for the admin API, but you can access it using curl.To list the current backends:  Alternatively, you can use the special string "allUsers" to make your server public
google-inverting-proxy	Registering Backends	 on the machine where the agent runs.Finally, to delete a backend:Once you have created the record for your backend using the API, you canrun the agent alongside your server with the following command:
google-inverting-proxy	Limitations	Currently, the inverting proxy only supports HTTP requests
google-inverting-proxy	Limitations	In particular,websockets are not supported, so you have to use an adapter like socket.ioif you want to use the inverting proxy with a service that requires websockets.
google-ion	Ion	Ion is a portable suite of libraries and tools for building client applications,especially graphical ones
google-ion	Ion	It is small, fast, robust, and is cross-platformacross many platforms and devices, including desktops, mobile devices, browsers,and other embedded platforms.For more details and a fair amount of documentation see
google-ion	Why Use Ion?	NOTE: This is not an official Google product.
google-ios-chatbot	Chatbot with API.AI and Google Cloud APIs	This sample demonstrates how to build an iOS chatbot with Google Cloud Vision,Speech, and Translate APIs and API.AI
google-ios-chatbot	Chatbot with API.AI and Google Cloud APIs	! English Demo   ! The Google Assistant / Google Home Demo  
google-ios-chatbot	Prerequisites	Create a new project on Enable Billing.Go to API Manager.Go to CredentialsCreate credentials
google-ios-chatbot	Prerequisites	Choose API Key.Replace @"your google API key" with your google API key in  CBDefines.m  ChatBot/ChatBot/Helpers/CBDefines.m 
google-ios-chatbot	API.AI	Optionally, follow these steps to create your own API.AI agents.Create TourGuide agent.Go to Settings and import  api.ai/TourGuide.zip  api.ai/TourGuide.zip 
google-ios-chatbot	API.AI	Optional steps to support Chinese  Create TourGuideChinese agent withlanguage set to Chinese.Go to Settings and import  api.ai/TourGuideChinese.zip  api.ai/TourGuideChinese.zip Replace CBApiAiToken with your API.AI token in  CBDefines.m  ChatBot/ChatBot/Helpers/CBDefines.m 
google-ios-chatbot	API.AI	You can find your token from the API.AI agent setting page.
google-ios-chatbot	Chinese Demo	 ! Chinese Demo  
google-ios-chatbot	License	This sample is released under the  Apache 2.0 license  LICENSE .
google-ios-chatbot	Disclaimer	This is not an official Google product.
google-ios-chatbot	Authors	 Chang Luo  changluo  and  Bob Liu  bobliu  getting-started :  cloud-console :  git :  xcode :  billing :  enable-speech :  api-key :  cocoapods :  changluo :  bobliu :  google-home : 
google-ios-device-control	iOS Device Control Library	iOS Device Control is a Java library for controlling the iOS Simulator and real physical  iOS devices tethered to a device running macOS
google-ios-device-control	iOS Device Control Library	The library offersthe ability to get device properties, install and start applications, takescreenshots, capture logs, and more!Examples of how to use this library can be found here  src/com/google/iosdevicecontrol/examples 
google-ios-device-control	iOS Device Control Library	To build the examples, run:which will create two runnable jars in the target directory.
google-ios-device-control	Installation	iOS Device Control only works on macOS with tethered real devices or with Xcode8+ with the simctl tool installed for the iOS Simulator.
google-ios-device-control	Simulator Automation	Install  Xcode 8 or above and verify the following command works:The following dependencies can be installed easily with homebrew Install libusbmuxd by building from source:Install libimobiledevice by building from source:Install ideviceinstaller by building from source:Install idevice_app_runner and idevicewebinspectorproxy by building fromsource
google-ios-device-control	Simulator Automation	This can be done by following the instructions outlined in theREADMEs of the respective projects in the  third_party directory  third_party .
google-ios-device-control	Optional Utilities	Most of the iOS Device Control library can be used with just the above tools.For additional control of real devices, the following tools can optionally beInstall  Apple Configurator 2 and install the automation tools by selecting the "Install Automation Tools..."option under the Apple Configurator 2 menu.Install the provided OpenUrl app by following the instructions here  OpenUrlApp/README  to automate Safari on real devices.
google-ios-device-control	Troubleshooting	For real devices, make sure that both the device is trusted and the lockdownfolder has the correct permissions.
google-ios-device-control	License	iOS Device Control is licensed under the open-source Apache 2.0 license  LICENSE .
google-ios-device-control	Contributing	Please  see the guidelines for contributing  CONTRIBUTING.md  before creatingpull requests.
google-ios-webkit-debug-proxy	iOS WebKit Debug Proxy	The ios_webkit_debug_proxy  aka _iwdp_  proxies requests from usbmuxd daemon over a websocket connection, allowing developers to send commands to MobileSafari and UIWebViews on real and simulated iOS devices.
google-ios-webkit-debug-proxy	Installation	iOS WebKit Debug Proxy works on Linux, MacOS & Windows.On a MacOS, it's easiest to install with  homebrew On Linux  or MacOS :sudo apt-get install autoconf automake libusb-dev libusb-1.0-0-dev libplist-dev libplist++-dev usbmuxd libtool libimobiledevice-devgit clone cd ios-webkit-debug-proxymakesudo make install
google-ios-webkit-debug-proxy	Usage	On Linux, you must run the usbmuxd daemon
google-ios-webkit-debug-proxy	Usage	 The above install adds a /lib/udev rule to start the daemon whenever a device is attached
google-ios-webkit-debug-proxy	Usage	 To verify that usbmuxd can list your attached device s , run idevice_id -l
google-ios-webkit-debug-proxy	Start the simulator or device	The iOS Simulator is supported, but it must be started **before*Your attached iOS devices must have ≥1 open browser tabs and the inspector enabled via:  Settings > Safari > Advanced > Web Inspector = ON
google-ios-webkit-debug-proxy	Start the proxy	ios_webkit_debug_proxy can be used with many tools such as Chrome DevTools and Safari Web Inspector.
google-ios-webkit-debug-proxy	Chrome Devtools	To use Chrome DevTools it's the recommendation to use the  RemoteDebug/remotedebug-ios-webkit-adapter  project, which has instructions on how to setup Chrome to remote debug iOS devices, much similar to Android debugging.The reason is that recent versions of Chrome and Safari there're major discrepancies between  Chrome Remote Debugging Protocol  and Apple's  Remote Web Inspector service  which means that newer versions of Chrome DevTools aren't compatible with Safari.
google-ios-webkit-debug-proxy	Safari Web Inspector	You can use Safari Web Inspector extracted from Webkit sources, e.g
google-ios-webkit-debug-proxy	Safari Web Inspector	 artygus/webkit-webinspector 
google-ios-webkit-debug-proxy	Firefox DevTools via Valence	Another option is  mozilla/valence  which enables Firefox DevTools to be used with iOS.
google-ios-webkit-debug-proxy	View and inspect debuggable tabs	Navigate to  localhost:9221  You'll see a listing of all connected devices.Click through to view tabs available on each, and click through again to open the DevTools for a tab.
google-ios-webkit-debug-proxy	Setting the DevTools UI URL	 Chrome DevTools UI  used as a default frontend: Chromium checkout  or another URL:Just the same, you can apply the appropriate port  9222  and page  2  values below.The -f value must end in ".html"
google-ios-webkit-debug-proxy	Setting the DevTools UI URL	Due to security reasons, https URLs will not work; use http or force-allow with the URL bar's shield icon
google-ios-webkit-debug-proxy	Setting the DevTools UI URL	As of Chrome 45, the primary URL  changed  from devtools.html to inspector.html.To disable the frontend proxy, use the --no-frontend argument.
google-ios-webkit-debug-proxy	Port assigment	The default configuration works well for most developers
google-ios-webkit-debug-proxy	Port assigment	The device_id-to-port assignment defaults to:If a port is in use then the next available port will be used, up to the range limit.The port assignment is first-come-first-serve but is preserved if a device is detached and reattached, assuming that the proxy is not restarted, e.g.:  the device list gets :9221  attach A gets :9222  attach B gets :9223  detach A, doesn't affect B's port  attach C gets :9224  not :9222   reattach A gets :9222 again  not :9225 The port assignment rules can be set via the command line with -c
google-ios-webkit-debug-proxy	Port assigment	 The default is equivalent to:where "null" represents the device list
google-ios-webkit-debug-proxy	Port assigment	 The following example restricts the proxy to a single device and port:
google-ios-webkit-debug-proxy	undefined reference to symbol 'log10@@GLIBC_2.2.5'	Run this before make: ./configure LIBS="-lm"
google-ios-webkit-debug-proxy	error while loading shared libraries: libimobiledevice.so.6	Run sudo ldconfig
google-ios-webkit-debug-proxy	idevice_id not found	The idevice_id executable may be found as part of the libimobiledevice-utils package.
google-ios-webkit-debug-proxy	could not start com.apple.webinspector! success	 Remove and rebuild libimobiledevice 
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	> Could not connect to lockdownd
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	Exiting.: No such file or directory
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	Unable to attach  inspector ios_webkit_debug_proxyCheck the device for  a prompt to trust the connected computer  Choose "Trust" and try again.> Could not connect to lockdownd
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	Exiting.: Broken pipe
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	Unable to attach  inspectorPlease upgrade libimobiledevice to version from master and rebuild ios-webkit-debug-proxy
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	Upcoming 1.2.1 has many fixes but not marked for release just yet
google-ios-webkit-debug-proxy	Could not connect to lockdownd  or doesn't work with iOS10+ 	If you're on OS X:
google-ios-webkit-debug-proxy	iOS 11	> Could not connect to lockdown
google-ios-webkit-debug-proxy	iOS 11	Exiting.: Resource temporarily unavailable> Unable to connect to XXX  > Please verify that Settings > Safari > Advanced > Web Inspector = ONBuild from master brew reinstall --HEAD ios-webkit-debug-proxy
google-ios-webkit-debug-proxy	Can not see Simulator	Lastly, always try replugging in the USB cable.
google-ios-webkit-debug-proxy	IWDP Clients	JSON-formatted APIs are provided for programmatic clients.
google-ios-webkit-debug-proxy	Design	! Alt overview  overview.png "Overview" View the  design document  design.md  for an overview of the source layout and architecture.
google-ios-webkit-debug-proxy	License and Copyright	Google BSD license <>Copyright 2012 Google Inc
google-ios-webkit-debug-proxy	License and Copyright	 The proxy uses the following open-source packages:
google-iosched-ios	Google I/O iOS App	Google I/O is a developer conference held each year with two days of deeptechnical content featuring technical sessions and hundreds of demonstrationsfrom developers showcasing their technologies.This project is the iOS app for the conference.
google-iosched-ios	Building	You'll need a Firebase project to run IOsched
google-iosched-ios	Building	Copy your project'sGoogleService-Info.plist file into the Source/IOsched/Configurationdirectory
google-iosched-ios	Building	For instructions on how to create an iOS app in your Firebaseproject, see the "Add Firebase to your app" section of this document CocoaPods 1.4.0 and Xcode 9.2 or higher are required.Run pod install in the Source directory, open IOsched.xcworkspace, andbuild and run the IOsched target.Note that the backend is dependent on Cloud Functions and Firestore, sowhen running the app you may not see any data if your project's Firestoredata store is empty
google-iosched-ios	Building	Similarly, backend functions like reservationsand stars won't function.
google-iosched	Features	The app displays a list of conference events reviews, codelabs, etc
google-iosched	Features	types and by topics  Android, Firebase, etc
google-iosched	Features	Users can see details aboutevents, and they can star events that interest them
google-iosched	Features	Conference attendees canreserve events to guarantee a seat.The app also displays a map of the venue and shows informational pages to guideattendees during the conference
google-iosched	Features	 
google-iosched	Development Environment	The app is written entirely in Kotlin and uses the Gradle build system.To build the app, use the gradlew build command or use "Import Project" inAndroid Studio
google-iosched	Development Environment	A canary or stable version >= 3.2 of Android Studio isrequired and may be downloaded here 
google-iosched	Architecture	The 2018 version of the app constitutes a comprehensive rewrite
google-iosched	Architecture	Thearchitecture is built around Android Architecture Components We followed the recommendations laid out in the Guide to App Architecture when deciding on the architecture for the app
google-iosched	Architecture	We kept logic away fromActivities and Fragments and moved it to ViewModel We observed data using LiveData and used the  Data Binding Library to bind UI components in layouts to the app's data sources.We used a Repository layer for handling data operations
google-iosched	Architecture	IOSched's data comesfrom a few different sources  Cloud Firestore  either remotely or ina local cache for offline use , user preferences and settings are stored inSharedPreferences, conference data is stored remotely and is fetched and storedin memory for the app to use, etc
google-iosched	Architecture	are responsible for handling all data operations and abstracting the data sourcesfrom the rest of the app  we liked using Firestore, but if we wanted to swap itout for a different data source in the future, our architecture allows us to doso in a clean way .We implemented a lightweight domain layer, which sits between the data layerand the presentation layer, and handles discrete pieces of business logic offthe UI thread
google-iosched	Architecture	See the .\*UseCase.kt files under shared/domain for examples We used  Dagger2  for dependency injectionand we heavily relied on dagger-android  to abstract awayboiler-plate code.We used  Espresso for basic instrumentation tests and JUnit and Mockito  for unit testing.
google-iosched	Firebase	The app makes considerable use of the following Firebase components:for all user data  events starred or reserved by a user 
google-iosched	Firebase	Firestore gave usautomatic sync  and also seamlessly managed offline functionalityfor us.allowed us to run backend code
google-iosched	Firebase	The reservations feature heavily depended on CloudFunctions working in conjuction with Firestore.let us inform the app about changes to conference data on our server.manage in-app constants.
google-iosched	Kotlin	We made an early decision to rewrite the app from scratch to bring it in linewith our thinking about modern Android architecture
google-iosched	Kotlin	Using Kotlin for therewrite was an easy choice: we liked Kotlin's expressive, concise, andpowerful syntax; we found that Kotlin's support for safety features fornullability and immutability made our code more resilient; and we leveraged theenhanced functionality provided by Android Ktx extensions 
google-ioweb2015	Setup	  to run and deploy GAE-based backend  hint: gcloud components update app 
google-ioweb2015	Setup	 configuration by executing the following command: gcloud config set project 
google-ioweb2015	Setup	 Project ID can be any non-empty string if you just want to run the app locally.gulp setupIf you plan on modifying source code, be a good citizen and:Install  EditorConfig plugin  for your favourite browser.Obey the pre-commit hook that's installed as part of gulp setup.
google-ioweb2015	Running	Run gulp serve to start a standalone backend, while still enjoying live-reload.You'll need Go for that.Normally the app is running in "dev" environment but you can change thatby providing --env argument to the gulp task:  # run in dev mode, default:  gulp serve  # set app environment to production:  gulp serve --env prod  # or run as if we were in staging:  gulp serve --env stage  Not that this does not change the way the backend code is compiledor the front-end is built
google-ioweb2015	Running	It merely changes a variable values,which the app takes into account when rendering a page or responding to a request.Running in stage or prod requires real credentials when accessing external services.You'll need to run a one-off gulp decrypt which will decrypt a service account private key.You can also use GAE dev appserver by running gulp serve:gae
google-ioweb2015	Running	This is closer to whatwe're using in our webapp environment but a bit slower on startup.You'll need gcloud tool and app component to do this.To change the app environment when using GAE SDK, provide --env argument:  # run in dev mode, default:  gulp serve:gae  # set app environment to production:  gulp serve:gae --env prod  # or run as if we were in staging:  gulp serve:gae --env stage  Other arguments are:Run gulp
google-ioweb2015	Running	This will create dist directory with both front-end and backend parts, ready for deploy.**Note**: Build won't succeed if either gulp jshint or gulp jscs reports errors.You can also serve the build from dist by running gulp serve:dist,and navigating to serve:dist runs the app in prod mode by default
google-ioweb2015	Running	You can change thatby providing the --env argument as with other serve tasks
google-ioweb2015	Running	For instance:  # run in stage instead of prod  gulp serve:dist --env stage  
google-ioweb2015	Deploying	To deploy complete application on App Engine:Run gulp which will build both frontend and backend in dist directory.Run gcloud preview app deploy dist/backend --version .The app will be deployed to the project configured in gcloud tool.To check which project you're deploying to, run gcloud config listand look for project = ..
google-ioweb2015	Deploying	line.
google-ioweb2015	Backend	Backend is written in Go
google-ioweb2015	Backend	It can run on either Google App Engine or any other platform as a standalonebinary program.gulp backend will build a self-sufficient backend server and place the binary in backend/bin/server.gulp backend:test will run backend server tests
google-ioweb2015	Backend	If, while working on the backend, you feel tiredof running the command again and again, use gulp backend:test --watch to watch for file changesand re-run tests automatically.Add --gae cmd line argument to the test task to run GAE-based tests.
google-ioweb2015	Debugging	A list of tools to help in a debugging process.**NOT available in prod**
google-ioweb2015	Proxy with the service account credentials	status code, content-type header and the content.Useful for browsing original CMS data on staging GCS bucket: go/iowastaging/debug/srvget?url= 
google-ioweb2015	Send GCM push notifications	Follow instructions on that page.On staging server this is  go/iowastaging/debug/push 
google-ioweb2015	Re-sync local datastore with remote	Frontend tests are run via Configuration is in wct.conf.js.To run tests, install wct globally:and run:
google-ioweb2016	Setup	  correctly by running goapp version, which should output something like  go version go1.6  appengine-1.9.35 .npm installIf you plan on modifying source code, be a good citizen and:Install  EditorConfig plugin  for your favourite editor.Obey the pre-commit hook that's installed as part of gulp setup.
google-ioweb2016	Running	Run gulp serve to start the app.Normally the app is running in "dev" environment but you can change thatby providing --env argument to the gulp task:  # run in dev mode, default:  gulp serve  # set app environment to production:  gulp serve --env prod  # or run as if we were in staging:  gulp serve --env stage  Not that this does not change the way the backend code is compiledor the front-end is built
google-ioweb2016	Running	It merely changes a "environment" variable value,which the app takes into account when rendering a page or responding to a request.Running in stage or prod requires real credentials when accessing external services.You'll need to run a one-off gulp decrypt which will decrypt a service account private key.Other arguments are:Run gulp
google-ioweb2016	Running	This will create dist directory with both front-end and backend parts, ready for deploy.**Note**: Build won't succeed if either gulp jshint or gulp jscs reports errors.You can also serve the build from dist by running gulp serve:dist,and navigating to serve:dist runs the app in prod mode by default
google-ioweb2016	Running	You can change thatby providing the --env argument as with other serve tasks
google-ioweb2016	Running	For instance:
google-ioweb2016	Deploying	To deploy complete application on App Engine:Run gulp serve:dist which will build the app in dist directoryPerform any necessary manual checks.Run GAE_SDK/goapp deploy -application io-webapp-2016 -version  dist/backend/.
google-ioweb2016	Backend	Backend is written in Go, hosted on Google App Engine.cd backend && goapp test will run backend server tests
google-ioweb2016	Backend	You'll need to make surethere's a server.config file in the backend dir.
google-ioweb2016	Debugging	A list of tools to help in a debugging process.**NOT available in prod**
google-ioweb2016	Proxy with the service account credentials	status code, content-type header and the content.Useful for browsing original CMS data on staging GCS bucket: go/iowastaging/debug/srvget?url= 
google-ioweb2016	Creating Databases/Shards and setting them up	When setting up your own version of the Google IO Web app you need to create new Firebase databases,set them up and configure the app to use them.First, create one or more  depending on how many shards you need  Firebase databases from and note their Databases URLs.In the backend/server.config file list the Firebase Databases URLs in the firebase.shards attribute.For each Firebase databases you need to configure configure Login and Auth:Run the following command to deploy the Firebase Security rules to all shards:By default the above will deploy rules to the dev Firebase shards.To deploy the rules to other environments' shards run:Follow instructions on that page.On staging server this is  go/iowastaging/debug/push 
google-ioweb2016	Re-sync local datastore with remote	Frontend tests are run via Configuration is in wct.conf.js.To run tests, install wct globally:and run:
google-ioweb2016	License	 Apache 2.0  © 2016 Google Inc.
google-j2objc	J2ObjC: Java to Objective-C Translator and Runtime #	**Project site:***J2ObjC blog:***Questions and discussion:*
google-j2objc	What J2ObjC Is ###	J2ObjC is an open-source command-line tool from Google that translatesJava source code to Objective-C for the iOS  iPhone/iPad  platform
google-j2objc	What J2ObjC Is ###	This toolenables Java source to be part of an iOS application's build, as no editingof the generated files is necessary
google-j2objc	What J2ObjC Is ###	The goal is to write an app's non-UIcode  such as application logic and data models  in Java, which is thenshared by web apps  using  GWT  Android apps,and iOS apps.J2ObjC supports most Java language and runtime features required byclient-side application developers, including exceptions, inner andanonymous classes, generic types, threads and reflection
google-j2objc	What J2ObjC Is ###	JUnit testtranslation and execution is also supported.J2ObjC is currently beta quality
google-j2objc	What J2ObjC Is ###	Several Google projects rely on it, butwhen new projects first start working with it, they usually find new bugsto be fixed
google-j2objc	What J2ObjC Is ###	If you run into issues with your project, please report them!
google-j2objc	What J2ObjC isn't ###	J2ObjC does not provide any sort of platform-independent UI toolkit, nor arethere any plans to do so in the future
google-j2objc	What J2ObjC isn't ###	We believe that iOS UI code needs tobe written in Objective-C, Objective-C++ or Swift using Apple's iOS SDK  AndroidUIs using Android's API, web app UIs using GWT, etc
google-j2objc	What J2ObjC isn't ###	.J2ObjC cannot convert Android binary applications
google-j2objc	What J2ObjC isn't ###	Developers must have sourcecode for their Android app, which they either own or are licensed to use.
google-j2objc	Requirements ##	This library is distributed under the Apache 2.0 license found in the LICENSE  file.The protocol buffers library is distributed under the same BSD license asGoogle's protocol buffers
google-j2objc	Requirements ##	See its README  and LICENSE 
google-jacs	JACS:  Geo Json API for Cloud SQL	JACS is an App Engine application that exposes an API for accessing geospatialdata located in  Cloud SQL The API mimics the Google Maps Engine API, and provides a convenient way for your Google Maps API application to fetch data for the Data Layer, withoutneeding to maintain a SQL Database or web server.
google-jacs	Deploy	Please see the  Deployment Guide  in the JACS Wiki
google-jacs	Next Steps	You need to populate you Cloud SQL database with geospatial data, and create afront-end application to display your map data
google-jacs	Next Steps	You can host the HTML and javascript in the same App Engine instance.
google-jacs	Installing Libraries	See the  Third partylibraries page for libraries that are already included in the SDK
google-jacs	Installing Libraries	 To include SDKlibraries, add them in your app.yaml file
google-jacs	Installing Libraries	Other than libraries included inthe SDK, only pure python libraries may be added to an App Engine project.
google-jacs	Feedback	Star this repo if you found it useful
google-jacs	Feedback	Use the  github issue tracker to give feedback on JACS.
google-jacs	Contributing changes	See  CONTRIB.md  CONTRIB.md 
google-jacs	Licensing	See  LICENSE  LICENSE 
google-jacs	Not a Google product	This is not an official Google product  experimental or otherwise , it isjust code that happens to be owned by Google.
google-jarjar	How does it work?	Jar Jar Links includes an Ant task that extends the built-in jar task
google-jarjar	How does it work?	Thenormal zipfileset element is used to embed jar files
google-jarjar	How does it work?	A new rule element isadded which uses wildcards patterns to rename the embedded class files
google-jarjar	How does it work?	Bytecodetransformation  via ASM  is used to change references to the renamed classes,and special handling is provided for moving resource files and transformingstring literals.
google-java-monitoring-client-library	Monitoring Client Library for Java	 ! BuildStatus  This is not an official Google product.This library provides an API that is powerful and java idiomatic for configuringand publishing application metrics
google-java-monitoring-client-library	Monitoring Client Library for Java	A reference implementation using Stackdriver Monitoring API v3  isincluded, but other monitoring backend implementations can also be used.Most of other monitoring libraries available are low-level and are tied directlyto the backend
google-java-monitoring-client-library	Monitoring Client Library for Java	This library provides type safety, retry logic and anbackend-agnostic approach to Java metrics instrumentation.
google-java-monitoring-client-library	Importing the library	The most recent release is  v1.0.3 The Maven group ID is metrics for the main library, and stackdriver for the stackdriver backendwriter
google-java-monitoring-client-library	Importing the library	We also provide a contrib library that is useful if you want to make testassertions on certain metric types with Google's  truth To add a dependency on the metrics library using Maven:
google-joint_vae	Variational autoencoder for images and text	Vedantam, Ramakrishna, Ian Fischer, Jonathan Huang, and Kevin Murphy
google-joint_vae	Variational autoencoder for images and text	*Generative Models of Visually Grounded Imagination.
google-joint_vae	Usage:	NOTE: All scripts should be run from the root directory of the project.
google-joint_vae	Install basic dependencies.	cd to the root directory and run the following command.This sets up the python virtual environment for the project, and downloadsnecessary files for MNIST-A experiments.
google-joint_vae	Additional Data Setup	To create your own MNISTA dataset see scripts/create_affine_mnist.sh.Set appropriate paths in datasets/mnist_attributes/affine_mnist_dataset_iid.py and datasets/mnist_attributes/affine_mnist_dataset_comp.py respectively.To download and process CELEBA dataset run scripts/process_and_write_celeba.sh.And set appropriate paths in datasets/celeba/celeba_dataset.py.
google-joint_vae	Experiments	See scripts/ for example uses of different models/ experiments reported in the  1  iclr_comp_mnista_fresh.sh: Experiments on compositional split of MNISTA.	2  iclr_mnista_fresh.sh: Experiments on iid split of MNISTA.	3  celeba_training.sh: Experiments on CelebA dataset.Running above scripts uses  slurm  to run/launch jobs on clusters, so onlyrun the above if you have access to a cluster with slurm installed on it
google-joint_vae	Experiments	If you dont have access to slurm simply run the correspondingpython commands in the above scripts with the appropriate parameters.Example commands to run experiments with slurm:for running experiments  in the above scripts  and run those commands in bash.
google-joint_vae	Quantiative Results	See the ipython notebook experiments/iclr_results_aggregate.ipynb on how to viewthe imagination results after running imeval  imagination evaluation  jobs, post
google-joint_vae	Contributors	This project is not an official Google project
google-joint_vae	Contributors	It is not supported by Googleand Google specifically disclaims all warranties as to its quality,merchantability, or fitness for a particular purpose.
google-joint_vae	Contributing:	See how to  contribute  ./CONTRIBUTING.md .
google-joint_vae	License:	 Apache 2.0  ./LICENSE .
google-js-green-licenses	JavaScript package.json License Checker	 ! NPM Version  npm-image   npm-url  ! CircleCI  circle-image   circle-url   david-image   david-url   david-dev-image   david-dev-url  ! Known Vulnerabilities  snyk-image   snyk-url  ! codecov  codecov-image   codecov-url  ! Greenkeeper badge  **This is not an official Google product.**This is a tool for checking the license of JavaScript projects
google-js-green-licenses	JavaScript package.json License Checker	It scans thepackage.json file to check its license and recursively checks all of its**DISCLAIMER: This tool is NOT a replacement for legal advice or duediligence for your project's license validity
google-js-green-licenses	JavaScript package.json License Checker	We recommend you consult alawyer if you want legal advice.**
google-js-green-licenses	Installation	usage: jsgl  -h   -v   --local    --pr  License checker for npm modulesPositional arguments:  Optional arguments:  -h, --help  -v, --version  --local , -l   --pr   --dev  --verboseThis tool checks licenses for 1  an already published NPM package, 2  a localdirectory, or 3  a GitHub pull request
google-js-green-licenses	Installation	For checking an NPM package, you canjust pass the package name  optionally together with the version  as theargument
google-js-green-licenses	Installation	To check a local directory, you should pass the --localpath/to/repo argument
google-js-green-licenses	Installation	To check for a GitHub PR, you should pass the --pr//pull/ argument.If the tool finds any non-green licenses in the given package or in itsdependencies, they will be printed out together with the detailedIf you pass dependencies.jsgl also checks sub-packages for --local and --pr flags when itdetects that the repository is a monorepo
google-js-green-licenses	Installation	It assumes a certain directorystructure for detecting whether a repository is a monorepo: the top-leveldirectory should have the packages directory in it and sub-packages mustexist under that directory
google-js-green-licenses	Installation	In that case, all the package.json files arefound from sub-packages and jsgl checks all of them.For example, when a directory , jsgl checks all of foo/package.json, foo/packages/bar/package.json,and foo/packages/baz/package.json.
google-js-green-licenses	Configurations	You can customize how greenLicenses section of the configuration file
google-js-green-licenses	Configurations	In that case, jsgl willuse that custom list instead of its default list.The default green license list is:You can also whitelist some NPM packages and they will be considered "green"even when they have non-green licenses or no licenses
google-js-green-licenses	Configurations	It's useful whenpackage.json but has a separate LICENSE file, jsgl can't verify that.You can whitelist that package to make jsgl not complain about thatA typical configuration file looks like this:The packageWhitelist section is for the package whitelist.Note that comments are allowed in js-green-licenses.json.The configuration file must be located in the top-level directory of arepository for jsgl tries to locate the configuration file in the current local directoryfrom which jsgl is invoked.It is desirable that the license names in the greenLicenses section bevalid license IDs defined in  whenever possible.
google-js-green-licenses	Interface as a Library	You can also use js-green-licenses as a library as well as a command-lineutility
google-js-green-licenses	Interface as a Library	Usually the LicenseChecker class is the only one you would have to
google-js-green-licenses	Instantiation	generates more verbose output.
google-js-green-licenses	Use in Gulp	const jsgl = require 'js-green-licenses' ;gulp.task 'check_licenses', function   {  const checker = new jsgl.LicenseChecker {  } ;  checker.setDefaultHandlers  ;  return checker.checkLocalDirectory '.' ;} ;
google-js-green-licenses	Events	A LicenseChecker object emits following events during its processing
google-js-green-licenses	Events	circle-image :  circle-url :  codecov-image :  codecov-url :  david-dev-image :  david-dev-url :  david-image :  david-url :  npm-image :  npm-url :  snyk-image :  snyk-url : 
google-jsaction	JsAction	JsAction is a tiny event delegation library that allows decoupling the DOM nodeson which the action occurs from the JavaScript code that handles the action.The traditional way of adding an event handler is to obtain a reference to thenode and add the event handler to it
google-jsaction	JsAction	JsAction allows us to map between eventsand names of handlers for these events via a custom HTML attribute calledSeparately, JavaScript code registers event handlers with given names which neednot be exposed globally
google-jsaction	JsAction	When an event occurs the name of the action is mappedto the corresponding handler which is executed.Finally, JsAction uncouples event handling from actual implementations
google-jsaction	JsAction	Thus onemay late load the implementations, while the app is always able to respond touser actions marked up through JsAction
google-jsaction	JsAction	This can help in greatly reducing pageload time, in particular for server side rendered apps.
google-jsaction	Building	JsAction is built using the  ClosureCompiler  You can obtain a recentcompiler from the site.JsAction depends on the  ClosureLibrary  You can obtain a copy of thelibrary from the GitHub repository.The compiler is able to handle dependency ordering automatically with the--only_closure_dependencies flag
google-jsaction	Building	It needs to be provided with the sources andany entry points.See the files dispatch_auto.js, eventcontract_auto.js, andeventcontract_example.js for typical entry points.Here is a typical command line for building JsAction's dispatch_auto.js:find path/to/closure-library path/to/jsaction -name "*.js" |
google-jsaction	Using drop-in scripts	If you would like to test out JsAction, you can link precompiled scripts intoyour page.
google-jsaction	Usage	You can play around with JsAction already set up with the following directionsat 
google-jsaction	In the DOM	Actions are indicated with the jsaction attribute
google-jsaction	In the DOM	They are separated by ;,where each one takes the form:
google-jsaction	Set up	const eventContract = new jsaction.EventContract  ;// Events will be handled for all elements under this container.eventContract.addContainer document.getElementById 'container'  ;// Register the event types we care about.eventContract.addEvent 'click' ;eventContract.addEvent 'dblclick' ;const dispatcher = new jsaction.Dispatcher  ;eventContract.dispatchTo dispatcher.dispatch.bind dispatcher  ;
google-jsaction	Register individual handlers	/*const doStuff = function flow  {  // do stuff  alert 'doStuff called!' ;dispatcher.registerHandlers 
google-jsaction	Late loading the JsAction dispatcher and event handlers	JsAction splits the event contract and dispatcher into two separably loadablebinaries
google-jsaction	Late loading the JsAction dispatcher and event handlers	This allows applications to load the small event contract early on thepage to capture events, and load the dispatcher and event handlers at a latertime
google-jsaction	Late loading the JsAction dispatcher and event handlers	Since captured events are queued until the dispatcher loads, this patterncan ensure that user events are not lost even if they happen before the primaryevent handlers load.Visit  to try out a working example.
google-jsaction	Load the contract early in the page	Just like in the regular example, in this example the event contract is loadedvery early on the page, ideally in the head of the page
google-jsaction	Load the contract early in the page	 const eventContract = new jsaction.EventContract  ;  eventContract.addContainer window.document.documentElement ;  eventContract.addEvent 'click' ;  click here to capture eventsThe event contract is configured to capture events for the entire page
google-jsaction	Load the contract early in the page	Sincethe dispatcher and event handlers are not loaded yet, the event contract willjust queue the events if the user tries to interact with the page
google-jsaction	Load the contract early in the page	These eventscan then be replayed after the dispatcher and event handlers are loaded, whichwill be shown in this example next
google-jsaction	Load the contract early in the page	This will ensure that no user interaction islost, even if it happens before the code is loaded.
google-jsaction	Loading the dispatcher and replaying events	At any point later in the page, the dispatcher and event handlers can be loadedand any queued events can be replayed.After the dispatcher and event handler code loads, you will configure thedispatcher just like in the regular example:// This is the actual event handler code.function handleEvent   {  alert 'event handled!' ;// Initialize the dispatcher, register the handlers, and then replay the queued events.const dispatcher = new jsaction.Dispatcher  ;eventContract.dispatchTo dispatcher.dispatch.bind dispatcher  ;dispatcher.registerHandlers There is some new code to replay the queued events:// This code replays the queued events
google-jsaction	Loading the dispatcher and replaying events	Applications can define custom replay// strategies.function replayEvents events, jsActionDispatcher  {  while  events.length  {  }// This will automatically trigger the event replayer to run if there are// queued events.dispatcher.setEventReplayer replayEvents ;Now any events that happen during page load before the JS has loaded will bereplayed when the primary JS does load, ensuring that user interactions are not
google-jsinterop-generator	Build the generator from source	TODO dramaix : provides link to download the generator.
google-jsinterop-generator	Run the generator	Now you have the jar file, just invokeList of required options :Option | Meaning--output _file_ | Path to the jar file that will contain the generated java classes--output_dependency_file _file_ | Path to the dependency file generated by the generator.--package_prefix _string_ | Prefix used when we build the java package--extension_type_prefix _string_ | Value used for prefixing extension types
google-jsinterop-generator	Run the generator	It's a good practice to pass the name of the library in upper camel case.----------------------------
google-jsonapi	jsonapi	   ! Go Report Card   ! GoDoc  A serializer/deserializer for JSON payloads that comply to the JSON API 
google-jsonapi	Background	You are working in your Go web application and you have a struct that isorganized similarly to your database schema
google-jsonapi	Background	 You need to send andreceive json payloads that adhere to the JSON API spec
google-jsonapi	Background	 Once you realize thatyour json needed to take on this special form, you go down the path ofcreating more structs to be able to serialize and deserialize JSON APIpayloads
google-jsonapi	Background	 Then there are more models required with this additionalstructure
google-jsonapi	Background	 Ugh! With JSON API, you can keep your model structs as is anduse  StructTags  to indicateto JSON API how you want your response built or your requestdeserialized
google-jsonapi	Background	 What about your relationships?  JSON API supportsrelationships out of the box and will even put them in your responseinto an included side-loaded slice--that contains associated records.
google-jsonapi	Introduction	JSON API uses  StructField tags to annotate the structs fields that you already have and use inyour app and then reads and writes  JSON API output based on the instructions you give the library in your JSON APItags
google-jsonapi	Introduction	 Let's take an example
google-jsonapi	Introduction	 In your app, you most likely have structsthat look similar to these:type Blog struct {	ID	Title	Posts	CurrentPost   *Post	CurrentPostId int	CreatedAt	ViewCounttype Post struct {	ID	BlogID   int	Title	Body	Comments   *Comment json:"comments"type Comment struct {	IdThese structs may or may not resemble the layout of your database
google-jsonapi	Introduction	 Butthese are the ones that you want to use right?  You wouldn't want to usestructs like those that JSON API sends because it is difficult to get atall of your data easily.
google-jsonapi	Example App	 examples/app.go This program demonstrates the implementation of a create, a show,and a list  http.Handler   Itoutputs some example requests and responses as well as serializedexamples of the source/target structs to json
google-jsonapi	Example App	 That is to say, I showyou that the library has successfully taken your JSON API request andturned it into your struct types.To run,
google-jsonapi	Example	out := bytes.NewBuffer nil // testModel returns a pointer to a Blogjsonapi.MarshalOnePayloadEmbedded out, testModel   h := new BlogsHandler w := httptest.NewRecorder  r, _ := http.NewRequest http.MethodPost, "/blogs", out h.CreateBlog w, r blog := new Blog jsonapi.UnmarshalPayload w.Body, blog // ..
google-jsonapi	Example	assert stuff about blog here ...
google-jsonapi	primary	Tag value arguments are comma separated
google-jsonapi	primary	 The first argument must be,types are shown in the examples, but not required.
google-jsonapi	relation	relationship with other structs
google-jsonapi	relation	JSON API will traverse the graph ofrelationships and marshal or unmarshal records
google-jsonapi	relation	 The first argument mustbe, relation, and the second should be the name of the relationship,used as the key in the relationships hash for the record
google-jsonapi	relation	The optionalthird argument is omitempty to-many from being serialized.
google-jsonapi	Methods Reference	**All Marshal and Unmarshal methods expect pointers to structinstance or slices of the same contained with the interface{}s**Now you have your structs prepared to be seralized or materialized, Whatabout the rest?
google-jsonapi	Create Record Example	You can Unmarshal a JSON API payload using jsonapi.UnmarshalPayload It reads from an  io.Reader containing a JSON API payload for one record  but can have relatedrecords 
google-jsonapi	Create Record Example	 Then, it materializes a struct that you created and passed in using new or & 
google-jsonapi	Create Record Example	 Again, the method supports single records only, atthe top level, in request payloads at the moment
google-jsonapi	Create Record Example	Bulk creates andupdates are not supported yet.After saving your record, you can use, MarshalOnePayload to write the JSON API response to an io.Writer 
google-jsonapi	MarshalPayload	Writes a JSON API response, with related records sideloaded, into anincluded array
google-jsonapi	MarshalPayload	 This method encodes a response for either a single record ormany records.
google-jsonapi	Handler Example Code	func CreateBlogs w http.ResponseWriter, r *http.Request  {	// ...create many blogs at once	blogs, err := UnmarshalManyPayload r.Body, reflect.TypeOf new Blog   	if err != nil {		t.Fatal err 	}	for _, blog := range blogs {		b, ok := blog
google-jsonapi	Handler Example Code	*Blog 		// ...save each of your blogs	}	w.Header  .Set "Content-Type", jsonapi.MediaType 	w.WriteHeader http.StatusCreated 	if err := jsonapi.MarshalPayload w, blogs ; err != nil {		http.Error w, err.Error  , http.StatusInternalServerError 	}
google-jsonapi	UnmarshalManyPayload	Takes an io.Reader and a reflect.Type representing the uniform typecontained within the "data" JSON API member.
google-jsonapi	Links	If you need to include  link objects  along with response data, implement the Linkable interface for document-links, and RelationshipLinkable for relationship links:func  post Post  JSONAPILinks   *Links {	return &Links{		"self": "href": fmt.Sprintf "", post.ID ,		"comments": Link{		},	}// Invoked for each relationship defined on the Post struct when marshaledfunc  post Post  JSONAPIRelationshipLinks relation string  *Links {	if relation == "comments" {		return &Links{		}	}	return nil
google-jsonapi	Meta	 If you need to include  meta objects  along with response data, implement the Metable interface for document-meta, and RelationshipMetable for relationship meta: gofunc  post Post  JSONAPIMeta   *Meta {	return &Meta{		"details": "sample details here",	}// Invoked for each relationship defined on the Post struct when marshaledfunc  post Post  JSONAPIRelationshipMeta relation string  *Meta {	if relation == "comments" {		return &Meta{		}	}	return nil
google-jsonapi	Custom types	If you need to support custom types  e.g
google-jsonapi	Custom types	for custom time formats , you'll need to implement the json.Marshaler and json.Unmarshaler interfaces on the type.// MyTimeFormat is a custom format I invented for funconst MyTimeFormat = "The time is 15:04:The year is 2006, and it is day 2 of January."// MyTime is a custom type used to handle the custom time formattype MyTime struct {	time.Time// UnmarshalJSON to implement the json.Unmarshaler interfacefunc  m *MyTime  UnmarshalJSON b   byte  error {	t, err := time.Parse MyTimeFormat, string b  	if err != nil {		return err	}	m.Time = t	return nil// MarshalJSON to implement the json.Marshaler interfacefunc  m *MyTime  MarshalJSON      byte, error  {	return json.Marshal m.Time.Format MyTimeFormat  
google-jsonapi	Errors	This package also implements support for JSON API compatible errors payloads using the following types.
google-jsonapi	go	type ErrorObject struct { ..
google-jsonapi	go	}// Error implements the ErrorObject is an Error implementation as well as an implementation of the JSON API error object.The main idea behind this struct is that you can use it directly in your code as an error type and pass it directly to MarshalErrors to get a valid JSON API errors payload.
google-jsonapi	MarshalOnePayloadEmbedded	This method is not strictly meant to for use in implementation code,although feel free
google-jsonapi	MarshalOnePayloadEmbedded	 It was mainly created for use in tests; in most cases,your request payloads for create will be embedded rather than sideloadedfor related records
google-jsonapi	MarshalOnePayloadEmbedded	 This method will serialize a single struct pointerinto an embedded json response
google-jsonapi	MarshalOnePayloadEmbedded	 In other words, there will be no,included, array in the json; all relationships will be serializedinline with the data.However, in tests, you may want to construct payloads to post to createmethods that are embedded to most closely model the payloads that willbe produced by the client
google-jsonapi	MarshalOnePayloadEmbedded	 This method aims to enable that.
google-jsonapi	Alternative Installation	I use git subtrees to manage dependencies rather than go get so thatthe src is committed to my repo.a collection of packages and GOPATH is set to the rootfolder--containing src.
google-jsonapi	Contributing	Fork, Change, Pull Request *with tests*.
google-jsonnet	Jsonnet 	  For an introduction to Jsonnet and documentation, visit our website Visit our  discussion forum 
google-jsonnet	Building Jsonnet	You can use either GCC or Clang to build Jsonnet
google-jsonnet	Building Jsonnet	Note that on recent versionsof macOS, /usr/bin/gcc and /usr/bin/g++ are actually Clang, so there is no
google-jsonnet	Makefile	To build Jsonnet with GCC, run:Bazel builds are also supported.Install  Bazel  if it isnot installed already
google-jsonnet	Makefile	Then, run the following command to build with GCC:env CC=clang CXX=clang++ bazel build -c opt //cmd:jsonnet
google-jsonnet	OR	bazel build -c opt --action_env=CC=clang --action_env=CXX=clang++ //cmd:jsonnetThis builds the jsonnet target defined in  cmd/BUILD  ./cmd/BUILD 
google-jsonnet	OR	Tolaunch the output binary, run:TODO: info about cmake
google-jsonnet	Contributing	See the  contributing page  on our website.
google-jws	Introduction	JWT  rfc7519  is widely used
google-jws	Introduction	However, the RFC standards JSON Web Encryption JWE   rfc7516 , JSON Web Signature  JWS   rfc7515 , JSON Web Token  JWT  rfc7519  contain several design mistakes which make both implementations anduse of JWT dangerous
google-jws	Introduction	For instance, existing research such as Critical vulnerabilities in JSON Web Token libraries  Practical Cryptanalysis of Json Web Token  High risk vulnerability in RFC 7515 showed several vulnerabilities at design and implementation level
google-jws	Introduction	Therefore, wewill only implement a safe subset of it
google-jws	Introduction	JWS Compact Serialization while not ideal, is the safest option and covers the majority of use cases.We'll harden the API to make it difficult to misuse.
google-jws	Using cryptography.io	PyCrypto has a lot of vulnerabilities
google-jws	Using cryptography.io	We’ll use cryptography.io that is builton top of OpenSSL.
google-jws	Do not support “none” option	This option is obviously broken at several layers.
google-jws	Separation of key configuration from signature or MAC verification	JWT allows the signature or MAC to contain public key, certificates or urlspointing to certificates
google-jws	Separation of key configuration from signature or MAC verification	This is a design mistake because in verification,signature and MAC are under attacker control which lead to various attacks.Therefore, in our API, once the key is configured by users, it can not beaffected by attackers through signature or MAC.
google-jws	Separation of MAC and digital signature	While MAC and signature are both used to authenticate data, they’re distinctsecurity primitives
google-jws	Separation of MAC and digital signature	MAC is symmetric key crypto, while digital signature ispublic key cryptography
google-jws	Separation of MAC and digital signature	They have different security requirements and keymanagement assumptions
google-jws	Separation of MAC and digital signature	Furthermore, in key rotation, accidental change fromdigital signature to MAC or vice versa changes the security properties of thesystem and jeopardizes its security.
google-jws	Separation of public key verifier and signer	While it’s tempting to merge them together, for one key, the typical use case isone side generates the signature and the other side verifies the signature.Furthermore, the key protection mechanism of signer and verifier is different.For verifier, we only need to protect the integrity of the key while for signer,we have to protect both the integrity and confidentiality of the key.
google-jws	“kid”  Key ID : signed or unsigned?	“kid” is used as hint indicating which key should be used for verification.RFC7515 doesn’t specify whether “kid” should be signed or unsigned
google-jws	“kid”  Key ID : signed or unsigned?	Forinstance,  shows an unsigned“kid”
google-jws	“kid”  Key ID : signed or unsigned?	However, as we only support Json Compact Serialization where the headeris signed, “kid” must be signed
google-jws	“kid”  Key ID : signed or unsigned?	This is consistent with existing use cases thatwe're aware of.
google-jws	Multiple keys to support key rotation/update	For JwsPublicKeyVerify, JwsMacVerify, we support key configuration that acceptsmultiple keys and “kid”
google-jws	Multiple keys to support key rotation/update	This feature is helpful in key rotation/update when thereceiver doesn’t know in advance which key should be used for verification
google-jws	Multiple keys to support key rotation/update	Themain difficulty in JWT is that at the time of parsing JWK, key type or kid don’tfully specify what algorithm will be used during sign/verify orcompute_mac/verify_mac
google-jws	Multiple keys to support key rotation/update	For instance, let’s look at the key:There is no way to tell whether the key should be used as encryption key or HMACkey
google-jws	Multiple keys to support key rotation/update	Even if we know that it’s used as HMAC key, we still don’t know what hashfunction should be used during HMAC verification
google-jws	Multiple keys to support key rotation/update	One way to mitigate this issueis to enforce the field “alg” as defined at Key without “alg” field isrejected
google-jws	Multiple keys to support key rotation/update	Note that for signer, we only support 1 key
google-jws	Multiple keys to support key rotation/update	There are 2 reasons:
google-jws	Installation	To install jws:To test jws: sudo python setup.py test
google-jws	Usage	import jwses256_ecdsa_token = 'eyJhbGciOiJFUzI1NiJ9.eyJpc3MiOiJqb2UiLA0KICJleHAiOjEzMDA4MTkzODAsDQogImh0dHA6Ly9leGFtcGxlLmNvbS9pc19yb290Ijp0cnVlfQ.DtEhU3ljbEg8L38VWAfUAqOyKAM6-Xx-F4GawxaepmXFCgfTjDxw5djxLa8ISlSApmWQxfKTUJqPP3-Kg6NU1Q'.encode 'utf-8' es256_ecdsa_pub_key = r"""
google-jws	Set up phase: parse the key and initialize the verifier.	key = jws.CleartextJwkSetReader.from_json es256_ecdsa_pub_key verifier = jws.JwtPublicKeyVerify key, 'joe', None, None, 1300819380 
google-jws	Verify phase	  verified_payload = verifier.verify es256_ecdsa_token   print verified_payload   print verified_payload 'iss'  == 'joe' and verified_payload 'exp' == 1300819380 except jws.SecurityException:  fail> This is not an official Google product.
google-kafel	WHAT IS IT?	Kafel is a language and library for specifying syscall filtering policies.The policies are compiled into BPF code that can be used with seccomp-filter.This is NOT an official Google product.
google-kafel	Policy language	A simple language is used to define policies.A policy file has 3 parts: Constant definitions  optional  Policy definitions Top level policy declaration
google-kafel	Numbers	Kafel supports following number notations:You may define numeric constants at the beging of policy file to make it moreThe defined constants can then be used anywhere where a number is expected.Policy definition is a list of action blocks and use statements separated by__samples/__ contains some example policies that demonstrate supported features.
google-kafel	Use statements	A USE someOtherPolicy behaves as if someOtherPolicy body was pasted in itsplace
google-kafel	Use statements	You may only use policies defined before the use statement.With use statements you can create meaningful groups of filtering rules that arebuilding blocks of bigger policies.
google-kafel	Action blocks	Action block consist of a target and list of syscall matching rules separatedwith commas.Target of first rule matched is the policy decision.Following table list Kafel targets and their corresponding seccomp-filterreturn values.--------------TRACE number  | SECCOMP_RET_TRACE+number
google-kafel	Syscall matching rules	A rules consist of syscall name and optional list of boolean expressions.List of boolean expressions separated by commas.A comma is semantically equivalent to || but has the lowest precedence,therefore it may be easier to read.
google-kafel	Syscall naming	Normally syscalls are specified by their names as defined in Linux kernel.However, you may also filter __custom syscalls__ that are not in the standardsyscall list.You can either define a constant and use it in place of syscall name orutilize SYSCALL keyword.
google-kafel	#define mysyscall -1	POLICY my_const {  ALLOW {  }POLICY my_literal {  ALLOW {  }
google-kafel	Argument filtering	Boolean expressions are used to filter syscalls based on their arguments.A expression resembles C language syntax, except that there are noarithmetic operators.their regular names as specified in Linux kernel and man pages.taken when no rule matches.
google-kafel	Example	When used with  nsjail  the following command allows to create a fairly constrained environment for your shell
google-kasane	Kasane	!    kasane   重ね    n
google-kasane	Kasane	 pile; heap; layers**This is not an official Google product**Kasane is a layering tool for kubernetes
google-kasane	Kasane	It allows you to use the officially published YAML documents and extend them further with your local configuration.Kasane can utilise Jsonnet for deep object modification and patching.
google-kasane	Installation	Kasane requires Python 3+
google-kasane	Installation	Install via pip:You can run kasane from a docker container, the official image is gcr.io/kasaneapp/kasane
google-kasane	Installation	The image is based on alpine and comes pre-packaged with bash, curl, git and kubectl in addition to kasane itself
google-kasane	Installation	The workdir is set to /app and the default command is kasane show so you can quickly examine your local Kasanefiles like this:
google-kasane	Helm	Helm is fully-featured package management solution for kubrnetes
google-kasane	Helm	Compared to it, kasane is a swiss army knife
google-kasane	Helm	It's simple, lightweight, doesn't install helper code into your production
google-kasane	Helm	Kasane allows you to use original YAML files written by application authors, modifying them to your local needs
google-kasane	Helm	If you see a kubectl apply -f http:// example you can turn it into a Kasane deployment with a single line of code and then extend it to your needs.Kasane doesn't do any templating, relying on Jsonnet for data manipulation
google-kasane	Helm	You won't ever need to count number of spaces to make sure your yaml go template is rendered correctly.
google-kasane	Ksonnet	Kasane is similar to Ksonnet but is much simpler to use
google-kasane	Ksonnet	Kasane allows to re-use original YAML files and minimizes amount of custom Jsonnet code you need to write
google-kasane	Ksonnet	Most of the time your Kasane project would consist of a Kasanefile and single yaml or jsonnet file
google-kasane	Ksonnet	Still, Kasane allows runtime flexibility with conditional layers and custom environment.
google-kasane	License	Kasane is distributed under Apache-2  license  LICENSE 
google-kasane	License	See the  contributing guidelines  CONTRIBUTING.md  on how you can contribute to the project.
google-kati	"make clean"	Note ./ninja.sh passes all parameters to ninja.
google-kati	Build a specific target	For example, the following is equivalent to "make cts":Or, if you know the path you want, you can do:
google-keyczar	Keyczar	Important note: KeyCzar has some known security issues which mayinfluence your decision to use it
google-keyczar	Keyczar	See  Known SecurityIssues  #known-security-issues .
google-keyczar	Introduction	Keyczar is an open source cryptographic toolkit designed to make iteasier and safer for developers to use cryptography in theirapplications
google-keyczar	Introduction	Keyczar supports authentication and encryption with bothsymmetric and asymmetric keys
google-keyczar	Introduction	Some features of Keyczar include:Team and is released under an Apache 2.0 license.
google-keyczar	Quick Links	Cryptography is easy to get wrong
google-keyczar	Quick Links	Developers can choose impropercipher modes, use obsolete algorithms, compose primitives in an unsafemanner, or fail to anticipate the need for key rotation
google-keyczar	Quick Links	Keyczarabstracts some of these details by choosing safe defaults,automatically tagging outputs with key version information, andproviding a simple programming interface.Keyczar is designed to be open, extensible, and cross-platformcompatible
google-keyczar	Quick Links	It is not intended to replace existing cryptographiclibraries like OpenSSL, PyCrypto, or the Java JCE, and in fact isbuilt on these libraries.
google-keyczar	An illustrative use case	Suppose an application needs to encrypt a URL parameter value with asymmetric key
google-keyczar	An illustrative use case	Normally, a developer would need to decide whichalgorithm to use, the key length to use, the mode of operation, how tohandle initialization vectors, how to rotate keys, and how to signciphertexts
google-keyczar	An illustrative use case	Keyczar simplifies these choices
google-keyczar	An illustrative use case	Using an existingkeyset, a Java developer would need to call the following:Interested in getting involved? We encourage open source developers tocontribute to the Keyczar project
google-keyczar	An illustrative use case	Please join us on the Keyczarproject and subscribe to the Keyczar discussion group.
google-keyczar	Known Security Issues	The following section lists known security issues.There are probably others that have not been identified.
google-keyczar	Use of SHA 1 and 1024 bit DSA	Keyczar uses 1024 bit DSA keys with SHABoth of these are considered weak bycurrent security standards
google-keyczar	Use of SHA 1 and 1024 bit DSA	 However, it is not trivial to upgrade without breakingbackwards compatibility.
google-keyczar	Signed Session Encryption Re-signing	Keyczar signed session encryption does not include the key ID of the signing key insidethe encrypted plaintext
google-keyczar	Signed Session Encryption Re-signing	This makes it possible for an attacker to strip the signaturefrom a message, and re-sign it using their private key, making it look like they sentthe original message.
google-keyczar	DSA Signature Malleability	DSA signatures are basically two variable length ints
google-keyczar	DSA Signature Malleability	So some DSA signatures are shorterthan others.There was a bug in KeyCzar  fixed here which essentially padded  right padding with 0  all DSA signatures to their maximum length.Some crypto libraries after finding both ints, which means that they will verify signature that have extradata
google-keyczar	DSA Signature Malleability	This is why keyczar did not discover the extra data in DSA signatures.However, this can be a problem for specific crypto applications that compute fingerprintsof data that includes a message and its signature
google-keyczar	DSA Signature Malleability	See the CVN  OpenSSL's comments and  problem  and this causes for BitCoint.Some new JCE implementations are more strict data
google-keyczar	DSA Signature Malleability	In order for older  improperly padded DSA signatures  to be acceptible even whenrunning KeyCzar on such new JCE implementations trims any extra data from the signature.Note that this means you should not use this implementation for such applications bitcoin As other underlying crypto libraries make this strict implementations may have this issue.
google-keystone	Keystone	Keystone is an architectural analysis toolset integrated in the Atom texteditor
google-keystone	Keystone	It allows software engineers to create models of system architectureswhich can be used to guide development decisions through analysis andsimulation
google-keystone	Keystone	The modelling and simulation capabilities are inspired by Palladio,a powerful analysis tool integrated into Eclipse, but with models represented ina plain text language
google-keystone	Keystone	This yields some compelling benefits over the binary blob+ Models can be checked into version control+ A common on-disk format enables integration with other tools, including designrules checkers+ Human-readable text can be viewed and considered without special tooling+ Support for multiple formats can be added; Keystone currently supports modelsembedded in Markdown files
google-keystone	Building	To build the project, follow these steps:Install the latest  Atom  release for your system.Clone the repository.Install the Elm toolset: npm install -g elm elm-testRun the build script: ./build.shLink Keystone to your Atom packages directory: apm link keystoneStart Atom in developer mode with atom -d or View > Developer > Open InDev ModeKeystone uses Elm, a strongly-typed functional language, for the bulk of itslogic
google-keystone	Building	You will need to recompile the project before your changes to any .elmfiles will be visible in Atom
google-keystone	Building	Generally, the edit flow goes something likeMake a change to an Elm file.Run ./build.sh, and fix any compile or test failures.Reload Atom  Alt+Ctrl+R on Linux, Cmd+Option+Ctrl+L on OSX, or View >Developer > Reload Window anywhere .Test the change in Atom.
google-keystone	Contributing	We'd love to accept your patches and contributions to this project
google-keystone	Contributing	Here are afew small guidelines you need to follow.
google-keystone	Contributor License Agreement	Contributions to any Google project must be accompanied by a Contributor LicenseAgreement
google-keystone	Contributor License Agreement	This is necessary because you own the copyright to your changes, evenafter your contribution becomes part of this project, so this agreement simplygives us permission to use and redistribute your contributions as part of theproject
google-keystone	Contributor License Agreement	Head over to <> to see your currentagreements on file or to sign a new one.You generally only need to submit a CLA once, so if you've already submitted one even if it was for a different project , you probably don't need to do it
google-keystone	Code reviews	All submissions, including submissions by project members, require review
google-keystone	Code reviews	Weuse GitHub pull requests for this purpose
google-keystone	Code reviews	Consult  GitHub Help  for moreinformation on using pull requests
google-keystone	Code reviews	GitHub Help : 
google-keystone	Disclaimer	Please note that while Keystone is an open-source project started by Googleengineers, it is *not
google-keytransparency-java	keytransparency-java	The Java Client for Key Transparency.
google-keytransparency	Key Transparency	 ! GoDoc     ! Go Report Card   ! codecov  ! Key Transparency Logo  docs/images/logo.png Key Transparency provides a lookup service for generic records and a public,tamper-proof audit log of all record changes
google-keytransparency	Key Transparency	While being publicly auditable,individual records are only revealed in response to queries for specific IDs.Key Transparency can be used as a public key discovery service to authenticateusers and provides a mechanism to keep the service accountable
google-keytransparency	Key Transparency	 It can be usedby account owners to  reliably see  docs/verification.md  what keys have beenassociated with their account, and it can be used by senders to see how long anaccount has been active and stable before trusting it.and  Certificate Transparency It is a work-in-progress with the  followingmilestones  under
google-keytransparency	Setup	Install  Go 1.10 go get -u github.com/google/keytransparency/cmd/keytransparency-client 
google-keytransparency	Generate a private key	  keytransparency-client authorized-keys create-keyset -p password  keytransparency-client authorized-keys list-keyset -p password  
google-keytransparency	Publish the public key	Get an  OAuth client ID  and download the generated JSON file to client_secret.json
google-keytransparency	Publish the public key	 keytransparency-client post user@domain.com app1 --client-secret=client_secret.json --insecure -d 'dGVzdA==' #Base64  
google-keytransparency	Get and verify a public key	  keytransparency-client get   --insecure --verbose  ✓ Commitment verified
google-keytransparency	Get and verify a public key	 ✓ VRF verified
google-keytransparency	Get and verify a public key	 ✓ Sparse tree proof verified
google-keytransparency	Get and verify a public key	 ✓ Signed Map Head signature verified
google-keytransparency	Get and verify a public key	 CT ✓ STH signature verified
google-keytransparency	Get and verify a public key	 CT ✓ Consistency proof verified
google-keytransparency	Get and verify a public key	 CT   New trusted STH: 2016-09-12 15:31:19.547 -0700 PDT  CT ✓ SCT signature verified
google-keytransparency	Get and verify a public key	Saving SCT for future inclusion proof verification
google-keytransparency	Get and verify a public key	 ✓ Signed Map Head CT inclusion proof verified
google-keytransparency	Get and verify a public key	 keys:  
google-keytransparency	Verify key history	    keytransparency-client history  --insecure  Epoch |Timestamp  4  
google-keytransparency	Install	 OpenSSL  Docker 
google-keytransparency	Run	Run Key TransparencyCreating keytransparency_db_1 ...Creating keytransparency_map_server_1 ..
google-keytransparency	Run	doneCreating keytransparency_log_server_1 ..
google-keytransparency	Run	doneCreating keytransparency_log_server_1 ..
google-keytransparency	Run	doneCreating keytransparency_server_1 ...Creating keytransparency_sequencer_1 ..
google-keytransparency	Run	 doneCreating keytransparency_monitor_1 ...Creating keytransparency_init_1 ...Creating keytransparency_prometheus_1 ..
google-keytransparency	Run	doneCreating keytransparency_monitor_1 ..
google-keytransparency	Run	 Watch it RunKey Transparency and its  Trillian  backenduse a  MySQL database which must be setup in order for the Key Transparency tests to work.
google-keytransparency	Directory structure	The directory structure of Key Transparency is as follows:
google-kir-holiday-lights	KIR Holiday Light Show	***This is not an official Google product.*** Light-O-Rama  sequence files and custom macros used in the KIR Holiday Light Show
google-kiwi-solver	Kiwi-Solver	Kiwi is a minimalist and extendable Constraint Programming  CP  solver specifically designed for education
google-kiwi-solver	Kiwi-Solver	The particularities of Kiwi stand in its generic trailing state restoration mechanism, its propagator-based propagation algorithm, and its modulable use of variables and heuristics
google-kiwi-solver	Kiwi-Solver	By developing Kiwi, the author does not aim to create an alternative to full-featured constraint solvers but rather to provide readers with a basic architecture that will  hopefully  help them to understand the core mechanisms hidden under the hood of constraint solvers, to develop their own extended constraint solver, or to test innovative ideas.
google-kiwi-solver	Disclaimer	This repository contains a Java version of Kiwi — the  first version of Kiwi  was implemented in Scala by rhartert during his PhD
google-kiwi-solver	Disclaimer	The original source code of Kiwi was the result of rethinking and simplifying the architecture of the open-source  OscaR  solver to achieve what the author believes to be a good trade-off between performance, clarity, and conciseness.
google-kmsan	KMSAN  KernelMemorySanitizer 	KMSAN is a detector of uninitialized memory use for the Linux kernel
google-kmsan	KMSAN  KernelMemorySanitizer 	It iscurrently in development.Contact: ramosian-glider@
google-kmsan	How to build	In order to build a kernel with KMSAN you'll need a custom Clang built from a patched tree on LLVM r
google-kmsan	Run the kernel	You can refer to  for the instructionson running the freshly built kernel in a QEMU VM.Also consider running a KMSAN-instrumented kernel under  syzkaller 
google-kmsan	Trophies	See  for the list of trophies.
google-knusperli	Knusperli	The goal of Knusperli is to reduce blocking artifacts in decoded JPEG images, byinterpreting quantized DCT coefficients in the image data as an interval, ratherthan a fixed value, and choosing the value from that interval that minimizesdiscontinuities at block boundaries.Left: a traditional JPEG decoder  Imagemagick 6.9.7-4 
google-knusperli	Knusperli	Right: Knusperli.! Lena JPEG, zoomed  lena-jpeg-crop  ! Lena Knusperli, zoomed  lena-knus-crop ! Lena JPEG  lena-jpeg  ! Lena Knusperli  lena-knus 
google-knusperli	Building	Knusperli builds with  Bazel  bazel :
google-knusperli	Details	A JPEG encoder quantizes DCT coefficients by rounding coefficients to thenearest multiple of the elements of the quantization matrix
google-knusperli	Details	For everycoefficient, there is an interval of values that would round to the samemultiple
google-knusperli	Details	A traditional decoder uses the center of this interval to reconstructthe image
google-knusperli	Details	Knusperli instead chooses the value in the interval that reducesdiscontinuities at block boundaries
google-knusperli	Details	The coefficients that Knusperli uses, wouldhave rounded to the same values that are stored in the JPEG image.
google-knusperli	Disclaimer	This is not an officially supported Google product
google-knusperli	Disclaimer	bazel :  lena-jpeg-crop : doc/img/lena.q50.jpeg.crop.png lena-knus-crop : doc/img/lena.q50.knusperli.crop.png lena-jpeg : doc/img/lena.q50.jpeg.png lena-knus : doc/img/lena.q50.knusperli.png
google-kratu	Installation	Simply  download Kratu  and extract, or check out the repository:*Note: If you're running Kratu locally, you might have to start your browser with a flag to allow local file loading.
google-kratu	Quick start	If you want to see more of what Kratu can do, have a look at the  examples included Otherwise, here's a quick look at how to render a simple report// Instantiate a new Kratu objectvar kratu = new Kratu  ;// Set the data we'd like to renderkratu.setEntities data ;// Tell Kratu where to render our reportkratu.setRenderElement  document.getElementById 'kratuReport'   ;// And render it!kratu.renderReport  ;
google-kratu	In-depth tutorial	To get a better understanding of what Kratu has to offer, go through  this in-depth tutorial  where we'll build a  product comparison analysis  that can help users figure out which spaceship to buy.
google-kratu	Fine print	Pull requests are very much appreciated
google-kratu	Fine print	Please sign the  Google Code contributor license agreement   There is a convenient online form  before submitting
google-kratu	Fine print	 AuthorTarjei Vassbotn  Google Inc
google-kratu	Fine print	  CopyrightCopyright © 2013 Google, Inc
google-kratu	Fine print	 LicenseApache 2.0  LimitationsOnly tested on the latest versions of browsers
google-kratu	Fine print	Expect it to fail on older versions.
google-kv-s3105c	kv-s3105c	The Panasonic KV-S3105C is an industrial bulk document scanner
google-kv-s3105c	kv-s3105c	It hasa document feed and can scan hundreds of pages at high speed withoutmanual aid
google-kv-s3105c	kv-s3105c	This userspace driver uses the newer USB interface.
google-kv-s3105c	kv-ss905c	The Panasonic KV-SS905C is an industrial bulk document scanner
google-kv-s3105c	kv-ss905c	It usesthe generic SCSI layer of the Linux kernel to work with their SCSI
google-kythe-cloud9	Kythe's Cloud9 Plugin	A Cloud9 UI and backend plugin for leveraging Kythe's   features in Cloud9 IDE
google-kythe-cloud9	Kythe's Cloud9 Plugin	These features include but not limited to:
google-language-jsonnet	Jsonnet syntax highlighting for Atom	This package adds syntax highlighting for  Jsonnet  jsonnet 
google-language-jsonnet	Jsonnet syntax highlighting for Atom	jsonnet : ! A screenshot of Jsonnet syntax highlighting 
google-language-jsonnet	Install	For more info on Jsonnet:
google-latency-benchmark	About the benchmark	The Web Latency Benchmark is a new kind of benchmark that tests your browser's responsiveness by directly measuring *latencyThe  Oculus Latency Tester  is a hardware device with a light sensor that can measure end-to-end latency from USB input to pixels changing on the screen
google-latency-benchmark	About the benchmark	This kind of hardware-based measurement accounts for all possible sources of latency
google-latency-benchmark	About the benchmark	It's the most complete and accurate measurement possible, and it's now supported by the Web Latency Benchmark
google-latency-benchmark	About the benchmark	Just plug it in and you'll see a special test page.
google-latency-benchmark	New: Automated testing	Thanks to jmaher, the benchmark now accepts command-line arguments that enable fully automated benchmark runs, with results reported in JSON format to a server of your choosing.
google-latency-benchmark	How it works	The Web Latency Benchmark works by programmatically sending input events to a browser window, and using screenshot APIs to detect when the browser has finished drawing its response.There are two main components: the latency-benchmark server  written in C/C++  and the HTML/JavaScript benchmark page
google-latency-benchmark	How it works	The HTML page draws a special pattern of pixels to the screen using WebGL or Canvas 2D, then makes an XMLHTTPRequest to the server to start the latency measurement
google-latency-benchmark	How it works	The server locates the browser window by searching a screenshot for the special pattern
google-latency-benchmark	How it works	Once the browser window is located, the server starts sending input events
google-latency-benchmark	How it works	Each time the HTML page receives an input event it encodes that information into pixels in the on-screen pattern, drawn using the canvas element
google-latency-benchmark	How it works	Meanwhile the server is taking screenshots every few milliseconds
google-latency-benchmark	How it works	By decoding the pixel pattern the server can determine to within a few milliseconds how long it takes the browser to respond to each input event.The native reference test is special because it requires extra support from the server
google-latency-benchmark	How it works	Using the native APIs of each platform, the server creates a special benchmark window that draws the same pattern as the test webpage, and responds to keyboard input in the same way
google-latency-benchmark	How it works	To ensure fairness when compared with the browser, this window is opened in a separate process and uses OpenGL to draw the pattern on the screen
google-latency-benchmark	How it works	The benchmark window opens as a popup window, only 1 pixel tall and without a border or title bar, so it's almost unnoticeable.
google-latency-benchmark	License and distribution	The Web Latency Benchmark is licensed under the Apache License version 2.This is an open source project; it is not an official Google product.
google-latency-benchmark	Build prerequisites	Python 2.x is required on all platforms for GYP, which generates the build files.First, you need to git submodule init && git submodule update to fetch the submodules in third_party
google-latency-benchmark	Build prerequisites	Then, you need to run generate-project-files, which will run GYP and generate platform-specific project files in build/.
google-layered-scene-inference	Layer-structured 3D Scene Inference via View Synthesis	This code accompanies the paper Layer-structured 3D Scene Inference via View Synthesis\Shubham Tulsiani, Richard Tucker, Noah Snavely\In ECCV, *Please note that this is not an officially supported Google product.* Project Page This is the initial release of the Layered Scene Inference TensorFlow code for learning to infer layered depth images  LDIs  from single input views via multi-view supervision.
google-layered-scene-inference	Training and Evaluating	You'll first need to follow the  installation instructions  docs/installation.md 
google-layered-scene-inference	Training and Evaluating	To subsequently train and evaluate the LDI prediction models, see the documentation for running experiments using the  Synthetic  docs/synth.md  or  KITTI  docs/kitti.md  datasets.
google-layered-scene-inference	Citation	If you use this code for your research, please consider citing:
google-leveldb	Limitations	This project supports  CMake  out of the box.Quick start:
google-leveldb	Contributing to the leveldb Project	The leveldb project welcomes contributions
google-leveldb	Contributing to the leveldb Project	leveldb's primary goal is to bea reliable and fast key/value store
google-leveldb	Contributing to the leveldb Project	Changes that are in line with thefeatures/limitations outlined above, and meet the requirements below,will be considered.Contribution requirements:**POSIX only**
google-leveldb	Contributing to the leveldb Project	We _generally_ will only accept changes that are both**Stable API**
google-leveldb	Contributing to the leveldb Project	We strive very hard to maintain a stable API
google-leveldb	Contributing to the leveldb Project	Changes that**Tests**: All changes must be accompanied by a new  or changed  test, or
google-leveldb	Submitting a Pull Request	Before any pull request will be accepted the author must first sign aContributor License Agreement  CLA  at In order to keep the commit timeline linear squash your changes down to a single commit and  rebase on google/leveldb/master
google-leveldb	Submitting a Pull Request	This keeps the commit timeline linear and more easily sync'edwith the internal repository at Google
google-leveldb	Submitting a Pull Request	More information at GitHub's About Git rebase  page.
google-leveldb	Performance	Here is a performance report  with explanations  from the run of theincluded db_bench program
google-leveldb	Performance	 The results are somewhat noisy, but shouldbe enough to get a ballpark performance estimate.
google-leveldb	Setup	We use a database with a million entries
google-leveldb	Setup	 Each entry has a 16 bytekey, and a 100 byte value
google-leveldb	Setup	 Values used by the benchmark compress toabout half their original size.
google-leveldb	Write performance	The "fill" benchmarks create a brand new database, in eithersequential, or random order
google-leveldb	Write performance	 The "fillsync" benchmark flushes datafrom the operating system to the disk after every operation; the otherwrite operations leave the data sitting in the operating system buffercache for a while
google-leveldb	Write performance	 The "overwrite" benchmark does random writes thatupdate existing keys in the database.Each "op" above corresponds to a write of a single key/value pair.I.e., a random write benchmark goes at approximately 400,000 writes per second.Each "fillsync" operation costs much less  0.3 millisecond than a disk seek  typically 10 milliseconds 
google-leveldb	Write performance	 We suspect that this isbecause the hard disk itself is buffering the update in its memory andresponding before the data has been written to the platter
google-leveldb	Write performance	 This mayor may not be safe based on whether or not the hard disk has enoughpower to save its memory in the event of a power failure.
google-leveldb	Read performance	We list the performance of reading sequentially in both the forwardand reverse direction, and also the performance of a random lookup.Note that the database created by the benchmark is quite small.Therefore the report characterizes the performance of leveldb when theworking set fits in memory
google-leveldb	Read performance	 The cost of reading a piece of data thatis not present in the operating system buffer cache will be dominatedby the one or two disk seeks needed to fetch the data from disk.Write performance will be mostly unaffected by whether or not theworking set fits in memory.LevelDB compacts its underlying storage data in the background toimprove read performance
google-leveldb	Read performance	 The results listed above were doneimmediately after a lot of random writes
google-leveldb	Read performance	 The results aftercompactions  which are usually triggered automatically  are better.Some of the high cost of reads comes from repeated decompression of blocksread from disk
google-leveldb	Read performance	 If we supply enough cache to the leveldb so it can hold theuncompressed blocks in memory, the read performance improves again:
google-leveldb	Repository contents	See  doc/index.md  doc/index.md  for more explanation
google-leveldb	Repository contents	See doc/impl.md  doc/impl.md  for a brief overview of the implementation.The public interface is in include/*.h
google-leveldb	Repository contents	 Callers should not include orrely on the details of any other header files in this package
google-leveldb	Repository contents	 Thoseinternal APIs may be changed without warning.Guide to header files:If you want just bytewise comparison of keys, you can use the defaultcomparator, but clients can write their own comparator implementations if theywant custom ordering  e.g
google-leveldb	Repository contents	to handle different character encodings, etc
google-leveldb	Repository contents	an iterator from a DB object.updates to a database.length into some other byte array.and is used to report success and various kinds of errors.Abstraction of the OS environment
google-leveldb	Repository contents	 A posix implementation of this interface isin util/env_posix.ccclients probably won't use directly
google-libnop	libnop: C++ Native Object Protocols	libnop is a header-only library for serializing and deserializing C++ datatypes without external code generators or runtime support libraries
google-libnop	libnop: C++ Native Object Protocols	The onlymandatory requirement is a compiler that supports the C++14 standard.Note: This is not an officially supported Google product at this time.
google-libnop	Goals	libnop has the following goals:Take a look at  Getting Started  docs/getting-started.md  for an introduction tothe library.
google-libnop	Quick Examples	Here is a quick series of examples to demonstrate how libnop is used
google-libnop	Quick Examples	You canfind more examples in the repository under  examples/  examples/ .
google-libnop	#include 	namespace example {// Contrived template type with private members.template struct UserDefined { public:  UserDefined   = default;  UserDefined std::string label, std::vector vector   const std::vector& vector   const { return vector_; } private:  std::string label_;  std::vector vector_;}  // namespace exampleint main int argc, char*  using Writer = nop::StreamWriter;  nop::Serializer serializer;  serializer.Write   std::cout << "Wrote " << data.size   << " bytes." << std::endl;  return 0;
google-libpam-policycache	Overview	Caches passwords from other PAM modules and bypasses those modules based on aconfigurable policy.Why use libpam-policycache?
google-libpam-policycache	Example	Built with autotools and includes an autogen.sh script:./autogen.sh  not needed when using source tarball makemake checksudo make install
google-libpam-policycache	TODO	In the following example policy, user "janedoe" may be the owner of the machineand her login experience is similar to having a password in /etc/shadow
google-libpam-policycache	TODO	Herpassword only needs to be checked by another module once a year.Others in the "users" group may also use the cache, but only for a short time.Their entries are evicted from the cache after an hour without use or two dayswithout being verified again using another module.
google-libpam-policycache	/etc/libpam-policycache.d/foo.policy	 user:janedoe expire=52w group:users refresh=1hexpire=2d
google-libpam-policycache	Cache Storage	Policy entries are stored in /var/cache/libpam-policycache by default
google-libpam-policycache	Cache Storage	Eachentry is stored in a file for the user it belongs to.The cache entry format is human-readable for easier debugging:Applications like screensavers that try to use the cache directly will bedenied, since the cache directory is only usable by root
google-libpam-policycache	Cache Storage	Those applicationsshould use pam_escalate.so instead, which proxies the authentication prompt s through a pipe to a setuid-root helper called pam-escalate-helper
google-libpam-policycache	Cache Storage	The helpercalls pam_start   and pam_authenticate   just like an application would, andit always uses /etc/pam.d/escalate for the service configuration
google-libpam-policycache	Cache Storage	It checks inadvance that the user calling it is the same user as the one who should beauthenticated so it doesn't work for cases like web oder mail servers who checksystem users.The escalate module clears all environment variables, ignores some PAM items,and only implements pam_sm_authenticate   so it may not cover all use cases.At some point before or during the 1.0 release, the escalate module will bemoved to its own project.
google-libprotobuf-mutator	Overview	libprotobuf-mutator is a library to randomly mutate protobuffers  It could be used together with guidedfuzzing engines, such as  libFuzzer 
google-libprotobuf-mutator	Quick start on Debian/Ubuntu	Install prerequisites:By default, the system-installed version of protobuf  is used
google-libprotobuf-mutator	Quick start on Debian/Ubuntu	 However, on somesystems, the system version is too old
google-libprotobuf-mutator	Quick start on Debian/Ubuntu	 You can passLIB_PROTO_MUTATOR_DOWNLOAD_PROTOBUF=ON to cmake to automatically download andbuild a working version of protobuf.
google-libprotobuf-mutator	Usage	To use libprotobuf-mutator simply include mutator.h  /src/mutator.h  and mutator.cc  /src/mutator.cc  into your build files.The ProtobufMutator class implements mutations of the protobuftree structure and mutations of individual fields.The field mutation logic is very basic -methods with more sophisticated logic, e.g.using  libFuzzer  mutators.To apply one mutation to a protobuf object do the following: mutator_test.cc  /src/mutator_test.cc .
google-libprotobuf-mutator	Integrating with libFuzzer	LibFuzzerProtobufMutator can help to integrate with libFuzzer
google-libprotobuf-mutator	Integrating with libFuzzer	For example 
google-libprotobuf-mutator	#include "src/libfuzzer/libfuzzer_macro.h"	DEFINE_PROTO_FUZZER const MyMessageType& input  {  // Code which needs to be fuzzed
google-libprotobuf-mutator	#include "src/libfuzzer/libfuzzer_macro.h"	 ConsumeMyMessageType input ;Please see  libfuzzer_example.cc  /examples/libfuzzer/libfuzzer_example.cc  as an example.
google-libprotobuf-mutator	UTF-8 strings	"proto2" and "proto3" handle invalid UTF-8 strings differently
google-libprotobuf-mutator	UTF-8 strings	In both casesstring should be UTF-8, however only "proto3" enforces that
google-libprotobuf-mutator	UTF-8 strings	So if fuzzer isapplied to "proto2" type libprotobuf-mutator will generate any strings includinginvalid UTF-If it's a "proto3" message type, only valid UTF-8 will be used.
google-librato.dart	librato	  A  Dart  dart  library to upload metrics data to librato.com 
google-librato.dart	Usage	To use this library, instantiate an instance of the postStats method to post a set of statistics.You need to provide a Librato username and access token, either explicitly inthe constructor, or implicitly via environment variables  LIBRATO_TOKEN .Please file feature requests and bugs at the  issue tracker  tracker 
google-librato.dart	Usage	tracker :  dart : 
google-librato.dart	Notes	This is not an official Google project.
google-licenseclassifier	License Classifier	 ! Build status  
google-licenseclassifier	Introduction	The license classifier is a library and set of tools that can analyze text todetermine what type of license it contains
google-licenseclassifier	Introduction	It searches for license texts in afile and compares them to an archive of known licenses
google-licenseclassifier	Introduction	These files could be,e.g., LICENSE files with a single or multiple licenses in it, or source codefiles with the license text in a comment.A "confidence level" is associated with each result indicating how close thematch was
google-licenseclassifier	Introduction	A confidence level of 1.0 indicates an exact match, while aconfidence level of 0.0 indicates that no license was able to match the text.
google-licenseclassifier	Adding a new license	Adding a new license is straight-forward: Create a file in licenses/
google-licenseclassifier	Adding a new license	Add the license name to the list in license_type.go
google-licenseclassifier	Adding a new license	Regenerate the licenses.db file by running the license serializer: Create and run appropriate tests to verify that the license is indeed
google-licenseclassifier	Identify license	identify_license is a command line tool that can identify the license s within a file.The license_serializer tool regenerates the licenses.db archive
google-licenseclassifier	Identify license	The archivecontains preprocessed license texts for quicker comparisons against unknowncode that happens to be owned by Google.
google-link022	Link022: an open WiFi access point	Link022 is an open reference implementation and experimental platform for an OpenConfig and gNMIcontrolled WiFi access point.The central part of Link022 is an gNMI agent that runs on a Linux host with WiFi capability
google-link022	Link022: an open WiFi access point	Theagent turns the host into an gNMI capable wireless access point which can be configured usingOpenConfig models.This repository contains following components.
google-link022	Link022 agent	A WiFi management component that runs on a Link022 AP, with OpenConfig and gNMI implemented.It supports gNMI "SET" and "GET" opertions for AP configuration.To run the agent on a Raspberry Pi device, see the  start guide  agent/README.md .
google-link022	Link022 demo	A demo for configuring Link022 AP though gNMI
google-link022	Link022 demo	 demo guide  demo/README.md 
google-link022	Link022 emulator	An emulator that runs Link022 agent inside a Linux namespace
google-link022	Link022 emulator	 start guide  emulator/README.md 
google-link022	gNMI test kit.	A tool to test the gNMI functionality of an AP device
google-link022	gNMI test kit.	 start guide  testkit/README.md 
google-liquidfun	Welcome to LiquidFun!	LiquidFun is a 2D physics engine for games
google-liquidfun	Welcome to LiquidFun!	 Go to our landing page    to browse our documentation and see some examples.LiquidFun is an extension of  Box2D   
google-liquidfun	Welcome to LiquidFun!	It adds a particle based fluid and softbody simulation to the rigid body functionality of  Box2D   
google-liquidfun	Welcome to LiquidFun!	LiquidFun can bebuilt for many different systems, including Android, iOS, Windows, OS X, Linux,and JavaScript
google-liquidfun	Welcome to LiquidFun!	Please see Box2D/Documentation/Building/ for details.Discuss LiquidFun with other developers and users on the LiquidFun Google Group   
google-liquidfun	Welcome to LiquidFun!	File issues on the  LiquidFun Issues Tracker   or post your questions to  stackoverflow.com    with a mention ofPlease see  Box2D/Documentation/Building/    to learn how to build LiquidFun andrun the testbed.LiquidFun has a logo that you can use, in your splash screens or documentation,for example
google-liquidfun	Welcome to LiquidFun!	Please see the  Programmer's Guide    for the graphics and furtherFor applications on Google Play that integrate this tool, usage is tracked.This tracking is done automatically using the embedded version string b2_liquidFunVersionString , and helps us continue to optimize it
google-liquidfun	Welcome to LiquidFun!	Aside fromconsuming a few extra bytes in your application binary, it shouldn't affectyour application at all
google-liquidfun	Welcome to LiquidFun!	We use this information to let us know if LiquidFunis useful and if we should continue to invest in it
google-liquidfun	Welcome to LiquidFun!	Since this is opensource, you are free to remove the version string but we would appreciate ifyou would leave it in
google-liquidfun	Welcome to LiquidFun!	  LiquidFun Issues Tracker :   landing page :   Box2D :   Programmer's Guide : 
google-lisp-koans	One-time Method	From a terminal, execute your lisp interpreter on the file 'contemplate.lsp' e.g.
google-lisp-koans	Watching the Koans	On Linux and MacOS systems, the shell scripts meditate-macos.sh can be used to automatically evaluate 'contemplate.lsp'whenever the koan files are modified, providing immediate feedback on changesto the koans
google-lisp-koans	Watching the Koans	To run the MacOS version you need to have fswatch  installed
google-lisp-koans	Watching the Koans	From a terminal:
google-lisp-koans	Results of Contemplation	Running on a fresh version should output the following:Thinking about ASSERTSYou have not yet reached enlightenment ..
google-lisp-koans	Results of Contemplation	 A koan is incomplete.Please meditate on the following code:You are now 0/169 koans and 0/25 lessons closer to reaching enlightenmentThis indicates that the script has completed, and that the learner should lookto asserts.lsp to locate and fix the problem
google-lisp-koans	Results of Contemplation	 The problem will be withina define-test expression such asIn this case, the test is incomplete, and the student should fillin the blank  ____  with appropriate lisp code to make the assert pass.In order to test code, or evaluate tests interactively, students may copyand paste code into the lisp command line REPL.
google-lisp-koans	Quoting the Ruby Koans instructions	refactor
google-lisp-koans	Quoting the Ruby Koans instructions	Write a failing test and run it  red , make the test pass  green ,then refactor it  that is look at the code and see if you can make it anybetter 
google-lisp-koans	Quoting the Ruby Koans instructions	In this case you will need to run the koan and see it fail  red , makethe test pass  green , then take a moment and reflect upon the test to see whatit is teaching you and improve the code to better communicate itsintent  refactor ."
google-lisp-koans	Content	The Common Lisp koans are based on the Python koans and Ruby koans projects.Additionally, many of the tests are based on new material that is specialto Common Lisp.Note that the unit on threads uses an SBCL specific threading API
google-lisp-koans	Content	 A readermacro will remove this unit on Lisp implementations other than SBCL.
google-lmctfy	Note	We have been collaborating with  Docker  over libcontainer and are in process of porting the core lmctfy concepts and abstractions to  libcontainer  We are not actively developing lmctfy further and have moved our efforts to libcontainer
google-lmctfy	Note	In future, we hope to replace the core of lmctfy with libcontainer.
google-lmctfy	Introduction	lmctfy  pronounced *l-m-c-t-fi*, IPA: /ɛlɛmsitifаɪ/  is the open source version of  Google ’s container stack, which provides Linux application containers
google-lmctfy	Introduction	These containers allow for the isolation of resources used by multiple applications running on a single machine
google-lmctfy	Introduction	This gives the applications the impression of running exclusively on a machine
google-lmctfy	Introduction	The applications may be container-aware and thus be able to create and manage their own subcontainers.The project aims to provide the container abstraction through a high-level API built around user intent
google-lmctfy	Introduction	The containers created are themselves container-aware within the hierarchy and can be delegated to be managed by other user agents.lmctfy was designed and implemented with specific use-cases and configurations in mind and may not work out of the box for all use-cases and configurations
google-lmctfy	Introduction	We do aim to support more use-cases and configurations so please feel free to  contribute  #contributing  patches or send e-mail to the  mailing list  #mailing-list  so that we may incorporate these into the  roadmap  #roadmap .lmctfy is released as both a C++ library and a CLI.
google-lmctfy	Current Status	lmctfy is currently stalled as we migrate the core concepts to libcontainer and build a standard container management library that can be used by many projects.lmctfy is beta software and may change as it evolves
google-lmctfy	Current Status	The latest release version is 0.5.0
google-lmctfy	Current Status	It currently provides isolation for CPU, memory, and devices
google-lmctfy	Current Status	It also allows for the creation of Virtual Hosts which are more heavily isolated containers giving the impression of running as an independent host
google-lmctfy	Getting Started	This section describes building the CLI, running all unit tests, and initializing the machine
google-lmctfy	Getting Started	The  CLI Commands  #cli-commands  section provides some examples of CLI operations and  C++ Library  #c-library  describes the use of the underlying library.
google-lmctfy	Dependencies	lmctfy depends on the following libraries and expects them to be available on the system:
google-lmctfy	Building the CLI	To build the lmctfy CLI:
google-lmctfy	Building the C++ Library	To build the lmctfy library:
google-lmctfy	Running Unit Tests	To build and run all unit tests:lmctfy has been tested on **Ubuntu 12.04+*In order to run lmctfy we must first initialize the machine
google-lmctfy	Running Unit Tests	This only needs to happen once and is typically done when the machine first boots
google-lmctfy	Running Unit Tests	If the cgroup hierarchies are already mounted, then an empty config is enough and lmctfy will auto-detect the existing mounts:
google-lmctfy	Container Names	Container names mimic filesystem paths closely since they express a hierarchy of containers  i.e.: containers can be inside other containers, these are called **subcontainers*Allowable characters for container names are:
google-lmctfy	Create	To create a container run:Example  create a memory-only container with 100MB limit :To destroy a container run:To list all containers in a machine, ask to recursively list from root:To run a command inside a container run:Use lmctfy help to see the full command listing and documentation.
google-lmctfy	C++ Library	The library is comprised of the ::containers::lmctfy::ContainerApi factory which creates, gets, destroys, and detects ::containers::lmctfy::Container objects that can be used to interact with individual containers
google-lmctfy	C++ Library	Full documentation for the lmctfy C++ library can be found in  lmctfy.h  /include/lmctfy.h 
google-lmctfy	Roadmap	The lmctfy project proposes a containers stack with two major layers we’ll call CL1 and CLCL1 encompases the driver and enforcement of the containers policy set by CLCL1 will create and maintain the container abstraction for higher layers
google-lmctfy	Roadmap	It should be the only layer that directly interacts with the kernel to manage containers
google-lmctfy	Roadmap	CL2 is what develops and sets container policy, it uses CL1 to enforce the policy and manage containers
google-lmctfy	Roadmap	For example: CL2  a daemon  implements a policy that the amount of CPU and memory used by all of a machine’s containers must not exceed the amount of available CPU and memory  as opposed to overcommitting memory in the machine 
google-lmctfy	Roadmap	To enforce that policy it uses CL1  library/CLI  to create containers with memory limits that add up to the machine’s available memory
google-lmctfy	Roadmap	Alternate policies may involve overcommitting a machine’s resources by X% or creating levels of resources with different guarantees for quality of service.The lmctfy project currently provides the CL1 component
google-lmctfy	Roadmap	The CL2 is not yet implemented.
google-lmctfy	CL1	Currently only provides robust CPU and memory isolation
google-lmctfy	CL1	 In our roadmap we have support for the following:The most basic CL2 would use a container policy that ensures the fair sharing of a machine’s resources without allowing overcommitment
google-lmctfy	CL1	We aim to eventually implement a CL2 that provides different levels of guaranteed quality of service
google-lmctfy	CL1	In this scheme some levels are given stronger quality of service than others
google-lmctfy	CL1	The following CL2 features are supported in our roadmap:
google-lmctfy	Kernel Support	lmctfy was originally designed and implemented around a custom kernel with a set of patches on top of a vanilla Linux kernel
google-lmctfy	Kernel Support	As such, some features work best in conjunction with those kernel patches
google-lmctfy	Kernel Support	However, lmctfy should work without them
google-lmctfy	Kernel Support	It should detect available kernel support and adapt accordingly
google-lmctfy	Kernel Support	We’ve tested lmctfy in vanilla **Ubuntu 3.3**Some of the relevant kernel patches:Interested in contributing to the project? Feel free to send a patch or take a look at our  roadmap  #roadmap  for ideas on areas of contribution
google-lmctfy	Kernel Support	Follow  Getting Started  #getting-started  above and it should get you up and running
google-lmctfy	Kernel Support	If not, let us know so we can help and improve the instructions
google-lmctfy	Kernel Support	There is some documentation on the structure of lmctfy in the  primer  /PRIMER.md .
google-lmctfy	Mailing List	The project mailing list is 
google-lmctfy	Mailing List	The list will be used for announcements, discussions, and general support
google-lmctfy	Mailing List	You can  subscribe via groups.google.com 
google-loaner	Contributing	We are not accepting external contributions at this time
google-loaner	Contributing	The current release ofthe application is still in alpha
google-loaner	Contributing	We will be actively contributing to thisproject throughout After this project reaches a 1.0 release, we will beginaccepting external contributions
google-loaner	Contributing	Please feel free to file bugs and featurerequests using  GitHub's IssueTracker 
google-loaner	Disclaimers	The current release of the application is in active development.This is **not*supported and the code is available as-is with no guarantees.Documentation, including those for end users of this system, is provided in thisrepository only as examples of the "out of box" experience for the app and doesnot account for any modifications made by the administrator in deploying theapp
google-loaner	Disclaimers	Administrators should review and adjust all documentation and instructionsfound in the app as applicable to their deployment.
google-logger	logger #	Logger is a simple cross platform Go logging library for Windows, Linux, andmacOS, it can log to the Windows event log, Linux/macOS syslog, and an io.Writer.This is not an official Google product.
google-logger	Usage ##	Set up the default logger to log the system log  event log or syslog  and afile, include a flag to turn up verbosity:import    "flag"  "os" const logPath = "/some/location/example.log"var verbose = flag.Bool "verbose", false, "print info level logs to stdout" func main   {  flag.Parse    if err != nil {  }  defer lf.Close    if err := doSomething  ; err != nil {  }The Init function returns a logger so you can setup multiple instances if youwish, only the first call to Init will set the default logger:lf, err := os.OpenFile logPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0660 if err != nil {  logger.Fatalf "Failed to open log file: %v", err defer lf.Close  // Log to system log and a log file, Info logs don't write to stdout.loggerOne := logger.Init "LoggerExample", false, true, lf defer loggerOne.Close  // Don't to system log or a log file, Info logs write to stdout..loggerTwo := logger.Init "LoggerExample", true, false, ioutil.Discard defer loggerTwo.Close  loggerOne.Info "This will log to the log file and the system log" loggerTwo.Info "This will only log to stdout" logger.Info "This is the same as using loggerOne" 
google-lovefield	Lovefield	    ! NPM version   ! Bower version  Lovefield is a relational database written in pure JavaScript.It provides SQL-like syntax and works cross-browser  currently supportingChrome 37+, Firefox 31+, IE 11+, Edge, and Safari 10+ .Please visit our public forum  forgeneral Q&A, feedback, and discussions
google-lovefield	Lovefield	Quick Start  demos/todo/README.md  Frequently Asked Questions  docs/FAQ.md  Specification  docs/spec_index.md  Developer Setup  docs/dev_setup.md  Design Documents  docs/dd_index.md Lovefield is Day 98 of 100 days of Google Dev This is a quick 7-minute video filmed in August Live 30min overview presentation at JS.LA  February 2015 : Watch on YouTube  or Vimeo 
google-lullaby	What is Lullaby?	Lullaby is a collection of C++ libraries designed to help teams develop virtualand augmented reality experiences.
google-lullaby	Documentation	 Documentation  g3doc/index.md  is available  here  g3doc/index.md .
google-lullaby	Status	The release of Lullaby is still very much a work-in-progress
google-lullaby	Status	Your patience isappreciated while we work on porting our internal libraries, build processes anddocs externally.
google-lullaby	Contributing	We are unable to take your pull requests at this time, but are working on fixing
google-lullaby	License	 Apache License, Version 2.0  LICENSE 
google-lullaby	Disclaimer	This is not an official Google product.
google-lvmd	LVMd	 ! Docker Repository on Quay  "Docker Repository on Quay"  **This is not an official Google product**LVMd provides GRPC-based access to LVM management.
google-macops-MOLAuthenticatingURLSession	MOLAuthenticatingURLSession	A wrapper around NSURLSession providing validation of server certificates and easy-to-use client certificate authentication.Requires ARC
google-macops-MOLAuthenticatingURLSession	MOLAuthenticatingURLSession	Tested on OS X 10.11+.
google-macops-MOLAuthenticatingURLSession	#import 	  authURLSession.userAgent = @"MyUserAgent";  authURLSession.refusesRedirects = YES;  authURLSession.serverHostname = @"my-hostname.com";  NSURLSession *session = authURLSession.session;  // You can use the NSURLSession as you would normally..If you'd like to print status/error information:Install using CocoaPods.
google-macops-MOLAuthenticatingURLSession	Documentation	Reference documentation is at CocoaDocs.org:Patches to this library are very much welcome.Please see the  CONTRIBUTING  file.
google-macops-MOLFCMClient	MOLFCMClient	A client for receiving and acknowledging FCM messages.
google-macops-MOLFCMClient	#import 	MOLFCMClient *fcmClient =   MOLFCMClient alloc  initWithFCMToken:token  NSLog @"%@", message ;   fcmClient acknowledgeMessage:message ;} ; fcmClient connect ;
google-macops-MOLFCMClient	Installation	Install using CocoaPods.Reference documentation is at CocoaDocs.org:Patches to this library are very much welcome.Please see the  CONTRIBUTING  file.
google-macops-MOLXPCConnection	MOLXPCConnection	A wrapper around NSXPCListener and NSXPCConnection to provide client multiplexing,signature validation of connecting clients, forced connection establishment anddifferent exported interfaces for privileged/unprivileged clients.
google-macops-MOLXPCConnection	Installation	Install using CocoaPods.Example server started by launchd where the launchd job has a MachServices key:messages are always delivered on a background thread!
google-macops-MOLXPCConnection	Documentation	Reference documentation is at CocoaDocs.org:Patches to this library are very much welcome.Please see the  CONTRIBUTING  file.
google-macops-MOMenu	MOMenu	MOMenu is a menubar item with a plug-in architecture which allows admins to create anything that helps their fleet, from setting user preferences to reporting on machine status.
google-macops-MOMenu	Building	Requires  CocoaPods  and  Xcode  to compile.Clone the repository, install necessary pods, then build the application:In order to use MOMenu, install suitable plugins to /Library/MOMenu/PlugInsAn example Snake plugin is included in this repository.To build and install the Snake plugin:
google-macops-keychainminder	Keychain Minder	Keychain Minder is a simple OS X SecurityAgentPlugin for monitoring keychainpassword synchronization in enterprise environments.Ordinarily when users change their login password, OS X will update the loginkeychain to match
google-macops-keychainminder	Keychain Minder	In enterprise environments, where the password is managedcentrally and synchronized with the machine  via LDAP, AD, etc
google-macops-keychainminder	Keychain Minder	 this doesn'thappen
google-macops-keychainminder	Keychain Minder	Instead, OS X has a built-in mechanism that appears after authenticatingat the login window to prompt users to update their keychain passwords but manyusers don't know what a keychain is, don't understand the dialog or haveforgotten their password.Keychain Minder re-creates this built-in mechanism but does so for screensaverand preference pane unlock instead of login
google-macops-keychainminder	Keychain Minder	Upon noticing the passworddoes not work for unlocking the keychain, it will pop-up a dialog informing theuser and giving them the option to either change the password  using both oldand new passwords  or reset the keychain.
google-macops-keychainminder	Testing	Keychain Minder is no longer in use at Google and while we will continue to maintain it as best as we can, it will not be as well tested on future OS releases
google-macops-keychainminder	Testing	We will still be responding to issues and pull requests.Keychain Minder has had very little testing so far but has been known towork on 10.9.5, 10.10.5 and 10.11.There's no real reason it shouldn't work on 10.7 and 10.8, it just hasn'tbeen tried
google-macops-keychainminder	Testing	If you find it works, please let us know!
google-macops-keychainminder	Screenshots	! Welcome  Docs/KeychainMinderWelcome.png ! Known Password  Docs/KeychainMinderKnownPw.png ! Unknown Password  Docs/KeychainMinderUnknownPw.png 
google-macops-keychainminder	Installation	Download the latest release from the  Releases  page.It's a standard Apple package, inside a disk image.If you would like to customize the package there's a Makefile in the Packagefolder
google-macops-keychainminder	Installation	You'll need  The Luggage  installedto build it.By default the package installs KeychainMinder so that it works at thescreensaver
google-macops-keychainminder	Installation	In order to do this, it has to: Restore the screensaver login UI to an older-looking UI
google-macops-keychainminder	Installation	SecurityAgentPlugins Set the screensaver login policy to authenticate-session-owner.The update_authdb.py script has options to change both of these behaviors.
google-macops-keychainminder	Uninstallation	sudo /Library/Security/SecurityAgentPlugins/KeychainMinder.bundle/Contents/Resources/uninstall.sh
google-macops-keychainminder	How it works	During every login the plugin is invoked
google-macops-keychainminder	How it works	It does the following:Check that the right being authenticated is either system.login.screensaverIf both are true, it retrieves the logging in user's default keychain path,Retrieves an array  encoded as a plist  from /Library/Preferences
google-macops-keychainminder	How it works	It eitherWhile all of this is happening, launchd is watching the plist file in step 4for changes and whenever the file is changed, it launches an app embedded inthe plugin
google-macops-keychainminder	How it works	The app does the following:Checks that the currently logged-in user is in the preference file on disk.Displays a simple UI explaining that the keychain password is out of sync3a
google-macops-keychainminder	How it works	If the user remembers their password, it asks for both old and new password,3b
google-macops-keychainminder	How it works	If the user does not remember their password, it asks for the new password,The hardlink/open/unlock/unlink dance used in both the plugin and UI appare to avoid locking the Local Items keychain, as doing so can cause issueswhen trying to update the password or reset
google-macops-keychainminder	How it works	The undocumented functions used to update the password or reset the keychaincould stop working at any time, though the same functions *are
google-macops-keychainminder	Acknowledgements	Thanks to  @tomjburgin  for inspiration andhelp getting the plugin working at the screensaver.
google-macops-molcertificate	MOLCertificate	Objective-C wrapper around SecCertificateRef with caching accessors.Requires ARC
google-macops-molcertificate	MOLCertificate	Tested on OS X 10.9+.
google-macops-molcertificate	#import 	  return   MOLCertificate alloc  initWithCertificateDataPEM:fileData ;  }  }  }
google-macops-molcertificate	Installation	Install using CocoaPods.
google-macops-molcertificate	Documentation	Reference documentation is at CocoaDocs.org:Patches to this library are very much welcome.Please see the  CONTRIBUTING  file.
google-macops-molcodesignchecker	MOLCodesignChecker	Provides an easy way to do code signature validation in Objective-C
google-macops-molcodesignchecker	#import 	  if  csInfo  {  }  return NO;  if  csInfo  {  }  return NO;
google-macops-molcodesignchecker	Installation	Install using CocoaPods.
google-macops-molcodesignchecker	Documentation	Reference documentation is at CocoaDocs.org:Patches to this library are very much welcome
google-macops-molcodesignchecker	Documentation	Please see the CONTRIBUTING 
google-maddpg-replication	maddpg-replication	This is a partial replication of  "Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"  Lowe, Wu, Tamar, Harb, Abbeel, Mordatch 2017   That paper introduced an algorithm called MADDPG  multi-agent deep deterministic policy gradient  for training multiple agents that can interact intelligently
google-maddpg-replication	maddpg-replication	The authors released  source code  for replicating the paper
google-maddpg-replication	maddpg-replication	This repository documents the process of running that code and the results.Although I  Nisan Stiennon  am affiliated with Google, this is not an official Google product.
google-maddpg-replication	Results	Check out the  Jupyter notebook  maddpg_replication.ipynb  for results.Each directory in  experiments/  experiments  contains:I used a  Google Compute Engine  n1-standard-2 virtual machine  2 vCPUs, 7.5 GB memory 
google-maddpg-replication	Results	Install these packages:Python packages:To run an experiment, edit  run.sh  run.sh  and adjust any command-line flags
google-maddpg-replication	Results	Then, from this repo's top directory run ./run.sh , where  can be anything you like
google-maddpg-replication	Results	This will create a new directory with that name under experiments/.You'll have to download the videos from your VM to view them
google-maddpg-replication	Results	See  these instructions  for connecting with gcloud or ssh if you're using GCE.To execute the Jupyter notebook, set up port forwarding from your local machine  where your browser is  to the cloud machine  where you cloned this repo 
google-maddpg-replication	Results	I did this by following the above instructions for ssh and runningssh -i  -L 8888:localhost:8888 @on my local machine.Once you've set up port forwarding, go to this repo's top directory and run jupyter notebook --port=8888
google-maddpg-replication	Results	Paste the url it gives you into your browser and then navigate to the .ipynb notebook.
google-maddpg-replication	References	Ryan Lowe, Yi Wu, Aviv Tamar, Jean Harb, Pieter Abbeel, Igor Mordatch
google-maddpg-replication	References	"Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments"
google-maddpg-replication	References	Neural Information Processing Systems  NIPS   2017 
google-maddpg-replication	References	  arXiv preprint 
google-mail-importer	Mail Importer for Gmail	Do you have an old Thunderbird mail archive that you POP3ed down from AOL?Do you want to move those old messages to Gmail so that you can use the Gmailapp on your phone and still have access to everything?If so, maybe _Mail Importer for Gmail_ is for you!If you are trying to bulk import mbox format files to Google Apps for Work,you should probably look at import-mailbox-to-gmail **DISCLAIMER**: This is not an official Google product.
google-mail-importer	What does it do?	_Mail Importer for Gmail_ will upload the contents of a Thunderbird mailarchive to Gmail and do its best to preserve the read state, flagged state, andfolders of the messages
google-mail-importer	What does it do?	As messages are uploaded verbatim, Gmail will have anexact copy, including all attachments and headers._Mail Importer_ also makes sure to only upload messages that aren't already inGmail
google-mail-importer	What does it do?	This makes it easy to re-run the import multiple times if something goes
google-mail-importer	How can I run it?	Currently, _Mail Importer for Gmail_ is in early development
google-mail-importer	How can I run it?	It is __not__user friendly in any way
google-mail-importer	How can I run it?	If you are not a developer, you probably want tostay away.
google-mail-importer	Getting a Client Secret	Each developer needs a _client secret_ to identify their version of MailImporter to Google using OAuth2  To get aclient secret, you have to create a project in the Google Developers Console configure it correctly, then download the generated credentials
google-mail-importer	Getting a Client Secret	The resultshould be a JSON file named something like:Importer project
google-mail-importer	Getting a Client Secret	_**Never check in this file!**_ It is _your_ key and no one
google-mail-importer	Building Mail Importer	Mail Importer uses  Maven  This means that it willdownload all of the necessary dependencies automatically when you build it like
google-mail-importer	Running Mail Importer	Once Mail Importer is built, you can run it like:Note that the Thunderbird Local Folders
google-mail-importer	Running Mail Importer	It is this last level of directory that contains the actualFor example, if you had old CompuServe mail on a Mac, you might run MailImporter like this:You bet! See the  CONTRIBUTING.md  CONTRIBUTING.md  file for more information.
google-makerspace-auth	Summary	! Sample controller box  hardware/box.jpg We started this project with two goals in mind, for Google makerspaces whereemployees all have the same kind of RFID badge:Only people authorized  trained  should be able to use dangerous toolsWe'd like to have reliable access logs for even non-dangerous tools
google-makerspace-auth	Contributing	We *welcomemakerspaces
google-makerspace-auth	Contributing	 We'd like this to be a generic solution wherever possible.
google-makerspace-emonth	Makerspace EMonth Class	This is a class that started at the Mountain View makerspace called the Garage, where we have a series of classes that teaches you hands-on electronics.The current edition  2017  features two sessions, numbered  session 
google-makerspace-emonth	Makerspace EMonth Class	week  in subdirectories with resources where they're first introduced.First Session  June 
google-makerspace-partsbin	Makerspace Partsbin	This repository houses various things  3D models, circuits, class materials that we've created for use in Google makerspaces.If you'd like to contribute, see  CONTRIBUTING  CONTRIBUTING.md 
google-maketrace	What does this do?	This is a tool that traces the build commands used to compile source code, andcreates a graph of the dependencies between files and the compiler flags used toproduce outputs
google-maketrace	What does this do?	It can then generate equivalent build files in another buildsystem such as  Bazel  or  Ninja 
google-maketrace	Current status	This project is still in very early stages
google-maketrace	Current status	 It's a proof of concept that workson some packages, but don't expect it to work perfectly on everything.
google-marmot	One line summary	Marmot is a service for processing workflows targeting DevOps/SRE needs
google-marmot	The long summary	Marmot is a GRPC service that executes workflow descriptions againstinfrastructure  network devices, servers, kubernetes pods, ..
google-marmot	The long summary	.This allows top level services/scripts to simply test the output for the correctworkflow descriptors instead of complex mocking, concurrency checks, ...This in turn provides code reuse and reduces code duplication
google-marmot	The long summary	It also providessafety by having a single system responsible for execution and not hundreds ofMamort provides:Marmot is based on an internal Google project which processes tens of thousandsof workflows per week for several internal SRE/DevOps organizations.
google-marmot	Use cases	Marmot has been designed as a DevOps/SRE tool for handlinginfrastructure changes, though it is not limited to this role
google-marmot	Use cases	 Marmot is wellsuited for any type of operation that must be performed in steps with certainpacing and may require state checks for health.Examples include:This is not an official Google product.
google-martian	Martian Proxy   	Martian Proxy is a programmable HTTP proxy designed to be used for testing.Martian is a great tool to use if you want to:anywhere that Go can target.
google-martian	Requirements	Go 1.9
google-martian	Installation	Martian Proxy can be installed using go install
google-martian	Start the Proxy	Assuming you've installed Martian, running the proxy is as simple asIf you want to see system logs as Martian is running, pass in the verbosityBy default, Martian will be running on port 8080, and the Martian API will be running on 8181
google-martian	Start the Proxy	The port can be specified via flags:
google-martian	Logging	For logging of requests and responses a  loggingmodifier  isavailable or  HAR  logs areavailable if the -har flag is used.
google-martian	HAR Logging	To enable HAR logging in Martian call the binary with the -har flag:If the -har flag has been enabled two HAR related endpoints will beWill retrieve the HAR log of all requests and responses seen by the proxy sincethe last reset.Will reset the in-memory HAR log
google-martian	HAR Logging	Note that the log will grow unbounded unlessit is periodically reset.
google-martian	Configure	Once Martian is running, you need to configure its behavior
google-martian	Configure	Withoutconfiguration, Martian is just proxying without doing anything to the requestsor responses
google-martian	Configure	If enabled, logging will take place without additionalMartian is configured by JSON messages sent over HTTP that take the generalform of:The above configuration tells Martian to inject a header with the name"Test-Header" and the value "true" on all responses.Let's break down the parts of this message
google-martian	Configure	 sets headers  to learn more about the header.Modifier, please  refer to the  modifier reference   "response", or both.This is a simple configuration, for more complex configurations, modifiers arecombined with groups and filters to compose the desired behavior.To configure Martian, POST the JSON to 
google-martian	Configure	You'llwant to use whatever mechanism your language of choice provides you to makeHTTP requests, but for demo purposes, curl works  assuming your configurationis in a file called modifier.json .
google-martian	Intercepting HTTPS Requests and Responses	Martian supports modifying HTTPS requests and responses if configured to do so.In order for Martian to intercept HTTPS traffic a custom CA certificate must beinstalled in the browser so that connection warnings are not shown.The easiest way to install the CA certificate is to start the proxy with thenecessary flags to use a custom CA certificate and private key using the -certand -key flags, or to have the proxy generate one using the -generate-ca-certAfter the proxy has started, visit  in thebrowser configured to use the proxy and a prompt will be displayed to installthe certificate.Several flags are available in examples/main.go to help configure MITM
google-martian	Check Verifiers	Let's assume that you've configured Martian to verify the presence a specificheader in responses to a specific URL.Here's a configuration to verify that all requests to example.com returnresponses with a 200 OK.Once Martian is running, configured and the requests and resultant responses youwish to verify have taken place, you can verify your expectation that you onlygot back 200 OK responses.To check verifications, performFailed expectations are tracked as errors, and the list of errors are retrievedby making a GET request to host:port/martian/verify, which will returna list of errors:Verification errors are held in memory until they are explicitly cleared by
google-martian	Martian as a Library	Martian can also be included into any Go program and used as a library.
google-martian	Modifiers All The Way Down	Martian's request and response modification system is designed to be generaland extensible
google-martian	Modifiers All The Way Down	The design objective is to provide individual modifierbehaviors that can arranged to build out nearly any desired modification.When working with Martian to compose behaviors, you'll need to be familiar withthese different types of interactions:Modifiers, filters and groups all implement ResponseModifier or RequestResponseModifier  defined in martian.go ModifyRequest req *http.Request  errorModifyResponse res *http.Response  errorThroughout the code  and this documentation  you'll see the word "modifier"used as a term that encompasses modifiers, groups and filters
google-martian	Modifiers All The Way Down	Even though agroup does not modify a request or response, we still refer to it as aWe refer to anything that implements the modifier interface as a Modifier.
google-martian	Parser Registration	Each modifier must register its own parser with Martian
google-martian	Parser Registration	The parser isresponsible for parsing a JSON message into a Go struct that implements amodifier interface.Martian holds modifier parsers as a map of strings to functions that is builtout at run-time
google-martian	Parser Registration	Each modifier is responsible for registering its parser with acall to parse.Register in init  .Signature of parse.Register:the same as the value of name in the JSON configuration message.In the following configuration message, header.Modifier is how the headermodifier is registered in the init   of header_modifier.go.Example of parser registration from header_modifier.go:func init   {  parse.Register "header.Modifier", modifierFromJSON func modifierFromJSON b   byte   interface{}, error  {  ...
google-martian	Adding Your Own Modifier	If you have a use-case in mind that we have not developed modifiers, filters orverifiers for, you can easily extend Martian to your very specific needs.There are 2 mandatory parts of a modifier:
google-martian	Contact	For questions and comments on how to use Martian, features announcements, ordesign discussions check out our public Google Group atFor security related issues please send a detailed report to our private coregroup at martianproxy-core@googlegroups.com.
google-martian	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-marzipano	Marzipano	A 360° media viewer for the modern web.This is not an official Google product.Check out our website at including the  demos and the  documentation Please report bugs using the  issue tracker  If you have any questions, head over to our  discussion forum 
google-marzipano	User guide	You can include Marzipano in your project in two different ways:
google-marzipano	Developer guide	This is an npm-based project.A  Node.js  installation is required for development.Some dependencies expect the Node.js interpreter to be called node
google-marzipano	Developer guide	However,on Debian and Ubuntu systems, the binary installed by the nodejs package iscalled nodejs
google-marzipano	Developer guide	To work around this, install the nodejs-legacy package, oruse  nvm  instead.You also need a Java compiler to build the SWF file containing the Flash renderers set 32-bit Java path in your PATH, as MXMLC does not support 64-bit Java .Run npm install to install the dependencies
google-marzipano	Developer guide	If you haven't in a while,bring them up to date with npm update.Run npm run dev to serve this directory at .While this script is running, the demos are live-reloaded whenever the sourcefiles are edited.Run npm run test to serve the browser-based test suite at .While this script is running, the test suite is live-reloaded whenever thesource or test files are edited.
google-marzipano	Maintainer guide	Before preparing a release, make sure there are no uncommitted changes.Create a new commit to bump the version number in package.json, tag itwith git tag vX.Y.Z, and publish the tag with git push --tags.Run npm run release to prepare a new release.Run npm run deploy to deploy the release to the website.Run npm publish to publish the release to the npm registry.
google-material-design-icons	Material design icons	Material design icons is the official  icon set  from Google
google-material-design-icons	Material design icons	 The icons are designed under the  material design guidelines 
google-material-design-icons	3.0.1 Update	License change to Apache 2.0!
google-material-design-icons	Getting Started	Read the  developer guide  on how to use the material design icons in your project.
google-material-design-icons	Using a font collection	The iconfont folder contains pre-generated font files that can be included in a project
google-material-design-icons	Using a font collection	This is especially convenient for the web; however, it is generally better to link to the web font hosted on Google Fonts:
google-material-design-icons	Using symbols and sprites	The css-sprite and svg-sprite folders contain pre-generated sprite sheets, as well as svg symbols that can be d more directly and with fewer constraints
google-material-design-icons	Using symbols and sprites	Instructions for using them are in the  sprites documentation 
google-material-design-icons	Polymer icons	If you wish to use the icon set with Polymer, we recommend consuming them via the    element     in v0.5 .
google-material-design-icons	License	We have made these icons available for you to incorporate into your products under the  Apache License Version 2.0  Feel free to remix and re-share these icons and documentation in your products.We'd love attribution in your app's *about
google-material-design-lite	Material Design Lite	 ! GitHub version   ! npm version   ! Bower version   ! Gitter version    > An implementation of  Material Design components in vanilla CSS, JS, and HTML.Material Design Lite  MDL  lets you add a Material Design look and feel to yourstatic content websites
google-material-design-lite	Material Design Lite	It doesn't rely on any JavaScript frameworks orlibraries
google-material-design-lite	Material Design Lite	Optimized for cross-device use, gracefully degrades in olderbrowsers, and offers an experience that is accessible from the get-go.> ### Limited support> Material Design Lite is now in limited support, with development having moved to the>  Material Components for the web  repository.> No further development is taking place in MDL by the core team, but we are happy to review PRs, fix critical bugs and> push out new releases
google-material-design-lite	Material Design Lite	No breaking changes will be accepted.
google-material-design-lite	Use MDL on your site?	**This document is targeted at developers that will contribute to or compileMDL
google-material-design-lite	Use MDL on your site?	If you are looking to use MDL on your website or web app please head to getmdl.io 
google-material-design-lite	Browser Support	| IE9 | IE10 | IE11 | Chrome | Opera | Firefox | Safari | Chrome  Android  | Mobile Safari || B   | AA-grade browsers are fully supported
google-material-design-lite	Browser Support	B-grade browsers will gracefully degradeto our CSS-only experience.
google-material-design-lite	Download / Clone	Clone the repo using Git:this repository.Windows users, if you have trouble compiling due to line endings then make sureyou configure git to checkout the repository with lf  unix  line endings
google-material-design-lite	Download / Clone	Thiscan be achieved by setting core.eol.production
google-material-design-lite	Download / Clone	Use a tagged state of the repository, npm, or bower for stability!
google-material-design-lite	Feature requests	MDL is currently in limited support mode, with no further development taking place by the core team.We are happy to accept and review pull requests for new functionality, however, as long as there are no breaking
google-material-design-lite	Want to contribute?	If you found a bug, have any questions or want to contribute
google-material-design-lite	Want to contribute?	Follow our guidelines and help improve the Material Design Lite
google-material-design-lite	Want to contribute?	For more information visit our wiki Please use the default branch, mdl-1.x.Take note that  Material Components for Web  which is MDL v2, is under early Alpha stages  which means everything is a moving target, and we can change anything at any moment 
google-material-design-lite	Want to contribute?	Use with caution.However, we would absolutely love to have people testing MCW and provide feedback about their experiences using it, especially integrating with other frameworks and libraries.
google-material-design-lite	License	© Google, Licensed under an Apache-2 
google-mechahamster	Motivation	 MechaHamster    serves as a demonstration, sample, and reference for integrating Firebase    with the  Firebase Unity SDK   , and  Daydream    with the  Google VR SDK for Unity   into a game project.
google-mechahamster	Overview	MechaHamster demonstrates the following concepts:
google-mechahamster	Downloading	 MechaHamster    source code can be downloaded from  Github   .And download the game to your mobile device from the AppStore and Google Play Store    
google-mechahamster	Building	For more information about MechaHamster see  MechaHamster Document   To contribute the this project see  CONTRIBUTING   
google-mechahamster	Building	  CONTRIBUTING :   Google :   Daydream :   MechaHamster :   Unity 5.6 beta :     Firebase Unity SDK iOS Setup :   Firebase Realtime Database :   Firebase Authentication :   Firebase Remote Config :   Firebase Test Lab :   Building MechaHamster : 
google-mentornet	MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks	This is the code for the paper:**MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted LabelsLu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, Li Fei-FeiPresented at  ICML 2018 *Please note that this is not an officially supported Google product.*If you find this code useful in your research then please citeWe are interested in training a deep network using curriculum learning  Bengio et al., 2009 , i.e
google-mentornet	MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks	learning examples with focus.Each curriculum is implemented as a network  called **MentorNet** .
google-mentornet	Setups	All code was developed and tested on Nvidia V100/P100  16GB  the following environment.export PYTHONPATH="$PYTHONPATH:$PWD/code/"python code/cifar_train_mentornet.py \  --dataset_name=cifar10   \  --trained_mentornet_dir=mentornet_models/models/mentornet_pd1_g_1/mentornet.model-29999 \  --loss_p_precentile=0.75  \  --nofixed_epoch_after_burn_in  \  --burn_in_epoch=0  \  --example_dropout_rates="0.5,17,0.05,83" \  --data_dir=data/cifar10/0.2 \  --train_log_dir=cifar_models/cifar10/resnet/0.2/mentornet_pd1_g_1/train \  --studentnet=resnet101 \  --max_number_of_steps=39000A full list of commands can be found in this file.The training script has a number of command-line flags that you can use to configure the model architecture, hyperparameters, and input / output settings:
google-mentornet	MentorNet Framework	MentorNet is a **general*It is **flexible*We train a few MentorNets listed below
google-mentornet	MentorNet Framework	We can think of a MentorNet as a hyper-parameter and will be tuned for different problems.| Curriculum| :-------------------------------------| :----------------------------------------------------------------------------------------------------| :------------------------------------------------| :-------------------| No curriculum| Self-paced  Kuma et al
google-mentornet	MentorNet Framework	2010 | SPCL linear  Jiang et al
google-mentornet	MentorNet Framework	2015 | Hard example mining  Felzenszwalb et al., 2008  | ! image  images/hard_example_mining.gif  | Favor samples of greater loss.| Focal loss  Lin et al., 2017 | Predefined Mixture| MentorNet Data-drivenprediction variance  Chang et al., 2017 , implicit regularizer  Fan et al
google-mentornet	MentorNet Framework	2017 , self-paced with diversity  Jiang et al
google-mentornet	MentorNet Framework	2014 ,sample re-weighting  Dehghani et al., 2018, Ren et al., 2018 , etc.*The numbers are slightly different from the ones reported in the paper due tothe re-implementation on the third party library.***CIFAR-10 ResNet**| noise_fraction| baseline | self_paced | focal_loss | mentornet_pd| mentornet_dd || ----------: | -------: | ---------: | ---------: | ---------: | -----------: || 0.2| 0.4| 0.8**CIFAR-100 ResNet**| noise_fraction| baseline | self_paced | focal_loss | mentornet_pd| mentornet_dd || ----------: | -------: | ---------: | ---------: | ---------: | -----------: || 0.2| 0.4| 0.8**CIFAR-10 Inception**| noise_fraction| baseline | self_paced | focal_loss | mentornet_pd | mentornet_dd|| ----------: | -------: | ---------: | ---------: | -----------: | ---------: || 0.2| 0.4| 0.8**CIFAR-100 Inception**| noise_fraction| baseline | self_paced | focal_loss | mentornet_pd | mentornet_dd|| ----------: | -------: | ---------: | ---------: | -----------: | ---------: || 0.2| 0.4| 0.8
google-mentornet	Algorithm	We propose an algorithm to optimize the StudentNet model parameter w jointly with agiven MentorNet
google-mentornet	Algorithm	Unlike the alternating minimization, it minimizes w  StudentNet parameter  and v  sample weight  **stochastically over mini-batches**.The curriculum can change during training, and MentorNet is updated a few times in the algorithm.! Algorithm  images/alg.gif To learn new curriculums  Step 6 , see  this page  TRAINING.md .*We found specific MentorNet architectures do not matter that much.*
google-merge_pyi	Regression tests	testdata/foo.py  : input we want to annotatetestdata/foo.pyi : type hints we want to add to foo.py  may be intentionally bad testdata/foo.comment.py : expected output, inserting types as commentstestdata/foo.pep484.py  : expected output, inserting types in PEP484 style
google-meta_tagger	Software and hardware requirements	This code is based on the paper:Maynez
google-meta_tagger	Software and hardware requirements	Morphosyntactic Tagging with a Meta-BiLSTM Model over Context Sensitive Token Encodings
google-meta_tagger	Software and hardware requirements	ACL, Our tagger **ranked 1st*had strong results for many languages on upos tags
google-meta_tagger	Software and hardware requirements	The tagger is especially strongfor cases where a wider context is required to determine the correct tag as for xpos and morphological features tagging.Bernd Bohnet, Ryan McDonald, Gonçalo Simões, Daniel Andor, Emily Pitler, JoshuaMaynez, Terry Koo.
google-meta_tagger	Training a tagger	python train_cw.py --train='en-wsj-std-train-stanford-3.3.0.conll' \--dev='en-wsj-std-dev-stanford-3.3.0.conll' \--embeddings='glove.6B.100d.txt' \--task='xtag' \The paths need to be adapted
google-meta_tagger	Training a tagger	The 'config.json' file contains the settings for the hyperparamerters
google-meta_tagger	Training a tagger	The settings for the number of LSTM layers, cells, etc
google-meta_tagger	Training a tagger	are smaller than the sizes used in the paper.The input and output files are in CoNLL-U format:The tagger supports three tasks: --task='upos' | 'xtag' | 'feats'
google-meta_tagger	Applying a tagger	python test_cw.py --test='en-wsj-std-test-stanford-3.3.0.conll' \--task='xtag' \--output_dir='model_save_dir' \
google-metallb	MetalLB	MetalLB is a load-balancer implementation for baremetal  Kubernetes  clusters, using standardrouting protocols
google-metallb	MetalLB	! Project maturity: beta    ! license    ! CircleCI    ! Containers    ! Go report card  Check out  MetalLB's website  for more
google-metallb	Contributing	We welcome contributions in all forms
google-metallb	Contributing	Please check out hacking and contributing guide for more information.Participation in this project is subject toa  code of conduct One lightweight way you can contribute is tell us that you're using MetalLB which will give us warm fuzzy feelings : .
google-metallb	Disclaimer	This is not an official Google project, it is just code that happensto be owned by Google.
google-metaserver	Metaserver	 ! Docker Repository on Quay  "Docker Repository on Quay"  **This is not an official Google product**Metaserver provides cloud-init bootstrap data in AWS EC2 metadata server formator NoCloud format
google-metaserver	Metaserver	The data is sourced from VMRegistry and PubkeyStore as
google-meterstick	MeterStick Documentation	The meterstick package provides a concise syntax to describe and executeroutine data analysis tasks.
google-meterstick	Building up an analysis	The .run  .Here is an example of a full analysis:relative to the control arm, for each country and device, together withjackknife standard errors.Repeating an operation group will raise an error.
google-meterstick	Data	Every analysis needs a source of data
google-meterstick	Data	Thus, every analysis objectbegins with Analyze data  which creates an analysis object for thedata data
google-meterstick	Data	Currently only pandas dataframes are supported.
google-meterstick	Subsetting and splitting	The library implements some basic data manipulation operations
google-meterstick	Subsetting and splitting	Ifmore complex data manipulation steps are required, it's suggested topreprocess the dataset using more specialized tools before starting toanalyze the data.The where query  method applies the analysis only to the subset of the datawhere the query is true
google-meterstick	Subsetting and splitting	The query should be a string which, in the context ofthe dataframe, evaluates to an array of booleans
google-meterstick	Subsetting and splitting	Thus, where "Device in 'desktop', 'mobile' "  will restrict the analysis only to those twodevices
google-meterstick	Subsetting and splitting	Where methods can be chained and are combined by an implicit "and".The mobile separately.
google-meterstick	Comparison functions	A function which takes a metric and compares them across subgroupsis a comparison function.These are added by the condition argument is a string for the variable which represents theconditions that are to be compared
google-meterstick	Comparison functions	 The baseline argument is thevalue of the condition variable which will be designated as thebaseline against which to compare.Currently supported comparisons include:+   PercentageDifference condition, baseline  : Computes the percent+   AbsoluteDifference condition, baseline  : Computes the absolute+   MH condition, baseline, index  : Computes theA common use case would berelative_to PercentageDifference 'Experimental Condition','Control'  
google-meterstick	Standard error functions	A function which takes a metric or comparison and calculatesstandard errors is a standard error function.Standard error functions are added to an analysis using thewith_standard_errors standard_error_function  method.Currently implemented standard error functions include:+   Jackknife unit, leave_out  : Computes a leave-one-out jackknife+   Bootstrap num_replicates, unit  : Computes a bootstrap estimateA sample usage is with_standard_errors Jackknife    which will addthe leave-one-out jackknife on rows.
google-meterstick	Metrics	The calculate   method specifies what metrics to calculate.A function which takes a dataframe and returns a result  usually a singlenumber  is a metric
google-meterstick	Metrics	 These are added by the calculate metric Currently supported metrics include:+   Sum variable  : calculates the sum of variable+   Mean variable : calculates the mean of variable+   Weighted Mean variable, weight_variable  : calculates the+   Ratio numerator, denominator  : calculates Sum numerator  /+   Quantile variable, quantile : calculates the quantile quantile+   Variance variable, unbiased=True : calculates the variance of variable;+   StandardDeviation variable, unbiased=True : calculates the standard+   Correlation variable1, variable2 : calculates the Pearson correction+   CV variable, unbiased=True : calculates the coefficient of variation ofAll metrics have an optional name argument which determines the column namefor results
google-meterstick	Metrics	If not specified, a default value will be provided
google-meterstick	Metrics	For instance,the metric Sum "Clicks"  will have default name sum Clicks .Common metrics can be implemented  modulo variable names  as follows:+   Click-through rate: Ratio 'Clicks', 'Impressions', name = 'CTR' +   Conversion rate: Ratio 'Conversions', 'Visits', name = 'CvR' +   Bounce rate: Ratio 'Bounce', 'Visits', name='BounceRate' +   Cost per click  CPC : Ratio 'Cost', 'Clicks', name = 'CPC' 
google-meterstick	Running the Analysis	The previous operations merely set up the analysis
google-meterstick	Running the Analysis	To actually run theanalysis, call .run   at the very end.
google-metrosvg	#MetroSVG	MetroSVG is a production-quality SVG renderer implementation for iOSand OS X
google-metrosvg	#MetroSVG	It is used in Google Maps for iOS.The library provides an Objective-C interface for iOS and a Cinterface for iOS and OS X.
google-metrosvg	##Supported Features	MetroSVG is intended to cover the most common use cases of SVG in native iOS app development where designers create and export image assets using graphics tools such as Illustrator and Inkscape
google-metrosvg	##Supported Features	Therefore, it is specialized for rendering of static images by design
google-metrosvg	##Supported Features	Below is a list of SVG 1.1 features and their implementation status.Feature | StatusPaths and Basic Shapes | Feature complete.Coordinate Systems and Transformations | Feature complete.Gradients | Near feature complete.Fill and Stroke Properties | Near feature complete.Document Structure | Only &lt;svg&gt; and &lt;g&gt; are implemented.Styling  CSS  | An experimental implementation of class selector is available.Clipping, Masking, Patterns, Markers, Length Units | Not implemented.Text, Fonts, Filter Effects | Not implemented
google-metrosvg	##Supported Features	Recommended to use other options.Color Profile, Linking, Interactivity, Scripting, Animation | Out of scope.
google-metrosvg	##Discussion Forum	MetroSVG is not an official Google product.
google-microdhcpd	MicroDHCPd	 ! Docker Repository on Quay  "Docker Repository on Quay"  **This is not an official Google product**MicroDHCPd provides DHCP services based on VMRegistry data.
google-microscopeimagequality	How to	Generate additional labeled training examples of defocused images using degrade.py.Launch microscopeimagequality fit to train a model.Launch microscopeimagequality evaluate with a held-out test dataset.Use TensorBoard to view training and eval progress  see evaluation.py .When satisfied with model accuracy, save the model.ckpt files for later use.Example fit:
google-microscopeimagequality	Requirements	images, .png of .tif format, all with the same width and height.
google-minions	Minions	  
google-minions	TL;DR	Minions is a filesystem-based, microservice oriented security scanner.It supports distributed security checks and isolates testing anddata access via  gRPC  can be *easily! High level schema of Minions 
google-minions	Status	We are actively opensourcing existing code and building new one, but the project is yet to hit the first full release  0.1 .Full roadmap  here  roadmap.md .
google-minions	Why does this project matter	Unlike traditional on-host security scanners, Minions minimizes the amount of code that needs to be executed on the target, and it's very easy to implement a new Goblin for a specific environment
google-minions	Why does this project matter	All the complex logic is in the Minions, and users can maintain control of what goes where by running their own Goblin and Overlord.Minions  scanners  also easily supports non-public scanners: adding a new tester using custom technology is as easy as implementing a well defined gRPC API.Minions is not thought to be a full end to end solution on its own: there is no fancy UI, nor dashboards
google-minions	Why does this project matter	It will,however, generate accurate findings that you can ingest in any other system, quickly and at scale
google-minions	Why does this project matter	It's likely mostuseful if you run a large infrastructure.
google-minions	Getting started	You can try the project by running everything on your local box.Install the latest version of  bazel  There are handy packages for most platforms.Check out the project.Run the backend scanning services locally via the execute_local.sh bash script.Scan your local machine by running, in the src directoryMuch like ancient Gaul, a Minions infrastructure is divided in three main components: the Goblins, the Overlord and the Minions.A **Goblin*A **Minion*Finally, the **Overlord*
google-minions	Interests	Separating data-gathering and actual testing of the data seems like a good idea on paper, but in practice has  at least  two main problems:  standard location might point to another configuration file in some directory hidden in a dark corner of the disk.Minions solves this problem with the use of *Interests*
google-minions	Interests	An interest is a way for a Minion to tell a Goblin what it cares about at a given moment
google-minions	Interests	All Minion instances start with a set of initial Interests they always care about, but the list is iteratively updated as they process files they have ingested.THe way this works in practice is that every time a Goblin sends files to an Overlord, it waits until the backend Minions have processed it and can be served back a new list of files to provide 
google-minions	Building and running	Minions is a set of microservices
google-minions	Building and running	You'll have to run at least 2 components to get aything useful: an Overlord, and one or more Minions.
google-minions	Minion	Start by running one or more Minions Each Minion carries its own set of flags and configs, but all need to be pointed to have the Overlord pointed at them, so they should be the first thing to start up.Minion have a *runnerIf you run more than a single replica of a minion, and if a minion keeps state, you'll want to have a shared backend.TODO paradoxengine : explain how one can know and what to do : 
google-minions	Overlord	Once a minion is running, you can start the overlord, the orchestrator of the system.The Overlord expects to be told where its minions are
google-minions	Overlord	Today, this is done simply by specifying as a flag the address of said minions.The overlord will then register with them and get ready to serve data.Assuming you have a minion running on localhost port 20001  the default when you run one , you'd start the Overlord as follows.
google-minions	Minion details: Vulners	The Vulners minion parses package databases on Linux systems to identify the presence of outdated software that carries security vulnerabilities
google-minions	Minion details: Vulners	To do so it needs to parse the RPM backend Sadly, this means that building it is non hermetic, as the system will have to provide the rpm lib
google-minions	Minion details: Vulners	On Debian/Ubuntu system, that means you need to make sure you have the librpm-dev package installed to build it.
google-minions	Goblin	Once you have the address of an Overlord with a set of working Minions you can run a Goblin to feed data to it.The simplest Goblin available is the Local Goblin, which fetches files from the filesystem of the box it runs on
google-minions	Goblin	To run it, enter the main src directory and run the following:We warmly welcome contributions, in particular of additional detectors  which are hopefully fairly easy to write once you get the hang of the APIs 
google-minions	Goblin	Please read the  contributing  CONTRIBUTING.md  policy first.
google-minions	Build environment	Minions has been developed using  Bazel  an opensource build infrastructure by Google
google-minions	Build environment	Bazel can compile multiple languages using a common idiom cross platform, which is a nice property to have for Minions.The Go code also builds and runs with the native compiler
google-minions	Build environment	In fact, one can have both working at the same timeThis is *not
google-mipsqa	README	**This is not an official Google product**This project contains code for training and running an extractive question answering model on the  SQuAD dataset  All methods and models contained in this project are described in the  technical report  Any extensions of this work should cite the report as:To download data, run:Change the directories where the data is stored if needed, and use them for runs below.
google-mipsqa	Train and test  draft mode 	If you are using default directories for the data:First, preprocess train data:--filter filters out very long examples, which can slow down training and cause memory issues.Second, preprocess for test data, which does not filter any example:Third, train a model:In general, --oom_test is a flag for testing if your GPU has enough memory for the model, but it can also serve as a quick test to make sure everything runs.Fourth, test the model:Note that --output_dir has to be changed to --restore_dir, and also --infer flag has been added.Instead of using data from prepro/draft/sort_filter/, it is using prepro/draft/sort_filter/sort, which does not filter any example.This outputs the json file in --restore_dir that is compatible with SQuAD official evaluator.If you want to run this fully  no draft mode , remove --draft and --oom_test flags when applicable.
google-mirandum	mirandum	This is a project designed to allow for the running of a website which willdeliver information about account changes while livestreaming; it usesGoogle's YouTube, Gmail, and Live Streaming  APIs  and eventually others to access information about your account, and provide a web UI for presentingthis information.This is an alternative to software like Stream Warrior/tnotify.The intent is to allow an extensible way to add additional alerting into thisapplication for additional features, e.g
google-mirandum	mirandum	highlighting on hotwords inlivestream chat, connecting to twitter, connecting to other features ofvideos, etc.This tool is designed to replace StreamWarrior for some of its uses, butmay still be useful with a combination of other tools.
google-mirandum	Disclaimer	This is not an official Google product.
google-mobly-bundled-snippets	Usage	 Compile and install the bundled snippets Use the Mobly snippet shell to interact with the bundled snippets To use these snippets within Mobly tests, load it on your AndroidDevice objects
google-mobly-bundled-snippets	Develop	If you want to contribute, use the usual github method of forking and sendinga pull request.Before sending a pull request, run the presubmit target to format and runlint over the code
google-mobly-bundled-snippets	Develop	Fix any issues it indicates
google-mobly-bundled-snippets	Develop	When complete, send the pull googleJavaFormat and run lint
google-mobly-bundled-snippets	Develop	The lint report should open in your default browser.Be sure to address *allrun presubmit one last time you should see:> No Issues Found>   Congratulations!in your browser.
google-mobly-snippet-lib	Getting Started with Snippets for Mobly	Mobly Snippet Lib is a library for triggering device-side code from host-side Mobly  tests
google-mobly-snippet-lib	Getting Started with Snippets for Mobly	This tutorial teaches you how touse the snippet lib to trigger custom device-side actions.Note: Mobly and the snippet lib are not official Google products.
google-mobly-snippet-lib	Overview	The Mobly Snippet Lib allows you to write Java methods that run on Androiddevices, and trigger the methods from inside a Mobly test case
google-mobly-snippet-lib	Overview	The Java methodsinvoked this way are called snippets.The snippet code can either be written in its own standalone apk, or as a product flavor of an existing apk
google-mobly-snippet-lib	Overview	This allows you to write snippets that instrument orautomate another app.
google-mobly-snippet-lib	Under The Hood	A snippet is launched by an InstrumentationRegistry.Once started, the special runner starts a web server which listens for requeststo trigger snippets
google-mobly-snippet-lib	Under The Hood	The server's handler locates the corrsponding methods byreflection, runs them, and returns results over the tcp socket
google-mobly-snippet-lib	Under The Hood	All commonbuilt-in variable types are supported as arguments.
google-mobly-snippet-lib	Usage	The  examples/  examples/  folder contains examples of how to use themobly snippet lib along with detailed tutorials.
google-mobly	Welcome to Mobly	cases that require multiple devices, complex environments, or custom hardwareHere are some example use cases:to plug your own device or custom equipment/service into Mobly.Mobly comes with a set of libs to control common devices like Android devices.While developed by Googlers, Mobly is not an official Google product.
google-mobly	Compatibility	Mobly is compatible with both *python 3.4+Mobly tests could run on the following platforms:| Linux| Windows  |    |
google-mobly	Installation	You can install the released package from pip
google-mobly	Tutorials	To get started with some simple tests, see the  Mobly tutorial  docs/tutorial.md .To get started running single-device Android instrumentation tests with Mobly,see the  instrumentation runner tutorial  docs/instrumentation_tutorial.md .
google-mobly	Mobly Snippet	The Mobly Snippet projects let users better control Android devices.triggering custom device-side code from host-side Mobly tests
google-mobly	Mobly Snippet	You could use existingAndroid libraries like UI Automator and Espresso.of Snippets to allow Mobly tests to control Android devices by exposing a simplifiedversion of the public Android API suitable for testing.
google-module-server	Source Maps	By default all JS responses support  source maps  for optimal debugging with Chrome Dev Tools  Don't forget to activate source map support in the Dev Tools settings 
google-module-server	Source Maps	We recommend to deactivate this for production use, if you only want to provide clients access to obfuscated JS
google-module-server	Setup	See  demo-server.js  demo-server.js  for an example server
google-module-server	Setup	You may want to adapt this to your individual serving stack  such as as for use within express 
google-module-server	Setup	We recommend doing actual serving through a caching reverse proxy CDN network for minimal latency.
google-module-server	Demo	Run node demo-server.js then drag  clients/test/demo.html  clients/test/demo.html  to a browser window.
google-module-server	Client	 clients/module-client.js  clients/module-client.js  provides the in-browser module loader
google-module-server	Client	It depends on $LAB.js but should be easily adaptable to most JS loaders.This will get you started:Whenever you want to do an incremental load of a module, replace require 'foo'  with loadModule 'foo', function foo  { … }  and you are all set.
google-module-server	Compiler	 module-compiler/bin.js  module-compiler/bin.js  is a wrapper around closure compiler for compiling JS for serving with Module Server
google-module-server	Compiler	Run with --help for usage
google-module-server	Compiler	It supports watching a directory tree for automatic compilation when you change your sources and it ships with closure compiler for easy installation.Make sure you have the java binary in your path : See the  INSTALL  module-compiler/INSTALL.md  instructions.
google-module-server	Compilation	Create a file called app.js  or whatever you like  and require all of your top-level modules in it  the ones you actually want to request from your application 
google-module-server	Compilation	This will ensure that everything gets compiled in one go.
google-module-server	Fine print	Pull requests are very much appreciated
google-module-server	Fine print	Please sign the  Google Code contributor license agreement   There is a convenient online form  before submitting
google-module-server	Fine print	 AuthorMalte Ubl  Google Inc
google-module-server	Fine print	  CopyrightCopyright © 2012 Google, Inc
google-module-server	Fine print	 LicenseApache 2.0
google-morphie	Morphie : Data Analysis with Graphs ##	Morphie is a tool that uses graphs to analyze and summarize the content offormatted input data in JSON or CSV format
google-morphie	Morphie : Data Analysis with Graphs ##	The primary use case is to analyzesupertimelines generated by  Plaso which is an open source, forensic analysis tool 
google-morphie	Morphie : Data Analysis with Graphs ##	Morphie currently parsessupertimelines and constructs labeled graphs from them
google-morphie	Morphie : Data Analysis with Graphs ##	There is support forvisualization using  GraphViz 
google-morphie	Disclaimers ###	Morphie uses graph transformations to reduce the amount of structure andcomplexity in a graph constructed from log data
google-morphie	Disclaimers ###	It morphs graphs and moreprecisely, the relationships between the graphs before and after atransformation are given by a kind of homomorphism.
google-morphie	System Requirements ##	In order to build, the following packages must be available in the system
google-morphie	System Requirements ##	 of how Google flags became gflags .
google-morphie	Installation ##	To install, run the following commands:
google-motive	Overview	Motive is an open-source, cross-platform, memory efficient, and performantanimation system.
google-motive	Features	The v1.1 release of Motive focusses on speed and scalability
google-motive	Features	Motive nowsupports rigged character animation and blending between those animations.Motive maintains its aptitude for procedural animation that was the focus of
google-motive	Downloading	Motive can be downloaded from  GitHub  orthe  releases page **Important**: Motive uses submodules to reference other components it dependsupon so download the source using:~~~
google-motive	Dependencies	Motive depends upon:Motive has optional features that depend upon:
google-motive	Notes	For applications on Google Play that integrate this tool, usage is tracked.This tracking is done automatically using the embedded version string inkVersion
google-motive	Notes	Aside from consuming a few extra bytes in your application binary,it shouldn't affect your application at all
google-motive	Notes	 We use this information to let usknow if Motive is useful and if we should continue to invest in it
google-motive	Notes	Since thisis open source, you are free to remove the version string, but we wouldappreciate if you would leave it in
google-motive	Notes	  FplUtil :
google-mozc	 src/data/dictionary_oss/  src/data/dictionary_oss 	See  src/data/dictionary_oss/README.txt  src/data/dictionary_oss/README.txt 
google-mozc	 src/data/test/dictionary/  src/data/test/dictionary 	The same to  src/data/dictionary_oss/  src/data/dictionary_oss .See  src/data/dictionary_oss/README.txt  src/data/dictionary_oss/README.txt 
google-mozc	 src/data/test/stress_test/  src/data/test/stress_test 	Public Domain
google-mozc	 src/data/test/stress_test/  src/data/test/stress_test 	 See the comment in src/data/test/stress_test/sentences.txt  src/data/test/stress_test/sentences.txt 
google-mozc	 src/data/unicode/  src/data/unicode 	UNICODE, INC
google-mozc	 src/data/unicode/  src/data/unicode 	LICENSE AGREEMENT.See each file header for details.
google-mr4c	About MR4C	MR4C is an implementation framework that allows you to run native code within the Hadoop execution framework
google-mr4c	About MR4C	Pairing the performance and flexibility of natively developed algorithms with the unfettered scalability and throughput inherent in Hadoop, MR4C enables large-scale deployment of advanced data processing applications.
google-mr4c	Map to this repo	This repository includes user guide, tutorials and source code for the MR4C framework created by Google Inc.We suggest you run through this repo in the following order:  Test that MR4C install was successful  Build your own algorithm using the examples as templates and let us know if you have questions or comments!There are four scripts included to build, clean, deploy and/or remove mr4c
google-mr4c	Map to this repo	Build with:If you get stuck, have questions, or would like to provide *anyLet’s do big things together.
google-mt	mt 	This is intended to be a modern, minimalist terminal emulator for X with thefollowing design priorities:  database entry.While satisfying these criteria, the terminal should be as small andlow-overhead as possible
google-mt	mt 	Also, it should use any modern software developmenttools that make it easier to work with.
google-mt	Requirements to build	You will need the Xlib header files, CMake, and a modern C++ toolchain
google-mt	Requirements to build	Usingthe Ninja generator of CMake is encouraged.
google-mt	How do I get scrolling functionality?	Using a terminal multiplexer like tmux or screen.
google-mt	Disclaimer	This is not an official Google product.
google-mt	Credits	This is based on the st terminal, but doesn't share the same goals ordevelopment philosophy and so is very likely to diverge
google-mt	Credits	From that project's
google-mtail	mtail 	 ! GoDoc      mtail is a tool for extracting metrics from application logs to be exportedinto a timeseries database or timeseries calculator for alerting andIt aims to fill a niche between applications that do not export their owninternal state, and existing monitoring systems, without patching thoseapplications or rewriting the same framework for custom extraction glue code.The extraction is controlled by  mtail programs  docs/Programming-Guide.md which define patterns and actions:Metrics are exported for scraping by a collector as JSON or Prometheus formatover HTTP, or can be periodically sent to a collectd, StatsD, or Graphitecollector socket.Read the  programming guide  docs/Programming-Guide.md  if you want to learn howto write mtail programs.Mailing list: 
google-mtail	Installation	There are various ways of installing **mtail**.
google-mtail	Precompiled binaries	Precompiled binaries for released versions are available in the Releases page  on Github
google-mtail	Precompiled binaries	Using thelatest production release binary is the recommended way of installing **mtail**.Windows, OSX and Linux binaries are available.
google-mtail	Building from source	To build mtail from the source code yourself you need to have a working Goenvironment with version 1.9 or greater installed, also some additional toolslike goyacc
google-mtail	Building from source	 You can't go get the software and have it build straight away.See the  Build instructions  docs/Building.md  for more details.A Dockerfile is included in this repository for local development as analternative to installing Go in your environment, and takes care of all thebuild dependency installation, if you don't care for that.
google-mtail	Deployment	mtail works best when it paired with a timeseries-based calculator andalerting tool, like  Prometheus > So what you do is you take the metrics from the log files and> you bring them down to the monitoring system? It deals with the instrumentation so the engineers don't haveto!   It has theextraction skills!  It is good at dealing with log files!!
google-mug	MµG	A small Java 8 utilities library   javadoc  with 0 deps
google-mug	MµG	!  Add the following to pom.xml:
google-mug	 BiStream  streams pairs of objects.	This class closely mirrors Jdk Stream API  the few extra methods of "its own" are very straight-forward 
google-mug	 BiStream  streams pairs of objects.	If you are familiar with Jdk stream, learning curve is minimal.**Example 1: to iterate over a stream with indices:**A: Sometimes Foo and Bar are just an arbitrary pair of objects, with no key-value relationship
google-mug	 BiStream  streams pairs of objects.	Or you may not trust Foo#equals   and hashCode  
google-mug	 BiStream  streams pairs of objects.	Instead, drop-in replace your Stream>/List> with BiStream/BiCollection to get better readability.**Q: Why not Stream?**A: When you already have a proper domain object, sure
google-mug	 BiStream  streams pairs of objects.	But you might find it cumbersome to define a bunch of FooAndBar, PatioChairAndKitchenSink one-off classes.**Q: Why not Stream>?**A: It's distracting to read code littered with opaque method names like getFirst   and getSecond  
google-mug	 BiStream  streams pairs of objects.	It's also less efficient because you end up creating lots of temporary Pair objects.
google-mug	 MoreStreams 	**Example 1: to split a stream into smaller-size chunks  batches :**The Stream API provides forEach   to iterate over a stream, if you don't have to throw checked exceptions.When checked exception is in the way, or if you need control flow  continue, return etc
google-mug	 MoreStreams 	, iterateThrough   and iterateOnce   can help
google-mug	 MoreStreams 	The following code uses iterateThrough   to write objects into an ObjectOutputStream, with  IOException propagated:**Example 3: to generate a stream  that can be finite  iteratively:*// Returns next round of elements, or empty to stop generating.private Stream nextValues T currentValue  {  ...Stream stream = MoreStreams.generate seed, this::nextValues ;**Example 4: to merge maps:*interface Page {  Map getTrafficHistogram  ;List pages = ...;// Merge traffic histogram across all pages of the web siteMap siteTrafficHistogram = pages.stream  
google-mug	 Retryer 	Blocking the thread for retry isn't always a good idea at server side
google-mug	 Retryer 	It is however simple and being able to propagate exceptions directly up the call stack is convenient:
google-mug	To retry asynchronously	If getAccount   itself already runs asynchronously and returns CompletionStage, it can be retried using the retryAsync   method.And for demo purpose, let's use Fibonacci backoff strategy, with a bit of randomization in the backoff to avoid bursty traffic, why not?
google-mug	To retry based on return value	Sometimes the API you work with may return error codes instead of throwing exceptions
google-mug	To retry based on return value	Retries can be based on return values too:Or, use a predicate:
google-mug	Backoffs are just List	exponentialBackoff  , fibonacci  , timed   and randomized   are provided out of the box for convenience purpose only
google-mug	Backoffs are just List	But at the end of the day, backoffs are just old-school boring Lists
google-mug	Backoffs are just List	This makes the backoff strategies extensible
google-mug	Backoffs are just List	You can create the List in any way you are used to, using any Java library
google-mug	Backoffs are just List	For example, there isn't a uniformDelay   in this library, because there is already Collections.nCopies n, delay .Or, to concatenate two different backoff strategies together  first uniform and then exponential , the Java 8 Stream API has a good tool for the job:What about to retry infinitely? Collections.nCopies Integer.MAX_VALUE, delay  isn't infinite but close
google-mug	Backoffs are just List	JDK only uses O 1  time and space for creating it; same goes for Delay#exponentialBackoff   and Delay#fibonacci  .
google-mug	To handle retry events	Sometimes the program may need custom handling of retry events, like, for example, to increment a stats counter based on the error code in the exception
google-mug	To handle retry events	Requirements like this can be done with a custom Delay implementation:class RpcDelay extends Delay {  }  }  }return new Retryer  Or, to get access to the retry attempt number, which is also the list's index, here's an example:class RpcDelay extends Delay {  RpcDelay int attempt, Duration duration  {...}  }List> delays = Delay.ofMillis 10 .fibonacci ..
google-mug	To handle retry events	;return new Retryer  
google-mug	To keep track of exceptions	If the method succeeds after retry, the exceptions are by default logged
google-mug	To keep track of exceptions	As shown above, one can override beforeDelay   and afterDelay   to change or suppress the loggging.If the method fails after retry, the exceptions can also be accessed programmatically through exception.getSuppressed  .
google-mug	 Maybe 	Represents a value that may have failed with an exception.Tunnels checked exceptions through streams or futures.
google-mug	Streams	For a stream operation that would have looked like this if checked exception weren't in the way:import static com.google.mu.util.Maybe.byValue;import static com.google.mu.util.Maybe.maybe;Stream> stream = files.stream  List contents = new ArrayList<>  ;Iterate.through stream, m -> contents.add m.orElseThrow    ;return contents;
google-mug	Futures	In asynchronous programming, checked exceptions are wrapped inside ExecutionException or CompletionException
google-mug	Futures	By the time the caller catches it, the static type of the causal exception is already lost
google-mug	Futures	The caller code usually resorts to instanceof MyException
google-mug	Futures	For example, the following code recovers from AuthenticationException:
google-mug	The problem	The following code converts a list of objects:Now assume the input can be of two different kinds, with one kind to be converted through a remote service
google-mug	The problem	Like this:Perhaps this?Tl;Dr: maintaining the encounter order while dispatching objects to batches requires careful juggling of the indices and messes up the code rather quickly.
google-mug	The tool	Funnel is a simple class designed for this use case:That is, define the batches with funnel.through   and then inputs can flow through arbitrary number of batch conversions
google-mug	The tool	Conversion results flow out of the funnel in the same order as inputs entered the funnel
google-mug	 Parallelizer 	Runs a  large  pipeline of tasks in parallel while limiting the number of in-flight tasks.For example, the following snippet uploads a large number of pictures in parallel:Note that this code will terminate if any picture fails to upload
google-mug	 Parallelizer 	If 
google-mug	Why not parallel stream?	Some major shopping-list differences:Again, use case is different:The thread pool queues all pending tasks
google-mug	Why not parallel stream?	If the input stream is too large to fit in memory, you'll get an OutOfMemoryError.Exceptions  including NullPointerException, OutOfMemoryError  are silently swallowed  but may print stack trace 
google-mug	Why not parallel stream?	To propagate the exceptions, the Future objects need to be stored in a list and then Future#get   needs to be called on every future object after all tasks have been submitted to the executor.Tasks submitted to an executor are independent
google-mug	Why not parallel stream?	One task failing doesn't automatically terminate the pipeline.
google-multibox	Multibox Object Detector	This repository contains a reference pre-trained network for the multiboxobject detector, complementing the Google publicationsDumitru Erhan, Christian Szegedy, Alexander Toshev, Dragomir Anguelov.Scalable Object Detection using Deep Neural Networks.Christian Szegedy, Scott Reed, Dumitru Erhan, Dragomir Anguelov.Scalable, High-Quality Object Detection.You can view "multibox.ipynb" directly on github, or clone therepository, install dependencies listed in the notebook and play with codeDisclaimer: this is not an official Google product  experimental or otherwise .
google-multichannel-audio-tools	Multichannel Audio Tools	 This is not an official Google product! Multichannel Audio Tools contains common signal processing building blocks,vectorized for multichannel processing using Eigen A non-exhaustive list of libraries in this repo:This library is intended to be built with  Bazel  Seecommand below regarding running tests and building with the proper flags.
google-mysql-protobuf	Getting started	Install the following packages:Clone this repo:Go to mysql-protobuf folder and create a new bin folder:Compile the project
google-mysql-protobuf	Getting started	For that, you have to run cmake and then make:Create a folder where you'll run mysqld:Copy mysqld to this folder:Copy errmsg.sys file to share folder:Create a tmpdir folder:Initialize mysqld:Run mysqld:Open another terminal and connect to mysqld:For examples of usage, please see our  wiki 
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Text of Copyright.txt mentioned above:CMake Copyright 2000-2009 Kitware, Inc., Insight Software ConsortiumAll rights reserved.Redistribution and use in source and binary forms, with or withoutmodification, are permitted provided that the following conditionsare met:  documentation and/or other materials provided with the distribution
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 products derived from this software without specific prior written  permission.THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOTLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FORA PARTICULAR PURPOSE ARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IN NO EVENT SHALL THE COPYRIGHTHOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  INCLUDING, BUT NOTLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,DATA, OR PROFITS; OR BUSINESS INTERRUPTION  HOWEVER CAUSED AND ON ANYTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT INCLUDING NEGLIGENCE OR OTHERWISE  ARISING IN ANY WAY OUT OF THE USEOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:CMake is distributed under BSD LicenseAdditional License s  gethostname.c: minimal substitute for missing gethostname   function created 2000-Mar-02 jmk requires SVR4 uname   and -lc by Jim Knoble  Copyright ? 2000 Jim Knoble Permission to use, copy, modify, distribute, and sell this software and its documentation for any purpose is hereby granted without fee, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This software is provided "as is", without warranty of any kind, express or implied, including but not limited to the warranties of merchantability, fitness for a particular purpose and noninfringement
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	In no event shall the author s  be liable for any claim, damages or other liability, whether in an action of contract, tort or otherwise, arising from, out of or in connection with the software or the use or other dealings in the software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	THIS CODE IS SPECIFICALLY EXEMPTED FROM THE NCURSES PACKAGE COPYRIGHT
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	You may freely copy it for use as a template for your own field types
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If you develop a field type that might be of general use, please send it back to the ncurses maintainers for inclusion in the next version
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	  See ITKCopyright.txt or  for  details
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Skeleton parser for Yacc-like parsing with Bison, zlib.h -  version 1.1.4, March 11th, 2002  warranty
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 In no event will the authors be held liable for any damages  arising from the use of this software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 including commercial applications, and to alter it and redistribute it  freely, subject to the following restrictions:  Altered source versions must be plainly marked as such, and must  This notice may not be removed or altered from any source This source code was modified by Martin Hedenfalk for use in Curl
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	His latest changes were done 2000-09- It has since been patched away like a madman by Daniel Stenberg to make it better applied to curl conditions, and to make it not use globals, pollute name space and more
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This source code awaits a rewrite to work around the paragraph 2 in the BSD licenses as explained below
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1995, 1996, 1997, 1998, 1999 Kungliga Tekniska Hgskolan It has since been patched and modified a lot by Daniel Stenberg to make it better applied to curl conditions, and to make it not use globals, pollute name space and more
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This source code awaits a rewrite to work around the paragraph 2 in the BSD licenses as explained below
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1998, 1999 Kungliga Tekniska Hgskolan  Royal Institute of Technology, Stockholm, Sweden 
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	All rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright Redistributions in binary form must reproduce the above copyright Neither the name of the Institute nor the names of its contributors THIS SOFTWARE IS PROVIDED BY THE INSTITUTE AND CONTRIBUTORS AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 IN NO EVENT SHALL THE INSTITUTE OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  INCLUDING NEGLIGENCE OR OTHERWISE  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Permission to use, copy, modify, and distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	THIS SOFTWARE IS PROVIDED AS IS'' AND WITHOUT ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF MERCHANTIBILITY AND FITNESS FOR A PARTICULAR PURPOSE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	THE AUTHORS AND CONTRIBUTORS ACCEPT NO RESPONSIBILITY IN ANY CONCEIVABLE MANNER.cmake-2.4.8/Source/CTest/Curl/inet_pton.c: This is from the BIND 4.9.4 release, modified to compile by itself Permission to use, copy, modify, and distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	THE SOFTWARE IS PROVIDED "AS IS" AND INTERNET SOFTWARE CONSORTIUM DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IN NO EVENT SHALL INTERNET SOFTWARE CONSORTIUM BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1994  The Regents of the University of California
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 All rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This code is derived from software contributed to Berkeley by Chuck Karish of Mindcraft, Inc
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright Redistributions in binary form must reproduce the above copyright Neither the name of the University nor the names of its contributors Copyright  c  1985, 1986 The Regents of the University of California
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	All rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This code is derived from software contributed to Berkeley by James A
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Woods, derived from original work by Spencer Thomas and Joseph Orost
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1989, 1993, 1994  The Regents of the University of California
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 All rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This code is derived from software contributed to Berkeley by Guido van Rossum
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1990 The Regents of the University of California
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	All rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright Redistributions in binary form must reproduce the above copyright All advertising materials mentioning features or use of this software Neither the name of the University nor the names of its contributors THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  INCLUDING NEGLIGENCE OR OTHERWISE  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  C  1998 This software is licensed as described in the file COPYING, which you should have received as part of this distribution
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	The terms are also available at copies of the Software, and permit persons to whom the Software is furnished to do so, under the terms of the COPYING file
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This software is distributed on an "AS IS" basis, WITHOUT WARRANTY OF ANY KIND, either express or implied
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1998,2000 Free Software Foundation, Inc
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	copy of this software and associated documentation files  the "Software" , to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, distribute with modifications, sublicense, and/or sell  copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: all copies or substantial portions of the Software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 IN NO EVENT SHALL THE ABOVE COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	holders shall not be used in advertising or otherwise to promote the sale, use or other dealings in this Software without prior written authorization
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Copyright  c  1997 Todd C
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Miller  All rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright Redistributions in binary form must reproduce the above copyright The name of the author may not be used to endorse or promote products THIS SOFTWARE IS PROVIDED AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  INCLUDING NEGLIGENCE OR OTHERWISE  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  INCLUDING NEGLIGENCE OR OTHERWISE  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.Fred Fish's Dbug LibraryUse of any of this software is governed by the terms of the license below:%%The following software may be included in this product:dbug_analyze.c  part of Fred Fish's Dbug Library Use of any of this software is governed by the terms of the license below:%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:GNU GENERAL PUBLIC LICENSEVersion 2, June 1991Copyright  C  1989, 1991 Free Software Foundation, Inc
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USAEveryone is permitted to copy and distribute verbatim copiesof this license document, but changing it is not allowed.The licenses for most software are designed to take away your freedom to shareand change it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	By contrast, the GNU General Public License is intended toguarantee your freedom to share and change free software--to make sure thesoftware is free for all its users
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This General Public License applies to mostof the Free Software Foundation's software and to any other program whoseauthors commit to using it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Some other Free Software Foundation software iscovered by the GNU Lesser General Public License instead
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 You can apply it toyour programs, too.When we speak of free software, we are referring to freedom, not price
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	OurGeneral Public Licenses are designed to make sure that you have the freedom todistribute copies of free software  and charge for this service if you wish ,that you receive source code or can get it if you want it, that you can changethe software or use pieces of it in new free programs; and that you know you cando these things.To protect your rights, we need to make restrictions that forbid anyone to denyyou these rights or to ask you to surrender the rights
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	These restrictionstranslate to certain responsibilities for you if you distribute copies of thesoftware, or if you modify it.For example, if you distribute copies of such a program, whether gratis or for afee, you must give the recipients all the rights that you have
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	You must makesure that they, too, receive or can get the source code
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	And you must show themthese terms so they know their rights.We protect your rights with two steps:  1  copyright the software, and  2  offeryou this license which gives you legal permission to copy, distribute and/ormodify the software.Also, for each author's protection and ours, we want to make certain thateveryone understands that there is no warranty for this free software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If thesoftware is modified by someone else and passed on, we want its recipients toknow that what they have is not the original, so that any problems introduced byothers will not reflect on the original authors' reputations.Finally, any free program is threatened constantly by software patents
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	We wishto avoid the danger that redistributors of a free program will individuallyobtain patent licenses, in effect making the program proprietary
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	To preventthis, we have made it clear that any patent must be licensed for everyone's freeuse or not licensed at all.The precise terms and conditions for copying, distribution and modification follow.TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATIONThis License applies to any program or other work which contains a noticeplaced by the copyright holder saying it may be distributed under the terms ofthis General Public License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	The "Program", below, refers to any such program orwork, and a "work based on the Program" means either the Program or anyderivative work under copyright law: that is to say, a work containing theProgram or a portion of it, either verbatim or with modifications and/ortranslated into another language
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Hereinafter, translation is included withoutlimitation in the term "modification"
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Each licensee is addressed as "you".Activities other than copying, distribution and modification are not covered bythis License; they are outside its scope
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	The act of running the Program is notrestricted, and the output from the Program is covered only if its contentsconstitute a work based on the Program  independent of having been made byrunning the Program 
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Whether that is true depends on what the Program does.You may copy and distribute verbatim copies of the Program's source code asyou receive it, in any medium, provided that you conspicuously and appropriatelypublish on each copy an appropriate copyright notice and disclaimer of warranty;keep intact all the notices that refer to this License and to the absence of anywarranty; and give any other recipients of the Program a copy of this Licensealong with the Program.You may charge a fee for the physical act of transferring a copy, and you may atyour option offer warranty protection in exchange for a fee.You may modify your copy or copies of the Program or any portion of it, thusforming a work based on the Program, and copy and distribute such modificationsor work under the terms of Section 1 above, provided that you also meet all ofthese conditions:you changed the files and the date of any change.in part contains or is derived from the Program or any part thereof, to belicensed as a whole at no charge to all third parties under the terms of thisyou must cause it, when started running for such interactive use in the mostordinary way, to print or display an announcement including an appropriatecopyright notice and a notice that there is no warranty  or else, saying thatyou provide a warranty  and that users may redistribute the program under theseconditions, and telling the user how to view a copy of this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Exception:if the Program itself is interactive but does not normally print such anannouncement, your work based on the Program is not required to print anannouncement
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 These requirements apply to the modified work as a whole
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If identifiablesections of that work are not derived from the Program, and can be reasonablyconsidered independent and separate works in themselves, then this License, andits terms, do not apply to those sections when you distribute them as separateworks
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	But when you distribute the same sections as part of a whole which is awork based on the Program, the distribution of the whole must be on the terms ofthis License, whose permissions for other licensees extend to the entire whole,and thus to each and every part regardless of who wrote it.Thus, it is not the intent of this section to claim rights or contest yourrights to work written entirely by you; rather, the intent is to exercise theright to control the distribution of derivative or collective works based on theIn addition, mere aggregation of another work not based on the Program with theProgram  or with a work based on the Program  on a volume of a storage ordistribution medium does not bring the other work under the scope of this License.You may copy and distribute the Program  or a work based on it, under Section2  in object code or executable form under the terms of Sections 1 and 2 aboveprovided that you also do one of the following:code, which must be distributed under the terms of Sections 1 and 2 above on amedium customarily used for software interchange; or,give any third party, for a charge no more than your cost of physicallyperforming source distribution, a complete machine-readable copy of thecorresponding source code, to be distributed under the terms of Sections 1 and 2above on a medium customarily used for software interchange; or,distribute corresponding source code
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 This alternative is allowed only fornoncommercial distribution and only if you received the program in object codeor executable form with such an offer, in accord with Subsection b above
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 The source code for a work means the preferred form of the work for makingmodifications to it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	For an executable work, complete source code means all thesource code for all modules it contains, plus any associated interfacedefinition files, plus the scripts used to control compilation and installationof the executable
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	However, as a special exception, the source code distributedneed not include anything that is normally distributed  in either source orbinary form  with the major components  compiler, kernel, and so on  of theoperating system on which the executable runs, unless that component itselfaccompanies the executable.If distribution of executable or object code is made by offering access to copyfrom a designated place, then offering equivalent access to copy the source codefrom the same place counts as distribution of the source code, even though thirdparties are not compelled to copy the source along with the object code.You may not copy, modify, sublicense, or distribute the Program except asexpressly provided under this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Any attempt otherwise to copy, modify,sublicense or distribute the Program is void, and will automatically terminateyour rights under this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	However, parties who have received copies, orrights, from you under this License will not have their licenses terminated solong as such parties remain in full compliance.You are not required to accept this License, since you have not signed it.However, nothing else grants you permission to modify or distribute the Programor its derivative works
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	These actions are prohibited by law if you do notaccept this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Therefore, by modifying or distributing the Program  or anywork based on the Program , you indicate your acceptance of this License to doso, and all its terms and conditions for copying, distributing or modifying theProgram or works based on it.Each time you redistribute the Program  or any work based on the Program ,the recipient automatically receives a license from the original licensor tocopy, distribute or modify the Program subject to these terms and conditions.You may not impose any further restrictions on the recipients' exercise of therights granted herein
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	You are not responsible for enforcing compliance by thirdparties to this License.If, as a consequence of a court judgment or allegation of patent infringementor for any other reason  not limited to patent issues , conditions are imposedon you  whether by court order, agreement or otherwise  that contradict theconditions of this License, they do not excuse you from the conditions of thisLicense
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If you cannot distribute so as to satisfy simultaneously yourobligations under this License and any other pertinent obligations, then as aconsequence you may not distribute the Program at all
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	For example, if a patentlicense would not permit royalty-free redistribution of the Program by all thosewho receive copies directly or indirectly through you, then the only way youcould satisfy both it and this License would be to refrain entirely fromdistribution of the Program.If any portion of this section is held invalid or unenforceable under anyparticular circumstance, the balance of the section is intended to apply and thesection as a whole is intended to apply in other circumstances.It is not the purpose of this section to induce you to infringe any patents orother property right claims or to contest validity of any such claims; thissection has the sole purpose of protecting the integrity of the free softwaredistribution system, which is implemented by public license practices
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Manypeople have made generous contributions to the wide range of softwaredistributed through that system in reliance on consistent application of thatsystem; it is up to the author/donor to decide if he or she is willing todistribute software through any other system and a licensee cannot impose thatThis section is intended to make thoroughly clear what is believed to be aconsequence of the rest of this License.If the distribution and/or use of the Program is restricted in certaincountries either by patents or by copyrighted interfaces, the original copyrightholder who places the Program under this License may add an explicitgeographical distribution limitation excluding those countries, so thatdistribution is permitted only in or among countries not thus excluded
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	In suchcase, this License incorporates the limitation as if written in the body of thisThe Free Software Foundation may publish revised and/or new versions of theGeneral Public License from time to time
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Such new versions will be similar inspirit to the present version, but may differ in detail to address new problemsor concerns.Each version is given a distinguishing version number
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If the Program specifiesa version number of this License which applies to it and "any later version",you have the option of following the terms and conditions either of that versionor of any later version published by the Free Software Foundation
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If theProgram does not specify a version number of this License, you may choose anyversion ever published by the Free Software Foundation.If you wish to incorporate parts of the Program into other free programswhose distribution conditions are different, write to the author to ask forpermission
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	For software which is copyrighted by the Free Software Foundation,write to the Free Software Foundation; we sometimes make exceptions for this.Our decision will be guided by the two goals of preserving the free status ofall derivatives of our free software and of promoting the sharing and reuse ofsoftware generally.NO WARRANTYBECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY FOR THEPROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	EXCEPT WHEN OTHERWISE STATEDIN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "ASIS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUTNOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR APARTICULAR PURPOSE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THEPROGRAM IS WITH YOU
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OFALL NECESSARY SERVICING, REPAIR OR CORRECTION.IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING WILLANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR REDISTRIBUTE THEPROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY GENERAL,SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE USE OR INABILITYTO USE THE PROGRAM  INCLUDING BUT NOT LIMITED TO LOSS OF DATA OR DATA BEINGRENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD PARTIES OR A FAILURE OFTHE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS , EVEN IF SUCH HOLDER OR OTHERPARTY HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.END OF TERMS AND CONDITIONSHow to Apply These Terms to Your New ProgramsIf you develop a new program, and you want it to be of the greatest possible useto the public, the best way to achieve this is to make it free software whicheveryone can redistribute and change under these terms.To do so, attach the following notices to the program
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	It is safest to attachthem to the start of each source file to most effectively convey the exclusionof warranty; and each file should have at least the "copyright" line and apointer to where the full notice is found.one line to give the program's name and an idea of what it does.Copyright  C  yyyy  name of authorThis program is free software; you can redistribute it and/ormodify it under the terms of the GNU General Public Licenseas published by the Free Software Foundation; either version 2of the License, or  at your option  any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program; if not, write to the Free SoftwareFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.Also add information on how to contact you by electronic and paper mail.If the program is interactive, make it output a short notice like this when itstarts in an interactive mode:Gnomovision version 69, Copyright  C  year name of authorGnomovision comes with ABSOLUTELY NO WARRANTY; for detailstype show w'
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 This is free software, and you are welcometo redistribute it under certain conditions; type show c' for details.The hypothetical commands show w' and show c' should show the appropriateparts of the General Public License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Of course, the commands you use may becalled something other than show w' and show c'; they could even bemouse-clicks or menu items--whatever suits your program.You should also get your employer  if you work as a programmer  or your school,if any, to sign a "copyright disclaimer" for the program, if necessary
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Here isa sample; alter the names:Yoyodyne, Inc., hereby disclaims all copyrightinterest in the program Gnomovision' which makes passes at compilers  written by James Hacker.signature of Ty Coon, 1 April 1989Ty Coon, President of ViceThis General Public License does not permit incorporating your program intoproprietary programs
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If your program is a subroutine library, you may considerit more useful to permit linking proprietary applications with the library
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Ifthis is what you want to do, use the GNU Lesser General Public License insteadof this License.Additional Documentation License s innochecksum.c is documented in the MySQL ReferenceManual at The Reference Manual is not licensed under the GPL; rather, itis offered under normal copyright, but with permission tocopy/redistribute electronically.%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:*/%%The following software may be included in this product:Richard A
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	O'Keefe strings packageUse of any of this software is governed by the terms of the license below:These files are in the public domain
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 This includes getopt.c, whichis the work of Henry Spencer, University of Toronto Zoology, who says ofit "None of this software is derived from Bell software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	I had no accessto the source for Bell's versions at the time I wrote it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 This softwareis hereby explicitly placed in the public domain
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 It may  be  used  forany purpose on any machine by anyone." I would greatly prefer it if *my%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:  Copyright  C  1998 by Theppitak Karoonboonyanan, all rights reserved
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Permission to use, copy, modify, distribute and sell this software%%The following software may be included in this product:SHA-1 in CUse of any of this software is governed by the terms of the license below:Additional License s 100% Public Domain%%The following software may be included in this product:The tz databaseUse of any of this software is governed by the terms of the license below:Sources for Time Zone and Daylight Saving Time Data@ # tz-link.htm 7.54Please send corrections to this web page to the time zone mailing list.The tz databaseThe public-domain time zone database contains code and data that represent thehistory of local time for many representative locations around the globe
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	It isupdated periodically to reflect changes made by political bodies to time zoneboundaries, UTC offsets, and daylight-saving rules
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	This database  often calledtz or zoneinfo  is used by several implementations, including the GNU C Libraryused in GNU/Linux, FreeBSD, NetBSD, OpenBSD, Cygwin, DJGPP, HP-UX, IRIX, Mac OSX, OpenVMS, Solaris, Tru64, and UnixWare.Each location in the database represents a national region where all clockskeeping local time have agreed since Locations are identified by continentor ocean and then by the name of the location, which is typically the largestcity within the region
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	For example, America/New_York represents most of the USeastern time zone; America/Phoenix represents most of Arizona, which usesmountain time without daylight saving time  DST ; America/Detroit representsmost of Michigan, which uses eastern time but with different DST rules in 1975;and other entries represent smaller regions like Starke County, Indiana, whichswitched from central to eastern time in 1991 and switched back in To usethe database on an extended POSIX implementation set the TZ environment variableto the location's full name, e.g., TZ="America/New_York".In the tz database's FTP distribution the code is in the file tzcodeC.tar.gz,where C is the code's version; similarly, the data are in tzdataD.tar.gz, whereD is the data's version
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	The following shell commands download these files to aGNU/Linux or similar host; see the downloaded README file for what to do next.wget 'gzip -dc tzcode*.tar.gz | tar -xf The code lets you compile the tz source files into machine-readable binaryfiles, one for each location
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	It also lets you read a tz binary file andinterpret time stamps for that location.The data are by no means authoritative
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	If you find errors, please send changesto the time zone mailing list
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	You can also subscribe to the mailing list,retrieve the archive of old messages  in gzip compressed format , or retrievearchived older versions of code and data; there is also a smaller HTTP mirror.%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:Unicode Terms of UseEXHIBIT 1UNICODE, INC
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	LICENSE AGREEMENT  and 
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	Unicode Software includes any source codepublished in the Unicode Standard or under the directories  andDOWNLOADING, INSTALLING, COPYING OR OTHERWISE USING UNICODE INC.'S DATA FILES "DATA FILES" , AND/OR SOFTWARE  "SOFTWARE" , YOU UNEQUIVOCALLY ACCEPT, ANDAGREE TO BE BOUND BY, ALL OF THE TERMS AND CONDITIONS OF THIS AGREEMENT
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IF YOUDO NOT AGREE, DO NOT DOWNLOAD, INSTALL, COPY, DISTRIBUTE OR USE THE DATA FILESOR SOFTWARE.the Terms of Use inof the Unicode data files and any associated documentation  the "Data Files"  orUnicode software and any associated documentation  the "Software"  to deal inthe Data Files or Software without restriction, including without limitation therights to use, copy, modify, merge, publish, distribute, and/or sell copies ofthe Data Files or Software, and to permit persons to whom the Data Files orSoftware are furnished to do so, provided that  a  the above copyright notice s and this permission notice appear with all copies of the Data Files or Software, b  both the above copyright notice s  and this permission notice appear inassociated documentation, and  c  there is clear notice in each modified DataFile or in the Software as well as in the documentation associated with the DataFile s  or Software that the data or software has been modified.KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OFMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT OF THIRDPARTY RIGHTS
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THISNOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIALDAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS,WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISINGOUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THE DATA FILES OR SOFTWARE.be used in advertising or otherwise to promote the sale, use or other dealingsin these Data Files or Software without prior written authorization of thecopyright holder.registered in some jurisdictions
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	All other trademarks and registered trademarksmentioned herein are the property of their respective owners.%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:  version 1.2.3, July 18th, 2005  warranty
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 In no event will the authors be held liable for any damages  arising from the use of this software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 including commercial applications, and to alter it and redistribute it  freely, subject to the following restrictions:  Altered source versions must be plainly marked as such, and must not be  This notice may not be removed or altered from any source distribution
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Mark Adler madler@alumni.caltech.edu%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:  permission notice:  purpose without fee is hereby granted, provided that this entire  notice is included in all copies of any software which is or includes a copy  or modification of this software and in all copies of the supporting  documentation for such software
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 WARRANTY
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 IN PARTICULAR, NEITHER THE AUTHOR NOR LUCENT MAKES ANY  REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY  OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	***************************************************************/%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:%%The following software may be included in this product:MD5 message-digest algorithm  md5_hash.cpp Use of any of this software is governed by the terms of the license below:%%The following software may be included in this product:Use of any of this software is governed by the terms of the license below:  Windows NT Service class library
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 This file is public domain and comes with NO WARRANTY of any kind%%The following software may be included in this product:GNU ReadlineUse of any of this software is governed by the terms of the license below:GNU GENERAL PUBLIC LICENSE Copyright  C  1989, 1991 Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed.freedom to share and change it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 By contrast, the GNU General PublicLicense is intended to guarantee your freedom to share and change freesoftware--to make sure the software is free for all its users
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 ThisGeneral Public License applies to most of the Free SoftwareFoundation's software and to any other program whose authors commit tousing it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	  Some other Free Software Foundation software is covered bythe GNU Lesser General Public License instead
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	  You can apply it toyour programs, too.price
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Our General Public Licenses are designed to make sure that youhave the freedom to distribute copies of free software  and charge forthis service if you wish , that you receive source code or can get itif you want it, that you can change the software or use pieces of itin new free programs; and that you know you can do these things.anyone to deny you these rights or to ask you to surrender the rights.These restrictions translate to certain responsibilities for you if youdistribute copies of the software, or if you modify it.gratis or for a fee, you must give the recipients all the rights thatyou have
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 You must make sure that they, too, receive or can get thesource code
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 And you must show them these terms so they know their 2  offer you this license which gives you legal permission to copy,distribute and/or modify the software.that everyone understands that there is no warranty for this freesoftware
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 If the software is modified by someone else and passed on, wewant its recipients to know that what they have is not the original, sothat any problems introduced by others will not reflect on the originalauthors' reputations.patents
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 We wish to avoid the danger that redistributors of a freeprogram will individually obtain patent licenses, in effect making theprogram proprietary
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 To prevent this, we have made it clear that anypatent must be licensed for everyone's free use or not licensed at all.modification follow.a notice placed by the copyright holder saying it may be distributedunder the terms of this General Public License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 The "Program", below,refers to any such program or work, and a "work based on the Program"means either the Program or any derivative work under copyright law:that is to say, a work containing the Program or a portion of it,either verbatim or with modifications and/or translated into anotherlanguage
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	  Hereinafter, translation is included without limitation inthe term "modification"
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	  Each licensee is addressed as "you".Activities other than copying, distribution and modification are notcovered by this License; they are outside its scope
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 The act ofrunning the Program is not restricted, and the output from the Programis covered only if its contents constitute a work based on theProgram  independent of having been made by running the Program .Whether that is true depends on what the Program does.source code as you receive it, in any medium, provided that youconspicuously and appropriately publish on each copy an appropriatecopyright notice and disclaimer of warranty; keep intact all thenotices that refer to this License and to the absence of any warranty;and give any other recipients of the Program a copy of this Licensealong with the Program.You may charge a fee for the physical act of transferring a copy, andyou may at your option offer warranty protection in exchange for a fee.of it, thus forming a work based on the Program, and copy anddistribute such modifications or work under the terms of Section 1above, provided that you also meet all of these conditions:These requirements apply to the modified work as a whole
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Ifidentifiable sections of that work are not derived from the Program,and can be reasonably considered independent and separate works inthemselves, then this License, and its terms, do not apply to thosesections when you distribute them as separate works
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 But when youdistribute the same sections as part of a whole which is a work basedon the Program, the distribution of the whole must be on the terms ofthis License, whose permissions for other licensees extend to theentire whole, and thus to each and every part regardless of who wrote it.Thus, it is not the intent of this section to claim rights or contestyour rights to work written entirely by you; rather, the intent is toexercise the right to control the distribution of derivative orcollective works based on the Program.In addition, mere aggregation of another work not based on the Programwith the Program  or with a work based on the Program  on a volume ofa storage or distribution medium does not bring the other work underthe scope of this License.under Section 2  in object code or executable form under the terms ofSections 1 and 2 above provided that you also do one of the following:The source code for a work means the preferred form of the work formaking modifications to it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 For an executable work, complete sourcecode means all the source code for all modules it contains, plus anyassociated interface definition files, plus the scripts used tocontrol compilation and installation of the executable
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 However, as aspecial exception, the source code distributed need not includeanything that is normally distributed  in either source or binaryform  with the major components  compiler, kernel, and so on  of theoperating system on which the executable runs, unless that componentitself accompanies the executable.If distribution of executable or object code is made by offeringaccess to copy from a designated place, then offering equivalentaccess to copy the source code from the same place counts asdistribution of the source code, even though third parties are notcompelled to copy the source along with the object code.except as expressly provided under this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Any attemptotherwise to copy, modify, sublicense or distribute the Program isvoid, and will automatically terminate your rights under this License.However, parties who have received copies, or rights, from you underthis License will not have their licenses terminated so long as suchparties remain in full compliance.signed it
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 However, nothing else grants you permission to modify ordistribute the Program or its derivative works
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 These actions areprohibited by law if you do not accept this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Therefore, bymodifying or distributing the Program  or any work based on theProgram , you indicate your acceptance of this License to do so, andall its terms and conditions for copying, distributing or modifyingthe Program or works based on it.Program , the recipient automatically receives a license from theoriginal licensor to copy, distribute or modify the Program subject tothese terms and conditions
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 You may not impose any furtherrestrictions on the recipients' exercise of the rights granted herein.You are not responsible for enforcing compliance by third parties tothis License.infringement or for any other reason  not limited to patent issues ,conditions are imposed on you  whether by court order, agreement orotherwise  that contradict the conditions of this License, they do notexcuse you from the conditions of this License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 If you cannotdistribute so as to satisfy simultaneously your obligations under thisLicense and any other pertinent obligations, then as a consequence youmay not distribute the Program at all
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 For example, if a patentlicense would not permit royalty-free redistribution of the Program byall those who receive copies directly or indirectly through you, thenthe only way you could satisfy both it and this License would be torefrain entirely from distribution of the Program.If any portion of this section is held invalid or unenforceable underany particular circumstance, the balance of the section is intended toapply and the section as a whole is intended to apply in otherIt is not the purpose of this section to induce you to infringe anypatents or other property right claims or to contest validity of anysuch claims; this section has the sole purpose of protecting theintegrity of the free software distribution system, which isimplemented by public license practices
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Many people have madegenerous contributions to the wide range of software distributedthrough that system in reliance on consistent application of thatsystem; it is up to the author/donor to decide if he or she is willingto distribute software through any other system and a licensee cannotimpose that choice.This section is intended to make thoroughly clear what is believed tobe a consequence of the rest of this License.certain countries either by patents or by copyrighted interfaces, theoriginal copyright holder who places the Program under this Licensemay add an explicit geographical distribution limitation excludingthose countries, so that distribution is permitted only in or amongcountries not thus excluded
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 In such case, this License incorporatesthe limitation as if written in the body of this License.of the General Public License from time to time
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Such new versions willbe similar in spirit to the present version, but may differ in detail toaddress new problems or concerns.Each version is given a distinguishing version number
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 If the Programspecifies a version number of this License which applies to it and "anylater version", you have the option of following the terms and conditionseither of that version or of any later version published by the FreeSoftware Foundation
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 If the Program does not specify a version number ofthis License, you may choose any version ever published by the Free Softwareprograms whose distribution conditions are different, write to the authorto ask for permission
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 For software which is copyrighted by the FreeSoftware Foundation, write to the Free Software Foundation; we sometimesmake exceptions for this
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Our decision will be guided by the two goalsof preserving the free status of all derivatives of our free software andof promoting the sharing and reuse of software generally.FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 EXCEPT WHENOTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIESPROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSEDOR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OFMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 THE ENTIRE RISK ASTO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 SHOULD THEPROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,REPAIR OR CORRECTION.WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/ORREDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISINGOUT OF THE USE OR INABILITY TO USE THE PROGRAM  INCLUDING BUT NOT LIMITEDTO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BYYOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHERPROGRAMS , EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THEPOSSIBILITY OF SUCH DAMAGES.possible use to the public, the best way to achieve this is to make itfree software which everyone can redistribute and change under these terms.to attach them to the start of each source file to most effectivelyconvey the exclusion of warranty; and each file should have at leastthe "copyright" line and a pointer to where the full notice is found.Also add information on how to contact you by electronic and paper mail.If the program is interactive, make it output a short notice like thiswhen it starts in an interactive mode:The hypothetical commands show w' and show c' should show the appropriateparts of the General Public License
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Of course, the commands you use maybe called something other than show w' and show c'; they could even bemouse-clicks or menu items--whatever suits your program.You should also get your employer  if you work as a programmer  or yourschool, if any, to sign a "copyright disclaimer" for the program, ifnecessary
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Here is a sample; alter the names:  Gnomovision'  which makes passes at compilers  written by James Hacker
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 Ty Coon, President of ViceThis General Public License does not permit incorporating your program intoproprietary programs
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 If your program is a subroutine library, you mayconsider it more useful to permit linking proprietary applications with thelibrary
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	 If this is what you want to do, use the GNU Lesser GeneralPublic License instead of this License.%%The following software may be included in this product:HandlerSocket plugin for MySQLCopyright  c  2010 DeNA Co.,Ltd.All rights reserved.Redistribution and use in source and binary forms, with or withoutmodification, are permitted provided that the following conditions are met:THIS SOFTWARE IS PROVIDED BY DeNA Co.,Ltd
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	"AS IS" AND ANY EXPRESS ORIMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OFMERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IN NOEVENT SHALL DeNA Co.,Ltd
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES  INCLUDING, BUT NOT LIMITED TO,PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;OR BUSINESS INTERRUPTION  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT  INCLUDING NEGLIGENCE OROTHERWISE  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IFADVISED OF THE POSSIBILITY OF SUCH DAMAGE.%%The following software may be included in this product:PCRE  Perl-compatible regular expression library THE BASIC LIBRARY FUNCTIONSWritten by:Email local part: ph10Email domain:University of Cambridge Computing Service,Cambridge, England.Copyright  c  1997-2013 University of CambridgeAll rights reserved.THE "BSD" LICENCERedistribution and use in source and binary forms, with or withoutmodification, are permitted provided that the following conditions are met:THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THEIMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSEARE DISCLAIMED
google-mysql	Thanks to Daniel Blezek  for the GTEST_ADD_TESTS code	IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BELIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, ORCONSEQUENTIAL DAMAGES  INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OFSUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESSINTERRUPTION  HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER INCONTRACT, STRICT LIABILITY, OR TORT  INCLUDING NEGLIGENCE OR OTHERWISE ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THEPOSSIBILITY OF SUCH DAMAGE.
google-n-digit-mnist	n-digit MNIST	MNIST handwritten digits have been arguably the most popular dataset for machine learning research.Although the state-of-the-art learned models have long ago reached possibly the best achievable performances on this benchmark,the dataset itself remains useful to the research community, providing a simple sanity check for new methods:if it doesn't work on MNIST, it doesn't work anywhere!We introduce n-digit variants of MNIST here
google-n-digit-mnist	n-digit MNIST	By adding more digits per data point, one can exponentially increase the number of classes for the dataset.Nonetheless, they still take advantage of the simpleness and light-weighted nature of data.These datasets provide a simple and useful toy examples for e.g
google-n-digit-mnist	n-digit MNIST	face embedding.One can furthermore draw an analogy between individual digits and e.g
google-n-digit-mnist	n-digit MNIST	face attributes.In this case, the dataset serves to provide quick insights into the embedding algorithm to be scaled up to more realistic, slow-to-train problems.Due to potential proprietarity issues and greater flexibility, we release the code for _generating_ the dataset from the original MNIST dataset,rather than releasing images themselves
google-n-digit-mnist	n-digit MNIST	For benchmarking purposes, we release four _standard_ datasets which are, again, generated via code, but deterministically
google-n-digit-mnist	Dataset protocols	Given n, the number of digits per sample, we generate data samples which are horizontal concatenations of the original MNIST digit images.We introduce training and test sets, each of which are built from individual digit images from original training and test sets, respectively.In both training and test splits, each n-digit class has exactly the same number of examples.
google-n-digit-mnist	Dependencies	Only numpy is required.
google-n-digit-mnist	Download the original MNIST dataset	Download from the  official MNIST website and unzip in the data/ folder:We have four _standard n-digit MNIST_ datasets ready: *mnist_2_instance*, *mnist_2_number*, *mnist_3_instance*, *mnist_3_number*.Unlike custom-built datasets, they are deterministically generated from pre-computed random arrays.These datasets are suitable for benchmarking model performances
google-n-digit-mnist	Download the original MNIST dataset	Above four datasets can be created by attaching the --use_standard_dataset flag.See n_digit_mnist.py argument options and configure a new dataset yourself.Example of 4-digit MNIST with number domain gap:This project is licensed under the Apache License This is not an officially supported Google product.
google-ndash	libndash	libndash is a C++ library that provides all the functionality one wouldneed to build an adaptive streaming media player  not includingdecoding/rendering frames to a display 
google-ndash	libndash	 It provides the following with non-DASH relatedfunctionality removed
google-ndash	libndash	It is best suited for environments that require anative code solution for adaptive streaming.
google-ndash	sdl_player	sdl_player is a sample media player written on top of libndash
google-ndash	sdl_player	Itdemonstrates how to implement the final steps of decoding and rendering framesdelivered by libndash using ffmpeg/SDL/Alsa.
google-ndash	Libraries	For Debian-type systems, the following packages should be installed:apt-get install libevent-dev libmodpbase64-dev libpthread-stubs0-dev libxml2-dev \ libcurl4-gnutls-dev libsdl2-dev libsdl2-mixer-dev libbz2-devIf you are using a recent Debian/Ubuntu with an up to date ffmpeg:apt-get install libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev libavresample-dev \  libavresample3 libavutil-dev libswresample-dev libswscale-dev libgoogle-glog-dev libgflags-devOtherwise you will need to install the following from source:To build:From the top directory:cmake .make -jX  # where X is the number of cores on your machine or around thereTo run the unit tests:From the top directory:./build/ndash_unittests --test_data_path=pwd/ndash/src
google-ndash	License	This software is licensed under Apache Software License, Version 2.0
google-ndprbrd	ndprbrd 	Disclaimer: This is not an official Google product.This daemon has a very specific purpose: to give the same IPv6 prefix /64 toseveral network interfaces using radvd without creating L2 bridge and withoutneed to configure DHCPvIt's designed to be used together with ndppd  for case if ISP givessingle /64 without delegating a bigger prefix to your router.
google-ndprbrd	Deprecation notice	On 2017-08-07 this functionality  wasmerged  into ndppd itself.However, there are several caveats:An example ndppd config with this functionality enabled:
google-ndprbrd	How to use ndprbrd	Below are 2 sample setups more complicated one which makes use of it
google-ndprbrd	How to use ndprbrd	The simple setup sets the base forthe more complicated one.
google-ndprbrd	Setup with makes use of ndprbrd	tries to reach an address 2001:db8:1:2::But which of two LANs contain thisaddress? They both use the same prefix! Having route 2001:db8:1:2::/64 on botheth1 and eth2 won't work, as such routes will collide, and kernel will sendpackets to only one of interfaces.This is where ndprbrd comes to rescue
google-ndprbrd	Setup with makes use of ndprbrd	It has 2 modes, using TAP interface  therecommended mode , and not using it.and ndprbrd resends it to all interfaces which it's configured to use
google-ndprbrd	Setup with makes use of ndprbrd	Let'ssay LAN-1 replies with neighbor advertisement
google-ndprbrd	Setup with makes use of ndprbrd	Then ndprbrd sees it, and adds astatic route to the advertised address 2001:db8:1:2::33 to interface ethFromthis point all packets to that address will go directly to eth1, and not toeth2, and not even to ndprbrdIf at some point later advertisements about 2001:db8:1:2::33 stopped coming frometh1, the static route is removed after a timeout  10 minutes by default 
google-ndprbrd	Setup with makes use of ndprbrd	Then,if a new packet comes to that address, all LANs will be used to discover itOnly absence of traffic will trigger such timeout, because with traffic theneighbor solicitations are still sent from time to time
google-ndprbrd	Setup with makes use of ndprbrd	The solicitation willgo directly to eth1 because of the static route, the machine will reply, andndprbrd will see it and reset the timer.send something to LAN-2? The answer is ndppd again: instead of listening only oneth0 ndppd should listen also on eth1 and ethNote about firewall setup: forwarding from eth0 to ndprbrd0 should be accepted.Otherwise, kernel won't generate NDP solicitations to ndprbrd TODO: thisstatement is true for static configuration of ndppd on ethProbably autodoesn't require this, but I didn't check 
google-ndprbrd	The mode without TAP interface  not recommended 	If Linux is compiled without TUN/TAP interface support, another mode isavailable
google-ndprbrd	The mode without TAP interface  not recommended 	In this mode, ndprbrd every second switches the route to2001:db8:1:2::/64 from one interface to another
google-ndprbrd	The mode without TAP interface  not recommended 	So when the neighborsolicitation is sent, there is a chance that it's sent to the correct LAN, inwhich case ndprbrd will see the neighbor advertisement, and add the route forthat address.Note that when an address is discovered in some LAN, due to the timeoutmechanism described above, that address will continue working until itdisappears from that LAN for 10 minutes
google-ndprbrd	The mode without TAP interface  not recommended 	However, several first packets arelikely to be dropped
google-ndprbrd	The mode without TAP interface  not recommended 	In TAP mode they are still likely to be dropped, butnumber of first packets dropped is smaller in TAP mode.
google-ndprbrd	Usage	./ndprbrd --interface=eth1 --interface=eth2 --prefix=2001:db8:1:2::/64To change name of TAP interface, use --tun=foo
google-ndprbrd	Usage	To use the mode without TAPinterface, use --pendulum.Sample config of ndppd:Also note that routers don't usually accept RA themselves, so you might need tospecify the default route yourself  or try to set accept_ra to 2 .
google-nel-collector	Network Error Logging collector	This repository implements a collector for the  Reporting    and  Network ErrorLogging     NEL  specifications
google-nel-collector	Network Error Logging collector	 These specs allow site owners to instructbrowsers and other user agents to collect and report on reliability informationabout the site
google-nel-collector	Network Error Logging collector	 This gives you the same information as you'd get from yourserver logs, but collected from your clients
google-nel-collector	Network Error Logging collector	 This client-side data set willinclude information about failed requests that never made it to your serving Reporting :  Network Error Logging : This repository provides a full working implementation of the collector side ofthe specs
google-nel-collector	Network Error Logging collector	 If you run this collector behind a publicly available URL, you canuse that URL in NEL configuration headers for your web site or service.NEL-compliant user agents will send reports about requests to your domain tothis collector
google-nel-collector	Network Error Logging collector	 You can then route them to a metrics or logs collection servicefor further analysis.
google-nel-reporter-java	Network Error Logging reporter	This library implements a reporter for the  Reporting    and  Network ErrorLogging     NEL  specifications
google-nel-reporter-java	Network Error Logging reporter	 These specs allow site owners to instructbrowsers and other user agents to collect and report on reliability informationabout the site
google-nel-reporter-java	Network Error Logging reporter	 This gives you the same information as you'd get from yourserver logs, but collected from your clients
google-nel-reporter-java	Network Error Logging reporter	 This client-side data set willinclude information about failed requests that never made it to your serving Reporting :  Network Error Logging : This library provides a full working implementation of the specs, with oneglaring omission: we don't handle any of the actual communication of sending andreceiving HTTP requests
google-nel-reporter-java	Network Error Logging reporter	 This lets you plug this library into *anyrequest library; we take of parsing and managing the reporting instructions foreach origin, caching reports, and deciding which collector to send each reportto
google-nel-reporter-java	Network Error Logging reporter	 You provide an implementation of the ReportDeliverer interface to handlethe actual HTTP communication using the library that you're integrating with.
google-neper	neper	neper is a Linux networking performance tool.neper as a small code base with clean coding style and structure, and iseasy to extend with new workloads and/or new options
google-neper	neper	 It can also be embeddedas a library in a larger application to generate epoll-based workloads.Disclaimer: This is not an official Google product.
google-neper	Basic usage	neper is intended to be used between two machines
google-neper	Basic usage	 On each machine, theneper process  e.g
google-neper	Basic usage	tcp_rr or tcp_stream  spawns T threads  workers ,creates F flows  e.g
google-neper	Basic usage	TCP connections , and multiplexes the F flows evenly overthe T threads
google-neper	Basic usage	 Each thread has a epoll set to manage multiple flows
google-neper	Basic usage	 Eachflow keeps its own state to make sure the expected workload is generated.For ease of explanation, we refer to the two machines as the server and theclient
google-neper	Basic usage	 The server is the process which binds to an endpoint, while the clientis the process which connects to the server
google-neper	Basic usage	 The ordering of connect   invocations is insignificant, as neper ensures the two processesare synchronized properly.When launching the client process, we can specify the number of seconds togenerate network traffic
google-neper	Basic usage	 After that duration, the client will notify theserver to stop and exit
google-neper	Basic usage	 To run the test again, we have to restart both theclient and the server
google-neper	Basic usage	 This is different from netperf, and hopefully shouldmake individual tests more independent from each other.
google-neper	tcp_rr options	The output is only available in the detailed form  samples.csv  but not inthe stdout summary.
google-neper	Output format	When consuming the key-value pairs in the output, the order of the keys shouldbe insignificant
google-neper	Output format	 However, the keys are case sensitive.
google-netboot	Netboot, packages and utilities for network booting	 ! license    ! CircleCI  This repository contains Go implementations of network protocols usedin booting machines over the network, as well as utilites built on topof these libraries.This is not an official Google project.
google-netboot	Programs	The canonical import path for Go packages in this repository is go.universe.tf/netboot.
google-netbsd-gce	Creating NetBSD images for Google Compute Engine	This repository holds tools to build a NetBSD image for use on Google ComputeEngine  GCE 
google-netbsd-gce	Creating NetBSD images for Google Compute Engine	GCE is part of the Google Cloud Platform.
google-netbsd-gce	Running make.bash	make.bash can be run under a GNU/Linux, BSD or macOS operating system
google-netbsd-gce	Running make.bash	 To runthe script, you need a few things to be installed:which will download and install NetBSD 8_BETA in a virtual machine on the localhost
google-netbsd-gce	Running make.bash	It then adds several tweaks to ensure that networking and storage willwork on GCE and packs the image into a tar.gz file.Optionally, you can give the script an architecture  i386 or amd64  and abranch name as parameters, for exampleNetBSD-7 releases are currently quite unstable
google-netbsd-gce	Running make.bash	NetBSD-8 and NetBSD-current areis because qemu emulates an IDE hard drive while Google Persistent Disk uses thevioscsi driver.
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	The how-to below describes how to do the required operations in a web browser.You can also use the  Google Cloud SDK  and itsgcloud command line tool
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	Run make.bash as described above
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	Go to  Log in with your Google account or Create a new Cloud project
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	A project is a collection of resources, such as In the left hand menu, click "Storage" and create a new bucket
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	Click on the bucket, then click the "Upload files" button and select the In the left hand menu, select "Compute Engine", then "Images"
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	Click "Create Select "Instances" from the left hand menu, then "Create Instance"
google-netbsd-gce	How to use the created image  i.e. how to get started on GCE 	Select a You will be transported back to the list of instances, where the instance
google-netbsd-gce	Using the interactive serial console	You will soon notice that you cannot use the SSH button to connect to the VM.Unfortunately, transferring of SSH keys to the machine does not work yet
google-netbsd-gce	Using the interactive serial console	Toconnect to the instance now, you can use the interactive serial console
google-netbsd-gce	Using the interactive serial console	Click"Edit" on the instance details page, scroll all the way to the bottom and tickthe "Enable connecting to serial ports" box.Now you can click the button labeled "Connect to serial port"
google-netbsd-gce	Using the interactive serial console	You will get aterminal window in the browser
google-netbsd-gce	Using the interactive serial console	Log in as root with no password
google-netbsd-gce	Using the interactive serial console	 This is thefirst thing you should change! Now you can create user accounts and copy SSH keys as you wish
google-netbsd-gce	Using the interactive serial console	For example, tocreate a user named myuser, use the following commands:your ssh client to the instance's external IP address.
google-netstack	Netstack	Netstack is a network stack written in Go.
google-netstack	Getting started	Try it out on Linux by installing the tun_tcp_echo demo:Please see  CONTRIBUTING.md  CONTRIBUTING.md  for more details.
google-netstack	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-network-mapper	Network Mapper	A collection of tools for network mapping
google-network-mapper	Network Mapper	It is designed specially for situations where there is a single central node, and a set of branches off of it which can each have various properties  typically size and color .The subdirectory 'networkx-d3-v2' contains the code that uses D3 to visualise the network graph.A live example of an earlier version of this code was used by Al-Jazeera to track defections from the Syrian regmine to the revolutionary opposition that started in 2009 is available here:
google-neuroglancer	Examples	A live demo is hosted at <>
google-neuroglancer	Examples	  The prior link opens the viewer without any preloaded dataset
google-neuroglancer	Examples	  Use the viewer links below to open the viewer preloaded with an example dataset.The four-pane view consists of 3 orthogonal cross-sectional views as well as a 3-D view  with independent orientation  that displays 3-D models  if available  for the selected objects
google-neuroglancer	Examples	 All four views maintain the same center position
google-neuroglancer	Examples	 The orientation of the 3 cross-sectional views can also be adjusted, although they maintain a fixed orientation relative to each other
google-neuroglancer	Examples	  Try holding the shift key and either dragging with the left mouse button or pressing an arrow key
google-neuroglancer	Examples	Neuroglancer itself is purely a client-side program, but it depends on data being accessible via HTTP in a suitable format
google-neuroglancer	Examples	 It is designed to easily support many different data sources, and there is existing support for the following data APIs/formats:For the complete set of bindings, see src/neuroglancer/ui/default_input_event_bindings.ts  src/neuroglancer/default_input_event_bindings.ts ,or within Neuroglancer, press h or click on the button labeled ? in the upper right corner.In order to maintain a responsive UI and data display even during rapid navigation, work is split between the main UI thread  referred to as the "frontend"  and a separate WebWorker thread  referred to as the "backend" 
google-neuroglancer	Examples	 This introduces some complexity due to the fact that current browsers:
google-neuroglancer	Documentation Index	node.js is required to build the viewer.First install NVM  node version manager  per the instructions here:Install the dependencies required by this project:To run a local server for development purposes:See  package.json  package.json  for other commands available.
google-neuroglancer	Creating a dependent project	See  examples/dependent-project  examples/dependent-project .
google-neuroglancer	Discussion Group	There is a Google Group/mailing list for discussion related to Neuroglancer:
google-neuroglancer	Related Projects	  Neuroglancer  precomputed data format  src/neuroglancer/datasource/precomputed , which may serve  as a useful example for converting other datasets.
google-neuroglancer	Contributing	Want to contribute?  Great!  First, read  CONTRIBUTING.md  CONTRIBUTING.md .
google-neuroglancer	Acknowledgements	  Copyright 2016 Google Inc
google-neuroglancer	Acknowledgements	Licensed under the Apache License, Version 2.0  the "License" ;you may not use this software except in compliance with the License.You may obtain a copy of the License at <>.Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-new-project	New Project Template	This repository contains a template you can use to seed a repository for anew open source project.See go/releasing  available externally at for more information aboutreleasing a new Google open source project.This template uses the Apache license, as is Google's default
google-new-project	New Project Template	 See thedocumentation for instructions on using alternate license.
google-new-project	How to use this template	Check it out from GitHub.Modify README.md and CONTRIBUTING.md to represent your project, not theDevelop your new project!Every file containing source code must include copyright and licenseinformation
google-new-project	How to use this template	This includes any JS/CSS files that you might be serving out tobrowsers
google-new-project	How to use this template	 This is to help well-intentioned people avoid accidental copying thatdoesn't comply with the license
google-new-project	How to use this template	Apache header:
google-nftables	Breaking changes	This package is in very early stages, and only contains enough data types andfunctions to install very basic nftables rules
google-nftables	Breaking changes	It is likely that mistakes withthe data types/API will be identified as more functionality is added.
google-nftables	Contributions	Contributions are very welcome!
google-ngx_brotli	ngx_brotli	Brotli is a generic-purpose lossless compression algorithm that compresses datausing a combination of a modern variant of the LZ77 algorithm, Huffman codingand 2nd order context modeling, with a compression ratio comparable to the bestcurrently available general-purpose compression methods
google-ngx_brotli	ngx_brotli	It is similar in speedwith deflate but offers more dense compression.ngx_brotli is a set of two nginx modules:Both Brotli library and nginx module are under active development.
google-ngx_brotli	brotli_static	extension
google-ngx_brotli	brotli_static	With the always value, pre-compressed file is used in all cases,without checking if the client supports it.
google-ngx_brotli	brotli_types	in addition to text/html
google-ngx_brotli	brotli_types	The special value * matches any MIME type.Responses with the text/html MIME type are always compressed.
google-ngx_brotli	brotli_buffers	By default, the buffer size is equal to one memory page.This is either 4k or 8k, depending on a platform.
google-ngx_brotli	brotli_comp_level	Acceptable values are in the range from 0 to 11.
google-ngx_brotli	brotli_min_length	The length is determined only from the Content-Length response header field.
google-ngx_brotli	$brotli_ratio	Achieved compression ratio, computed as the ratio between the originaland compressed response sizes.
google-ngx_brotli	Contributing	See  Contributing  CONTRIBUTING.md .
google-ngx_token_binding	ngx_token_binding	This NGINX module provides mechanism to cryptographically bind HTTP cookiesto client's HTTPS channel using Token Binding, as defined by following IETFThis NGINX module is under active development.
google-ngx_token_binding	Installation	 Token Bind  library used by this modulerequires support for adding custom TLS extensions, which means that NGINX mustbe compiled against  BoringSSL or  patched  OpenSSL To build nginx binary with patched OpenSSL:
google-ngx_token_binding	token_binding	Token Binding ID variables  described below  are going to be available whenclient successfully negotiates Token Binding.
google-ngx_token_binding	token_binding_cookie	properly bound cookies are received from the client.Because Token Binding ID can be established only over HTTPS, Secure attributeis going to be added to cookies bound this way
google-ngx_token_binding	token_binding_cookie	Also, such cookies are going tobe removed from HTTP requests and responses.
google-ngx_token_binding	$provided_token_binding_id	Returns base64url sha256 ProvidedTokenBindingID   if client negotiatedToken Binding.
google-ngx_token_binding	$provided_token_binding_key_type	Returns key type of ProvidedTokenBindingID if client negotiated Token Binding.
google-ngx_token_binding	$referred_token_binding_id	Returns base64url sha256 ReferredTokenBindingID   if client negotiatedToken Binding.
google-ngx_token_binding	$referred_token_binding_key_type	Returns key type of ReferredTokenBindingID if client negotiated Token Binding.
google-ngx_token_binding	Contributing	See  Contributing  CONTRIBUTING.md .
google-ngx_token_binding	Disclaimer	This is not an official Google product.
google-nips_assignments	NIPS Assignments	This directory contains code that was used by the NIPS 2017 program chairs,mosty to help them assign papers to reviewers and area chairs, as well asassign area chairs to senior area chairs.NIPS is the main machine learning conference  www.nips.cc .The program chairs for 2017 were Samy Bengio, Hanna Wallach, Rob Fergus andS.V.N
google-nips_assignments	NIPS Assignments	Vishwanathan.NIPS usually use CMT  cmt.research.microsoft.com  to handle the reviewingprocess, and the program chairs could have use it as well for the assignmenttasks, but they felt the need to control more precisely the assignments,for instance by better balancing the interests of the reviewers and the areachairs, and adding various constraints for fairness  such as the number ofreviewers from the same organization for a given paper .In order to use this code, you first need to install the Google operationsresearch toolbox, details here:Once this is done, modify OR_DIR in Makefile to pointto the underlying or-tools directory, then run "make".Furthermore, it is recommended to install additional third-party solverssuch as SCIP and GUROBI to obtain a faster result, in particular for thelarge assignment problem between reviewers and papers
google-nips_assignments	NIPS Assignments	Details aboutinstalling them are available on the Google operations research toolboxinstallation page.Note that this is not an official Google product.Samy BengioGoogle Brain
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	**This is not an official Google product.** HTTP/2  is a major revision of the HTTPprotocol
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	One of its differences from HTTP/1 is  *serverpush*  which allows aserver to pre-emptively send responses to a client in association with aprevious client-initiated request
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	This can be useful when the server knowsthe client will need to have those responses available in order to fullyprocess the response to the original request.It sounds simple and easy but is quite tricky for service developers tomanually figure out and configure what resources to push in association withanother resource
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	There are also many pitfalls the implementors must knowabout
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	See  Rules of Thumb for HTTP/2Push for the details.This project is for automating server push and getting rid of the need formanual configurations from service developers
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	It is a fastify  plugin that serves static files and isimplemented on top of the h2-auto-push  package
google-node-fastify-auto-push	Fastify plugin for HTTP/2 automatic server push	It can bethought as a replacement of the fastify-static  plugin thatsupports automatic server-push.For more details, see the h2-auto-push package.**This package currently works only with Node >=9.4.0.**
google-node-gtoken	node-gtoken	 ! NPM Version  npm-image   npm-url  ! CircleCI  circle-image   circle-url   david-image   david-url   david-dev-image   david-dev-url  ! Known Vulnerabilities  snyk-image   snyk-url  ! codecov  codecov-image   codecov-url  ! style badge  gts-image   gts-url Node.js Google Authentication Service Account Tokens
google-node-gtoken	Use with a .pem or .p12 key file:	 jsconst { GoogleToken } = require 'gtoken' ;const gtoken = new GoogleToken {  keyFile: 'path/to/key.pem', // or path to .p12 key file  email: 'my_service_account_email@developer.gserviceaccount.com',  scope:  ' '  // or space-delimited string of scopes} ;gtoken.getToken function err, token  {  if  err  {  }  console.log token ;} ;You can also use the async/await style API: jsconst { GoogleToken } = require 'gtoken' ;const gtoken = new GoogleToken {  keyFile: 'path/to/key.json',  scope:  ' '  // or space-delimited string of scopes} ;gtoken.getToken function err, token  {  if  err  {  }  console.log token ;} ;
google-node-gtoken	Pass the private key as a string directly:	> Various options that can be set when creating initializing the gtoken object.> Returns the cached token or requests a new one and returns it.> Given a keyfile, returns the key and  if available  the client email.> Various properties set on the gtoken object after call to .getToken  .> Returns true if the token has expired, or token does not exist.> Revoke the token if set.Open the  Google Developer Console  gdevconsole .Open your project and under "APIs & auth", click Credentials.Generate a new .p12 key and download it into your project.
google-node-gtoken	Converting your .p12 key to a .pem key	You can just specify your .p12 file  with .p12 extension  as the keyFile and it will automatically be converted to a .pem on the fly, however this results in a slight performance hit
google-node-gtoken	Converting your .p12 key to a .pem key	If you'd like to convert to a .pem for use later, use OpenSSL if you have it installed.
google-node-gtoken	1.2.2 -> 2.0.0	New features:Breaking changes: MIT  LICENSE  circle-image :  circle-url :  codecov-image :  codecov-url :  david-image :  david-url :  david-dev-image :  david-dev-url :  gdevconsole :  gts-image :  gts-url :  npm-image :  npm-url :  snyk-image :  snyk-url : 
google-node-h2-auto-push	HTTP/2 automatic server push	 ! Greenkeeper badge  **This is not an official Google product.** HTTP/2  is a major revision of the HTTPprotocol
google-node-h2-auto-push	HTTP/2 automatic server push	One of its differences from HTTP/1 is  *serverpush*  which allows aserver to pre-emptively send responses to a client in association with aprevious client-initiated request
google-node-h2-auto-push	HTTP/2 automatic server push	This can be useful when the server knowsthe client will need to have those responses available in order to fullyprocess the response to the original request.It sounds simple and easy but is quite tricky for service developers tomanually figure out and configure what resources to push in association withanother resource
google-node-h2-auto-push	HTTP/2 automatic server push	There are also many pitfalls the implementors must knowabout
google-node-h2-auto-push	HTTP/2 automatic server push	See  Rules of Thumb for HTTP/2Push for the details.This project is for automating server push and getting rid of the need formanual configurations from service developers
google-node-h2-auto-push	HTTP/2 automatic server push	It is meant as a helperlibrary for building middlewares for various  Node.js web servers, such as  Express  fastify  etc.This library assumes that the middlewares built on top of it act as a staticfile server
google-node-h2-auto-push	HTTP/2 automatic server push	That is because static file serving is one of the most commonuse cases for HTTP/2 server push.See  for an example
google-node-h2-auto-push	HTTP/2 automatic server push	It is a fastify  plugin for supporting auto-push.**This package currently works only with Node >=9.4.0.**
google-node-h2-auto-push	Constructor	preprocessRequest interface PreprocessResult {  newCacheCookie: string;  pushFn:    => Promise;This method must be called for every request from the client
google-node-h2-auto-push	Constructor	It determineswhich other resources must be pushed, if any, in association with the currentrequest path
google-node-h2-auto-push	Constructor	It also checks whether any resources to be pushed are alreadycached in the browser side
google-node-h2-auto-push	Constructor	It is done by storing and reading the relatedinformation in a cookie value.Returns a promise for the result  pushFn to push static resources that are associated with the currentThis method  and index.html is a non-static file that is dynamically generated by theapplication, it probably wants to push related resources such as stylesheets,images, JavaScript files, etc
google-node-h2-auto-push	Constructor	that are needed for the browser to render theWhen there is an error while pushing resources, a 'pushError' will beemitted on the parent stream, whose argument is an error object that caused
google-node-h2-auto-push	recordRequestPath  	called for non-static file requests as well as static files, as explained forpreprocessRequest   above.
google-node-h2-auto-push	AssetCacheConfig	This can be passed to the constructor of AutoPush to customize the cachingThe time duration  in milliseconds  after a client request during which torecord additional requests
google-node-h2-auto-push	AssetCacheConfig	That record will be used for determining theassociated resources that may be pushed for a request path.
google-node-h2-auto-push	promotionRatio	If an additional request is frequently made for a certain original requestand its hit ratio is over the promotionRatio value, that request path isconsidered one of the associated resources of the original request, and it'llbe pushed when a request is made for the same original request path later.
google-node-h2-auto-push	demotionRatio	Similar to demotionRatio, the request path will not be considered an associatedresource anymore.
google-node-h2-auto-push	minimumRequests	The minimum number of requests for a certain path before being considered asa candidate for an associated resource.
google-node-sec-roadmap	Node.js Security Roadmap	The security roadmap is a  gitbook publication available at* nodesecroadmap.fyi Please file errata at the issue tracker or send us a pull request.If you'd like to help out, please also see our contribution guidelines  CONTRIBUTING.md .
google-nogotofail	nogotofail	Nogotofail is a network security testing tool designed to help developers andsecurity researchers spot and fix weak TLS/SSL connections and sensitivecleartext traffic on devices and applications in a flexible, scalable, powerful way.It includes testing for common SSL certificate verification issues, HTTPS and TLS/SSLlibrary bugs, SSL and STARTTLS stripping issues, cleartext issues, and more.
google-nogotofail	Design	Nogotofail is composed of an on-path network MiTM and optional clients for the devices being tested.See  docs/design.md  docs/design.md  for the overview and design goals of nogotofail.
google-nogotofail	Dependencies	Nogotofail depends only on Python 2.7 and pyOpenSSL>=0.The MiTM is designed to work on Linuxmachines and the transparent traffic capture modes are Linux specific and require iptables as well.Additionally the Linux client depends on  psutil 
google-nogotofail	Getting started	See  docs/getting_started.md  docs/getting_started.md  for setup and a walkthrough of nogotofail.
google-nogotofail	Discussion	For discussion please use our  nogotofail Google Group 
google-nomulus	Nomulus	! Nomulus logo  ./nomulus-logo.png 
google-nomulus	Overview	Nomulus is an open source, scalable, cloud-based service for operating top-level domains   TLDs 
google-nomulus	Overview	Itis the authoritative source for the TLDs that it runs, meaning that it isresponsible for tracking domain name ownership and handling registrations,renewals, availability checks, and WHOIS requests
google-nomulus	Overview	End-user registrants  i.e.people or companies that want to register a domain name  use an intermediatedomain name registrar acting on their behalf to interact with the registry.Nomulus runs on  Google App Engine  gae  and is written primarily in Java
google-nomulus	Overview	It isthe software that  Google Registry  uses tooperate TLDs such as .google, .app, .how, .soy, and .みんな
google-nomulus	Overview	It can run anynumber of TLDs in a single shared registry system using horizontal scaling
google-nomulus	Overview	Itssource code is publicly available in this repository under the  Apache 2.0 freeand open source license 
google-nomulus	Getting started	The following resources provide information on getting the code and setting up arunning system:If you are thinking about running a production registry service using ourplatform, please drop by the user group and introduce yourself and your usecase
google-nomulus	Getting started	To report issues or make contributions, use GitHub issues and pull
google-nomulus	Capabilities	Nomulus has the following capabilities:
google-nomulus	Additional components	Registry operators interested in deploying Nomulus will likely require someadditional components that are need to be configured separately.
google-novm	Bootloader ###	Currently, the in-built bootloader supports only modern Linux kernels.It follows the Linux boot convention by setting the vcpu directly into 32-bitprotected mode and jumping to the ELF entry point
google-novm	Bootloader ###	Or, if it finds a 64-bitkernel, it will do a bit of additional setup  creating an identity-mapped pagetable  and then jumps directly into 64-bit long mode at the entry point.For full details on this convention see:The embedded bootloader works different than traditional bootloaders, such asGRUB or LILO
google-novm	Bootloader ###	Unlike other bootloaders, the embedded bootloader requires theELF kernel binary  vmlinux , not the compressed image  bzImage .This is because the compressed image  bzImage  contains a compressed version ofthe ELF kernel binary, real-mode setup code, and a small setup sector.Traditional bootloaders typically lay these components out in memory andexecute the real-mode code
google-novm	Bootloader ###	The real-mode setup code will construct a few basicdata structures via BIOS calls, extract the vmlinux binary into memory andfinally jump into 32-bit protected mode in the newly uncompressed code.This is a sensible approach, as the real-mode kernel code will be able toexecute arbitrary BIOS calls and probe the hardware in arbitrary ways beforefinally switching to protected mode
google-novm	Bootloader ###	However, for a virtualized environmentwhere the hardware is fixed and known to the hypervisor, the bootloader itselfcan lay out the necessary data structures in memory and start *directly32-bit protected mode
google-novm	Bootloader ###	In addition to skipping a batch of real-mode executionand emulation, this allows us to avoid having to build a BIOS at all.If a bzImage is provided, the ELF binary will be extracted and cached using asimple script derived from the script found in the Linux tree.Given a vmlinux binary file, we load the file directly into memory as specifiedby the ELF program headers
google-novm	Bootloader ###	For example:We also note the entry point for the binary  here it happens to be 0x1000000 .Before we are able to jump to the entry point, we need to setup some basicrequirements that would normally be done by the real-mode setup code:into memory
google-novm	Bootloader ###	This is pointed to as part of the boot parameters, anddecompression is handled by the kernel.
google-novm	Devices ###	The device model implemented by this kernel is substantially different frommost VMs
google-novm	Devices ###	Instead of attemping to emulate a legacy machine, we instead tosupport only the mechanisms which make sense for a next generationpurpose-built Virtual Machine.
google-nsjail	Overview	NsJail is a process isolation tool for Linux
google-nsjail	Overview	It utilizes Linux namespace subsystem, resource limits, and the seccomp-bpf syscall filters of the Linux kernel.It can help you with  among other things :Linux __namespaces__: UTS  hostname , MOUNT  chroot , PID  separate PID tree , IPC, NET  separate networking context , USER, CGROUPS__FS constraints__: chroot  , pivot_root  , RO-remounting, custom /proc and tmpfs mount points__Resource limits__  wall-time/CPU time limits, VM/mem address space limits, etc
google-nsjail	Overview	Programmable seccomp-bpf __syscall filters__  through the  kafel language Cloned and isolated __Ethernet interfaces____Cgroups__ for memory and PID utilization control
google-nsjail	Isolation of network services  inetd style 	_PS: You'll need to have a valid file-system tree in /chroot
google-nsjail	Isolation of network services  inetd style 	If you don't have it, change /chroot to /_+ Server: + Client:  /  /  lo /  PID   USER 1 99999 3 99999 / $
google-nsjail	Isolation with access to a private, cloned interface  requires root/setuid 	_PS: You'll need to have a valid file-system tree in /chroot
google-nsjail	Isolation with access to a private, cloned interface  requires root/setuid 	If you don't have it, change /chroot to /_/ uid=9999 gid=9999/ 1: lo:  mtu 65536 qdisc noqueue2: vs:  mtu 1500 qdisc noqueue/ GET / HTTP/1.0HTTP/1.0 302 FoundCache-Control: privateContent-Type: text/html; charset=UTF-8Location: Content-Length: 258Date: Wed, 02 Mar 2016 02:14:08 GMT.../ $ 
google-nsjail	Isolation of local processes	_PS: You'll need to have a valid file-system tree in /chroot
google-nsjail	Isolation of local processes	If you don't have it, change /chroot to /_  /  lo /  uid=99999 gid=99999 /  PID   USER 1 99999 4 99999 / $exit $
google-nsjail	Isolation of local processes  and re-running them, if necessary 	_PS: You'll need to have a valid file-system tree in /chroot
google-nsjail	Isolation of local processes  and re-running them, if necessary 	If you don't have it, change /chroot to /_  BusyBox v1.21.1  Ubuntu 1:1.21.0-1ubuntu1  built-in shell  ash  Enter 'help' for a list of built-in commands
google-nsjail	Isolation of local processes  and re-running them, if necessary 	/  PID   USER 1 99999 2 99999 /  BusyBox v1.21.1  Ubuntu 1:1.21.0-1ubuntu1  built-in shell  ash  Enter 'help' for a list of built-in commands
google-nsjail	Isolation of local processes  and re-running them, if necessary 	/  PID   USER 1 99999 2 99999 / $
google-nsjail	Bash in a minimal file-system with uid==0 and access to /dev/urandom only	 2017-05-24T17:08:02+0200  Mode: STANDALONE_ONCE 2017-05-24T17:08:02+0200  Jail parameters: hostname:'NSJAIL', chroot:' null ', process:'/bin/bash', bind: :: :0, max_conns_per_ip:0, time_limit:0, personality:0, daemonize:false, clone_newnet:true, clone_newuser:true, clone_newns:true, clone_newpid:true, clone_newipc:true, clonew_newuts:true, clone_newcgroup:false, keep_caps:true, tmpfs_size:4194304, disable_no_new_privs:false, pivot_root_only:false 2017-05-24T17:08:02+0200  Mount point: src:'none' dst:'/' type:'tmpfs' flags:MS_RDONLY|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'none' dst:'/proc' type:'proc' flags:MS_RDONLY|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'/bin/' dst:'/bin/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'/lib' dst:'/lib' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'/lib64/' dst:'/lib64/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'/usr/' dst:'/usr/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'/sbin/' dst:'/sbin/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'none' dst:'/dev' type:'tmpfs' flags:0 options:'size=4194304' isDir:True 2017-05-24T17:08:02+0200  Mount point: src:'/dev/urandom' dst:'/dev/urandom' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:False 2017-05-24T17:08:02+0200  Uid map: inside_uid:0 outside_uid:69664 2017-05-24T17:08:02+0200  Gid map: inside_gid:99999 outside_gid:5000 2017-05-24T17:08:02+0200  Executing '/bin/bash' for ' STANDALONE_MODE 'bash: cannot set terminal process group  -1 : Inappropriate ioctl for devicebash: no job control in this shellbash-4.3# ls -ltotal 28drwxr-xr-x   2 65534 65534  4096 May 15 14:04 bindrwxrwxrwt   2drwxr-xr-x  28 65534 65534  4096 May 15 14:10 libdrwxr-xr-x   2 65534 65534  4096 May 15 13:56 lib64dr-xr-xr-x 391 65534 65534drwxr-xr-x   2 65534 65534 12288 May 15 14:16 sbindrwxr-xr-x  17 65534 65534  4096 May 15 13:58 usrbash-4.3# iduid=0 gid=99999 groups=65534,99999bash-4.3# exit 2017-05-24T17:08:05+0200  PID: 129839 exited with status: 0,  PIDs left: 0 
google-nsjail	/usr/bin/find in a minimal file-system  only /usr/bin/find accessible from /usr/bin 	 2017-05-24T17:04:37+0200  Mode: STANDALONE_ONCE 2017-05-24T17:04:37+0200  Jail parameters: hostname:'NSJAIL', chroot:' null ', process:'/usr/bin/find', bind: :: :0, max_conns_per_ip:0, time_limit:0, personality:0, daemonize:false, clone_newnet:true, clone_newuser:true, clone_newns:true, clone_newpid:true, clone_newipc:true, clonew_newuts:true, clone_newcgroup:false, keep_caps:true, tmpfs_size:4194304, disable_no_new_privs:false, pivot_root_only:false 2017-05-24T17:04:37+0200  Mount point: src:'none' dst:'/' type:'tmpfs' flags:MS_RDONLY|0 options:'' isDir:True 2017-05-24T17:04:37+0200  Mount point: src:'none' dst:'/proc' type:'proc' flags:MS_RDONLY|0 options:'' isDir:True 2017-05-24T17:04:37+0200  Mount point: src:'/lib/x86_64-linux-gnu/' dst:'/lib/x86_64-linux-gnu/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:04:37+0200  Mount point: src:'/lib/x86_64-linux-gnu' dst:'/lib/x86_64-linux-gnu' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:04:37+0200  Mount point: src:'/lib64' dst:'/lib64' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:04:37+0200  Mount point: src:'/usr/bin/find' dst:'/usr/bin/find' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:False 2017-05-24T17:04:37+0200  Mount point: src:'/dev/urandom' dst:'/dev/urandom' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:False 2017-05-24T17:04:37+0200  Uid map: inside_uid:99999 outside_uid:69664 2017-05-24T17:04:37+0200  Gid map: inside_gid:99999 outside_gid:5000 2017-05-24T17:04:37+0200  Executing '/usr/bin/find' for ' STANDALONE_MODE '/usr/bin/find: /proc/tty/driver': Permission denied 2017-05-24T17:04:37+0200  PID: 129525 exited with status: 1,  PIDs left: 0 
google-nsjail	Using /etc/subuid	 2017-05-24T17:12:31+0200  Mode: STANDALONE_ONCE 2017-05-24T17:12:31+0200  Jail parameters: hostname:'NSJAIL', chroot:' null ', process:'/bin/ls', bind: :: :0, max_conns_per_ip:0, time_limit:0, personality:0, daemonize:false, clone_newnet:true, clone_newuser:true, clone_newns:true, clone_newpid:true, clone_newipc:true, clonew_newuts:true, clone_newcgroup:false, keep_caps:false, tmpfs_size:4194304, disable_no_new_privs:false, pivot_root_only:false 2017-05-24T17:12:31+0200  Mount point: src:'none' dst:'/' type:'tmpfs' flags:MS_RDONLY|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'none' dst:'/proc' type:'proc' flags:MS_RDONLY|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/lib' dst:'/lib' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/lib64/' dst:'/lib64/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/usr/lib' dst:'/usr/lib' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/usr/bin/' dst:'/usr/bin/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/usr/sbin/' dst:'/usr/sbin/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/bin/' dst:'/bin/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/sbin/' dst:'/sbin/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'/dev/null' dst:'/dev/null' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:False 2017-05-24T17:12:31+0200  Mount point: src:'/tmp/' dst:'/tmp/' type:'' flags:MS_RDONLY|MS_BIND|MS_REC|0 options:'' isDir:True 2017-05-24T17:12:31+0200  Mount point: src:'none' dst:'/tmp/' type:'tmpfs' flags:0 options:'size=4194304' isDir:True 2017-05-24T17:12:31+0200  Uid map: inside_uid:0 outside_uid:69664 2017-05-24T17:12:31+0200  Gid map: inside_gid:5000 outside_gid:5000 2017-05-24T17:12:31+0200  Newuid mapping: inside_uid:'0' outside_uid:'10000000' count:'1' 2017-05-24T17:12:31+0200  Executing '/bin/ls' for ' STANDALONE_MODE 'total 120drwxr-xr-x   5 65534 65534 77824 May 24 12:25 bindrwxr-xr-x 210 65534 65534 20480 May 22 16:11 libdrwxr-xr-x   4 65534 65534 20480 May 24 00:24 sbin 2017-05-24T17:12:31+0200  PID: 130841 exited with status: 0,  PIDs left: 0 
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	 2017-01-15T21:53:08+0100  Mode: STANDALONE_ONCE 2017-01-15T21:53:08+0100  Jail parameters: hostname:'NSJAIL', chroot:'/', process:'/bin/sh', bind: :: :0, max_conns_per_ip:0, uid: ns:1000, global:1000 , gid: ns:1000, global:1000 , time_limit:0, personality:0, daemonize:false, clone_newnet:true, clone_newuser:true, clone_newns:true, clone_newpid:true, clone_newipc:true, clonew_newuts:true, clone_newcgroup:false, keep_caps:false, tmpfs_size:4194304, disable_no_new_privs:false, pivot_root_only:false 2017-01-15T21:53:08+0100  Mount point: src:'/' dst:'/' type:'' flags:0x5001 options:'' 2017-01-15T21:53:08+0100  Mount point: src:' null ' dst:'/proc' type:'proc' flags:0x0 options:'' 2017-01-15T21:53:08+0100  PID: 18873 about to execute '/bin/sh' for  STANDALONE_MODE /bin/sh: 0: can't access tty; job control turned off'PATH='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'PS1='PS2='> 'PS4='+ 'Bad system call 2017-01-15T21:53:17+0100  PID: 18873 exited with status: 159,  PIDs left: 0 You will also find all examples in the  configs  directory
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	config.proto  contains ProtoBuf schema for nsjail's configuration format.You can examine an example config file in  configs/bash-with-fake-geteuid.cfg You can also override certain options with command-line options
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Here, the executed binary  _/bin/bash_  is overriden with _/usr/bin/id_, yet options from _configs/bash-with-fake-geteuid.cfg_ still apply INSIDE-JAIL : iduid=999999 gid=999998 euid=4294965959 groups=999998,65534 INSIDE-JAIL : exit 2017-05-27T18:45:40+0200  PID: 16579 exited with status: 0,  PIDs left: 0 You might also want to try using  configs/home-documents-with-xorg-no-net.cfg The  configs/firefox-with-net.cfg config file will allow you to run firefox inside a sandboxed environment:A more complex setup, which utilizes virtualized  cloned  Ethernetinterfaces  to separate it from the main network namespace , can befound in  configs/firefox-with-cloned-net.cfg Remember to change relevant UIDs and Ethernet interface names before use.As using cloned Ethernet interfaces  MACVTAP  required root privileges, you'llhave to run it under sudo:The command-line options should be self-explanatory, while the proto-buf config options are described in  config.proto ./nsjail --helpUsage: ./nsjail  options  - --help|-h 	Help plz.
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	--mode|-M VALUE	Execution mode  default: 'o'  MODE_STANDALONE_ONCE  :	l: Wait for connections on a TCP port  specified with --port   MODE_LISTEN_TCP 	o: Launch a single process on the console using clone/execve  MODE_STANDALONE_ONCE 	e: Launch a single process on the console using execve  MODE_STANDALONE_EXECVE 	r: Launch a single process on the console with clone/execve, keep doing it forever  MODE_STANDALONE_RERUN  --config|-C VALUE	Configuration file in the config.proto ProtoBuf format  see configs/ directory for examples  --exec_file|-x VALUE	File to exec  default: argv 0   --execute_fd 	Use execveat   to execute a file-descriptor instead of executing the binary path
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	In such case argv 0 /exec_file denotes a file path before mount namespacing --chroot|-c VALUE	Directory containing / of the jail  default: none  --rw 	Mount chroot dir  /  R/W  default: R/O  --user|-u VALUE	Username/uid of processess inside the jail  default: your current uid 
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	You can also use inside_ns_uid:outside_ns_uid:count convention here
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Can be specified multiple times --group|-g VALUE	Groupname/gid of processess inside the jail  default: your current gid 
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	You can also use inside_ns_gid:global_ns_gid:count convention here
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Can be specified multiple times --hostname|-H VALUE	UTS name  hostname  of the jail  default: 'NSJAIL'  --cwd|-D VALUE	Directory in the namespace the process will run  default: '/'  --port|-p VALUE	TCP port to bind to  enables MODE_LISTEN_TCP   default: 0  --bindhost VALUE	IP address to bind the port to  only in  MODE_LISTEN_TCP  ,  default: '::'  --max_conns_per_ip|-i VALUE	Maximum number of connections per one IP  only in  MODE_LISTEN_TCP  ,  default: 0  unlimited   --log|-l VALUE	Log file  default: use log_fd  --log_fd|-L VALUE	Log FD  default: 2  --time_limit|-t VALUE	Maximum time that a jail can exist, in seconds  default: 600  --max_cpus VALUE	Maximum number of CPUs a single jailed process can use  default: 0 'no limit'  --daemon|-d 	Daemonize after start --verbose|-v 	Verbose output --quiet|-q 	Log warning and more important messages only --really_quiet|-Q 	Log fatal messages only --keep_env|-e 	Pass all environment variables to the child process  default: all envvars are cleared  --env|-E VALUE	Additional environment variable  can be used multiple times  --keep_caps 	Don't drop any capabilities --cap VALUE	Retain this capability, e.g
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	CAP_PTRACE  can be specified multiple times  --silent 	Redirect child process' fd:0/1/2 to /dev/null --stderr_to_null	Redirect FD=2  STDERR_FILENO  to /dev/null --skip_setsid 	Don't call setsid  , allows for terminal signal handling in the sandboxed process
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Dangerous --pass_fd VALUE	Don't close this FD before executing the child process  can be specified multiple times , by default: 0/1/2 are kept open --disable_no_new_privs 	Don't set the prctl NO_NEW_PRIVS, 1   DANGEROUS  --rlimit_as VALUE	RLIMIT_AS in MB, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 512  --rlimit_core VALUE	RLIMIT_CORE in MB, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 0  --rlimit_cpu VALUE	RLIMIT_CPU, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 600  --rlimit_fsize VALUE	RLIMIT_FSIZE in MB, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 1  --rlimit_nofile VALUE	RLIMIT_NOFILE, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 32  --rlimit_nproc VALUE	RLIMIT_NPROC, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 'soft'  --rlimit_stack VALUE	RLIMIT_STACK in MB, 'max' or 'hard' for the current hard limit, 'def' or 'soft' for the current soft limit, 'inf' for RLIM64_INFINITY  default: 'soft'  --persona_addr_compat_layout 	personality ADDR_COMPAT_LAYOUT  --persona_mmap_page_zero 	personality MMAP_PAGE_ZERO  --persona_read_implies_exec 	personality READ_IMPLIES_EXEC  --persona_addr_limit_3gb 	personality ADDR_LIMIT_3GB  --persona_addr_no_randomize 	personality ADDR_NO_RANDOMIZE  --disable_clone_newnet|-N 	Don't use CLONE_NEWNET
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Enable global networking inside the jail --disable_clone_newuser 	Don't use CLONE_NEWUSER
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Requires euid==0 --disable_clone_newns 	Don't use CLONE_NEWNS --disable_clone_newpid 	Don't use CLONE_NEWPID --disable_clone_newipc 	Don't use CLONE_NEWIPC --disable_clone_newuts 	Don't use CLONE_NEWUTS --disable_clone_newcgroup 	Don't use CLONE_NEWCGROUP
google-nsjail	Even more contrained shell  with seccomp-bpf policies 	Might be required for kernel versions To launch nsjail in a docker container clone the repository and build the docker image:docker build -t nsjail .This will build up an image containing njsail and kafel.From now you can either use it in another Dockerfile  FROM nsjail  or directly:docker run --privileged --rm -it nsjail nsjail --user 99999 --group 99999 --disable_proc --chroot / --time_limit 30 /bin/bash  
google-nucleus	Nucleus	Nucleus is a library of Python and C++ code designed to make it easy toread, write and analyze data in common genomics file formats like SAM and VCF.In addition, Nucleus enables painless integration with the TensorFlow machinelearning framework, as anywhere a genomics file is consumed or produced, aTensorFlow tfrecords file may be substituted.
google-nucleus	Poll	Which of these would most increase your usage of Nucleus? !    !    !    !    !    !    !    !    !    !   
google-nucleus	Installation	For Ubuntu 14, Ubuntu 16 and Debian 9 systems, installation is easy:just runthe instructions at    before running install.sh.Note that install.sh extensively depends on apt-get, so it is unlikelyto run without extensive modifications on non-Debian-based systems.Finally, Nucleus depends on TensorFlow and by default, install.sh willinstall a CPU-only version of a stable TensorFlow release  currently 1.7 .If that isn't what you want, there are several other installation options thatcan be enabled with a simple edit to install.sh.Running install.sh will build all of Nucleus's programs and libraries.You can find the generated  binaries under bazel-bin/nucleus
google-nucleus	Installation	 If inaddition to installing Nucleus you would like to run its tests, executeInterested in contributing? See  CONTRIBUTING  CONTRIBUTING.md .
google-nucleus	Support	The  Genomics team in Google Brain actively supports Nucleus and are always interested in improving its quality.If you run into an issue, please report the problem on our  Issuetracker  Be sure to add enoughdetail to your report that we can reproduce the problem and fix it
google-nucleus	Support	We encourageincluding links to snippets of BAM/VCF/etc files that provoke the bug, ifpossible
google-nucleus	Support	Depending on the severity of the issue we may patch Nucleusimmediately with the fix or roll it into the next release.
google-nucleus	Version	This is Nucleus 0.1
google-nucleus	Version	Nucleus follows  semanticversioning 
google-nucleus	License	Nucleus is licensed under the terms of the  Apache 2 license  LICENSE .
google-nucleus	History	Nucleus grew out of the  DeepVariant 
google-nucleus	Disclaimer	This is not an official Google product.
google-nvidia_libs_test	Tests and Benchmarks for cuDNN	The repository contains a set of convolution tests and benchmarks for NVIDIA's cuDNN  library.This is not an officially supported Google product.
google-nvidia_libs_test	Prerequisites	Install bazel  instructions Install the  CUDA Toolkit   CUDA 8 isthe minimal supported version Install the  cuDNN SDK   cuDNN 6 is theminimal supported version .
google-nvidia_libs_test	Common parameters	Bazel parameters:Executable parameters:
google-nvidia_libs_test	Test instructions	bazel run  bazel parameters  //:cudnn_test -Bazel can run tests in a sandbox  which allows reporting crashes as failures .To run in a sandbox, replace 'bazel run ...' with 'bazel test ...' and prefixeach test parameter with '--test_arg='bazel test  bazel parameters  //:cudnn_test --test_arg= test parameter 1  ...Test parameters:bazel run  bazel parameters  //:cudnn_benchmark -Benchmark parameters:
google-nxt-standalone	Dawn, a WebGPU implementation	Dawn  formerly NXT  is an open-source and cross-platform implementation of the work-in-progress WebGPU standard.It exposes a C/C++ API that maps almost one-to-one to the WebGPU IDL and can be managed as part of a larger system such as a Web browser.Dawn provides several WebGPU building blocks:Dawn uses the Chromium build system and dependency management so you need to  install depot_tools  and add it to the PATH.Then get the source as follows: install depots_tools : 
google-nxt-standalone	Clone the repo as "dawn"	git clone  dawn && cd dawn
google-nxt-standalone	Bootstrap the gclient configuration	cp scripts/standalone.gclient .gclient
google-nxt-standalone	Fetch external dependencies and toolchains with gclient	gclient syncThen generate build files using gn args out/Debug or gn args out/Release.A text editor will appear asking build options, the most common option is is_debug=true/false; otherwise gn args out/Release --list shows all the possible options.Then use ninja -C out/Release to build dawn and for example ./out/Release/dawn_end2end_tests to run the tests.
google-nxt-standalone	Contributing	Please read and follow  CONTRIBUTING.md  /CONTRIBUTING.md .Dawn doesn't have a formal coding style yet, except what's defined by our clang format style.Overall try to use the same style and convention as code around your change.
google-nxt-standalone	License	Please see  LICENSE  /LICENSE .
google-nxt-standalone	Disclaimer	This is not an officially supported Google product.
google-oatts	OpenAPI Test Templates  oatts 	> Generate basic unit test scaffolding for your  OpenAPI specification 
google-oatts	Disclaimer	This is not an officially supported Google product.oatts is based off of the  swagger-test-templates  module and the lessons learned during its development._This is a work in progress._
google-oatts	Goal	The goal of oatts is to provide a standalone module for generating Node.js unit test code scaffolding based on a given OpenAPI specification.The hope is that by providing such a tool, API developers will be encouraged to test the contract between their spec and backend early, often and continuously as the project grows.
google-oatts	Usage	There are a couple ways to use oatts.
google-oatts	Module	Install via npmThen use it in codevar oatts = require 'oatts' ;var options = {var tests = oatts.generate '/path/to/openapi.yaml', options ;console.log tests 
google-oatts	Command line interface	Install globally via npmThen use in your command line> oatts generate --help> oatts generate -s ./path/to/openapi.yaml -w ./output/dir> ls ./output/dirpet-test.js  pet-{petId}-uploadImage-test.js  user-test.js 
google-oatts	Command line interface	.
google-oatts	Using the result	The resulting test files are built using the  mocha  testing framework and  chakram  API testing framework
google-oatts	Using the result	Thus, you will need both of these dependencies installed in order to run your newly generated tests.After installing these, you can run the tests with mocha:
google-oatts	start your API server to test against!!	> mocha --recursive 
google-oatts	Custom Values	Custom values can be supplied through both the command line and a JSON file
google-oatts	Custom Values	The in-line, command line supplied JSON will take precedent.An example custom values JSON file can be found  here  ./test/process/documents/customValuesTest.json .
google-oatts	Custom Templates	Custom templates can be supplied via the templates option
google-oatts	Custom Templates	The directory pointed to by the option must contain 4  Handlebars  templates named the same way as those found in ./templates.There are also a few helpers available to be used in the Handlebars templates, which can be found in the templateHelpers documentation namespace
google-oatts	Custom Templates	Use the default templates as examples of how to use them.
google-oatts	Options	The following options can be passed to the generation function, some/all are exposed in the accompanying CLI:| Name | CLI Flag | Default | Required | Description || ---| spec | --spec -s | n/a | true | Path to a swagger.yaml or openapi.yaml || host | --host | spec.host | false | Hostname to put in test requests; defaults to host in given spec || paths | --paths -p | spec.paths | false | API paths to generate tests for; defaults to all paths in given spec || samples | --samples -e | false | false | Toggle generating sample responses for assertion || writeTo | --writeTo -w | n/a | false | Directory to write generated tests to; will create the directory if it doesn't exist || consumes | --consumes -c | operation.consumes 0  &#124; &#124; spec.conumes 0  | false | Consumes header to use in a request when applicable | | produces | --produces -o | operation.produces 0  &#124; &#124; spec.produces 0  | false | Produces header to use in a request when applicable || customValues | --customValues -u | n/a | false | Values to be populated in requests where specified; overrides customValuesFile || customValuesFile | --customValuesFile | n/a | false | Path to a JSON file with values to populate in requests || scheme | --scheme -m | spec.schemes 0  | false | Override for multiple scheme present in a spec || templates | --templates -t | './templates' | false | Path to directory containing custom templates || statusCodes |--status-codes -S | operation.responses | false | comma separated list of status codes to explicity generate tests for |
google-oatts	Testing	To test this module simply use the npm script
google-oatts	Discussion	If you have a question or a topic you'd like to discuss, please feel free to opena discussion on our Google Group  oatts-users 
google-oatts	Contributing	Contributors are welcome! Please see  CONTRIBUTING.md  CONTRIBUTING.md .
google-oatts	Copyright	Copyright 2018, Google Inc.
google-oatts	License	See  LICENSE  LICENSE  file.
google-oauth2l	Overview	oauth2l supports all Google OAuth 2.0 authentication flows for both useraccounts and service accounts in different environments:NOTE: oauth2l caches the OAuth credentials in user's home directory toavoid prompting user repeatedly.
google-oauth2l	--json	Specifies an OAuth credential file, either an OAuth client ID or a ServiceAccount key, to start the OAuth flow
google-oauth2l	--json	You can download the file from Google Cloud Console Using an external Single Sign-on  SSO  command to fetch OAuth token.The command outputs an OAuth access token to its stdout
google-oauth2l	--json	The defaultcommand is for Google's corporate SSO
google-oauth2l	--json	For example:When this option is set and the json file specified in the --json optionis a service account key file, a JWT token signed by the service accountprivate key will be generated
google-oauth2l	--json	When this option is set, no scope list isneeded but a single JWT audience must be provided
google-oauth2l	--json	See how to construct theaudience  here 
google-oauth2l	fetch	Fetch and print an access token for the specified OAuth scopes
google-oauth2l	fetch	For example,the following command prints access token for the following OAuth2 scopes:  "access_token": "ya29.zyxwvutsrqpnmolkjihgfedcba",  "token_expiry": "2017-02-27T21:20:47Z",  "user_agent": "oauth2l/1.0.0",  ...NOTE: the -f flag specifies the output format
google-oauth2l	fetch	The supported formats are:bare  default , header, json, json_compact, pretty.
google-oauth2l	header	The same as fetch, except the output is in HTTP header format:the following command uses the PubSub API to list all PubSub topics.shell alias for it
google-oauth2l	header	For example:Print information about a valid token
google-oauth2l	header	This always includes the list of scopesand expiration time
google-oauth2l	header	If the token has either the scope, it also prints the emailaddress of the authenticated identity.Test a token
google-oauth2l	header	This sets an exit code of 0 for a valid token and 1 otherwise,which can be useful in shell pipelines.Reset all tokens cached locally
google-oauth2l	header	We cache previously retrieved tokens in thefile ~/.oauth2l.token.
google-oboe	Oboe   	**Oboe is currently in developer preview.**Oboe is a C++ library which makes it easy to build high-performance audio apps on Android
google-oboe	Oboe   	It was created primarily to allow developers to target a simplified API that works across multiple API levels back to API level 16  Jelly Bean 
google-oboe	Oboe   	Get started with Oboe here  docs/GettingStarted.md .
google-oboe	Features	To build Oboe you will need the Android NDK r17 or above
google-oboe	Features	It can be installed using Android Studio's SDK manager, or via  direct download 
google-oboe	Documentation	Sample apps can be found in the  samples directory  samples 
google-oboe	Documentation	Also check out the  Rhythm Game codelab 
google-oboe	Contributing	We would love to receive your pull requests
google-oboe	Contributing	Before we can though, please read the  contributing  CONTRIBUTING.md  guidelines.
google-oboe	Version history	 LICENSE  LICENSE 
google-offline-content-packager	What is it?	**This is not an official Google product.*
google-offline-content-packager	Documentation	additional information regarding copyright ownership
google-offline-content-packager	Documentation	 The ASF licenses thisfile to you under the Apache License, Version 2.0  the "License" ; you may notuse this file except in compliance with the License
google-offline-content-packager	Documentation	 You may obtain a copy ofthe License atWARRANTIES OR CONDITIONS OF ANY KIND, either express or implied
google-offline-content-packager	Documentation	 See theLicense for the specific language governing permissions and limitations underthe License.
google-offline-content-packager	##Mailing List	The project mailing list is offline-content-packager@googlegroups.com
google-offline-content-packager	##Mailing List	The list will be used for announcements, discussions, and general support
google-offline-content-packager	##Mailing List	You can subscribe via  groups.google.com 
google-okay	okay: abstract cross-package auth nz 	okay is a package that allows consumers to pass authentication andauthorization checks across package boundaries.Consumers should start with the base OK, which denies everyone to everything,and add permissions as required with the Allow, Validate, and Verify
google-okay	Overview	Often there is some resource to which we want to restrict access; databases  orcolumns, or rows , file systems, URL endpoints, or even specific functions orSay we have a file system type:package fsimport  	"io"	"os"	"path/filepath" type FileSystem struct {	Root stringfunc  fs FileSystem  Open path string   io.ReadCloser, error  {	return os.Open filepath.Join fs.Root, path  This could be used to e.g
google-okay	Overview	serve the file via HTTP, but it provides no accesscontrols
google-okay	Overview	 We could add this by modifying Open to take a Context which containsthe appropriate credentials:import  	"context"	"io"	"os"	"path/filepath" func  fs FileSystem  Open ctx context.Context, path string   io.ReadCloser, error  {	// TODO: check context somehow	return os.Open filepath.Join fs.Root, path  How should we check the context?  If we're serving this via HTTP, we couldprovide simple authentication by wrapping HTTP basic authentication into apackage serverimport  	"context"	"net/http" type authType stringfunc getContext r *http.Request  context.Context {	ctx := r.Context  	if user, pass, ok := r.BasicAuth  ; ok {		ctx = context.WithValue ctx, authType "user" , user 		ctx = context.WithValue ctx, authType "pass" , pass 	}	return ctxfunc handleRequest rw http.ResponseWriter, r *http.Request  {	ctx := getContext r 	doTheThing ctx, rw ...and then providing a facility to verify that context:package serverimport "context"func  s *Server  Authenticate ctx context.Context   bool, error  {	user, ok := ctx.Value authType "user"  
google-okay	Overview	string 	if !ok {		return false, nil	}	pass, ok := ctx.Value authType "pass"  
google-okay	Overview	string 	if !ok {		return false, nil	}Now we know how to check the context and can successfully gate access to ourimport  	"context"	"fmt"	"io"	"os"	"path/filepath"	"server" type FileSystem struct {	Server server.Server	Root   stringfunc  fs *FileSystem  Open ctx context.Context, path string   io.ReadCloser, error  {	ok, err := fs.Server.Authenticate ctx 	if err != nil {		return nil, err	}	if !ok {		return nil, fmt.Errorf "%s: permission denied", path 	}	return os.Open filepath.Join fs.Root, path  Unfortunately, this very tightly couples packages fs and server
google-okay	Overview	 If fswants to grant users via another scheme, such as OAuth2, or to certainadministrator users, or in some other way, all the methods which check forauthentication must be updated
google-okay	Overview	 It may be that server is not something wecan modify; it may be that fs isn't something we can modify.This can be fixed by having fs accept OK types:import  	"context"	"fmt"	"io"	"okay"	"os"	"path/filepath" type FileSystem struct {	Auths   okay.OK	Root  stringfunc  fs FileSystem  Open ctx context.Context, path string   io.ReadCloser, error  {	ok, err := okay.Check ctx, path, fs.Auths..
google-okay	Overview		if err != nil {		return nil, err	}	if !ok {		return nil, fmt.Errorf "%s: permission denied", path 	}	return os.Open filepath.Join fs.Root, path  Now FileSystem.Auths can be extended at will by fs or any consumer of fs, andit will gate the guarded resources appropriately.
google-okay	Use	Packages using okay should begin with the base type, and add authentication Verify   , authorization  Allows   , and validation  Valid    checks asThe base type is always valid, and authenticates nobody and authorizes nothing.
google-okay	Validation	OKs are valid until they are not, and are thereafter never valid
google-okay	Validation	 If aconsumer wishes to create an access grant that expires  for example, to allowaccess to a file for only 24 hours , they should do so by creating an OK thatexpires after that period of time
google-okay	Validation	 The okay package has several helperfunctions for this:their own validation functions:import  	"os"	"os/signal"	"sync/atomic"	"okay" func SigintCancel   OK {	ch := make chan os.Signal, 1 	signal.Notify ch, os.Interrupt 	var v int32	go func   {		<-ch		atomic.StoreInt32 &v, 1 	}  	ok := okay.New  	ok = okay.Validate ok, func   bool {		return atomic.LoadInt32 &v  == 0	} 	return ok
google-okay	Authentication	Consumers are expected to provide custom authentication with the Verify  Here is a simple package that provides token-based authentication:package authtokenimport  	"context"	"okay" type authToken struct{}// WithToken returns a context that contains the given auth token.func WithToken ctx context.Context, token string  context.Context {	return context.WithValue ctx, authToken{}, token // TokenOK returns an OK that verifies the given token.func TokenOK ok okay.OK, token string  okay.OK {	return okay.Verify ok, func ctx context.Context   bool, error  {		tok, ok := ctx.Value authToken{} 
google-okay	Authentication	string 		if !ok {		}		return tok == token, nil	} 
google-okay	Authorization	Authorization is provided via the Allow   function, which allows access toThe fs package  or consumers of it  might implement the following:package fsimport  	"strings"	"okay" func AllowFiles ok okay.OK, file ...string  OK {	check := make map string bool 	for _, f := range file {		check f  = true	}	return okay.Allow ok, func i interface{}   bool, error  {		f, ok := i
google-okay	Authorization	string 		if !ok {		}		return check f , nil	} func AllowPrefix ok okay.OK, pfx string  OK {	return okay.Allow ok, func i interface{}   bool, error  {		f, ok := i
google-okay	Authorization	string 		if !ok {		}		return strings.HasPrefix f, pfx , nil	} 
google-older-mirrored-patches	VLC from Google video #	A previous version of the Google Video web browser plugin was based on a patched version of VLC 0.8.A previous version of Google Desktop used a patched version of pdftohtml 0.33a.Picasa 2.2 used Wine to run on Linux
google-older-mirrored-patches	VLC from Google video #	 More info can be found on  our wine information page  Wine.md .
google-older-mirrored-patches	Hspell #	Some Google products use data from  Hspell  to implement Hebrew spell-checking.The  Really Simple History  framework makes it easy for AJAX applications to incorporate bookmarking and back and button support.You can find the  search appliance's  distribution  mirror  here.
google-omaha	This is not an official Google product. ##	Omaha is the open-source version of Google Update, a program to install requested software and keep it up to date
google-omaha	This is not an official Google product. ##	 The Google-branded version of Omaha is used to support software patching  both background updating, and on-demand update checks  for Google Chrome, Earth, and a variety of other Google products on Windows.We know that keeping software updated is both important and hard, and so by open-sourcing this project, our hope is that perhaps we can help others solve this problem
google-omaha	This is not an official Google product. ##	So, if you'd like to get involved, or even use Omaha to support your own software projects, then just follow the instructions in the  Developer Setup Guide  and you'll be good to go!There is also an unofficial  tutorial  Please note that it was written by a third party so we cannot guarantee its availability, accuracy or safety.
google-oodle-demo	Oodle Theatre	> An unofficial Google Doodles web app built as a demo for Google I/O 2018
google-oodle-demo	Build for deployment	For any issues or feature requests, we would really appreciate it if you report using our issue tracker.
google-oodle-demo	Contributing	Contributing to Oodle is subject to the guidelines in the  CONTRIBUTING.md  CONTRIBUTING.md  file, which, in brief, requires thatcontributors sign the  Individual Contributor License Agreement  CLA  
google-oodle-demo	Credits	Oodle is made possible thanks to the tireless work of the Doodles createdby the  Google Doodles  team
google-oodle-demo	Credits	We also extend ourthanks to the numerous open-source projects we rely on, including Vue and webpack.
google-open-location-code-swift	Open Location Code for Swift	   ! Carthage compatible  Convert between decimal degree coordinates and Open Location Codes
google-open-location-code-swift	Open Location Code for Swift	Shortenand recover Open Location Codes for a given reference location.This repository is the Swift implementation of Open Location Code.It supports Swift and Objective-C projects on iOS, macOS, tvOS andwatchOS, and Swift projects on Linux
google-open-location-code-swift	Open Location Code for Swift	The master repository has Open Location Code support for many other languages.
google-open-location-code-swift	About Open Location Codes	 Open Location Codes  are short, 10-11 charactercodes that can be used instead of street addresses
google-open-location-code-swift	About Open Location Codes	The codes can be generatedand decoded offline, and use a reduced character set that minimises the chanceof codes including words.Codes are able to be shortened relative to a nearby location
google-open-location-code-swift	About Open Location Codes	This meansthat in many cases, only four to seven characters of the code are needed.To recover the original code, the same location is not required, as long asa nearby location is provided.Codes represent rectangular areas rather than points, and the longer thecode, the smaller the area
google-open-location-code-swift	About Open Location Codes	A 10 character code represents a 13.5x13.5meter area  at the equator
google-open-location-code-swift	About Open Location Codes	An 11 character code represents approximatelya 2.8x3.5 meter area.Two encoding algorithms are used
google-open-location-code-swift	About Open Location Codes	The first 10 characters are pairs ofcharacters, one for latitude and one for latitude, using base Each pairreduces the area of the code by a factor of Only even code lengths aresensible, since an odd-numbered length would have sides in a ratio of 20:At position 11, the algorithm changes so that each character selects oneposition from a 4x5 grid
google-open-location-code-swift	About Open Location Codes	This allows single-character refinements.
google-open-location-code-swift	Supported Environments	This library is provided as a Swift and Objective-C Cocoa Frameworkfor iOS, macOS, tvOS and watchOS, and as a pure Swift modulefor macOS and Linux.
google-open-location-code-swift	Swift Versions	release if you're fully in the Swift 4 world!
google-open-location-code-swift	Cocoa Framework	To build the Framework:Or, if you have  Carthage  installed:Testing the framework:
google-open-location-code-swift	Swift Module	To build the pure Swift module:Testing the pure Swift module:A Dockerfile is included to build and run the pure Swift module ina Linux container:
google-open-location-code-swift	Swift Code Example	import OpenLocationCode// Encode a location with default code length.if let code = OpenLocationCode.encode latitude: 37.421908,  print "Open Location Code: \ code " // Encode a location with specific code length.if let code10Digit = OpenLocationCode.encode latitude: 37.421908,  print "Open Location Code: \ code10Digit " // Decode a full code:if let coord = OpenLocationCode.decode "849VCWC8+Q48"  {  print "Center is \ coord.latitudeCenter , \ coord.longitudeCenter " // Attempt to trim the first characters from a code:if let shortCode = OpenLocationCode.shorten code: "849VCWC8+Q48",  print "Short code: \ shortCode " // Recover the full code from a short code:if let fullCode = OpenLocationCode.recoverNearest shortcode: "CWC8+Q48",  print "Recovered full code: \ fullCode " 
google-open-location-code-swift	Objective-C Code Example	@import OpenLocationCode;// ...// Encode a location with default code length.NSString *code =  OLCConverter encodeLatitude:37.421908NSLog @"Open Location Code: %@", code ;// Encode a location with specific code length.NSString *code10Digit =  OLCConverter encodeLatitude:37.421908NSLog @"Open Location Code: %@", code10Digit ;// Decode a full code:OLCArea *coord =  OLCConverter decode:@"849VCWC8+Q48" ;NSLog @"Center is %.6f, %.6f", coord.latitudeCenter, coord.longitudeCenter ;// Attempt to trim the first characters from a code:NSString *shortCode =  OLCConverter shortenCode:@"849VCWC8+Q48"NSLog @"Short Code: %@", shortCode ;// Recover the full code from a short code:NSString *recoveredCode =  OLCConverter recoverNearestWithShortcode:@"CWC8+Q48"NSLog @"Recovered Full Code: %@", recoveredCode ;
google-open-vcdiff	open-vcdiff README	open-vcdiff is an encoder and decoder for the VCDIFF format, as described in RFC 3284  The VCDIFF Generic Differencingand Compression Data Format.You will need to first synchronize gflags and gtest by runninggit submodule update --init --recursive
google-open-vcdiff	open-vcdiff README	Or if you have system installedgflags and/or gtest libraries you can provide -Dvcdiff_use_system_gflags=ONand -Dvcdiff_use_system_gtest=ON for cmake invokation in the buildA library with a simple API is included, as well as a command-line executablethat can apply the encoder and decoder to source, target, and delta files.For further details, please refer to this link open-vcdiff comes with a CMake build script   CMakeLists.txt  CMakeLists.txt   that can be used on a wide range of platforms  "C" stands forcross-platform
google-open-vcdiff	open-vcdiff README	If you don't have CMake installed already, you candownload it for free from <>.CMake works by generating native makefiles or build projects that canbe used in the compiler environment of your choice
google-open-vcdiff	open-vcdiff README	 The typicalworkflow starts with:If you are on a \*nix system, you should now see a Makefile in thecurrent directory
google-open-vcdiff	open-vcdiff README	 Just type 'make' to build gtest.If you use Windows and have Visual Studio installed, a gtest.sln fileand several .vcproj files will be created
google-open-vcdiff	open-vcdiff README	 You can then build themusing Visual Studio.On Mac OS X with Xcode installed, a .xcodeproj file will be generated.After compilation you should have the unit tests as well as To see the command-line syntax of vcdiff, use vcdiff --help or just vcdiff.To run tests just use make test inside build directory.To call the encoder from C++ code, assuming that dictionary, target, and deltaare all c++
google-open-vcdiff	#include   // Read this file for interface details	//  ..
google-open-vcdiff	#include   // Read this file for interface details	open_vcdiff::VCDiffDecoder decoder;decoder.Decode dictionary.data  , dictionary.size  , delta, &target ;When using the encoder, the C++ application must be linked with the libraryoptions -lvcdcom and -lvcdenc; when using the decoder, it must be linkedwith -lvcdcom and -lvcddec.To verify that the package works on your system, especially after makingmodifications to the source code, please run the unit tests using make check.For further details, please refer to this link 
google-openhtf	OpenHTF	The open-source hardware testing framework
google-openhtf	OpenHTF	    Issue Stats 
google-openhtf	Overview	OpenHTF is a Python library that provides a set of convenient abstractionsdesigned to remove as much boilerplate as possible from hardware test setup andexecution, so test engineers can focus primarily on test logic
google-openhtf	Overview	It aspires todo so in a lightweight and minimalistic fashion
google-openhtf	Overview	It is general enough to beuseful in a variety of hardware testing scenarios, from the lab bench to themanufacturing floor.
google-openhtf	Installing OpenHTF	an isolated Python environments for your projects, so as to protect system-widePython packages the OS depends upon
google-openhtf	Installing OpenHTF	The installation instructions assume you've_already_ created a virtualenv and activated it if you wish to do so.
google-openhtf	Option 1: Installing via 'pip'  recommended 	The most straightforward way to get the openhtf Python package into yourPython environment is simply to install it via pip  This will install the most recentproduction release.If you want to install from source instead  for example, if you want some newfeature that hasn't made it to the production release yet , you can download the source code  via git  or other means, and install the openhtf packageinto your Python environment using the standard setup.py script.The fastest way to get started is to take a look in the examples/ directory,where you'll find sample test scripts and plugs
google-openhtf	Option 1: Installing via 'pip'  recommended 	In addition, many of OpenHTF'smodules are fairly well documented inline through the use of docstrings.Note: some of the python setup.py build command
google-openhtf	Option 1: Installing via 'pip'  recommended 	 This requires protocol buffer compilerlibrary to be installed  additional instructions  CONTRIBUTING.md#setting-up-your-dev-environment  .
google-openhtf	Nomenclature	OpenHTF uses certain nomenclature internally for several of its core concepts.Some of the more important terms are listed here for clarity.
google-openhtf	DUT  Device Under Test 	DUT refers to an individual piece of hardware being evaluated, exercised, or
google-openhtf	Test	The top-level abstraction that OpenHTF deals with is the test
google-openhtf	Test	A test is justa series of steps performed on/with a DUT, usually along with somedata-gathering or measurement steps
google-openhtf	Test	In the OpenHTF paradigm, tests areexpressed as regular Python programs  .py files  that import and instantiate the'Test' class from the openhtf module
google-openhtf	Test	That way test code is as straightforwardas possible to read and write
google-openhtf	Test	This also provides for the flexibility to doanything in a test that can normally be done in Python
google-openhtf	Test	Superficially, whatdistinguishes an OpenHTF test from any other Python program is that the OpenHTFtest imports the openhtf package, instantiates the Test class, and callsits Execute   function
google-openhtf	Test	From there, OpenHTF manages the setup, execution,and teardown of the test, keeps track of anything gathered, and provides apass/fail result.At times it may be necessary to disambiguate between different common readingsof the word _test_
google-openhtf	Test	In such scenarios we use the following more precise terms:_Stations_ capture the notion that a given test ran at some point and may runagain
google-openhtf	Test	It loosely reflects the idea of physical test stations that processmultiple DUTs over time
google-openhtf	Test	OpenHTF writes a breadcrumb to the filesystem  in adirectory that can be set using the --rundir flag  each time a test runs, andall tests that have the same name are considered to be of the same station
google-openhtf	Test	Thisway the web frontend can display a consolidated list of known tests as a list of
google-openhtf	Phase	OpenHTF tests are broken down into logical blocks called _phases_
google-openhtf	Phase	Phases are nomore than normal Python callables  usually functions  combined with the neededmetadata
google-openhtf	Phase	Writing an OpenHTF test is just a matter of writing a bunch of phasefunctions and specifying the order in which they should be executed.
google-openhtf	Measurement	OpenHTF gathers data about a DUT in the form of _measurements_
google-openhtf	Measurement	Usually,measurements are declared along with a specification that describes whatconstitutes a "passing" value
google-openhtf	Measurement	If OpenHTF finishes the test run and one or moremeasurements were out of that spec, the result of the whole test run will beconsidered a fail.
google-openhtf	Attachment	Sometimes may want to capture additional data that is more complex or free-formthan a measurement
google-openhtf	Attachment	An _attachment_ can link arbitrary binary data to atest record, along with an optional MIME type.
google-openhtf	Plug	The essence of an OpenHTF test is to interact with a DUT to exercise it invarious ways and observe the result
google-openhtf	Plug	Sometimes this is done by communicatingdirectly with the DUT, and other times it's done by communicating with a pieceof test equipment to which the DUT is attached in some way
google-openhtf	Plug	A _plug_ is a pieceof code written to enable OpenHTF to interact with a particular type of hardware,whether that be a DUT itself or a piece of test equipment
google-openhtf	Plug	OpenHTF comespackaged with a growing collection of useful plugs, but supports thecreation of custom plugs as well.
google-openpgp-interop	OpenPGP interoperability tests	This directory contains simple test cases to read OpenPGP keys and messages generated by a variety of implementations
google-openpgp-interop	OpenPGP interoperability tests	The tests are declarative, and any implementation can write a driver for these tests to check for interoperability issues.These test cases are not exhaustive by any means, and should be viewed as a simple check that messages and keys generated by various implementations can interoperate with each other.
google-openpgp-interop	Format of a test case	Tests are based on a naming convention
google-openpgp-interop	Format of a test case	Any file ending with .json is assumed to be a JSON file that declares a new test case
google-openpgp-interop	Format of a test case	It _must_ have an string field called type that declares the type of test case.There are currently two types of tests
google-openpgp-interop	Format of a test case	An __import__ test, and a __decrypt__ test.
google-openpgp-interop	Import test	This test expects the implementation to read a public key, validate it, and reject any invalid userids or subkeys
google-openpgp-interop	Import test	An example JSON file mykey.jsonThe public key is located by a naming convention, and found in the same directory by replacing the .json extension with .asc
google-openpgp-interop	Import test	So in this example, the public key to read is mytest.asc within the same directory as the JSON file.All the fields in the JSON file  except for the type field  are optional
google-openpgp-interop	Import test	But if a field is present, the implementation must confirm that after validation, it has the same information represented by the field
google-openpgp-interop	Import test	Unknown fields must be ignored.expected_uids is an optional array of strings
google-openpgp-interop	Import test	This contains an array of  validated  UserID strings in the same order as was present in the key.expected_fingerprint is an optional fingerprint of the primary key.expected_subkeys is an optional array of objects representing each valid subkey  in the same order as was present in the key
google-openpgp-interop	Import test	 Each object may also include an optional expected_fingerprint field for the subkey fingerprint.
google-openpgp-interop	Decrypt test	This test expects the implementation to decrypt a message using a provided private key, and verify it if  an optional  public key is provided
google-openpgp-interop	Decrypt test	An example JSON file mymessage.jsonThe message to decrypt is located by a naming convention, and found in the same directory by replacing the .json extension with .asc
google-openpgp-interop	Decrypt test	So in this example, the message to decrypt is mymessage.asc within the same directory as the JSON file.decryptKey is a _required_ string field, and is the name of a file within the same directory
google-openpgp-interop	Decrypt test	This file contains a private key that can decrypt the message.passphrase is a _required_ string field, and provides a passphrase to unlock the private key.verifyKey is an optional string field
google-openpgp-interop	Decrypt test	If present, it is the name of a file within the same directory
google-openpgp-interop	Decrypt test	This file contains a public key, and the message must be signed by it.filename is an optional string field that is the filename indicated by the message.timestamp is an optional numeric field that is the creation timestamp indicated by the message.textcontent is an optional string field and is the expected content of the file.
google-openpgp-interop	Attributions	These test cases are a community effort to improve interoperability between various OpenPGP implementations.Copyright 2015 The OpenPGP Interoperability Project Authors.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-openssl-tests	Notes ##	This is not an official Google product.This is an experimental patch
google-openssl-tests	Notes ##	Several tests fail for the wrong reasons,for example, because the BoringSSL test harness is tuned to specificBoringSSL errors, or because a BoringSSL feature is not available inOpenSSL and BoringSSL are provided as git submodules
google-openssl-tests	Notes ##	This means that,by default, they're checked out to a specific git commit at which thepatch and build are known to work.Please check the openssl INSTALL file for build pre-requisites
google-openssl-tests	Notes ##	You willalso need "go" installed.
google-openssl-tests	Build instructions ##	Initialize the OpenSSL and BoringSSL submodules:Configure OpenSSLPatch BoringSSLBuild and run tests
google-openssl-tests	Other instructions ##	submodule directory and use git as usual, e.g., to pull the latestoriginal state, do:
google-opentest4j	History	This project is the result of an initiative by the  JUnit Lambda team 
google-opentest4j	Status Quo	There is no standard for testing on the JVM: the only common building block we have is java.lang.AssertionError.AssertionError is great for signaling that a test has failed, but it doesn't go far enough
google-opentest4j	Status Quo	Each testing framework is therefore forced to fill the gap with custom subclasses of AssertionError or RuntimeException to provide a richer feature set to end users
google-opentest4j	Status Quo	The downside is that each framework has its **own*For example, JUnit has long supported the notion of a _failed assumption_ via its AssumptionViolatedException, but assertion frameworks like AssertJ cannot integrate that feature without a direct dependency on JUnit
google-opentest4j	Status Quo	Furthermore, the status quo makes the work of IDEs and build tools more difficult than it should be.
google-opentest4j	Proposal	The only real solution to this problem is to create a foundation that we can all build on!Based on recent discussions with IDE and build tool developers from Eclipse, Gradle, and IntelliJ, the JUnit Lambda team is working on a proposal for an open source project to provide a minimal common foundation for testing libraries on the JVM
google-opentest4j	Proposal	The primary goal of the project is to enable testing frameworks like JUnit, TestNG, Spock, etc
google-opentest4j	Proposal	and third-party assertion libraries like Hamcrest, AssertJ, etc
google-opentest4j	Proposal	to use a common set of exceptions that IDEs and build tools can support in a consistent manner across all testing scenarios -
google-opentest4j	Draft Implementation	We have begun with a small set of errors and exceptions that we consider to be common for all testing and assertion frameworks
google-opentest4j	Draft Implementation	In fact, early drafts of these errors and exceptions are already used in the  JUnit Lambda Project .Please take a look at our current draft in this project and let us know what you think.
google-opentest4j	Feedback is welcome!	What types of _errors_ and _exceptions_ should the OTA support?What types of properties should such errors and exceptions have?What additional functionality  e.g., interfaces, utility methods, etc
google-opentest4j	Feedback is welcome!	 should the OTA provide?
google-opentest4j	Projects already contacted	We've already reached out to and asked for feedback from the maintainers of the following projects.Snapshot artifacts are deployed to Sonatype's  snapshots repository .
google-opentest4j	Continuous Integration Builds	   ! built on DEV@cloud   JUnit Lambda Project :  snapshots repository : 
google-or-tools	OR-Tools 	 ! BuildStatus   ! Build status   ! PyPI version   ! NuGet version   ! Binder  Google's software suite for combinatorial optimization.
google-or-tools	Table of Contents	Google Optimization Tools  a.k.a., OR-Tools  is an open-source, fast andportable software suite for solving combinatorial optimization problems.The suite contains:We wrote OR-Tools in C++, but also provide wrappers in Python, C# and
google-or-tools	Codemap	This software suite is composed of the following components:This software suite has been tested under:For installation instructions  both source and binary , please visit
google-or-tools	Experimental Build with CMake	We also provide experimental CMake support.Please check the CMake build instructions  cmake/README.md .
google-or-tools	Quick Start	The best way to learn how to use OR-Tools is to follow the tutorials in ourdeveloper guide: examples  examples  directory.
google-or-tools	Documentation	The complete documentation for OR-Tools is available at:
google-or-tools	Contributing	The  CONTRIBUTING.md  CONTRIBUTING.md  file contains instructions on how tosubmit the Contributor License Agreement before sending any pull requests  PRs .Of course, if you're new to the project, it's usually best to discuss anyproposals and reach consensus before sending your first PR.
google-or-tools	License	The OR-Tools software suite is licensed under the terms of the Apache License 2.See  LICENSE-2.0  LICENSE-2.0.txt  for more information.
google-orderedcode	orderedcode	orderedcode provides a byte encoding of a sequence of typed items.The resulting bytes can be lexicographically compared to yield the sameordering as item-wise comparison on the original sequences.This is particularly useful for specifying the order of rows in a database withlexicographically ordered string keys, such as Bigtable.See the package documentation in orderedcode.go for details and examples.
google-osdetector-gradle-plugin	OS Detector Plugin for Gradle	A Gradle plugin that detects the OS name and architecture, providing a uniformclassifier to be used in the names of native artifacts.It uses  os-maven-plugin  under thehood thus produces the same result.
google-osdetector-gradle-plugin	Latest version	The latest version 1.6.0 is available on Maven Central.Its output is identical to os-maven-plugin:1.6.0.
google-osdetector-gradle-plugin	Usage	To use this plugin, include in your build script
google-osdetector-gradle-plugin	For Gradle 1.x and 2.0:	apply plugin: 'com.google.osdetector'buildscript {  repositories {  }  dependencies {  }The plugin creates osdetector extension in your project, through which youcan access the following attributes:  linux release:known  issue  Itwill be either removed or changed to a different form in the next version.
google-osdetector-gradle-plugin	To have separate artifacts for different operating systems	other linux systemsdef getLinuxReleaseSuffix   {  if  osdetector.release.isLike 'debian'   {  } else if  osdetector.release.isLike 'redhat'   {  } else {  }artifacts {  archives artifactFile  {  }
google-oss-fuzz	OSS-Fuzz 	> *Status*: Stable
google-oss-fuzz	OSS-Fuzz 	We are accepting applications from widely-used open source projects
google-oss-fuzz	OSS-Fuzz 	FAQ  docs/faq.md |  Ideal Fuzzing Integration  docs/ideal_integration.md |  New Project Guide  docs/new_project_guide.md |  Reproducing Bugs  docs/reproducing.md |  Projects  projects |  Projects Issue Tracker |  Glossary  docs/glossary.md  Create New Issue  for questions or feedback about OSS-Fuzz.
google-oss-fuzz	Introduction	 Fuzz testing  is a well-knowntechnique for uncovering various kinds of programming errors in software.Many of these detectable errors  e.g
google-oss-fuzz	Introduction	 buffer overflow  can have serious security implications.We successfully deployed  guided in-process fuzzing of Chrome components and found  hundreds  of security vulnerabilities and stability bugs
google-oss-fuzz	Introduction	We now want to share the experience and the service with the open source community
google-oss-fuzz	Introduction	In cooperation with the  Core Infrastructure Initiative  OSS-Fuzz aims to make common open source software more secure and stable bycombining modern fuzzing techniques and scalabledistributed execution.At the first stage of the project we use libFuzzer  with Sanitizers  More fuzzing engines will be added later
google-oss-fuzz	Introduction	ClusterFuzz  docs/clusterfuzz.md provides a distributed fuzzer execution environment and reporting.Currently OSS-Fuzz supports C and C++ code  other languages supported by  LLVM  may work too .
google-oss-fuzz	Process Overview	! diagram  docs/images/process.png?raw=true The following process is used for projects in OSS-Fuzz:one or more  fuzz targets  and  integrates  docs/ideal_integration.md  them with the project's build and test system
google-oss-fuzz	Process Overview	   example     Why use a different tracker?  docs/faq.md#why-do-you-use-a-different-issue-tracker-for-reporting-bugs-in-oss-projects  
google-oss-fuzz	Process Overview	 Project owners are CC-ed to the bug report./project.yaml file   example  projects/libarchive/project.yaml   giving at least the following information:
google-oss-fuzz	Bug Disclosure Guidelines	Following  Google's standard disclosure policy OSS-Fuzz will adhere to following disclosure principles:
google-oss-fuzz	More Documentation	 3  3 
google-oss-fuzz	Build Status	 This page gives the latest build logs for each project
google-oss-fuzz	Build Status	Internal only   Builds dashboard 
google-oss-fuzz	Trophies	 This page gives a list of publicly-viewable fixed bugs found by OSS-Fuzz.
google-ot-crdt-papers	Operational Transform and CRDT papers and prototypes	This repository will hold papers Raph Levien is writing on technologies forcollaborative text editing, in particular at the intersection ofOperational Transformation and Conflict-free Replicated Data Types  CRDT's .It also holds a prototype implementation in JavaScript, using socket.io 
google-ot-crdt-papers	Running the prototype collaborative editor	Do npm install to install the required Node dependencies, then node 
google-ot-crdt-papers	Running the prototype collaborative editor	to runthe server
google-ot-crdt-papers	Running the prototype collaborative editor	Connect any number of clients, then start typing
google-ot-crdt-papers	Running the prototype collaborative editor	You can simulatenetwork lag by enabling an optional "sleep" call in the server.
google-ot-crdt-papers	Disclaimer	This is not an official Google product.
google-p0tools	Project Zero Docs and Tools	This project contains various documents published by Google Project Zero and small tools that don't need a separate GitHub project.For individual topics, see subdirectories.
google-p0tools	Disclaimer	This is not an official Google product.
google-packet-queue	Packet Queue	This is a configurable TCP/UDP packet impairment tool for Linux
google-packet-queue	Packet Queue	It looks like
google-packet-queue	Setup	Install the dependencies, including the Linux nfqueue library:to set the MTU to something small:For example, to impair TCP traffic on loopback port 3000:shut down gracefully, you can clear the rules like this:You can run most of the tests like this:they require root:
google-packetdrill	packetdrill	This is the official Google release of packetdrill.The packetdrill scripting tool enables quick, precise tests for entire TCP/UDP/IPv4/IPv6 network stacks, from the system call layer down to the NIC hardware
google-packetdrill	packetdrill	packetdrill currently works on Linux, FreeBSD, OpenBSD, and NetBSD
google-packetdrill	packetdrill	It can test network stack behavior over physical NICs on a LAN, or on a single machine using a tun virtual network device.The code is GPLvCurrently the source for the testing tool and a number of test scripts is in the git repository
google-packetdrill	packetdrill	We will continue to post more tests from our team's Linux TCP test suite  described in our USENIX paper , as time permits.
google-paco	PACO is an opensource, mobile, behavorial research platform	For general information visit the home page:To get the iOS app, go to the App Store:Also, you can stay in touch
google-paco	Social Media	Paco is licensed under the Apache 2.0 License
google-page-timer	How long have I been on this page?	Ever open an email, do a task, then wonder how long that took?  Install this,then just look at the timer next to the URL bar
google-page-timer	How long have I been on this page?	 It records how long it's beensince the URL has changed
google-page-timer	How long have I been on this page?	 Click to see the last few pages you were on and howlong you spent there.All data is kept locally in ram; no data is sent over the network or saved toOr  get it from the Chrome Web Store This is not an official Google product.
google-pageloader	HtmlPageLoaderElement example:	import 'package:pageloader/html.dart';Element myElement = ...;final context = HtmlPageLoaderElement.createFromElement myElement ;final myPO = MyPO.create context ;createFromElement has an additional named argument SyncFn externalSyncFn.This synchronizing function is called on asynchronous events  click, type, etc
google-pageloader	HtmlPageLoaderElement example:	 and ensures that these events have time to take into effect
google-pageloader	HtmlPageLoaderElement example:	By default, this is a no-op function
google-pageloader	HtmlPageLoaderElement example:	An example of a custom sync function:for more information about which events are asynchronous.
google-pageloader	WebdriverPageLoaderElement example:	import 'package:pageloader/webdriver.dart';import 'package:webdriver/sync_io.dart';String pagePath = ...; // Page uri pathWebdriver driver = ...; // Refer to Webdriver package documentationWebDriverPageUtils loader = WebDriverPageUtils driver ;driver.get pagePath ;WebDriverPageLoaderElement context = loader.root;WebDriverMouse get mouse = loader.mouse;final myPO = MyPO.create context ;// ...run tests...loader = null;driver.quit  ;How do I trigger the generation step?pub run build_runner buildLazy LoadingStarting from version 3, all elements are lazy.read information from the page or interact with the browser:you read text lazily, and now you find elements lazily.Existence CheckingIn PageLoader version 2.X.X, the @optional tag was used to mark some entityas possibly not existing
google-pageloader	WebdriverPageLoaderElement example:	For example:exist, it would have null value
google-pageloader	WebdriverPageLoaderElement example:	Starting from version 3, @optional is removed and these entities nolonger return as null
google-pageloader	WebdriverPageLoaderElement example:	For PageLoaderElement, you directly useits .exists getter to check or use provided matchers.import 'package:pageloader/testing.dart';PageLoaderElement myElement = ...;expect myElement.exists, isTrue ;expect myElement, exists ;For PageObjects, use provided matchers:import 'package:pageloader/testing.dart';SomePO somePO = SomePO.create context ;expect somePO, exists ;What is synchronous/asynchronous?PageLoaderElements in version 3.0.0 and above use both synchronousand asynchronous calls in the API
google-pageloader	WebdriverPageLoaderElement example:	The basic rule is as follows:any call that cannot change the DOM is synchronous, and any callthat can change the DOM is asynchronous.For example, reading DOM attributes or finding elements is synchronous.Click and typing are still asynchronous.Interactions, e.g
google-pageloader	WebdriverPageLoaderElement example:	clicking, typing, etc
google-pageloader	WebdriverPageLoaderElement example:	still return Futures
google-pageloader	WebdriverPageLoaderElement example:	Why?Remember that component tests actually run in the browser, with the component,in the same thread
google-pageloader	WebdriverPageLoaderElement example:	Dart  like JavaScript  has no threads, so if the test isdoing something then the component is not
google-pageloader	WebdriverPageLoaderElement example:	If the whole test is synchronousit'll execute start to finish without any pause, as one massive action inthe event loop.So, we'll type something, but the component won't update..
google-pageloader	WebdriverPageLoaderElement example:	because itcan't actually execute
google-pageloader	WebdriverPageLoaderElement example:	And the next line, where we assert something aboutthe component it will fail: i.e
google-pageloader	WebdriverPageLoaderElement example:	clicking, typing  be asynchronous allows the component to change:With code-gen, direct inheritance is no longer allowed
google-pageloader	WebdriverPageLoaderElement example:	However,you can use mixins or delegation to keep 'inheritance-like'behavior in your code.Consider: @PageObject  abstract class BasePO {  // ..
google-pageloader	WebdriverPageLoaderElement example:	boilerplate code ..
google-pageloader	WebdriverPageLoaderElement example:	 MyWidgetPO get myWidget;@PageObject  abstract class ExtraPO extends BasePO { // 'extends' not allowed  // ..
google-pageloader	WebdriverPageLoaderElement example:	boilerplate code ..
google-pageloader	WebdriverPageLoaderElement example:	 MyExtraWidgetPO get extraWidget;Delegation method fix:@PageObject  abstract class BasePO {  // ..
google-pageloader	WebdriverPageLoaderElement example:	boilerplate code ..
google-pageloader	WebdriverPageLoaderElement example:	 MyWidgetPO get myWidget;@PageObject  abstract class ExtraPO {  // ..
google-pageloader	WebdriverPageLoaderElement example:	boilerplate code ..
google-pageloader	WebdriverPageLoaderElement example:	 BasePO get _basePO;  MyExtraWidgetPO get extraWidget;Mixin method fix:@PageObject  abstract class BasePO extends Object with BasePOMixin {  // This should ONLY have the constructors  BasePO  ;  factory BasePO.create PageLoaderElement context  =@PageObject  abstract class BasePOMixin {  // Note that here are no constructors here
google-pageloader	WebdriverPageLoaderElement example:	 MyWidgetPO get myWidget;@PageObject  abstract class ExtraPO extends Object with BasePOMixin {  // ..
google-pageloader	WebdriverPageLoaderElement example:	boilerplate code ..
google-pageloader	WebdriverPageLoaderElement example:	 BasePO get _basePO;  MyExtraWidgetPO get extraWidget;
google-pagespeed-inslides	PageSpeed InSlides	**✏️ Description:**The *PageSpeed InSlides not a typo, think "PageSpeed, but in slides"  —lifts the output from the PageSpeed Insights API and creates an interactive  HTML5 slide deck for you, on the fly
google-pagespeed-inslides	PageSpeed InSlides	The target audience is technical, for example,front-end engineers and webmasters, this is not meant as an introductory pitch deck.Also, the decks are designed for *desktop*, to be shown in *full screen mode*, ideally on a projector.*Please note: this is not an official Google product.***🖥 Screenshots:**Input form with various options:! Input Form Slide examples:! Title Slide ! Screenshot Slide ! Waterfall Diagram Slide ! Optimization Slide **📚 Instruction Manual:**The features of the PageSpeed InSlides tool are described in the  manual   PDF .**🔥 Demo:**Navigate to this  demo deck then navigate in the slides with the arrow keys ⬅️ ➡️ .Please note that this demo is not generated live, but an archived older version.**⚙️ Setup:**Get an API key and activate the necessary APIs in the Google Developer Console:Now you are good to go and launch the tool via npm run start.**🔨 Usage:**Open the form at  localhost:3000/  and simply enter a URL,optionally change any of the other fields.As an alternative, the user interface is also accessible in form of a hackable URL 😎.Just replace the highlighted parts as explained below:  Thomas Steiner   tomac@google.com  mailto:tomac@google.com  **📄 License:**Copyright 2017 GoogleLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atUnless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-pam-cryptsetup	Overview	pam-cryptsetup provides a PAM module that allows LUKS-based disk encryption passwords to bekept in sync with account passwords automatically based on factors like if the user hasdecypted the disk successfully previously.
google-pam-cryptsetup	Module Configuration	When adding this module to an authentication stack, it is recommended to use either the ' default=ignore ' or 'optional' flags and to place the entry for the module at the very end of the PAM config file sequence, as one probably doesn't want authentication of a user hinging on a module that doesn't provide any.
google-pam-cryptsetup	Arguments:	For an encrypted device at /dev/mapper/rootdev_crypt:
google-pam-cryptsetup	Crypt Slot Cache	All user information, such as which  if any  slot was most recently unlocked with their login password, is recoded in /var/cache/libpam-cryptsetup as a GLib string array.The default format, before any unlocking has happened, is as follows:where each string associates with one of the 8 LUKS slots  numbered 0-7  available
google-pam-cryptsetup	Crypt Slot Cache	Once a user's password has sucessfully unlocked a slot on the disk, their username is added to the string associated with the number slot unlocked.For example, if we had a user "kathy" unlock slot 3, the cache would be updated as follows:Next time kathy authenticates, this info will be used to determine the appropriate action for the module to take.
google-pam-cryptsetup	Operation	During authentication, the module takes the following information into account:Authentication mode:
google-pam-cryptsetup	Building	Built with autotools and includes an autogen.sh script: ./autogen.sh ./configure make make check #  optional  sudo make install
google-pandas	pandas: powerful Python data analysis toolkit	 ! Scatter-CI Status page  
google-pandas	What is it	structures designed to make working with "relational" or "labeled" data botheasy and intuitive
google-pandas	What is it	It aims to be the fundamental high-level building block fordoing practical, **real world*the broader goal of becoming **the most powerful and flexible open source dataanalysis / manipulation tool available in any language**
google-pandas	What is it	It is already well onits way toward this goal.
google-pandas	Main Features	Here are just a few of the things that pandas does well:
google-pandas	Where to get it	The source code is currently hosted on GitHub at:Binary installers for the latest released version are available at the Pythonpackage index
google-pandas	Notes about HTML parsing libraries	  pandas.read_html will **not*  installed
google-pandas	Notes about HTML parsing libraries	 installation and usage of the above three libraries
google-pandas	Notes about HTML parsing libraries	 libraries  sudo apt-get build-dep python-lxml    This will prevent further headaches down the line.
google-pandas	Installation from sources	To install pandas from source you need Cython in addition to the normaldependencies above
google-pandas	Installation from sources	Cython can be installed from pypi:cloning the git repo , execute:in automatically  the -e option is for installing it in  developmentmode 
google-pandas	Documentation	The official documentation is hosted on PyData.org: The Sphinx documentation should provide a good starting point for learning howto use the library
google-pandas	Documentation	Expect the docs to continue to expand as time goes on.
google-pandas	Background	Work on pandas started at AQR  a quantitative hedge fund  in 2008 andhas been under active development since then.
google-pandas	Discussion and Development	Since pandas development is related to a number of other scientificPython projects, questions are welcome on the scipy-user mailinglist
google-pandas	Discussion and Development	Specialized discussions or design issues should take place onthe pystatsmodels mailing list / Google group, wherescikits.statsmodels and other libraries will also be discussed:
google-paper-gui	PaperGUI	A clone of  dat.GUI  using nice Polymer  1.0   paper elements
google-paper-gui	PaperGUI	One of the advantages is that this makes it touch and mobile friendly
google-paper-gui	PaperGUI	The API is intentionally similar, although not all features have been ported to PaperGUI.
google-paper-gui	Install	Building requires node, gulp and bower.The dist folder contains the build
google-paper-gui	Install	The paper-gui.html file is the only oneyou need if you want to use web component-style, synchronous import.Otherwise, you'll need all 3 files in the dist folder as paperGUI.js loadsthe other two.To try out the demo, run a webserver in the papergui root folder, eg:Then open  in a browser.
google-paper-gui	Basic usage	With very little code, PaperGUI creates an interface that you can use to modify variables, exactly like  dat.GUI  from which the below example is adapted.var FizzyText = function   {  this.message = 'PaperGUI';  this.speed = 0.8;  this.displayOutline = false;  this.explode = function   { ..
google-paper-gui	Basic usage	};  // Define render logic ..
google-paper-gui	Basic usage	document.addEventListener 'PaperGUIReady', function e  {  var text = new FizzyText  ;  var gui = new PaperGUI  ;  gui.add text, 'message' ;  gui.add text, 'speed', -5, 5 ;  gui.add text, 'displayOutline' ;  gui.add text, 'explode' ;As shown above, the paperGUI.js script loads a polyfill and then imports the web components necessary for the PaperGUI library to work
google-paper-gui	Basic usage	Once it's all set, it triggers a PaperGUIReady event
google-paper-gui	Basic usage	This allows to delay the loading of PaperGUI as much as possible.Alternatively, you can skip the loader script call and use a  blocking  import directly
google-paper-gui	Basic usage	Add this at the top of your HTML:
google-paper-gui	Constrain	You can specify limits on numbers
google-paper-gui	Constrain	A number with a min and max value becomes a slider
google-paper-gui	Constrain	This is exactly the  same API as dat.GUI // Choose from accepted valuesgui.add text, 'message',   'pizza', 'chrome', 'hooray'    ;// Choose from named valuesgui.add text, 'speed', { Stopped: 0, Slow: 0.1, Fast: 5 }  ;
google-paper-gui	Events	You can listen for events on individual controllers using an event listener syntax.var controller = gui.add fizzyText, 'maxSize', 0, 10 ;controller.onChange function value  {  // Fires on every change, drag, keypress, etc.} ;Note: the onFinishChange handler  from dat.GUI  is currently not supported.
google-paper-gui	Styling & positioning	PaperGUI exposes custom CSS properties and mixins  see  Polymer documentation  through which you can change the colors and style of the UI.
google-paper-gui	Custom properties	Properties below can be used to modify the default colors of the PaperGUI interface and components:| Custom Property| ----------------------------------| --paper-gui-accent-color| --paper-gui-accent-contrast-color | Applied to fonts and icons where the background uses accent color  buttons   || --paper-gui-background-color| --paper-gui-text-color| --paper-gui-ui-color| --paper-gui-ui-secondary-color
google-paper-gui	Example	In your main html file:
google-paper-gui	PaperGUI constructor parameters	The PaperGUI constructor can accept an object containing various options  eg
google-paper-gui	PaperGUI constructor parameters	var gui = new PaperGUI {autoPlace: false} ; | Property name | Type| autoPlace   | Boolean | Whether to automatically append the PaperGUI element to the DOM as soon as at least one controller has been added
google-paper-gui	PaperGUI constructor parameters	Default is **true**
google-paper-gui	PaperGUI constructor parameters	|
google-paper-gui	PaperGUI methods	PaperGUI has several methods.| Method name | Description || add  | el  | open  | close     | Closes the dialog containing the controllers
google-paper-gui	PaperGUI methods	Equivalent to clicking the close button in the dialog
google-paper-gui	PaperGUI methods	|| hide  | show  Here's a summary of the controller types PaperGUI currently supports:| PaperGUI Controller type | Property type | Extra parameters || Button| Toggle| Text input| Select box| Slider| Select box
google-paper-gui	Controller methods	All controller methods return themselves, allowing to chain method calls
google-paper-gui	Controller methods	Here is a list of methods.| Method| name labelString | onChange callbackFunction  | Calls the function when the value changes| min minNumber | max minNumber | step stepNumber 
google-param_runner	param_runner	param_runner.sh is a minimalistic task batching / queueing tool built on top of etcd version 3, written as a bash script library.In order to use param_runner, write your own task as a bash function that takes parameters to partition work item, then pass the function as an argument to param_runner::run
google-param_runner	param_runner	The following example illustrates the usage of this library end to end.
google-param_runner	Installation	etcdctl commandline tool is required
google-param_runner	Installation	See  etcd  document for instructions on getting etcd, which also bundles etcdctl
google-param_runner	Installation	You can either put etcdctl in PATH, or path to etcdctl can be specified by --param_runner_etcdctl_bin flag.Apart from bash, coreutils and etcdctl executable, the only external dependency is  jq  used for commandline json parsing
google-param_runner	Installation	jq is widely available as binary package in most popular OS distributions
google-param_runner	Installation	In Ubuntu, install jq by doing:Suppose we have a simple addition calculating job defined  see  the included example  example/calc_and_sleep_etcd.sh  for the full example :
google-param_runner	#!/bin/bash	source path/to/param_runner_etcd.sh || exit 1FLAGS "$@" || exit 1set -extra_flags=  "$@"  function run {  echo "Task example $1: $2 + $3 = $  $2 + $3  "  echo "${extra_flags @ }"param_runner::run runNote that param_runner.sh sources shflags, and it is the wrapping script's job to initialize FLAGS  after defining its own flags 
google-param_runner	#!/bin/bash	This job takes three parameters, the name of task and two numbers whose sum will be an output of the job
google-param_runner	#!/bin/bash	Also note the extra_flags handling
google-param_runner	#!/bin/bash	This allows us to specify parameters at run time independent of the parameter sets
google-param_runner	#!/bin/bash	Now run the example:Note that we use etcdctl version 3 API.Running with parameter set found at /ls/test/home/$USER/param_runner/param/1Task example 1plusTen: 1 + 10 = 11--some --extra=argumentParameter set 1 succeededWe can see the execution results by listing /result path:Once we are done with the tasks, we can place poison pill so that the param runner will exit gracefully.See the included example  Docker file  Dockerfile.example .
google-param_runner	Disclaimer	This is not an official Google product.
google-paramgmt	Disclaimer	This is not an official Google product
google-paramgmt	Disclaimer	This project was created by Nic McDonald  at Google.
google-paramgmt	Summary	ParaMgmt is a python package designed to ease the burden of interacting withmany remote machines via SSH
google-paramgmt	Summary	The primary focus is on parallelism, good errorhandling, automatic connection retries, and nice viewable output
google-paramgmt	Summary	The abilitiesof ParaMgmt include running local commands, running remote commands,transferring files to and from remote machines, and executing local scripts onremote machines
google-paramgmt	Summary	This package includes command-line executables that wrap thefunctionality provided by the Python package.
google-paramgmt	Install	ParaMgmt is compatible with both Python2.7+ and Python3.x
google-paramgmt	Install	I personallyrecommend Python3, so the following installation example will be for that
google-paramgmt	Install	Ifyou insist on using Python2, substitute python2
google-paramgmt	Install	If you want ParaMgmt installed in both, install it in Python2 then inPythonThe command-line executables will then use the latter
google-paramgmt	Install	The installerrequires the setuptools package.Both installations methods below will install a Python package called rscript.
google-paramgmt	Python package manager  PIP 	Install globally:
google-paramgmt	Source installation	Install globally:
google-paramgmt	Uninstall	The following command will uninstall the paramgmt Python package and thecommand-line executables.
google-paramgmt	Test	Create a hosts file
google-paramgmt	Usage	Tutorial here: 
google-pasta	pasta: **P**ython **AST*	*This is still a work-in-progress; there is much more to do
google-pasta	pasta: **P**ython **AST*	Existingfunctionality may not be perfect.*
google-pasta	Mission	Enable python source code refactoring through AST modifications.Sample use cases:
google-pasta	Python Version Support	Targeted for Python 2.7, with additional support for Python 3.4.
google-pasta	Basic Usage	import pastatree = pasta.parse source_code 
google-pasta	... Augment contents of tree ...	source_code = pasta.dump tree 
google-pasta	Built-in Augmentations	Pasta includes some common augmentations out-of-the-box
google-pasta	Built-in Augmentations	These can be used asbuilding blocks for more complex refactoring actions.*There will be more of these basic augmentations added over time
google-pasta	Built-in Augmentations	Stay tuned!*
google-pasta	Rename an imported name	Rewrites references to an imported name, module or package
google-pasta	Rename an imported name	For some moreexamples, see  pasta/augment/rename_test.py  pasta/augment/rename_test.py .
google-pasta	Rewrite references from one module to another	rename.rename_external tree, 'pkg.subpkg.module', 'pkg.other_module' 
google-pasta	Rewrite references from one package to another	rename.rename_external tree, 'pkg.subpkg', 'pkg.other_pkg' 
google-pasta	Rewrite references to an imported name in another module	rename.rename_external tree, 'pkg.module.Query', 'pkg.module.ExecuteQuery' 
google-pasta	Known issues and limitations	  extracting a method
google-pasta	Known issues and limitations	 pasta relies on  ast.parse 
google-pasta	Developing	This project uses setuptools  tofacilitate testing and packaging.
google-pasta	Run all tests	python setup.py test
google-pasta	Run a single test suite	python setup.py test -s pasta.base.annotate_test.suite
google-pasta	Disclaimer	This is not an official Google product.
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	The contents of this repository are not an official Google product
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	Google Patents Public Datasets  is a collection of compatible BigQuery database tables from government, research and private companies for conducting statistical analysis of patent data
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	The data is available to be queried with SQL through BigQuery, joined with private datasets you upload, and exported and processed using many other compatible analysis tools
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	This repository is a centralized source for examples which use the data.Currently the repo contains two examples: Patent Landscaping   A demo of an automated process of finding patents related to a particular topic given an initial seed set of patents
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	Based on the paper by Dave Feltenberger and Aaron Abood,  Automated Patent Landscaping  models/landscaping/AutomatedPatentLandscaping.pdf 
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	Claim Text Extraction  A demo of interacting with patent claim text data using BigQuery and python
google-patents-public-data	Patent analysis using the Google Patents Public Datasets on BigQuery	Claim Breadth Model  A machine learning method for estimating patent claim breadth using data from BigQuery.
google-patrick	Introducing patrick	This package is an extension to testthat that enables parameterized unittesting in R.
google-patrick	Installing	The release version of patrick is available on CRAN
google-patrick	Installing	Install it in the usualInstall it using devtools.Many packages within R employ the following pattern when writing tests:test_that "Data is a successfully converted: numeric", {  input <  expect_is input, "numeric" } test_that "Data is a successfully converted: character", {  input <  expect_is input, "character" } While explicit, recycling a test pattern like this is prone to user error andother issues, as it is a violation of the classic DNRY rule  do not repeatyourself 
google-patrick	Installing	patrick eliminates this problem by creating test parameters.usual, you call all of your tests with devtools::test, and they'll also runduring package checks
google-patrick	Installing	Each executes independently and then your test reportwill produce a single report
google-patrick	Installing	A complete name for each test will be formed usingthe initial test description and the strings in the test_name parameter.Small sets of cases can be reasonably passed as parameters towith_parameters_test_that
google-patrick	Installing	This becomes less readable when the number of casesincreases
google-patrick	Installing	To help mitigate this issue, patrick provides a case generatorhelper function.This package is inspired by parameterized testing packages in other languages,notably the  parameterized  libraryin Python.
google-patrick	Contributing	Please read the  CONTRIBUTING.md  CONTRIBUTING.md  for details on how tocontribute to this project.
google-patrick	Disclaimer	This is not an officially supported Google product.
google-pawn	Pawn BIOS Dumping Tool   	Copyright 2014-2018 Google LLC.Disclaimer: This is not an official Google product  experimental or otherwise ,it is just code that happens to be owned by Google.
google-pawn	What is it?	Pawn is a tool to extract the BIOS firmware from Intel-based workstations andThe name is a play on an internal tool that is also named after a chess piece.
google-pawn	Usage	The following command will extract the BIOS firmware and save the image toNote: When running a Linux kernel > 4.8.4, make sure that eitherCONFIG_IO_DEVMEM=n is set or that you've booted with the iomem=relaxedboot option.After extraction, you can then use other tools like UEFITool  to process the firmwareimage further.
google-payjs	Google Pay Integration Library	For a detailed tutorial on how to use this library please go through
google-payjs	Build this library	Once you have bazel installed  "Bazel Installation instructions" please run
google-pbvi	pbvi  Point-Based Value Estimation 	This is an implementation of Point-based value iteration: An anytime algorithmfor POMDPs  Pineau, Gordon, Thrun 2003 .This is not an official Google product.So far, only the value iteration step is implemented.
google-pde-superresolution	Super-resolution methods for solving PDEs	This is not an official Google product.
google-pde-superresolution	Installation	Clone this repository and install in-place:Note that Python 3 is required
google-pde-superresolution	Installation	Dependencies  including TensorFlow  arespecified in setup.py and should be installed automatically as required.
google-pde-superresolution	Running tests	From the source directory, execute each test file:
google-percy-node	percy-node	This is a wrapper of  percy-js  that simplifies the API so it can be used for automated visual regression testing in node environments such as testing an express app, an Angular app, or AngularJS app.For more general information about Percy, visit  Percy's homepage This is not an official Google product.
google-percy-node	How to use	Percy-node is an installable  npm package Percy-node provides an optional feature to return Percy build results
google-percy-node	How to use	Passing 'true' to finalizeBuild   to enable that feature
google-percy-node	How to use	You also need a token with read access, please reach out to the Percy team for that.This package was originally created specifically to allow testing of Express AngularJS apps tested with Jasmine, Karma, and Protractor
google-percy-node	How to use	However, it is written in a general enough way that it could be used in another node based testing environment.
google-percy-node	How to use with Protractor	See the  Protractor guide  /docs/protractor.md 
google-percy-node	Contributing	See  CONTRIBUTING.md  /CONTRIBUTING.md 
google-perf_data_converter	Introduction	The perf_to_profile binary can be used to turn a perf.data file, which isgenerated by the linux profiler, perf, into a profile.proto file which can bevisualized using the tool pprof.For details on pprof, see **THIS IS NOT AN OFFICIAL GOOGLE PRODUCT**
google-perf_data_converter	Prerequisites to build	  sudo apt-get -y install g++ git libelf-dev libcap-dev  
google-perf_data_converter	Compile and Test	To install all dependences and build the binary, run the following commands.These were tested on Ubuntu 14.04 LTS:
google-perf_data_converter	Running tests	  make check clean  make check clean -C quipper/ -f Makefile.external  
google-perf_data_converter	Usage	  perf record /bin/ls    pprof -web perf.data  
google-perf_data_converter	Contribution	We appreciate your help!Note that perf data converter and quipper projects do not use GitHub pullrequests, and that we use the issue tracker for bug reports.
google-periph	periph 	 ! mascot  Documentation is at  ! GoDoc   ! Go Report Card      Join us for a chat on gophers.slack.com/messages/periph get an  invite here 
google-periph	Example	Blink a LED:package mainimport   func main   {~~~Curious? Look at  supported devices  for more
google-periph	Authors	periph was initiated with ❤️️ and passion by  Marc-AntoineRuel  The full list of contributors is in AUTHORS  and CONTRIBUTORS 
google-periph	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.This project is not affiliated with the Go project.
google-personfinder	Person Finder   	Person Finder is a searchable missing person database written in Python andhosted on App Engine.Person Finder implements the PFIF data model and provides PFIF import and exportas well as PFIF Atom feeds
google-personfinder	Person Finder   	It was initially created by Google volunteers inresponse to the Haiti earthquake in January 2010, and today containscontributions from many volunteers inside and outside of Google
google-personfinder	Person Finder   	It was usedagain for the earthquakes in Chile, Yushu, and Japan, and now runs at
google-personfinder	How to Contribute	Follow  GettingStarted  to set up your development environment.Follow  CONTRIBUTING  to send pull requests.
google-pg_page_verification	pg_page_verification	Keeping data safe is the top responsibility of anyone running a database
google-pg_page_verification	pg_page_verification	 To prevent against data loss, the Cloud SQL for PostgreSQL team has developed thePostgreSQL Page Verification tool  pg_page_verification  to verify checksumson PostgreSQL data pages without having to load each page into shared buffercache
google-pg_page_verification	pg_page_verification	 The tool currently skips the Free Space Map  FSM , Visibility Map  VM and pg_internal.init files since they can be regenerated
google-pg_page_verification	pg_page_verification	 It can be run whenthe database process is online or offline and supports subsequent segmentsfor tables larger than 1GB
google-pg_page_verification	pg_page_verification	 Cloud SQL for PostgreSQL uses the tool at scaleto validate backups.
google-pg_page_verification	Usage	./pg_page_verification -D /path/to/data/dir
google-pg_page_verification	Disclaimer	This is not an official Google product.
google-physical-web	The Physical Web	The Physical Web is an effort to extend the superpower of the web At its base, the Physical Web is a discovery service: a smart object broadcasts relevant URLs that any nearby device can receive
google-physical-web	The Physical Web	This simple capability can unlock exciting new ways to interact with the Web
google-physical-web	The Physical Web	 
google-physical-web	Why URLs?	The URL is the fundamental building block of the web, giving remarkable flexibility of expression
google-physical-web	Why URLs?	It can be:The number of smart objects is going to explode, both in our homes and in public spaces
google-physical-web	Why URLs?	Much like the web, there is going to be a long tail of interactivity for smart objects
google-physical-web	Why URLs?	But the overhead of installing an app for each one just doesn’t  scale
google-physical-web	Why URLs?	We need a system that lets you walk up and use a device with just a tap
google-physical-web	Why URLs?	The Physical Web isn’t about replacing native apps; it’s about allowing interaction for the times when native apps just aren’t practical.
google-physical-web	Open Design	The Physical Web must be an open standard that everyone can use
google-physical-web	Open Design	This can’t be a product that is locked down by a single company
google-physical-web	Open Design	Like many web specifications, this is an open source design that is being released early so everyone can experiment and comment on it
google-physical-web	Open Design	There is much to discuss and add to this specification.
google-pienoon	Motivation	 Pie Noon    is a demonstration for several technologies, including the FlatBuffers    serialization system, the  Motive    animation system, the MathFu    geometry math library, the  Pindrop    audio engine, and the fplutil    utility library for Android C++ development
google-pienoon	Motivation	It also uses simplerendering and GUI subsystems  see  Engine    .Pie Noon is also an example of a quick and fun party game for the living roomvia support for the  Nexus Player   , an  Android TV    device.
google-pienoon	Downloading	 Pie Noon    can be downloaded from:**Important**: Pie Noon uses submodules to reference other components itdepends upon, so download the source from  GitHub    using:~~~
google-pienoon	Documentation	See our online documentation for how to  Build and Run Pie Noon   , and for a Programmer's Guide    that details the overall structure of the game and allof it's subsystems.To contribute the this project see  CONTRIBUTING   .For applications on Google Play that are derived from this application, usageis tracked.This tracking is done automatically using the embedded version string kVersion , and helps us continue to optimize it
google-pienoon	Documentation	Aside fromconsuming a few extra bytes in your application binary, it shouldn't affectyour application at all
google-pienoon	Documentation	We use this information to let us know if Pie Noonis useful and if we should continue to invest in it
google-pienoon	Documentation	Since this is opensource, you are free to remove the version string but we would appreciate ifyou would leave it in
google-pienoon	Documentation	  Pindrop :   Engine :   fplutil :   MathFu :   Pie Noon :   CONTRIBUTING :
google-pik	Pik	 ! Build status  build-status-img   build-status Pik is a new lossy image format for the internet
google-pik	Pik	This directory containsan encoder and a decoder for the format.This project is in the initial research stage, please don't use it for any
google-pik	Project Goals	Pik is to have roughly the same performance requirements space thatJPEG is holding today
google-pik	Project Goals	We aim to have roughly similar decoding speed,i.e., no more than 50 % slower in decoding, but adding more moderncompression and prediction methods, giving 55 % more density
google-pik	Project Goals	We plan toimprove to 65 % before freezing the format
google-pik	Project Goals	Some of these new advances maycome with a moderate drop in decoding speed  possibly 40 % of jpeg speed .The bitstream supports tiles so that multi-core decoding can decode a singleimage faster  up to 1 GB/s .We are planning to keep the format 8x8 DCT based, possibly with some supportfor non-integral-transform-based direct mode blocks  or overlay blocks .
google-pik	Build instructions	The software currently requires an AVX2 and FMA capable CPU, e.g
google-pik	Build instructions	Haswell.Please run git submodule init && git submodule update, then make -j8, whichcreates cpik and dpik binaries in bin/.The --distance command line argument to cpik is a Butteraugli distance  see which indicates the largest acceptableerror
google-pik	Build instructions	Larger values lead to smaller files and lower quality
google-pik	Build instructions	Try 1.0 for avisually lossless result.
google-pik	Related projects	 build-status :
google-pinotify	PiNotify project	PiNotify seeks to provide a way to notify and send short  140 character  messages via a tabletdisplay, along with physical blinking lights and a physical button.The flashing lights will blink until the message is acknowledged.See PiNotify Design.py for more details about the project design.
google-pinotify	Disclaimer	This is not an official Google product.
google-pinotify	Setup	The project consists of 3 apps that work in concert: a backend and web UI that runs on GoogleAppEngine, an Android app that runs on the tablet, and a Raspberry Pi app that controls the lightsand physical button based on Bluetooth commands from the tablet.Before the AppEngine and Android apps can be built and run, some setup is required
google-pinotify	Setup	Most of thissetup involves creating keys for Firebase Push Notifications and Google Cloud Endpoints, which areused to allow the Android app to communicate with the backend.Comments marked in the code with SETUP_TODO are things that need to be done to build, run, andSome of this setup can probably be simplified in the future.Setup steps:Create a Google Cloud Platform project and enable AppEngine on pip install -t lib google-endpoints --ignore-installedFollow the instructions atIn app/src/main/java/com/pinotify/BackendService.java, enter the Cloud Endpoints audience.In appengine/api.py, enter the Android and web client IDs from your project's Cloud ConsoleIn appengine/web_handlers.py, add your Firebase cloud messaging API key.Follow the instructions onWhen you launch the Android app, you'll need to enter the backend service URL
google-pinotify	Setup	This can either be
google-pixelvisualcorecamera	Pixel Visual Core Camera	The Pixel Visual Core Camera application was designed to provide Androiddevelopers with a simple example on how to enable Pixel Visual Core in theircamera applications to accelerate HDR+ processing using Camera API 1 and 
google-pixelvisualcorecamera	Device Requirements	Pixel Visual Core is available in Google Pixel 2 devices only.
google-pixelvisualcorecamera	Software Requirements	Applications should target API Level 26  or greater  to get access to PixelVisual Core functionality
google-pixelvisualcorecamera	Software Requirements	Pixel Visual Core has been available to developerssince Android Oreo build OPM1.171019.011, as a developer option
google-pixelvisualcorecamera	Software Requirements	Pixel Visual Coreis officially enabled by default starting from Android Oreo build
google-platform.dart	Platform	 ! Build Status -   ! Coverage Status -   ! Pub  A generic platform abstraction for Dart.Like dart:io, package:platform supplies a rich, Dart-idiomatic API foraccessing platform-specific information.package:platform provides a lightweight wrapper around the static Platformproperties that exist in dart:io
google-platform.dart	Platform	However, it uses instance properties ratherthan static properties, making it possible to mock out in tests.
google-platform_benchmarks	What are Platform Benchmark?	Platform Benchmarks are a benchmark suite to measure basic architecturalmetrics of a platform
google-platform_benchmarks	What are Platform Benchmark?	Currently it only consists of CPUtest and AnalogCPUtest is a set of microbenchmarks to measure fundamental micro-architecturalcharacteristics of a CPU.Analog benchmarks are synthesized benchmarks that mimics some relevant workloadin Google cloud
google-platform_benchmarks	What are Platform Benchmark?	Since we have a very dyanmic workload, over the time theseAnalog benchmarks would change or even become obsolete.Some fundamental properties of CPUtest
google-platform_benchmarks	Writing C code	Write test in C
google-platform_benchmarks	Writing C code	Have test measure wall clock time at the beginning and end
google-platform_benchmarks	Writing C code	Return a simple measure  eg: operations per second Here is an example test to measure the latency of dependent ALU ops.struct Result dostuff1   {  uint64_t t = now_nsec  ;  strcpy result.function, __FUNCTION__ ;  result.resulthash = a;  strcpy result.metricname, "Stuff per second" ;  return result;
google-platform_benchmarks	Edit cputest.h	Edit cputest.h to declare your new test function, associate your test with acommandline flag etcstruct Result dostuff1 int param ;  // declare your new test function...
google-platform_benchmarks	#define NUMTESTS 25   // total number of tests. Increment this number	...const struct Test alltests NUMTESTS  = {..
google-platform_benchmarks	#define NUMTESTS 25   // total number of tests. Increment this number	 {"--dostuff X",  },...
google-platform_benchmarks	BUILD file	Create the appropriate targets in the BUILD file.
google-platform_benchmarks	Compiling and building the benchmarks	Building the benchmark can be configured and managed by Bazel Please note that this benchmark is only tested in Linux systems
google-platform_benchmarks	Compiling and building the benchmarks	Therefore wecannot guarantee it would work in other systems yet.Users external to Google can set environment variable $CC to specify whichcompiler should be used to build the benchmark
google-platform_benchmarks	Compiling and building the benchmarks	However, it is stronglysuggested to use LLVM compiler
google-platform_benchmarks	Compiling and building the benchmarks	GNU tool chain is very inefficient in handlingthe large inline assembly chunk inside the benchmarks
google-platform_benchmarks	Compiling and building the benchmarks	Our experiment shows thatit takes several hours to build **bigtable_analog*several minutes with LLVM.Please compile the benchmark in debug mode  -c dbg , with no optimizations,and force static linking  --linkopt=-static .
google-platform_benchmarks	Testing the test	Using traditional unit testing techniques for CPUtest can catch cerebralflatulence on the part of the developer, but cannot get at fundamental issues inthe test
google-platform_benchmarks	Testing the test	Generally the best way is to run the test on a target machine of knownfrequency and of known micro-architectural characteristics  as described inmanuals 
google-platform_benchmarks	Testing the test	If the test produces results consistent with disclosures from thevendor, then there is a strong likelihood that the test is correct/robust
google-platform_benchmarks	Testing the test	Whilemodifying a test, it is good practice to check the result against the existingMPM
google-platform_benchmarks	Testing the test	There are two shell scripts that help you do that...
google-platform_benchmarks	test.sh	Runs on the host machine
google-platform_benchmarks	test.sh	Copies CPUtest executable from bazel-bin directory,copies test-on-target.sh to target machine and runs it.Runs on target machine
google-platform_benchmarks	test.sh	Fetches latest cputest MPM, runs it and the copied overexecutable for the cputest arguments passed in.TIP: Remember to build cputest for the correct architecture before running test.sh on a particular target machine.cputestFetched package platforms/benchmarks/microbenchmarks/cputest version latest.mpm/cputestmax_scalar_store_ipc	resulthash=1048576	GOPS=3.422395max_scalar_store_ipc	resulthash=1048576	GOPS=3.424247In this case, the local version and the MPM version produce virtually the sameresult
google-platform_benchmarks	test.sh	Sometimes test result differences can be intentional
google-platform_benchmarks	test.sh	Correctness is forthe test writer to ascertain depending on the context.
google-platform_benchmarks	How do I run a test?	Fetch the  MPM  like this on the target machineYou can simply run it as follows  to measure ALU latency  ...
google-platform_benchmarks	Thread and numa node binding	Often, to run a test reliably, you need to bind it to a particular logical thread using taskset or numactl
google-platform_benchmarks	Thread and numa node binding	Otherwise the scheduler might migrate your test to a differnet hardware thread unexpectedly, causing your result to become suspect.
google-platform_benchmarks	Using taskset	To bind cputest to logical thread 16 ....numactl is a third party utility that lets you bind a task to not just a thread  or a combination thereof , but also a particular memory node
google-platform_benchmarks	Using taskset	This is useful for tests that exercise the memory subsystem  eg: measuring memory bandwidth numactl is available as a multi-arch  MPM On the target machine, fetch the mpm as follows ...To bind the cputest run to logical core 16 and numa node 0 do...
google-platform_benchmarks	Using taskset	assuming you fetched the cputest mpm as described before If you are running a test to evaluate structural hazards that come to the fore when multiple logical threads share and contend for the same resource, you can invoke cputest multiple times..Example: If logical threads 16, 17, 18 and 19, all share the same physical core, you can run a test on all of them concurrently as follows
google-play-instant-unity-plugin	Overview	The Google Play Instant Plugin for Unity Beta simplifies conversion of a Unity-based Android app into an instant app that can be deployed through  Google Play Instant The plugin’s Unity Editor  IDE  features include:
google-play-instant-unity-plugin	Prerequisites	After import there will be a “PlayInstant” menu in Unity providing several options described below.
google-play-instant-unity-plugin	Build Settings...	Opens a window that enables switching between "Installed" and "Instant" development modes
google-play-instant-unity-plugin	Build Settings...	Switching to "Instant" performs the following changes:The Play Instant Build Settings window also provides control over the scenes included in the build:Opens a window that lists Android Player Settings that should be changed to make the app Google Play Instant compatible
google-play-instant-unity-plugin	Build Settings...	These are divided into Required and Recommended settings
google-play-instant-unity-plugin	Build Settings...	Click on an “Update” button to change a setting.
google-play-instant-unity-plugin	Set up Instant Apps Development SDK...	Installs or updates the “Instant Apps Development SDK” using  sdkmanager  The plugin requires SDK version 1.2 or higher
google-play-instant-unity-plugin	Set up Instant Apps Development SDK...	If there is a license that needs to be accepted, the plugin will prompt for acceptance.
google-play-instant-unity-plugin	Build for Play Console...	 Google Play Console  requires that the APKs for an instant app are published together in a ZIP file
google-play-instant-unity-plugin	Build for Play Console...	Although most Unity instant apps will consist of a single APK, the requirement holds
google-play-instant-unity-plugin	Build for Play Console...	This menu option performs a build and stores the resulting APK in a ZIP file suitable for publishing.
google-play-instant-unity-plugin	Build and Run	This option runs the instant app on an adb connected device by performing the following steps:The goal of many instant apps is to give users a chance to experience the app before installing the full version
google-play-instant-unity-plugin	Build and Run	The plugin provides methods for transferring state from instant to installed app and for displaying a Play Store install dialog
google-play-instant-unity-plugin	Build and Run	These methods are also available via  Google Play Services Java APIs  but the plugin's C# implementations are easier to use in Unity.
google-play-instant-unity-plugin	Show Install Prompt	An instant app with an "Install" button can display a Play Store install dialog by calling the following from an install button click handler:The Cookie API provides methods for passing a "cookie"  e.g
google-play-instant-unity-plugin	Show Install Prompt	player ID or level completion data  from an instant app to its corresponding installed app
google-play-instant-unity-plugin	Show Install Prompt	Unlike postInstallIntent extras, the "cookie" state is available even if the user doesn't immediately launch the installed app
google-play-instant-unity-plugin	Show Install Prompt	For example, an instant app could call the following code from an install button click handler: 
google-play-services-plugins	Google Play services Plugins	This project contains plugins to help with using Google Play services andFirebase libraries.
google-play-services-plugins	Getting Started	The plugins contained in this project are meant to work with the Google Playservices SDK
google-play-services-plugins	Getting Started	 See  toget started.
google-play-services-plugins	strict-version-matcher-plugin	Helps with managing cross-library version dependencies between components.
google-play-services-plugins	oss-licenses-plugin	Helps apps to display open source software licenses and notices.
google-play-work	EMM Support Tools	A repository to provide tools and examples for EMMs integrating with the managed Google Play Store as part of  managed Android 
google-playhvz	Humans vs Zombies	Full stack solution leveraging Firebase, Polymer, and a Python Flask server on App Engine to create a live action game
google-playhvz	Humans vs Zombies	Learn more at 
google-playhvz	Contributing	Pull requests very welcome and encouraged, to help you get started we have broken it down to the level you want to test against
google-playhvz	Contributing	As mentioned in CONTRIBUTING.md, we do need you to submit a CLA first, but that should be an easy process.
google-playhvz	Local Development	You may run against the fake JS server  do nothing , run against production, or create your own Firebase project.
google-playhvz	Quick Start	Clone this project and follow the setup section if you are missing any dependenciesIf the last line fails with an "Invalid project selection" error, then run ./node_modules/firebase-tools/bin/firebase login to make sure you are logged in using the right account.Copy the first relevant part of web/config_.json to web/config.json  i.e., remove the underscore Stop your webserver via Ctrl-C to abort
google-playhvz	Installing a Polymer component	Run bower install paper-button under web directory
google-playhvz	Running against prod	Copy the first relevant part of web/config_.json to web/config.json  i.e., remove the underscore Restart your web serverGo to  localhost:5000/?bridge=remote  localhost:5000/?bridge=remote 
google-playhvz	Your own Firebase project and backend	These are one time firebase setup instructions along with backend configuration
google-playhvz	Front End  /web 	Change config.json's backendUrl to be "" Create a firebase project Open authentication using the left hand pane and enable  1  Google and  2  Email/PasswordOpen the users tab, create 8 users listed belowHit the copy button next to zella's name and put that into your config.py and config.jsonIn Firebase, open the web config and have these values ready to copy into the config.json fileIn your project make a new web/config.json file, similar to the examples in web/config_.json and copy over the valuesRun ./node_modules/firebase-tools/bin/firebase use --add  ...your project..
google-playhvz	Front End  /web 	If this command fails with an "Invalid project selection" error, then run ./node_modules/firebase-tools/bin/firebase login to make sure you are logged in using the right account
google-playhvz	Front End  /web 	Restart your development environment and visit  localhost:5000/?bridge=remote  localhost:5000/?bridge=remote |Fake Users||zella@playhvz.com||zeke@playhvz.com||jack@playhvz.com||reggie@playhvz.com|
google-playhvz	Back End  /backend 	Open your Firebase account page and use the gear icon to select the settingsMake a copy of config\_.py and name it config.py  remove the underscore Back in Firebase copy your webconfig and place a copy into your newly created config.pyClick on the Service Accounts tab and navigate to the Database Secrets sub tab.Show your the secrets key and copy it over for the FIREBASE_SECRET value in config.py.You can now run your server with dev_appserver.py app.yamlYou can also navigate your front end to use this server with  localhost:5000/?bridge=remote  localhost:5000/?bridge=remote  as long as you setup your front end config's backend URL  config.json 
google-playhvz	Front End	Make sure you have webdriver setup by following instructions in the setup section aboveFirst, start up your local server; the webdrivers assume something is running at localhost:5000To run the webdrivers:cd web/testspython run.py --p PASSWORD  --url TARGET_URL   SPECIFIC_TEST_NAMES   -d|m   -l|r   -s|-max MAX_PARALLEL   -cp NEW_PASSWORD   -cmp MAX_PARALLEL   -rr   -rf Replacing ALLCAPS'd segments with your values.
google-playhvz	Mac 	Add this to your ~/.bash_profile: export PATH=$PATH: ghvz folder path here /web/tests/macdrivers for example: export PATH=$PATH:/Users/verdagon/Desktop/ghvz/web/tests/macdriverssource ~/.bash_profile continue in the common section below 
google-playhvz	Linux 	Navigate to web/tests/linuxdrivers
google-playhvz	Linux 	Run chmod +x chromedriver to make thechromedriver executable.Note: If the default chromedriver does not work, you can download the latestversion  here Add this to your ~/.bashrc: export PATH=$PATH: ghvz folder path here /web/tests/linuxdrivers for example: export PATH=$PATH:/Users/verdagon/Desktop/ghvz/web/tests/linuxdrivers continue in the common section below 
google-playhvz	Mac	Go to Click PythonClick DOWNLOAD AND INSTALL THE CLOUD SDKDownload and install that SDK
google-playhvz	Mac	continue in the common section below 
google-playhvz	Back End Common	pip install -r requirements.txt -t libCopy config_.py to config.pyIf you're running your server against the prod firebase instance, replace FIREBASE_SECRET withthe key from  and replace the FIREBASE_CONFIG map with the map from clicking on "Web Setup" link at Start up the local server with dev_appserver.py app.yaml
google-playhvz	Back End	WARNING: This test will nuke our prod firebase
google-playhvz	Back End	This is fine, everyone knows that that data could disappear at any moment
google-playhvz	Back End	Though if two people run this test at the same time, it could fail
google-playhvz	Back End	There's an open task on go/hvz-milestones  #201  to fix these particular inconveniences.**First, get a local backend server running.*
google-playhvz	Deploying back end	To launch a new version  once you have gcloud hooked in to the right app engine account :gcloud app deploy app.yaml cron.yaml queue.yaml
google-playhvz	Set up Firebase	./node_modules/firebase-tools/bin/firebase deploy
google-pods-helper	Google Pods Helper Tool 	A helper tool for creating/modifying Podfile with  suggested pods from Google It can also add custom URL schemes for integrations requiring Sign In.
google-pods-helper	How to build and run?	PROJECT_DIR> xcodebuild  requires XCode Command Line Tools installed PROJECT_DIR> build/Release/GooglePodsHelper $PROJECT_NAME $PROJECT_PATH
google-pods-helper	How to make contributions?	Please read and follow the steps in the  CONTRIBUTING.md  CONTRIBUTING.md 
google-pods-helper	License	See  LICENSE  LICENSE 
google-polymer-dart-log-controller	log-controller	A small polymer element which lets you control the global logging configuration, and can optionally log all statements to the console.
google-polymer-dart-log-controller	Usage	Simply include the element like any other polymer element.There are two configurable attributes:
google-post-install-check	Post Install Check	> Make sure TypeScript projects can use the d.ts you're feeding them.**This is not an officially supported Google product.**It's not uncommon to ship a library written in TypeScript that exports type definitions that cannot be used by dependent code
google-post-install-check	Post Install Check	 Typically if the library does not export all types correctly, a TypeScript codebase using the library will fail to compile, potentially forcing the codebase to use the library without typechecks.The Install Check library is designed to be used as part of the tests for your library to verify that your library can be used by dependent code.
google-post-install-check	Installation	The following could be the contents of a test file in your module that is run with mocha as part of your test suite.import const tsCode =   import  const something = new Something {  } ;  app.use something ;const jsCode =   const express = require 'express' ;  const {Something} = require 'some-module' ;  const something = new Something {  } ;  app.use something ;const TS_SAMPLES: check.CodeSample   =    {  } const JS_SAMPLES: check.CodeSample   =    {  } // Create a new project for each sample in a temp// directory, with 
google-post-install-check	Questions/problems?	If you've found an bug/issue, please  file it on GitHub 
google-post-install-check	Contributing	See  CONTRIBUTING 
google-post-install-check	License	This library is licensed under Apache 2.Full license text is available in  LICENSE *Made with ❤️ by the Google Node.js team*
google-pprof	Introduction	pprof is a tool for visualization and analysis of profiling data.pprof reads a collection of profiling samples in profile.proto format andgenerates reports to visualize and help analyze the data
google-pprof	Introduction	It can generate bothtext and graphical reports  through the use of the dot visualization package .profile.proto is a protocol buffer that describes a set of callstacksand symbolization information
google-pprof	Introduction	A common usage is to represent a set ofsampled callstacks from statistical profiling
google-pprof	Introduction	The format isdescribed on the  proto/profile.proto  ./proto/profile.proto  file
google-pprof	Introduction	For details on protocolbuffers, see Profiles can be read from a local file, or over http
google-pprof	Introduction	Multipleprofiles of the same type can be aggregated or compared.If the profile samples contain machine addresses, pprof can symbolizethem through the use of the native binutils tools  addr2line and nm .**This is not an official Google product.**
google-pprof	Building pprof	  go tool and set up GOPATH.To build and install it, use the go get tool.Remember to set GOPATH to the directory where you want pprof to beinstalled
google-pprof	Building pprof	 The binary will be in $GOPATH/src/github.com/google/pprof.
google-pprof	Basic usage	pprof can read a profile from a file or directly from a server via http.Specify the profile input s  in the command line, and use options toindicate how to format the report.
google-pprof	Generate a text report of the profile, sorted by hotness:	If no output formatting option is specified, pprof runs on interactive mode,where reads the profile and accepts interactive commands for visualization andrefinement of the profile.pprof  main_binary  profile.pb.gzThis will open a simple shell that takes pprof commands to generate reports.Type 'help' for available commands/options.
google-pprof	Run pprof via a web interface	If the -http flag is specified, pprof starts a web server atthe specified host:port that provides an interactive web-based interface to pprof.Host is optional, and is "localhost" by default
google-pprof	Run pprof via a web interface	Port is optional, and is arandom available port by default
google-pprof	Run pprof via a web interface	-http=":" starts a server locally ata random port.the right page; if not, you can manually visit the specified port inyour web browser.
google-pprof	Using pprof with Linux Perf	pprof can read perf_to_profile program from the perf_data_converter  package.
google-pprof	Further documentation	See  doc/README.md  doc/README.md  for more detailed end-user documentation.See  CONTRIBUTING.md  CONTRIBUTING.md  for contribution documentation.See  proto/README.md  proto/README.md  for a description of the profile.proto format.
google-prettytensor	Pretty Tensor 	Pretty Tensor provides a high level builder API for TensorFlow
google-prettytensor	Pretty Tensor 	It providesthin wrappers on Tensors so that you can easily build multi-layer neuralPretty Tensor provides a set of objects that behave likes Tensors, but alsosupport a chainable object syntax to quickly define neural networksand other layered architectures in TensorFlow.Please look here for full documentation of the PrettyTensor object for allavailable operations: Available Operations  docs/PrettyTensor.md  or you can check out the  completedocumentation  docs/pretty_tensor_top_level.md See the tutorial directory for samples: tutorial/  prettytensor/tutorial/ 
google-prettytensor	Installation	The easiest installation is just to use pip:Follow the instructions atpip install prettytensor
google-prettytensor	Full power of TensorFlow is easy to use	Pretty Tensors can be used  almost  everywhere that a tensor can
google-prettytensor	Full power of TensorFlow is easy to use	 Just callpt.wrap to make a tensor pretty.You can also add any existing TensorFlow function to the chain using apply applies the current Tensor as the first argument and takes all the otherarguments as normal.world.
google-prettytensor	Plays well with other libraries	It also uses standard TensorFlow idioms so that it plays well with otherlibraries, this means that you can use it a little bit in a model or throughout.Just make sure to run the update_ops on each training set see  with_update_ops  docs/pretty_tensor_top_level.md#with_update_ops  .
google-prettytensor	Terse	You've already seen how a Pretty Tensor is chainable and you may have noticedthat it takes care of handling the input shape
google-prettytensor	Terse	 One other feature worth notingare defaults
google-prettytensor	Terse	 Using defaults you can specify reused values in a single placewithout having to repeat yourself.Check out the documentation to see all supported defaults  docs/pretty_tensor_top_level.md#defaults_scope .
google-prettytensor	Code matches model	Sequential mode lets you break model construction across lines and providesthe subdivide syntactic sugar that makes it easy to define and understandcomplex structures like an  inception module ! Inception module showing branch and rejoin  inception_module.png Templates provide guaranteed parameter reuse and make unrolling recurrentnetworks easy:There are also some convenient shorthands for LSTMs and GRUs:! Unrolled RNN  unrolled_lstm.png 
google-prettytensor	Extensible	You can call any existing operation by using apply and it will simplysubsitute the current tensor for the first argument.You can also create a new operation  There are two supported registrationmechanisms to add your own functions
google-prettytensor	Extensible	@Register   allows you to create amethod on PrettyTensor that operates on the Tensors and returns either a loss ora new value
google-prettytensor	Extensible	Name scoping and variable scoping are handled by the framework.The following method adds the leaky_relu method to every Pretty Tensor:@RegisterCompoundOp   is like adding a macro, it is designed to group togethercommon sets of operations.
google-prettytensor	Safe variable reuse	Within a graph, you can reuse variables by using templates
google-prettytensor	Safe variable reuse	 A template isjust like a regular graph except that some variables are left unbound.See more details in  PrettyTensor class  docs/PrettyTensor.md .
google-prettytensor	Accessing Variables	Pretty Tensor uses the standard graph collections from TensorFlow to store variables
google-prettytensor	Accessing Variables	 These can be accessed using tf.get_collection key  with the following keys:Eider Moore  eiderman with key contributions from:
google-process.dart	Process	 ! Build Status -   ! Coverage Status -  A generic process invocation abstraction for Dart.Like dart:io, package:process supplies a rich, Dart-idiomatic API forspawning OS processes.Unlike dart:io, package:process:
google-processingjs-ide	Processing.js IDE  early prototype 	This is an early prototype of a project to create a lightweight web-based IDEfor  Processing.js The target audience are students in Japan who participate in introductoryprogramming workshops, having the first ever experience of text-basedprogramming
google-processingjs-ide	Processing.js IDE  early prototype 	For this reason the main focus areas of this project will be:development and a very small application to serve the static HTML fileof the IDE from Google App Engine.
google-processingjs-ide	Getting started	Install the dependencies using npmOpen the file ide.html in browser.
google-processingjs-ide	Building the project	Currently the project is in half-way state of transitionto Bazel-based build system
google-processingjs-ide	Building the project	So parts of the code  includingthe unprocessed ide.html  still rely on the modulesinstalled with npm install, and parts of the code especially rewritten ide-bin.html that is intendedto be served as part of App Engine application  areusing the files produced with the Bazel build.So you need to run both:Note, that you need a fairly recent verion of Bazel  tested with 0.13 .
google-processingjs-ide	Deploy to Google App Engine	First you need to download and install Google Cloud SDK and install Go AppEngine component  app-engine-go 
google-processingjs-ide	Deploy to Google App Engine	Then you need to create a project using Cloud  instruction and enable App Engine on it, and configure the default project for gcloud.Second you need to build the static assets using combination of NPM and Bazel:Finally you may deploy your project:
google-processingjs-ide	License	Apache-2.0; see  LICENSE  LICENSE  for details.
google-processingjs-ide	Disclaimer	This project is not an official Google project
google-processingjs-ide	Disclaimer	It is not supported by Googleand Google specifically disclaims all warranties as to its quality,merchantability, or fitness for a particular purpose.
google-promises	Promises	Promises is a modern framework that provides a synchronization construct forObjective-C and Swift to facilitate writing asynchronous code.
google-proto-lens	Tutorial	You can find tutorial documentation in the  proto-lens-tutorial  ./proto-lens-tutorial  subdir.There is also a  reference document, TYPES.md  ./TYPES.md , showing the protobuf scalar type -> haskell type mappings used by the generated lenses.
google-proto-lens	Setup	First, install the "protoc" binary somewhere in your PATH
google-proto-lens	Setup	 You can get it byfollowing  these instructions  docs/installing-protoc.md .
google-proto-lens	Building from HEAD	To build and test this repository from HEAD, run:Note: building this repository requires stack-1.7.1 or newer.
google-proto-lens	Using in a Cabal or Stack package	proto-lens is available on Hackage and Stackage
google-proto-lens	Using in a Cabal or Stack package	 Cabal and Stack projects can use itto auto-generate Haskell source files from the originalprotocol buffer specifications  .proto files .Note: if using Stack, these instructions require v1.4.0 or newer.First, edit the .cabal file of your project to:  library/executable/etc
google-proto-lens	Using in a Cabal or Stack package	 executables 
google-proto-lens	Using in a Cabal or Stack package	**Note:*using a version earlier than proto-lens-protoc
google-proto-lens	Using in a Cabal or Stack package	Next, write a Setup.hs file that uses Data.ProtoLens.Setup and specifies thedirectory containing the .proto files
google-proto-lens	Using in a Cabal or Stack package	 For example:Then, when you run cabal build or stack build, Cabal will generate a Haskellfile from each .proto file, and use it as part of building theSee the proto-lens-tests package for some more detailed examples.
google-proto-lens	Manually running the protocol compiler	Suppose you have a file foo.proto
google-proto-lens	Manually running the protocol compiler	Then to generate bindings, run:This will generate a file Proto/Foo.hs which contains Haskell definitionscorresponding to the messages and fields in the protocol buffer file.Use --haskell_out to control the location of the output file.Use bar.proto has the lineThen running:will generate the haskell files Proto/Project/{Foo,Bar}.hs.
google-proto-lens	Rebuilding	Due to  stack issue #1891 if you only change the .proto files then stack won't rebuild the package  thatis, it won't regenerate the Proto.* modules .
google-proto-lens	Loading into ghci with Stack	stack ghci can get confused when trying to directly load a package thatgenerates Proto.* modules  for example: stack ghci  .To work around this issue, run instead:And then manually import the generated modules within ghci, for example:Alternately, you can make those modules available at the same time as another localpackage, by running:
google-proto-lens	Linking errors	Due to the limitations of how we can specify the dependencies of Setupfiles, stack may try to link them against the terminfo package
google-proto-lens	Linking errors	Youmay get an error from stack build similar to:
google-protobuf-dt	About	This project provides IDE integration to Eclipse users when working on protobuffiles
google-protobuf-dt	About	 Contributions can be made through Google Source For more info see CONTRIBUTING 
google-protobuf-dt	License	 Eclipe Public License can be found in com.eclipse.protobuf.feature.
google-protobuf-dt	Installing protobuf-dt	The update site for protobuf-dt isAs of version 2.3.0, the Protocol Buffer requires Eclipse Neon or greater.
google-protobuf-dt	Install using Eclipse Install tool	Navigate to "Help" > "Install New Software...".Click **Add...**.Enter _Protobuf Editor_ into the "Name:" field.Paste _into the "Location:" field.Click **OK**.From the dropdown labeled "Work with:" select the repository you just added.Make sure that "Group items by category" is deselected."Google Inc." should be listed in the repository explorer window.Select the checkbox next to "Google Inc.".Click **Next**.Click **Next*Accept the terms of the license agreement and click **Finish**.
google-protobuf-dt	Install using the Eclipse Marketplace	Navigate to "Help" > "Eclipse Marketplace...".Search for _protobuf-dt_."protobuf-dt" should be listed in the search window.Click "Install".Accept the terms of the license agreement and click **Finish**.
google-protobuf-gradle-plugin	Protobuf Plugin for Gradle  ! Status  	The Gradle plugin that compiles Protocol Buffer  aka
google-protobuf-gradle-plugin	Protobuf Plugin for Gradle  ! Status  	Protobuf  definitionfiles  *.proto  in your project
google-protobuf-gradle-plugin	Protobuf Plugin for Gradle  ! Status  	There are two pieces of its job: It assembles the Protobuf Compiler  protoc  command line and use it to It adds the generated Java source files to the input of the correspondingFor more information about the Protobuf Compiler, please refer to Google Developers Site 
google-protobuf-gradle-plugin	Latest Version	The latest version is To try out the head version, you can download the source and build itwith ./gradlew install -x test  we skip tests here because theyrequire Android SDK , then:A stand-alone example project is located under  exampleProject Run ../gradlew build under that directory to test it out.Directories that start with testProject can also serve as usageexamples for advanced options, although they cannot be compiled asindividual projects.
google-protobuf-gradle-plugin	Adding the plugin to your project	This plugin must work with either the Java plugin or the Android plugin.
google-protobuf-gradle-plugin	Using the apply method	The Java plugin or the Android plugin must be applied before the Protobuf plugin:
google-protobuf-gradle-plugin	Using the Gradle plugin DSL	The order of the plugins doesn't matter:The Protobuf plugin assumes Protobuf files  protoc run, and the generated files are added to the input of the Javacompilation run of that _sourceSet_  or _variant_ .
google-protobuf-gradle-plugin	Customizing source directories	The plugin adds a new sources block named src/$sourceSetName/proto
google-protobuf-gradle-plugin	Customizing source directories	You can customize it in the same way as you wouldcustomize the java sources.The plugin adds a protobuf block to the project
google-protobuf-gradle-plugin	Customizing source directories	It provides all theconfiguration knobs.
google-protobuf-gradle-plugin	Locate external executables	By default the plugin will search for the protoc executable in the systemsearch path
google-protobuf-gradle-plugin	Locate external executables	We recommend you to take the advantage of pre-compiled protocthat we have published on Maven Central:Multiple assignments are allowed in the protoc block
google-protobuf-gradle-plugin	Locate external executables	The last one wins.You may also run protoc with codegen plugins
google-protobuf-gradle-plugin	Locate external executables	You need to define all thecodegen plugins you will use in the plugins block, by specifying thedownloadable artifact or a local path, in the same syntax as in the protocblock above
google-protobuf-gradle-plugin	Locate external executables	This will __not__ apply the plugins
google-protobuf-gradle-plugin	Locate external executables	You need to configure thetasks in the generateProtoTasks block introduced below to apply the pluginsdefined here.
google-protobuf-gradle-plugin	Customize code generation tasks	The Protobuf plugin generates a task for each protoc run, which is for asourceSet in a Java project, or a variant in an Android project
google-protobuf-gradle-plugin	Customize code generation tasks	The task hasconfiguration interfaces that allow you to control the type of outputs, thecodegen plugins to use, and parameters.You must configure these tasks in the generateProtoTasks block, whichprovides you helper functions to conveniently access tasks that are tied to acertain build element, and also ensures you configuration will be picked upcorrectly by the plugin.protobuf {  ..
google-protobuf-gradle-plugin	Customize code generation tasks	 generateProtoTasks {  }Each code generation task has two collections:
google-protobuf-gradle-plugin	Configure what to generate	Code generation is done by protoc builtins and plugins
google-protobuf-gradle-plugin	Configure what to generate	 Eachbuiltin/plugin generate a certain type of code
google-protobuf-gradle-plugin	Configure what to generate	 To add or configure abuiltin/plugin on a task, list its name followed by a braces block.Put options in the braces if wanted
google-protobuf-gradle-plugin	Configure what to generate	 For example:task.builtins {  // This yields  // "--java_out=example_option1=true,example_option2:/path/to/output"  // on the protoc commandline, which is equivalent to  // "--java_out=/path/to/output --java_opt=example_option1=true,example_option2"  // with the latest version of protoc
google-protobuf-gradle-plugin	Configure what to generate	 java {  }  // Add cpp output without any option
google-protobuf-gradle-plugin	Configure what to generate	 // DO NOT omit the braces if you want this builtin to be added
google-protobuf-gradle-plugin	Configure what to generate	 // This yields  // "--cpp_out=/path/to/output" on the protoc commandline
google-protobuf-gradle-plugin	Configure what to generate	 cpp { }task.plugins {  // Add grpc output without any option
google-protobuf-gradle-plugin	Configure what to generate	 grpc must have been defined in the  // protobuf.plugins block
google-protobuf-gradle-plugin	Configure what to generate	 // This yields  // "--grpc_out=/path/to/output" on the protoc commandline
google-protobuf-gradle-plugin	Configure what to generate	 grpc { }
google-protobuf-gradle-plugin	Default outputs	protobuf {  generatedFilesDir = "$projectDir/generated"  }See  this section  #change-where-files-are-generated  for details about where the code will be generated.3.0.0,  protobuf-lite is the recommended Protobuf library for Android, and you will need toadd it as a codegen plugin
google-protobuf-gradle-plugin	Default outputs	 For example:dependencies {  // You need to depend on the lite runtime library, not protobuf-java  compile 'com.google.protobuf:protobuf-lite:3.0.0'protobuf {  protoc {  }  plugins {  }  generateProtoTasks {  }
google-protobuf-gradle-plugin	Generate descriptor set files	{ task ->  // If true, will generate a descriptor_set.desc file under  // $generatedFilesBaseDir/$sourceSet
google-protobuf-gradle-plugin	Generate descriptor set files	Default is false
google-protobuf-gradle-plugin	Generate descriptor set files	 // See --descriptor_set_out in protoc documentation about what it is
google-protobuf-gradle-plugin	Generate descriptor set files	 task.generateDescriptorSet = true  task.descriptorSetOptions.path =  // and comments
google-protobuf-gradle-plugin	Generate descriptor set files	Default is false
google-protobuf-gradle-plugin	Generate descriptor set files	 task.descriptorSetOptions.includeSourceInfo = true  // is therefore self-contained
google-protobuf-gradle-plugin	Generate descriptor set files	Default is false
google-protobuf-gradle-plugin	Generate descriptor set files	 task.descriptorSetOptions.includeImports = true
google-protobuf-gradle-plugin	Change where files are generated	By default generated Java files are under$generatedFilesBaseDir is $buildDir/generated/source/proto by default,and is configurable
google-protobuf-gradle-plugin	Change where files are generated	E.g., see previous section 
google-protobuf-gradle-plugin	Change where files are generated	E.g.,If a Java project contains proto files, they will be packaged in the jar filesalong with the compiled classes
google-protobuf-gradle-plugin	Change where files are generated	If a compile configuration has adependency on a project or library jar that contains proto files, they will beadded to the --proto_path flag of the protoc command line, so that they canbe imported in the proto files of the dependent project
google-protobuf-gradle-plugin	Change where files are generated	The imported protofiles will not be compiled since they have already been compiled in their ownprojects
google-protobuf-gradle-plugin	Change where files are generated	Example:files, whose compiled classes are absent, and you want to use these proto filesin your project and compile them, you can add it to protobuf dependencies.This  Maven Central directory lists pre-compiled protoc artifacts that can be used by this plugin.
google-protobuf-gradle-plugin	IntelliJ IDEA	Be sure to enable delegate IDE build/run actions to Gradle sothat Intellij does not use its internal build mechanism tocompile source code
google-protobuf-gradle-plugin	IntelliJ IDEA	This plugin ensures that code generationhappens before Gradle's build step
google-protobuf-gradle-plugin	IntelliJ IDEA	If the setting is off,Intellij's own build system will be used instead of Gradle.Enable the setting with:This plugin integrates with the idea plugin and automaticallyregisters the proto files and generated Java code as sources.apply plugin: 'idea'protobuf {clean {idea {
google-protobuf-gradle-plugin	Testing the plugin	.proto files
google-protobuf-gradle-plugin	Testing the plugin	Because the tests include an Android project, youneed to install Android SDK Tools After you made any change to the plugin, be sure to run these tests.
google-protocall	Assign the integer value 5 to the identifier 'x'	> x = 5;literal {  integer {  }
google-protocall	bound to a local variable 'x' within the function.  The print_ function returns None.	> print_ x=x ;x: 5The assignment statement above is expressed in protocall as:A simple program to compute Fibonacci numbers
google-protocall	bound to a local variable 'x' within the function.  The print_ function returns None.	 This demonstates scoping,function definition and conditionals.SeeThruP0 uses { and } for scopingEach scope induces a new local variable space
google-protocall	bound to a local variable 'x' within the function.  The print_ function returns None.	 Arguments are passed to functionby copy; use return values to communicate.
google-prudaq	Documentation is on the  Wiki 	*This is not an official Google product.*
google-pubkeystore	PubkeyStore	 ! Docker Repository on Quay  "Docker Repository on Quay"  **This is not an official Google product**PubkeyStore is a ssh key management server, that provides public keys upon request, to be used with metaserver for VM seeding.You can find all the currently exposed APIs in proto/pubkeystore.proto.
google-pulito	pulito	Conventions and structure for a Vanilla JS application with a supporting webpack config.See  A la carte Web Development for more background on pulito and how it fits into "A la carte" webPulito expects a project to be laid out in the following format:If your project follows the conventions then pulito provides a webpack configfile that will build your application, both development and production profiles,and will build demo pages for custom elements if they are present.----------This is not an officially supported Google product.--------If you are starting a fresh project, pulito contains a project skeletonto get you going.You will be prompted to overwrite package.json, select 'yes'.At this point you should be able to visit the running skeletonapp at 
google-pulito	pulito	This page is a builtversion of pages/index.html which has an  on it You can visit the demo page directly for the spinner by navigating toDirectory StructureJS modules are stored under /modules and each custom element has its owndirectory under modules/
google-pulito	pulito	Each element may have a demo page, which isindicated by the presence of a file ending in -demo.html and -demo.js inthe element's directory
google-pulito	pulito	If both files exist then a demo page will be writteninto the dist directory.Similary, pages of the webapp are expected to sit under the /pagesdirectory, and consist of both a JS and HTML file
google-pulito	pulito	These will be processed andtheir output will also appear in the dist directory.See also, section **Public Path**.Element StructureEach element has its own directory.a demo, just omit the -demo.js and -demo.html files.-----The webpack.config.js for such a project can be very simple, just run:Then create a webpack.config.js file that looks like:At this point there's a lot of functionality present.Will build a debug version of all the demo pages and all the app pagesin dist
google-pulito	pulito	In the example Makefile, this is the default make command.Will do the same as build, but served by the webpack-dev-server, whichwill rebuild all source and reload the webpage any time you edit a file.In the example Makefile, this is command make serve.Will do the same as build, but will rebuild all the files in distwhen you edit a file
google-pulito	pulito	In the example Makefile, this is the command make watch.Will build a release version of the pages in dist, no demo pages will beemitted
google-pulito	pulito	In the example Makefile, this is the command make release.Public PathSometimes, an app wants to specify that the js/css files are in an absolute path e.g
google-pulito	pulito	/js/, /static/ 
google-pulito	pulito	Webpack supports this with  publicPath Since Pulito just returns a Webpack object, the output of commonBuilder can bemodified directly, like:After re-creating the files  e.g
google-pulito	pulito	make release , the js and css will be linked in likeAlso note that when running the dev server make serve, **all*of that localhost:8080/ publicPath , for example, localhost:8080/static/example-element.html.
google-pull-request-mailer	pull-request-mailer	Sends a GitHub pull request as a patch series via emailMany open-source projects  such as the Linux kernel or the  Ganeti project  accept patches only via their mailing lists.This tool makes it easy to integrate contributors who prefer Github pull requests into mailing list review workflows.
google-pull-request-mailer	Procesing a single pull request	Usage: pull-request-mailer USER REPO N --to EMAIL  --post-checkout-hook PROGRAM   Sends a GitHub pull request as a patch series via emailAvailable options:  -h,--help  USER  REPO  N  --to EMAIL  --post-checkout-hook PROGRAM  --no-thread-tracking  --discussion-location STRINGAvailable environment variables:  PULL_REQUEST_MAILER_OAUTH_TOKEN
google-pull-request-mailer	Automated server mode	Usage: pull-request-mailer-server --to EMAIL  --post-checkout-hook PROGRAM   Receive GitHub pull request webbooks and send the patch series via emailAvailable options:  -h,--help  --to EMAIL  --post-checkout-hook PROGRAM  --no-thread-tracking  --discussion-location STRINGAvailable environment variables:  PULL_REQUEST_MAILER_OAUTH_TOKEN
google-pull-request-mailer	Contact	The tool has been created and is maintained by the Ganeti  team
google-pull-request-mailer	Contact	Please send any questions tothe ganeti-devel@googlegroups.com mailing list  also available online 
google-pulldown-cmark	pulldown-cmark	 Documentation This library is a pull parser for  CommonMark  writtenin  Rust  It comes with a simple command-line tool,useful for rendering to HTML, and is also designed to be easy to use from asa library.It is designed to be:There are many parsers for Markdown and its variants, but to my knowledge noneuse pull parsing
google-pulldown-cmark	pulldown-cmark	Pull parsing has become popular for XML, especially formemory-conscious applications, because it uses dramatically less memory thanconstructing a document tree, but is much easier to use than push parsers
google-pulldown-cmark	pulldown-cmark	Pushparsers are notoriously difficult to use, and also often error-prone because ofthe need for user to delicately juggle state in a series of callbacks.In a clean design, the parsing and rendering stages are neatly separated, butthis is often sacrificed in the name of performance and expedience
google-pulldown-cmark	pulldown-cmark	Many Markdownimplementations mix parsing and rendering together, and even designs that tryto separate them  such as the popular  hoedown make the assumption that the rendering process can be fully represented as aserialized string.Pull parsing is in some sense the most versatile architecture
google-pulldown-cmark	pulldown-cmark	It's possible todrive a push interface, also with minimal memory, and quite straightforward toconstruct an AST
google-pulldown-cmark	pulldown-cmark	Another advantage is that source-map information  the mappingbetween parsed blocks and offsets within the source text  is readily available;you basically just call get_offset   as you consume events.While manipulating AST's is the most flexible way to transform documents,operating on iterators is surprisingly easy, and quite efficient
google-pulldown-cmark	pulldown-cmark	Here, forexample, is the code to transform soft line breaks into hard breaks:A lot of the internal scanning code is written at a pretty low level  itpretty much scans byte patterns for the bits of syntax , but the externalinterface is designed to be idiomatic Rust.Pull parsers are at heart an iterator of events  start and end tags, text,and other bits and pieces 
google-pulldown-cmark	pulldown-cmark	The parser data structure implements theRust Iterator trait directly, and Event is an enum
google-pulldown-cmark	pulldown-cmark	Thus, you can use thefull power and expressivity of Rust's iterator infrastructure, includingfor loops and map  as in the examples above , collecting the events intoa vector  for recording, playback, and manipulation , and more.Further, the Text event  representing text  is a copy-on-write string  note:this isn't quite true yet 
google-pulldown-cmark	pulldown-cmark	The vast majority of text fragments are justslices of the source document
google-pulldown-cmark	pulldown-cmark	For these, copy-on-write gives a convenientrepresentation that requires no allocation or copying, but allocatedstrings are available when they're needed
google-pulldown-cmark	pulldown-cmark	Thus, when rendering text toHTML, most text is copied just once, from the source document to theHTML buffer.
google-pulldown-cmark	Building only the pulldown-cmark library	By default, the binary is built as well
google-pulldown-cmark	Building only the pulldown-cmark library	If you don't want/need it, then build like this:The main author is Raph Levien.
google-pulldown-cmark	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-pulldown-cmark	Contributions	Please see CONTRIBUTIONS.md formore details.
google-pulldown-cmark	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.
google-pyaedj	Goals	py-ae-dj is an experimental project helping developers use Python and Djangoon Google App Engine
google-pyaedj	Goals	It has minimal, but all nessesary tools for setting up,developing, testing, configuring, deploying, managining, and supporting atypical Python App Engine application
google-pyaedj	Goals	It also shows how to develop Djangoapplication with Google Cloud SQL, Google Cloud Datastore and other GoogleCloud APIs.
google-pyaedj	Disclaimer	py-ae-dj is not an official Google product.
google-pyaedj	Licensing	py-ae-dj is Licensed under the Apache License, Version 2.
google-pybadges	pybadges	pybadges is a Python library and command line tool that allows you to createGithub-style badges as SVG images
google-pybadges	pybadges	For example:! pip installation  tests/golden-images/pip.svg ! pip installation  tests/golden-images/license.svg ! pip installation  tests/golden-images/build-passing.svg The aesthetics of the generated badges matches the  visual design found in this specification The implementation of the library was heavily influenced by Shields.io  and the JavaScript gh-badges  library.
google-pybadges	Installing	pybadges can be installed using  pip You will see a badge like this in your browser:! pip installation  tests/golden-images/build-failure.svg 
google-pybadges	Usage	pybadges can be used both from the command line and as a Python library.The command line interface is a great way to experiment with the API beforewriting Python code.
google-pybadges	Command line usage	Complete documentation of pybadges command arguments can be found using the --help! pip installation  tests/golden-images/complete.svg Note that the --logo option can include a regular URL:
google-pybadges	Library usage	pybadges is primarily meant to be used as a Python library.described above except with keyword arguments using underscore instead ofhyphen/minus  e.g
google-pybadges	Library usage	--left-text => left_text= 
google-pybadges	Development	 contributer guide
google-pybadges	Development	 CONTRIBUTING.md 
google-pybadges	Versioning	We use  SemVer  for versioning.
google-pybadges	License	This project is licensed under the Apache License This is not an officially supported Google product.
google-python-adb	Using as standalone tool	Install using pip:can be run similar to native adb and fastboot via the python interpreter:
google-python-adb	Using as a Python Library	A  presentation was made at PyCon 2016  pycon_preso , and here's some demo code:import os.path as opfrom adb import adb_commandsfrom adb import sign_m2crypto
google-python-adb	KitKat+ devices require authentication	signer = sign_m2crypto.M2CryptoSigner 
google-python-adb	Connect to the device	device = adb_commands.AdbCommands  device.ConnectDevice 
google-python-adb	Now we can use Shell, Pull, Push, etc!	for i in xrange 10 :  print device.Shell 'echo %d' % i 
google-python-adb	Other changes/fixes	Many changes since 1.2.0! coverage_link :  build_img :  build_link :  pycon_preso : 
google-python-cloud-utils	Multi Cloud Utils	Multi Cloud Utils is a library to handle standard operations across mutliple cloud platforms.Currently supported clouds are GCP, and AWS.This is not an official Google productsupported opertations:
google-python-cloud-utils	list_instances	Example: list_instances.py foo\*bar\*ex\ aws gcpRecommended alias:alias li='path/to/list_instances.py'
google-python-fanotify	Overview	python-fanotify provides Python bindings for Linux's fanotify interface
google-python-fanotify	Overview	See thepydocs for usage info and read the fanotify manpages for additional details
google-python-fanotify	Overview	Inaddition, there are examples for usage under doc/.
google-python-fanotify	Building, testing, and installing	This is not an official Google product.
google-python-fire	Python Fire  ! PyPI  	_Python Fire is a library for automatically generating command line interfaces CLIs  from absolutely any Python object._modules and variables you'll need already imported and created
google-python-fire	Python Fire  ! PyPI  	  5   docs/benefits.md#repl 
google-python-fire	Installation	To install Python Fire with pip, run: pip install fireTo install Python Fire with conda, run: conda install fire -c conda-forgeTo install Python Fire from source, first clone the repository and then run:python setup.py install
google-python-fire	Basic Usage	You can call Fire on any Python object:functions, classes, modules, objects, dictionaries, lists, tuples, etc.They all work!Here's an example of calling Fire on a class.import fireclass Calculator object :  """A simple calculator class."""if __name__ == '__main__':  fire.Fire Calculator Then, from the command line, you can run:about Fire's other features, see the  Using a Fire CLI page  docs/using-cli.md .For additional examples, see  The Python Fire Guide  docs/guide.md .
google-python-fire	Why is it called Fire?	When you call Fire, it fires off  executes  your command.
google-python-fire	Where can I learn more?	Please see  The Python Fire Guide  docs/guide.md .
google-python-fire	Reference	| Setup   | Command| :-----| install | pip install fire  || Creating a CLI | Command| :--------------| :--------------------| import| Call| Call| Using a CLI| :------------|  Help  docs/using-cli.md#help-flag  | command -|  REPL  docs/using-cli.md#interactive-flag  | command -|  Separator  docs/using-cli.md#separator-flag  | command -|  Completion  docs/using-cli.md#completion-flag  | command -|  Trace  docs/using-cli.md#trace-flag  | command -|  Verbose  docs/using-cli.md#verbose-flag  | command -_Note that flags are separated from the Fire command by an isolated -- arg._
google-python-fire	Disclaimer	This is not an official Google product.
google-python_portpicker	Python portpicker module	This module is useful for finding unused network ports on a host.It supports both Python 2 and Python This module provides a pure Python pick_unused_port   function.It can also be called via the command line for use in shell scripts.If your code can accept a bound TCP socket rather than a port number considerusing socket.bind  'localhost', 0   to bind atomically to an available portrather than using this library at all.There is a race condition between picking a port and your application codebinding to it
google-python_portpicker	Python portpicker module	 The use of a port server by all of your test code to avoidthat problem is recommended on loaded test hosts running many tests at a time.Unless you are using a port server, subsequent calls to pick_unused_port   toobtain an additional port are not guaranteed to return a unique port.
google-python_portpicker	What is the optional port server?	A port server is intended to be run as a daemon, for use by all processesrunning on the host
google-python_portpicker	What is the optional port server?	 It coordinates uses of network ports by anything usinga portpicker library
google-python_portpicker	What is the optional port server?	 If you are using hosts as part of a test automationcluster, each one should run a port server as a daemon
google-python_portpicker	What is the optional port server?	 You should set thePORTSERVER_ADDRESS=@unittest-portserver environment variable on all of yourtest runners so that portpicker makes use of it.A sample port server is included
google-python_portpicker	What is the optional port server?	 This portserver implementation works but hasnot spent time in production
google-python_portpicker	What is the optional port server?	 If you use it with good results please reportback so that this statement can be updated to reflect that
google-python_portpicker	What is the optional port server?	 : A port server listens on a unix socket, reads a pid from a new connection,tests the ports it is managing and replies with a port assignment port for thatpid
google-python_portpicker	What is the optional port server?	 A port is only reclaimed for potential reassignment to another processafter the process it was originally assigned to has died
google-python_portpicker	What is the optional port server?	 Processes that needmultiple ports can simply issue multiple requests and are guaranteed they willeach be unique.
google-python_portpicker	Typical usage:	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-pytruth	PyTruth: Truth in Python	Provides unittest assertions in a fluent style.Translated from the Java implementation, google/truth 
google-pytruth	License	PyTruth is licensed under the  Apache 2.0 license  LICENSE .
google-pytruth	Disclaimer	PyTruth is not an official Google product.
google-pytruth	Contributing	Please see the  guidelines for contributing  CONTRIBUTING.md before creating pull requests.
google-pytruth	Support	PyTruth is not an actively maintained project
google-pytruth	Support	No support is provided.It is shared with the community to bring an expressive, consistent assertionstyle to projects that may be using a combination of unittest  googletest  mox  and mock to people familiar with  Java Truth User group: pytruth-users@googlegroups.com 
google-pytruth	Overview	Import the truth module and alias the AssertThat   method to begin asserting
google-pytruth	Limitations	unittest assertions accept a msg parameter to display if the assertion fails.PyTruth has no such mechanism, though its failure messages tend to be moreThe type of the subject under test  the parameter passed to AssertThat    willnot be known until runtime, unlike Java where the type is known at compile time.IDEs may not correctly autocomplete available predicates on an asserted subject.In Python 2, IsNone   or IsNotNone   before performing an inequality assertion.In Python 3, None is no longer comparable using  =.PyTruth detects the version of the Python interpreter and compares or failsappropriately, rather than allowing Python 3's TypeError to bubble up.If the iterator over a shared value  either expected or actual  changes thatvalue or its underlying elements, the behavior is undefined:all, none, or some of the assertions may succeed or fail, arbitrarily.This library is threadsafe; you may execute multiple assertions in parallel.
google-pytruth	General	-----------------------------|---------------------------------------assertFalse callable a     | AssertThat a .IsNotCallable  
google-pytruth	Truthiness	PyTruth supports a finer grained distinction of truthiness than unittest does.In particular, it differentiates between "is True" and "is *truthy*."unittest's assertTrue x  is equivalent to assertIs bool x , True ,and its assertFalse x  is equivalent to assertIs bool x , False .PyTruth's IsTrue   and IsFalse   predicates match *onlysubjects True and False themselves.Therefore it is important not to blindly convert assertTrue   to IsTrue  ,and likewise with assertFalse   and IsFalse  .Truthy assertionAssertThat None .IsTruthy   | fails
google-pytruth	Strings	---------------------------------------------------------------|--------------------------------------assertNotRegex s, '^r' assertNotRegexpMatches s, '^r'  | AssertThat s .DoesNotMatch 'r' 
google-pytruth	Matching strings	The r'raw string', or a pattern object returned from re.compile  .
google-pytruth	Numbers, strings, and other comparable things	---------------------------|--------------------------------assertGreaterEqual a, b  | AssertThat a .IsAtLeast b 
google-pytruth	Numbers	--------------------------------------|------------------------------------assertNotAlmostEqual a, b, delta=d  | AssertThat a .IsNotWithin d .Of b 
google-pytruth	Lists, strings, and other iterables	--------------------------------|--------------------------------------------assertTrue b not in a and c not in a N/AN/A
google-pytruth	Defining order	The IsStrictlyOrderedAccordingTo   should be a callable that follows the contractof cmp x, y : it should return negative if x  y.depending on cf  from beginning to end
google-pytruth	Defining order	Adjacent elements are allowed to beequal
google-pytruth	Defining order	*Strictly ordered *i.e.*, monotonically increasing or decreasing .IsOrdered   is equivalent to IsOrderedAccordingTo cmp .IsStrictlyOrdered   is equivalent to IsStrictlyOrderedAccordingTo cmp .
google-pytruth	Asserting order	By default, ContainsAll..
google-pytruth	Asserting order	and ContainsExactly..
google-pytruth	Asserting order	do not enforce that theorder of the elements in the subject under test matches the that of the expectedvalue
google-pytruth	Asserting order	To do that, append InOrder   to the returned predicate.Containment assertionAssertThat  2, 4, 6  .ContainsExactly 2, 4, 6 .InOrder   | succeedsWhen using AssertThat list_a .ContainsExactlyElementsIn set_a .InOrder  may or may not succeed, depending on how the set implements ordering.
google-pytruth	Dictionaries, in addition to the table above	-----------------------------------|-----------------------------------------------assertDictContainsSubset d1, d2  | AssertThat d1.items   .ContainsAllIn d2.items   
google-pytruth	Exceptions	----------------------------------------|------------------------------------------------assertIn a, e.args 
google-pytruth	Matching raised exceptions	When expecting an exception using the AssertThat e .IsRaised   context, anyexception raised whose type is equal to e or a subclass of e is accepted.If an exception is raised that is not a subclass of e, the assertion fails.The ValueError 'some error' 
google-pytruth	Matching raised exceptions	If an instance is passed, then any exception raisedby the code under test must also have matching message and args properties,in addition to being a subclass of the expected exception.
google-pytruth	Mocked functions	----------------------------------------------------|------------------------------------------------m.assert_any_call *a, **k 
google-pytruth	Being called once, with arguments	The WasCalled  .Once  .With ..
google-pytruth	Being called once, with arguments	 and WasCalled  .With ..
google-pytruth	Being called once, with arguments	.Once   assertionsare subtly different
google-pytruth	Being called once, with arguments	WasCalled  .Once  .With ..
google-pytruth	Being called once, with arguments	 asserts that the functionwas called one time ever, and that one time it was called, it was passed thosearguments
google-pytruth	Being called once, with arguments	WasCalled  .With ..
google-pytruth	Being called once, with arguments	.Once   asserts that the function was passedthose arguments exactly once, but it is permitted to have been called withother, irrelevant arguments
google-pytruth	Being called once, with arguments	Thus, WasCalled  .Once  .With ..
google-pytruth	Being called once, with arguments	 is thestricter assertion
google-pytruth	Being called once, with arguments	Consider using HasExactlyCalls   for more clarity.
google-pytruth	Classes	------------------------------|-------------------------------
google-pytype	Pytype	Statically check and infer types for unannotated Python code
google-pytype	Pytype	This is not an official Google product
google-pytype	Abstract	Pytype is a static analyzer that helps you find type errors in Python code
google-pytype	Abstract	Itcan type-check code with or without type annotations  as well asgenerate annotations
google-pytype	Abstract	Pytype runs under Python 2.7 or 3.5+ and analyzes bothPython 2 and Python 3 code.
google-pytype	Example	Below, print_greeting calls make_greeting incorrectly:def make_greeting user_id :def print_greeting  :Run pytype to catch the bug:File "foo.py", line 2, in make_greeting: Function str.__add__ was called with the wrong arguments  wrong-arg-types   Expected:  self, y: str   Actually passed:  self, y: int   line 5, in print_greetingMerge pytype's generated type information back into foo.py:def make_greeting user_id  -> str: ...def print_greeting   -> None: ...def make_greeting user_id  -> str:def print_greeting   -> None:
google-pytype	Requirements	You need a Python 2.7 or 3.5+ interpreter to run pytype, as well as aninterpreter in $PATH for the Python version of the code you're analyzing.Platform support:The rest of this document provides complete instructions for installing andusing pytype
google-pytype	Requirements	To quickly get started with some common workflows, check out thefollowing docs:Pytype can be installed via pip
google-pytype	Requirements	Note that the installation requires wheeland setuptools
google-pytype	Requirements	 If you're working in a virtualenv, these two packages shouldalready be present
google-pytype	Usage	usage: pytype  options  input  input ..
google-pytype	Usage	positional arguments:  inputCommon options:   this doc   Defaults to empty.For a full list of options, run pytype --help.In addition to the above, you can direct pytype to use a custom typeshedinstallation instead of its own bundled copy by setting $TYPESHED_HOME.
google-pytype	Config File	For convenience, you can save your pytype configuration in a file
google-pytype	Config File	The configfile is an INI-style file with a setup.cfg file found by walking upwards from the current working directory.Start off by generating a sample config file:need
google-pytype	Config File	Directories may be relative to the location of the config file, which isuseful if you want to check in the config file as part of your project.For example, suppose you have the following directory structure and want toanalyze package ~/repo1/foo, which depends on package ~/repo2/bar:Python 3.6 code and ignore attribute errors
google-pytype	Config File	Notice that the path to a packagedoes not include the package itself.
google-pytype	NOTE: All relative paths are relative to the location of this file.	 pytype 
google-pytype	Python version  major.minor  of the target code.	python_version = 3.6
google-pytype	Paths to source code directories, separated by ':'.	pythonpath =We could've discovered that ~/repo2 needed to be added to the pythonpath byrunning pytype's broken dependency checker:Unresolved dependencies:  bar.dependency
google-pytype	Subtools	Pytype ships with three scripts in addition to pytype itself:single Python file assuming that .pyi files have already been generated for allof its dependencies.
google-pytype	Roadmap	Apache 2.0
google-pytypedecl	Pytypedecl - 	Pytypedecl consists of a type declaration language for Python and an optionalrun-time type checker
google-pytypedecl	Pytypedecl - 	This project was started by  Raoul-GabrielUrma  under the supervision of Peter Ludemann and GregoryP
google-pytypedecl	Pytypedecl - 	Smith during a summer 2013 internship at Google.
google-pytypedecl	License	Apache 2.0
google-pytypedecl	Why types declarations?	Type declarations are useful to document your code
google-pytypedecl	Why types declarations?	This proposal starts aconversation with the community to reach a standard for a type declarationlanguage for Python.
google-pytypedecl	Why runtime type-checking?	Runtime type-checking of optional type declarations is useful for codemaintenance and debugging
google-pytypedecl	Why runtime type-checking?	Our type-checker is available as a Python package.You therefore do not need to run external tools to benefit from the
google-pytypedecl	Status	This project is in its infancy -couple of months
google-pytypedecl	Status	We currently support Python 2.Support for Python 3 coming
google-pytypedecl	Type declaration language	Types declarations are specified in an external file with theextension **"pytd"**
google-pytypedecl	Type declaration language	For example if you want to provide types for**"application.py"**, you define the type inside the file**"application.pytd"**
google-pytypedecl	Type declaration language	Examples of type declarations files can befound in the **/tests/*Here’s an example of a type declaration file that mixes several features:Python 3 function annotation convention
google-pytypedecl	Type declaration language	However, we extended it in a number ofways that would be difficult or clumsy using Python 3's annotations.exceptions that the function might raise
google-pytypedecl	Type declaration language	There is no runtime checkingfor this, but exceptions can be useful documentation and an automatedtype inferencer could deduce the possible exceptions that a functionmight throw.This is not supported in the Python 3 function annotation syntax but issupported by pytypedecl.values from a number of different types
google-pytypedecl	Type declaration language	Union types allow to express thisidea
google-pytypedecl	Type declaration language	For example float
google-pytypedecl	Type declaration language	There is no limit to the number of types in a union
google-pytypedecl	Type declaration language	A none-able typecan be seen as the union of a type and None
google-pytypedecl	Type declaration language	Note: None is a unit type and is a subtype of NoneType
google-pytypedecl	Type declaration language	Because there'sonly one subtype of NoneType, for type-specification purposes, None andNoneType are the same
google-pytypedecl	Type declaration language	similarly to Java generics
google-pytypedecl	Type declaration language	For example, generator describes a generatorthat only produces strs, dict describes a dictionary of keys oftype str and values of type int.
google-pytypedecl	Coming soon:	The **-B*You can also run the tests:Look into the **/examples/*works
google-pytypedecl	Coming soon:	You need to do two things to type-check your program:**Create a type declaration file**Create a type declaration file that has the name of the Python file you want totype-check but with the extension .pytd  e.g
google-pytypedecl	Coming soon:	email.pytd for email.py **Import the checker package**Include the following two imports in the Python file that you want toThat’s it! You can now run your python program and it will be type-checked atruntime using the type declarations you defined in the **pytd*
google-pyu2f	pyu2f	  pyu2f is a python based U2F host library for Linux, Windows, and MacOS
google-pyu2f	pyu2f	Itprovides functionality for interacting with a U2F device over USB.
google-pyu2f	Features	pyu2f uses ctypes to make system calls directly to interface with the USB HIDdevice
google-pyu2f	Features	This means that no platform specific shared libraries need to becompiled for pyu2f to work.By default pyu2f will use its own U2F stack implementation to sign requests
google-pyu2f	Features	Ifdesired, pyu2f can offload signing to a pluggable command line tool
google-pyu2f	Features	Offloadingis not yet supported for U2F registration.
google-pyu2f	Usage	The recommended approach for U2F signing  authentication  is through theconvenience interface:from pyu2f import modelfrom pyu2f.convenience import authenticatorregistered_key = model.RegisteredKey b64_encoded_key challenge_data =  {'key': registered_key, 'challenge': raw_challenge_data} api = authenticator.CreateCompositeAuthenticator origin response = api.Authenticate app_id, challenge_data See baseauthenticator.py for interface details.
google-pyu2f	Authentication Plugin	The convenience interface allows for a pluggable authenticator to be defined andused instead of the built in U2F stack.This can be done by setting the SK_SIGNING_PLUGIN environment variable to theplugin tool
google-pyu2f	Authentication Plugin	The plugin tool should follow the specification detailed inIf SK_SIGNING_PLUGIN is set, the convenience layer will invoke the signingplugin whenver Authenticate   is called.
google-pywebsocket	pywebsocket #	The pywebsocket project aims to provide a  WebSocket  standalone server and a WebSocket extension for  Apache HTTP Server  mod\_pywebsocket.pywebsocket is intended for **testing*Please see  Wiki  ../../wiki  for more details.
google-quark	Project Quark	__Post-Quantum Verified Boot for IoT Devices__This repository contains work-in-progress hash-based signature verification code that is optimized for low-end ARM-based IoT devices
google-quark	Project Quark	IoT devices have unique security requirements that include the following:Unlike desktops, laptops and phones, they may not be associated with an individual that could keep the device up-to-date, and they are not necessarily 'always on', or even 'occasionally on.' Furthermore, many of these devices are battery powered, with anemic compute resources and constrained bandwidth availability
google-quark	Project Quark	These IoT devices are often installed, ignored, and may need to be in operation for several years
google-quark	Project Quark	To keep these devices secure, it is important to support Verified Boot, and to sign Over The Air  OTA  firmware updates
google-quark	Project Quark	These require signature schemes that provide compact signatures, and support efficient signature verification
google-quark	Project Quark	Furthermore, since these devices may operate 'in the wild' for several years, perhaps decades, the signature scheme needs to be resilient against anticipated attacks
google-quark	Project Quark	One possible attack would be due to sufficiently large quantum computers that could break RSA and ECC-based signature schemes
google-quark	Project Quark	There is no consensus regarding when these quantum attacks might become practical, but it is estimated to be between 10-15 years from now
google-quark	Project Quark	Hash-based signatures are believed to be resilient against quantum attacks, have been around for a few decades and hence are well-understood from a security perspective
google-quark	Project Quark	They can be efficient, but their signature sizes tend to be larger than RSA/ECDSA equivalents
google-quark	Project Quark	These hash-based signatures can be either stateful or stateless, and the former tend to provide more compact signatures than the latter
google-quark	Project Quark	There are two candidate standards for stateful signatures, one of which is an IETF RFC, the other of which is still in the IETF draft stage:XMSS  RFC 8391 This project hosts just the signature verification portions of these schemes, which have been optimized to run on low-end ARM devices
google-quark	Project Quark	The initial version of this code was authored by Crypto4A, Inc., one of our Industry partners that is based in Ottawa, Canada
google-quark	Project Quark	A limitation of stateful signatures is that any misuse of state would completely break security
google-quark	Project Quark	To address this, Google is collaborating with Stanford University, one of our Academic Research partners, to explore techniques to make these stateful signatures more resilient against limited misuse of state.There are currently no plans to productize, or officially support this code at this time
google-quark	Project Quark	This will continue to be work-in-progress for the forseeable future
google-quark	Project Quark	You are encouraged to leverage this code in your own experiments, and we welcome collaboration
google-quark	Project Quark	The initial version of this code was authored under contract from Google by Crypto4A, Inc., one of our Industry partners that is based in Ottawa, Canada.
google-quark	Building	Simple recursive Makefiles are provided at the root and module levels
google-quark	Building	 The outputs of these Makefiles are libraries in the src/xmssmt directories which implement the verification code as well as test executables in the test module.CMake projects are also provided.
google-quark	Copyright	Copyright &copy; 2018 Google LLCLicensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License
google-quic-trace	QUIC trace utilities	This repository contains a format for recording a trace of QUIC connection,together with the tools for analyzing the resulting traces
google-quic-trace	QUIC trace utilities	 This format oftraces is currently partially supported by Chromium, and we hope for moreimplementations to adopt it in the future.The primary focus of this format is debugging congestion-control relatedissues, but other transport aspects  e.g
google-quic-trace	QUIC trace utilities	flow control  and transport-relatedaspects of the application  e.g
google-quic-trace	QUIC trace utilities	annotations for the types of data carried bythe streams  are also within the scope.
google-quic-trace	How to record this format	The traces are represented as a Protocol Buffer, which is completely describedin lib/quic_trace.proto
google-quic-trace	How to record this format	 Projects that use Bazel can embed this repositorydirectly and use the provided Bazel rules.
google-quic-trace	How to render the resulting trace	Currently, we only support a simple visualization that uses gnuplot.Build the helper tool by running bazel buildGenerate the graph by running tools/time_sequence_gnuplot.sh trace_file
google-quiver-dart	Documentation	 API Docs  are available.
google-quiver-dart	Installation	Add Quiver to your project's pubspec.yaml file and run pub get.We recommend the following version constraint:
google-quiver-dart	 quiver.async   	Utilities for working with Futures, Streams and async computations.enumerate and concat represent Stream versions of the same-named quiver.iterables    methods.doWhileAsync, reduceAsync and forEachAsync perform async computations onthe elements of on Iterables, waiting for the computation to complete beforeprocessing the next element.StreamBuffer allows for the orderly reading of elements from a stream, suchas a socket.FutureStream turns a Future into a Stream which emits the sameevents as the stream returned from the future.StreamRouter splits a Stream into mulltiple streams based on a set ofCountdownTimer is a simple countdown timer that fires events in regularMetronome is a self-correcting alternative to Timer.periodic
google-quiver-dart	 quiver.async   	It providesa simple, tracking periodic stream of DateTime events with optional anchor quiver.async : 
google-quiver-dart	 quiver.cache   	Cache is a semi-persistent, asynchronously accessed, mapping of keys tovalues
google-quiver-dart	 quiver.cache   	Caches are similar to Maps, except that the cache implementation mightstore values in a remote system, so all operations are asynchronous, and cachesmight have eviction policies.MapCache is a Cache implementation backed by a Map
google-quiver-dart	 quiver.cache   	quiver.cache : 
google-quiver-dart	 quiver.check   	checkArgument throws ArgumentError if the specifed argument check expressionis false.checkListIndex throws RangeError if the specified index is out of bounds.checkNotNull throws ArgumentError if the specified argument is null.checkState throws StateError if the specifed state check expression is quiver.check : 
google-quiver-dart	 quiver.collection   	listsEqual, mapsEqual and setsEqual check collections for equality.LruMap is a map that removes the least recently used item when a thresholdlength is exceeded.Multimap is an associative collection that maps keys to collections ofBiMap is a bidirectional map and provides an inverse view, allowinglookup of key by value.TreeSet is a balanced binary tree that offers a bidirectional iterator,the ability to iterate from an arbitrary anchor, and 'nearest' search
google-quiver-dart	 quiver.collection   	quiver.collection : 
google-quiver-dart	 quiver.core   	Optional is a way to represent optional values without allowing null.firstNonNull returns its first non-null argument.hashObjects, hash2, hash3, and hash4 generate high-quality hashCodes fora list of objects, or 2, 3, or 4 arguments respectively
google-quiver-dart	 quiver.core   	quiver.core : 
google-quiver-dart	 quiver.io   	visitDirectory is a recursive directory lister that conditionally recursesinto sub-directories based on the result of a handler function
google-quiver-dart	 quiver.io   	quiver.io : 
google-quiver-dart	 quiver.iterables   	zip create, transform, or combine Iterables in different ways, similar toPython's itertools.min, max, and extent retreive the minimum and maximum elements from anGeneratingIterable is an easy way to create lazy iterables that produceelements by calling a function
google-quiver-dart	 quiver.iterables   	A common use-case is to traverse properties inan object graph, like the parent relationship in a tree.InfiniteIterable is a base class for Iterables that throws on operations thatrequire a finite length
google-quiver-dart	 quiver.iterables   	quiver.iterables : 
google-quiver-dart	 quiver.mirrors   	getTypeName returns the name of a Type instance.implements and classImplements determine if an instance or ClassMirror,respectively, implement the interface represented by a Type instance
google-quiver-dart	 quiver.mirrors   	Theyimplement the behavior of is for mirrors, except for generics.getMemberMirror searches though a ClassMirror and its class hierarchy fora member
google-quiver-dart	 quiver.mirrors   	This makes up for the fact that ClassMirror.members doesn'tcontain members from interfaces or superclasses.Method wraps an InstanceMirror and Symbol to create a callable that invokesa method on the instance
google-quiver-dart	 quiver.mirrors   	It in effect closurizes a method reflectively
google-quiver-dart	 quiver.mirrors   	quiver.mirrors : 
google-quiver-dart	 quiver.pattern   	pattern.dart container utilities for work with Patterns and RegExps.Glob implements glob patterns that are commonly used with filesystem paths.matchesAny combines multiple Patterns into one, and allows for exclusions.matchesFull returns true if a Pattern matches an entire String.escapeRegex escapes special regex characters in a String so that it can beused as a literal match inside of a RegExp
google-quiver-dart	 quiver.pattern   	quiver.pattern : 
google-quiver-dart	 quiver.strings   	isBlank checks if a string is null, empty or made of whitespace characters.isEmpty checks if a string is null or empty.isNotEmpty checks if a string is not null and not empty.equalsIgnoreCase checks if two strings are equal, ignoring case.compareIgnoreCase compares two strings, ignoring case.loop allows you to loop through characters in a string starting and ending atarbitrary indices
google-quiver-dart	 quiver.strings   	Out of bounds indices allow you to wrap around the string,supporting a number of use-cases, including:
google-quiver-dart	 quiver.time   	Clock provides points in time relative to the current point in time, forexample: now, 2 days ago, 4 weeks from now, etc
google-quiver-dart	 quiver.time   	For tesability, use Clockrather than other ways of accessing time, like new DateTime  , so that youcan use a fake time function in your tests to control time.Now is a typedef for functions that return the current time in microseconds,since Clock deals in DateTime which only have millisecond accuracy.aWeek are unit duration constants to allow writing for example:
google-quiver-dart	Testing Libraries	The Quiver testing libraries are intended to be used in testing code, notproduction code
google-quiver-dart	Testing Libraries	It currently consists of fake implementations of some Quiver
google-quiver-dart	 quiver.testing.async   	FakeAsync enables testing of units which depend upon timers and microtasks.It supports fake advancements of time and the microtask queue, which cause faketimers and microtasks to be processed
google-quiver-dart	 quiver.testing.async   	A Clock is provided from which to readthe current fake time
google-quiver-dart	 quiver.testing.async   	 Faking synchronous or blocking time advancement is also quiver.testing.async : 
google-quiver-dart	 quiver.testing.equality   	hashCode implementations
google-quiver-dart	 quiver.testing.equality   	quiver.testing.equality : 
google-quiver-dart	 quiver.testing.runtime   	assertCheckedMode asserts the current runtime has checked mode enabled
google-quiver-dart	 quiver.testing.runtime   	quiver.testing.runtime : 
google-quiver-dart	 quiver.testing.time   	FakeStopwatch is a Stopwatch that uses a provided now   function to get thecurrent time
google-quiver-dart	 quiver.testing.time   	quiver.testing.time : 
google-quiver-log	Documentation	 API Docs  are
google-quiver-log	The Basics	Dart's built-in logging utilities are fairly low level
google-quiver-log	The Basics	This means each time youstart a new project you have to copy/paste a bunch of logging configurationcode to setup output locations and logging formats
google-quiver-log	The Basics	Quiver-log provides a set ofhigher-level abstractions to make it easier to get logging setup correctly.Specifically, there are two new concepts: appender and formatter
google-quiver-log	The Basics	Appendersdefine output locations like the console, http or even in-memory data structuresthat can store logs
google-quiver-log	The Basics	Formatters, as the name implies, allow for custom loggingHere is a simple example that sets up a SimpleStringFormatter:import 'package:logging/logging.dart';import 'package:quiver_log/log.dart';class SimpleStringFormatter implements FormatterBase {  String call LogRecord record  => record.message;main   {  var logger = new Logger 'quiver.TestLogger' ;  var appender = new InMemoryListAppender new SimpleStringFormatter   ;  appender.attachLogger logger ;That's all there is to it!Quiver-log provides three BasicLogFormatter is included and uses a "MMyy HH:mm:ss.S" format
google-quiver-log	The Basics	Of coursethere is no limit to what kind of appenders you can create, we have plans toadd appenders HTTP, WebSocket, DOM, Isolate and SysOut.To create a new kind of Formatter just implement the Formatter typedef or FormatterBase class ifyou need to hold state in your formtatter
google-quiver-log	The Basics	Take a look at PrintAppender and BasicLogFormatter for an example.
google-radioreceiver	Radio Receiver	An application to listen to broadcast FM and AM radio from your Chrome browser or your ChromeBook computer using a $15 USB digital TV tuner.! Radio Receiver screenshot  image-src/interface.png 
google-radioreceiver	What is this	Radio Receiver is a Chrome application that uses an USB digital TV receiver to capture radio signals, does FM and AM demodulation in the browser, and plays them through your computer's speakers or headphones
google-radioreceiver	What is this	This is called SDR  Software-Defined Radio , because all the radio signal processing is done by software running in the computer.Radio Receiver is 100% written in JavaScript, but is nevertheless fast enough that it can run on a 2012 Samsung ChromeBook laptop at full quality.
google-radioreceiver	Features	Radio Receiver was written to work with an RTL-2832U-based DVB-T  European digital TV  USB receiver, with a R820T tuner chip
google-radioreceiver	Features	You can easily buy one for $15 or less by searching for  RTL2832U R820T  on your favorite online store or web search engine.You can use this application on a ChromeBook, or on any other computer running a Chrome browser
google-radioreceiver	Features	Just  install it using the Chrome Web Store  or any other mechanism, plug in your USB dongle, and click on the icon to start the Radio Receiver application.To listen to Medium Wave and Short Wave radio, you need an upconverter connected between your antenna and the USB dongle
google-radioreceiver	Features	This upconverter shifts the signals up in frequency so that they can be tuned by your dongle
google-radioreceiver	Features	You can find upconverters for sale by searching for  SDR upconverter  on your favorite online store or web search engine.
google-radioreceiver	Support	If you'd like to talk about Radio Receiver, or have any bug reports or suggestions, please post a message in  the radioreceiver Google Group Note: This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-radioreceiver	Acknowledgements	Kudos and thanks to the  RTL-SDR project  for figuring out the magic numbers needed to drive the USB tuner.If you want to experiment further with Software-Defined Radio and listen to more things using your $15 tuner, you can try  the various programs listed on rtl-sdr.com 
google-rally	Disclaimers	**This is not an official Google product.**
google-randen	Overview	What if we could default to attack-resistant random generators without excessiveCPU cost? We introduce 'Randen', a new generator with security guarantees; itoutperforms MT19937, pcg64_c32, Philox, ISAAC and ChaCha8 in real-worldbenchmarks
google-randen	Overview	This is made possible by AES hardware acceleration and a largeFeistel permutation.
google-randen	Related work	AES-CTR  encrypting a counter  is a well-known and easy to implement generator.It has two known weaknesses:NIST 800-90a r1    is a standardized generator that ensuresbacktracking resistance, but is not fast enough for a general-purpose generator 5-10x slower than AES .
google-randen	Algorithm	The Randen generator is based upon three existing components:1   Reverie    is a sponge-like generator2   Simpira v2    constructs up to 1024-bit3   "New criterion for diffusion property"    shows thatWe combine these by plugging the larger Simpira-like permutation into Reverie.
google-randen	Performance	The implementation targets x86  Westmere , POWER 8 and ARMx86 microbenchmark results  cpb=cycles per byte, MAD=median absolute deviation :RNG | cpb | MADRandenmt19937_64ISAAC/dev/urandom  ChaCha20 BCryptGenRandom  CTR-DRBG  | 16.80 | 0.009x86 real-world benchmark  reservoir sampling :RNG | cpb | MADRandenpcg64_c32 |  3.03 | 0.009mt19937_64|  2.82 | 0.009ChaCha8   |  3.75 | 0.008Philox/dev/urandom  ChaCha20 BCryptGenRandom  CTR-DRBG  | 16.41 | 0.015
google-randen	Security	Randen is indistinguishable from random and backtracking-resistant
google-randen	Security	For moredetails and benchmarks, please seethe paper "Randen AES+Feistel+Reverie"  pending publication .
google-randen	Usage	make && bin/randen_benchmarkNote that the code relies on compiler optimizations
google-randen	Usage	Cycles per byte mayincrease by factors of 1.6 when compiled with GCC 7.3, and 1.3 withClang 4.0.This can be mitigated by manually unrolling the loops.
google-randen	Third-party implementations / bindings	Thanks to Frank Denis for making us aware of these third-party implementationsor bindings
google-randen	Third-party implementations / bindings	Note that the algorithm is still under review and subject tochange, but please feel free to get in touch or raise an issue and we'lladd yours as well.By | Language | URLFrank Denis | C |
google-rbe-integration-test	Bazel RBE Extensions	This directory contains various extensions, environment setups and examples thatwork with integration test library within Bazel Remote Build Execution service.This is not an officially supported Google product.
google-re2j	Why should I switch?	If you use regular expression patterns with a high degree of alternation, yourcode may run faster with RE2/J
google-re2j	Why should I switch?	In the worst case, the java.util.regexmatcher may run forever, or exceed the available stack space and fail; thiswill never happen with RE2/J.
google-re2j	Caveats	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.RE2/J is not a drop-in replacement for java.util.regex
google-re2j	Caveats	Aside from thedifferent package name, it doesn't support the following parts of thespecial regular expression constructs.
google-re2j	Getting RE2/J	If you're using Maven, you can use the following snippet in your pom.xml to get RE2/J:You can also download RE2/J the old-fashioned way: go to  the latest RE2/J release tag  download the RE2/J JAR and add it to your CLASSPATH.
google-re2j	Discussion and contribution	We have set up a Google Group for discussion, please join the  RE2/J discussionlist  if you'd like to get inIf you would like to contribute patches, please see the  instructions forcontributors  CONTRIBUTING.md .
google-re2j	Who wrote this?	RE2 was designed and implemented in C++ by Russ Cox
google-re2j	Who wrote this?	The C++ implementationincludes both NFA and DFA engines and numerous optimisations
google-re2j	Who wrote this?	Russ also porteda simplified version of the NFA to Go
google-re2j	Who wrote this?	Alan Donovan ported the NFA-based Goimplementation to Java
google-re2j	Who wrote this?	Afroz Mohiuddin wrapped the engine in a familiar JavaMatcher / Pattern API
google-re2j	Who wrote this?	James Ring prepared the RE2/J source for itsrelease to Open Source.
google-readahead	readahead	*This is not an official Google product*readahead is a package that provides readers that enable concurrentreads from seekable or compressed files
google-readahead	readahead	It's useful when reading froma network file system  like Google Cloud Storage .To install: go get github.com/google/readaheadFor information on use, see the godoc 
google-reagera	Reagera	Reagera is a minimal implementation of a predictable state container in Java, inspired by Elm and Redux.License: Apache 2.0This is not an official Google product.
google-recaptcha	reCAPTCHA PHP client library	     ! Latest Stable Version   ! Total Downloads  reCAPTCHA is a free CAPTCHA service that protect websites from spam and abuse.This is a PHP library that wraps up the server-side verification step requiredto process responses from the reCAPTCHA service
google-recaptcha	reCAPTCHA PHP client library	This client supports both v2and v
google-recaptcha	Composer  recommended 	Use  Composer  to install this library from Packagist: google/recaptcha Run the following command from your project directory to add the dependency:Download the  ZIP file and extract into your project
google-recaptcha	Composer  recommended 	An autoloader script is provided insrc/autoload.php which you can require into your script
google-recaptcha	Composer  recommended 	For example: PSR-4  standard, so you can also use yourown autoloader or require the needed files directly in your code.
google-recaptcha	Usage	First obtain the appropriate keys for the type of reCAPTCHA you wish tointegrate for v2 at  or v3 atThen follow the  integration guide on the developersite  to add the reCAPTCHAfunctionality into your frontend.This library comes in when you need to verify the user's response
google-recaptcha	Usage	On the PHPside you need the response from the reCAPTCHA service and secret key from yourcredentials
google-recaptcha	Usage	Instantiate the ReCaptcha class with your secret key, specify anyadditional validation rules, and then call verify   with the reCAPTCHAresponse and user's IP address
google-recaptcha	Usage	For example:  credentials
google-recaptcha	Usage	 "Domain/Package Name Validation" for your credentials.Each of the set\*   methods return the ReCaptcha instance so you can chainthem together
google-recaptcha	Usage	For example:setExpectedHostname 'recaptcha-demo.appspot.com' if  $resp->isSuccess    {} else {You can find the constants for the libraries error codes in the ReCaptchaclass constants, e.g
google-recaptcha	Usage	ReCaptcha::E_HOSTNAME_MISMATCHFor more details on usage and structure, see  ARCHITECTURE  ARCHITECTURE.md .
google-recaptcha	Examples	You can see examples of each reCAPTCHA type in  examples/  examples/ 
google-recaptcha	Examples	You canrun the examples locally by using the Composer script:These are also hosted on Google AppEngine Flexible environment at This is configured by app.yaml  ./app.yaml  which you can also use to  deploy to your own AppEngineproject 
google-recaptcha	Contributing	No one ever has enough engineers, so we're very happy to accept contributionsvia Pull Requests
google-recaptcha	Contributing	For details, see  CONTRIBUTING  CONTRIBUTING.md 
google-recki-ct	Stability	Recki-CT is **pre-alpha*
google-recki-ct	What Is Recki-CT?	Recki-CT is a set of tools that implement a compiler for PHP, and is written in PHP! Specifically, Recki-CT compiles a subset of PHP code
google-recki-ct	What Is Recki-CT?	The subset is designed to allow a code base to be statically analyzed
google-recki-ct	What Is Recki-CT?	This means that global variables, dynamic variables  variable-variables, variable function calls, etc  and references are not allowed
google-recki-ct	What Isn't Recki-CT?	Recki-CT is not a re-implementation of PHP
google-recki-ct	What Isn't Recki-CT?	It aims to be a limited subset of the language  one that can be staticly reasoned about .This means that it is not designed to replace PHP, but instead augment it.
google-recki-ct	Why?	PHP itself isn't slow
google-recki-ct	Why?	It's plenty fast enough for most use-cases
google-recki-ct	Why?	As a language, PHP has a lot of corner cases and results in a be in there somewhere.So with Recki-CT, we take a different approach
google-recki-ct	Why?	Rather than rewriting the entire engine, we sit on top of an existing engine
google-recki-ct	Why?	The compilerthen can compile PHP code into native machine code which can out-perform most JIT compiled implementations  sometimes by very significant margins .The designed mode of operation for Recki is as an AOT  Ahead-Of-Time  compiler
google-recki-ct	Why?	Since it uses aggressive analysis and optimizations, runtime compilation would be a inefficient target
google-recki-ct	Why?	Instead, an Intermediate Representation can be cached, leaving only the final conversionto machine code to happen at runtime
google-recki-ct	Where can I find out more?	Check out the documentation!!!  Introduction and FAQ  doc/0_introduction.md   Installation  doc/1_installation.md   Basic Operation  doc/2_basic_operation.md   Types  doc/3_types.md   Intermediate Representation  doc/4_intermediate_representation.md 
google-recki-ct	How do I install Recki-CT?	See the  Installation Documentation  doc/1_installation.md .
google-recki-ct	How do I use Recki-CT?	A very simple example:/* */function foo $bar  {}// Instead of using:foo $baz ;// Use:$foo = Jit::JitFu 'foo' ;$foo $baz ;Note that a docblock *mustCheck out the examples folder for more examples!
google-recki-ct	License	Recki-CT is released under the  Apache-2 License  LICENSE .
google-recki-ct	Contributing	See  CONTRIBUTING.md  CONTRIBUTING.md And join the  Google Group  mailing list.
google-redgrep	About	redgrep is a grep based on regular expression derivatives
google-redgrep	About	That is,it uses regular expression derivatives to construct the DFA
google-redgrep	About	It thenuses LLVM to JIT the DFA.Since regular expression derivatives permit the three basic Booleanoperations of disjunction  | , conjunction  &  and complement  ! ,redgrep enables you to write very powerful regular expressions veryeasily and guarantees to match them in linear time.
google-redgrep	Building	You must have GNU make, GNU bison and either GCC or Clang.redgrep follows the "latest and greatest" in LLVMdevelopment, so you should check out the source from Subversion or  Git then configure, build, check and install as per the instructions  Debian and Ubuntu users may prefer to install the  nightlypackages  instead
google-redgrep	Building	You should set the LLVM_CONFIG environment variable appropriately whenyou run make.
google-redgrep	Contact	 redgrep@googlegroups.com  mailto:redgrep@googlegroups.com 
google-redgrep	Disclaimer	This is not an official Google product.
google-refr	ReFr  Reranker Framework 	ReFr is a software architecture for specifying, training and usingreranking models
google-refr	ReFr  Reranker Framework 	Reranking models take the n-best output of someexisting system and produce new scores for each of the n hypothesesthat potentially induce a different ranking, ideally yielding betterresults than the original system
google-refr	ReFr  Reranker Framework 	The Reranker Framework  **ReFr*short  has some special support for building discriminative languagemodels, but can be applied to any reranking problem.For documentation, please visit our documentation site 
google-reil	REIL	A c++ translation/emulation library for the aarch64 instruction set to REIL.This is not an officially supported Google product.
google-reil	Building	Cmake has been used in an attempt to make downloading and building dependencies painless, but this has had the unfortunate side-effect of making the whole process more complicated than it really needs to be
google-reil	Building	Sorry.If you have the necessary dependencies, it should be straightforward to just build the source yourself if you don't like cmake
google-reil	Building	Apart from Unicorn, the other dependencies are all header-only libraries, and Unicorn is only required to build the tests.For a normal  cmake  buildThis translation library has a reasonable selection of unit tests to verify the translation against unicorn/qemu
google-reil	Building	To run the tests for the aarch64 translator, you can use the following commands:See the code in reil/test for examples of how to use the translator, and the implementation in reil/interpreter.cpp for the intended semantics of the translated IL instructions.
google-rejoiner	Rejoiner	     ! Maven Central  
google-rejoiner	Experimental Features	These features are actively being developed.SchemaModule is a Guice module that is used to generate parts of a GraphQLschema
google-rejoiner	Experimental Features	It finds methods and fields that have Rejoiner annotations when it'sinstantiated
google-rejoiner	Experimental Features	It then looks at the parameters and return type of these methodsin order to generate the appropriate GraphQL schema
google-rejoiner	Experimental Features	Examples of queries,mutations, and schema modifications are presented below.
google-rejoiner	GraphQL Query	it's used as a parameter in the generated GraphQL query
google-rejoiner	GraphQL Query	todoService isn't aprotobuf message, so it's provided by the Guice injector.This is useful for providing rpc services or database access objects forfetching data
google-rejoiner	GraphQL Query	Authentication data can also be provided here.Common implementations for these annotated methods:In this example we are adding a reference to the User type on the Todo type.In this case the Todo parameter is the parent object which can be referenced toget the creator's email.This is how types are joined within and across APIs.! Rejoiner API Joining  ./website/static/rejoiner.svg 
google-rejoiner	Removing a field	import com.google.api.graphql.rejoiner.SchemaProviderModule;public final class TodoModule extends AbstractModule {  @Override  protected void configure   {  }
google-rejoiner	Dependency information	Apache Mavencompile 'com.google.api.graphql:rejoiner:0.0.4'Scala SBTlibraryDependencies += "com.google.api.graphql" % "rejoiner" % "0.0.4"
google-rejoiner	Supported return types	All generated proto messages extend Message
google-rejoiner	Supported return types	 
google-rekall	The Rekall Forensic and Incident Response Framework	The Rekall Framework is a completely open collection of tools,implemented in Python under the Apache and GNU General Public License,for the extraction and analysis of digital artifacts computer systems.The Rekall distribution is available from:Rekall should run on any platform that supports Python Rekall supports investigations of the following 32bit and 64bit memorymajor operating systems  see the tools directory .
google-rekall	Quick start	Rekall is available as a python package installable via the pippackage manager
google-rekall	Quick start	To install it, first create a virtal env, switch toit and then install rekall:package
google-rekall	Quick start	Please check the download page for the most appropriate installer touse  Rekall-Forensic.com To install from this git repository you will need to use pip--editable and follow the correct order of installation  otherwise pipwill pull released dependencies which might be older :for python  for more info see this blog post
google-rekall	Mailing Lists	Mailing lists to support the users and developers of Rekallcan be found at the following address:
google-rekall	Licensing and Copyright	Copyright  C  2007-2011 Volatile SystemsCopyright 2012-2016 Google Inc
google-rekall	Licensing and Copyright	All Rights Reserved.All Rights ReservedThis program is free software; you can redistribute it and/ormodify it under the terms of the GNU General Public Licenseas published by the Free Software Foundation; either version 2of the License, or  at your option  any later version.This program is distributed in the hope that it will be useful,but WITHOUT ANY WARRANTY; without even the implied warranty ofMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE
google-rekall	Licensing and Copyright	 See theGNU General Public License for more details.You should have received a copy of the GNU General Public Licensealong with this program; if not, write to the Free SoftwareFoundation, Inc., 59 Temple Place 02111-1307, USA.
google-rekall	Bugs and Support	There is no support provided with Rekall
google-rekall	Bugs and Support	There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULARIf you think you've found a bug, please report it at:please include the following information when filing a bug:In December 2011, a new branch within the Volatility project was created toexplore how to make the code base more modular, improve performance, andincrease usability
google-rekall	Bugs and Support	The modularity allowed Volatility to be used in GRR, makingmemory analysis a core part of a strategy to enable remote live forensics
google-rekall	Bugs and Support	 As aresult, both GRR and Volatility would be able to use each other's strengths.Over time this branch has become known as the "scudette" branch or the"Technology Preview" branch
google-rekall	Bugs and Support	 It was always a goal to try to get these changesinto the main Volatility code base
google-rekall	Bugs and Support	 But, after two years of ongoingdevelopment, the "Technology Preview" was never accepted into the Volatilitytrunk version.Since it seemed unlikely these changes would be incorporated in the future, itmade sense to develop the Technology Preview branch as a separate project
google-rekall	Bugs and Support	OnDecember 13, 2013, the former branch was forked to create a new stand-aloneproject named "Rekall.” This new project incorporates changes made to streamlinethe codebase so that Rekall can be used as a library
google-rekall	Bugs and Support	Methods for memoryacquisition and other outside contributions have also been included that werenot in the Volatility codebase.Rekall strives to advance the state of the art in memory analysis, implementingthe best algorithms currently available and a complete memory acquisition andanalysis solution for at least Windows, OSX and Linux.
google-rekall	More documentation	Further documentation is available at
google-request-test	request-test	Collects responses from URLs with various User-Agents, recording the response
google-request-test	Installation	Make sure you have the prereqs on the machine  python, sqlite, et al Instantiate the sqlite db with some data: sqlite3 request-test.db < request-test.sql uatest.sqlThat's it!  usually 
google-request-test	Usage	There is one request test at this time: uatest.py
google-request-test	uatest	The UA test has two modes:running all untested UA/URL combos as found in the SQLite DB,testing a specific URL with all known UAsThe test is invoked like: python uatest.py  --untested|| Data is stored in the 'requests' table and responses are saved in the ./saves
google-request-test	Analysis	Once the data is collected, you can perform analysis by connecting to the sqlitedatabase on the command line  sqlite request-test.db  and reviewing the htmlfiles in the saves dir.Here are some interesting queries you could perform:
google-request-test	Contributing	Review  CONTRIBUTING Fork this repoCreate your feature branch: git checkout -b my-new-featureCommit your changes: git commit -am 'Add some feature'Push to the branch: git push origin my-new-featureSubmit a pull request!  If I don't respond quickly, send me a ping : 
google-request-test	License	This sample code is an official Google product and is licensed under the Apache 2 License  LICENSE .
google-rerast	Rerast	 ! Latest Version    Rerast is a search/replace tool for Rust code using rules
google-rerast	Rerast	A rule consists of asearch pattern, a replacement and possibly some placeholders that can appear inboth the search pattern and the replacement
google-rerast	Rerast	Matching is done on syntax, not ontext, so formatting doesn't matter
google-rerast	Rerast	Placeholders are typed and must match thetype found in the code for the rule to apply.
google-rerast	Installation	Ensuring you have the latest nightly toolchain installed  rustup update nightly  simply run:Basic operations can be performed entirely from the command lineAlternatively you can put your rule in a Rust filethen usePutting your rules in a file is required if you want to apply multiple rules at once.If you'd like to actually update your files, that can be done as follows:an Rc "r" is a placeholder which will match any expression of the type specified
google-rerast	Installation	The name of the function"rule1" is not currently used for anything
google-rerast	Installation	In future it may be possible to selectivelyenable/disable rules by specifying their name, so it's probably a good idea to put a slightlydescriptive name here
google-rerast	Installation	Similarly, comments placed before the function may in the future be displayedto users when the rule matches
google-rerast	Installation	This is not yet implemented.A function can contain multiple invocations of the replace! macro, with earlier rules taking precedence.This is useful if you want to do several replacements that make use of the same placeholders or if you wantto handle certain special patterns first, ahead of a more general match.Besides replace! there are several other replacement macros that can be used:  matched within let statements and function arguments
google-rerast	Installation	 replace\_trait\_ref! instead, since trait references can appear in contexts where types cannot
google-rerast	Matching macro invocations	Macro invocations can be matched so long as they expand to code that can be matched
google-rerast	Matching macro invocations	Note howeverthat a macro invocation will not match against the equivalent code, nor the invocation of adifferent, but identical macro
google-rerast	Matching macro invocations	This is intentional
google-rerast	Matching macro invocations	When verifying a match, we check that the samesequence of expansions was followed
google-rerast	Matching macro invocations	Also note, that if a macro expands to something different everytime it is invoked, it will never match
google-rerast	Matching macro invocations	println! is an example of such a macro, since it generatesa constant that is referenced from the expanded code and every invocation references a different
google-rerast	Order of operations	Suppose you're replacing foo a, b  with a && !b
google-rerast	Order of operations	Depending on what the placeholders end up matchingand what context the entire expression is in, there may be need for extra parenthesis
google-rerast	Order of operations	For exampleif the matched code was !foo x == 1, y == 2 , if we didn't add any parenthesis, we'd end up with !x== 1 && !y == 2 which clearly isn't correct
google-rerast	Order of operations	Rerast detects this and adds parenthesis as needed inorder to preserve the order or precedence found in the replacement
google-rerast	Order of operations	This would give ! x == 1 && ! y== 2  .
google-rerast	Formatting of code	No reformatting of code is currently done
google-rerast	Formatting of code	Unmatched code will not be affected
google-rerast	Formatting of code	Replacement code isproduced by copying the replacement code from the rule and splicing in any matched patterns
google-rerast	Formatting of code	Infuture, we may adjust identation for multi-line replacements
google-rerast	Formatting of code	Running rustfmt afterwards is probablya good idea since some identation and line lengths may not be ideal.
google-rerast	Recursive and overlapping matches	The first matched rule wins
google-rerast	Recursive and overlapping matches	When some code is matched, no later rules will be applied to thatcode
google-rerast	Recursive and overlapping matches	However, code matched to placeholders will be searched for further matches to all rules.
google-rerast	Automatically determining a rule from a source code change	If you're about to make a change multiple times throughout your source code and you're using git,you can commit  or stage  your changes, make one edit then run:to determine a rule that would have produced this change
google-rerast	Automatically determining a rule from a source code change	It will print the rule, then apply it toyour project
google-rerast	Automatically determining a rule from a source code change	If you are happy with the changes, you can run again with --force to apply them, oryou could copy the printed rule into a .rs file and apply it with --rules_file
google-rerast	Automatically determining a rule from a source code change	 kind of tricky
google-rerast	Automatically determining a rule from a source code change	 workaround is to create a new API temporarily.See the  Rerast Cookbook  COOKBOOK.md  for more examples.
google-rerast	Groups	See Cargo.toml
google-rerast	Contributing	See  CONTRIBUTING.md  CONTRIBUTING.md 
google-rerast	Code of conduct	This project defers to the  Rust code of conduct  Ifyou feel someone is not adhering to the code of conduct in relation to this project, please contactDavid Lattimore
google-rerast	Code of conduct	My email address is in Cargo.toml.
google-rerast	Disclaimer	This is not an official Google product
google-rerast	Disclaimer	It's released by Google only because the  original  authorhappens to work there.
google-restor	Restor	Restor is a user-friendly application to  mass  image macOS computers from asingle source
google-restor	Restor	It is an application intended to be run interactively on aYou can attach the machine-to-be-imaged via Thunderbolt or USB to the machinerunning Restor.Restor will cache an image once it has been downloaded for future use, and willvalidate the image via SHAOnly if the signature has changed, will the imagebe downloaded again.
google-restor	Example Configuration	Restor has two configurable features: ConfigURL and CustomImage.
google-restor	ConfigURL	Set the ConfigURL preference to point at a plist containing the images to besudo defaults write /Library/Preferences/com.google.corp.restor.plist ConfigURL ""The following format for the plist is required:Set the CustomImage preference to toggle the use of a local custom image.sudo defaults write /Library/Preferences/com.google.corp.restor.plist CustomImage -bool true
google-restor	10.13 and APFS Note	In order to restore an APFS 10.13 DMG to a machine, the host machine runningRestor must also be upgraded to High Sierra 10.Otherwise, you will receivean error when attempting to image the machine.
google-restor	Building from source	Building Restor from source is _not_ required for general usage
google-restor	Building from source	Please see the Releases  page to download apre-compiled version of Restor.
google-restor	Requirements	pod installFind your Team Identifer
google-restor	Requirements	Manually selecting the correct Team Identifier might be required if you have multiple developer certificates.Build with the following command, making sure to insert a valid Team Identifier from the previous step.If the build was successful the last line will contain the path to yourcompiled Restor.app.
google-restor	Contributing	Patches to this library are very much welcome
google-restor	Contributing	Please see the CONTRIBUTING 
google-resumable-assert	Resumable Assert	!  
google-resumable-assert	Assert replacement to continue execution in debugger	In any large app, it sometimes happens that some asserts are failing in code youdon't currently care about, and blocking the entire team from being able to runthe app until the issue is fixed is not the best workflow
google-resumable-assert	Assert replacement to continue execution in debugger	So we usually end upmoving the execution marker past the assert line in IDE or debugger, or evencomment the assert out, recompile and relaunch
google-resumable-assert	Assert replacement to continue execution in debugger	With Resumable Assert, you cansimply continue execution when an assertion fails in debugger, or even disableasserts that you are not interested in, so that those never bother you again._Disclaimer: be careful with that power though, since execution of potentiallybroken code may lead to unrecoverable errors in future._
google-resumable-assert	C/C++/Objective-C	First, include or import the header:instead of the standard ones: assert    NSAssert   Once RESUMABLE_ASSERT   variant is hit in debug mode, you can ignore it andcontinue execution, or disable it permanently, or even disable all assertspermanently with corresponding lldb commands when prompted.For example, the following assert somewhere in ViewController.viewDidLoadRESUMABLE_ASSERT   macro in C uses stdout to print the failure message bydefault
google-resumable-assert	C/C++/Objective-C	To change this behavior and use something else for logging, e.g
google-resumable-assert	C/C++/Objective-C	 NSLog   redefine the RESUMABLE_ASSERT_LOG   macro in C like so:
google-resumable-assert	#define RESUMABLE_ASSERT_LOG condition, format, ... 	  do {  } while  0 Similarly, you can define your own assert macro with a custom name:For Swift and other languages, we provide ResumableAssertDebugTrap   functionthat implements the core logic of resumable assert
google-resumable-assert	#define RESUMABLE_ASSERT_LOG condition, format, ... 	You can then implementa custom assert   function somewhere in a custom Diagnostics module whichwould use ResumableAssertDebugTrap   internally:import ResumableAssert // Import the module or use a bridging header and import ResumableAssert.h.public func assert   _ condition: @autoclosure    -> Bool,  _ message: @autoclosure    -> String = "",  file: StaticString = #file,  function: StaticString = #function,  line: UInt = #line  {
google-resumable-assert	#ifdef DEBUG	  if !condition   {  }}Then, you can use the new function as:
google-resumable-assert	Bazel	In your BUILD file, add ResumableAssert deps to corresponding targets:To use ResumableAssert for Objective-C, add the following to your Podfile:
google-rfmt	**rfmt**: A code formatter for R	The **rfmt*for Go, and  **clang-format**  forC/C++ 
google-rfmt	**rfmt**: A code formatter for R	It shares many of the objectives of Yihui Xie's  **formatR**  package, though with its more eleborate layout algorithm  documented in  this technical report  also included in the package documentation  and general approach to code formatting, it aims to produce more ''aesthetically appealing'' results.To use **rfmt**, you'll need to have a Python  v
google-rfmt	**rfmt**: A code formatter for R	2.7 or later  installation available
google-rfmt	**rfmt**: A code formatter for R	If this is not the case, you can download one yourself from  python.org The implementation of the formatter relies heavily on David Beazley's  ply package  a copy of which is supplied with the package.
google-riegeli	Riegeli	typically serialized protocol buffers
google-riegeli	Riegeli	It supports dense compression, fastdecoding, seeking, detection and optional skipping of data corruption, filteringof proto message fields for even faster decoding, and parallel encoding.See  documentation  doc/index.md .
google-riegeli	Status	Riegeli file format will only change in a backward compatible way  i.e
google-riegeli	Status	futurereaders will understand current files, but current readers might not understandfiles using future features .Riegeli C++ API might change in incompatible ways.
google-roboto	Setup	Create a clean directory for Roboto:Download the latest tarball release of HarfBuzz here  and extract it intothe **home*latest source from GitHub viagit clone  .Build and install HarfBuzz:manager , make sure eog is installed:
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	"Rowhammer" is a problem with recent DRAM modules in which repeatedlyaccessing a row of memory can cause bit flips in adjacent rows
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	 Thisrepo contains a program for testing for the rowhammer problem whichruns as a normal userland process.The rowhammer problem is described by:  Errors "   2014 
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	  2015 , on the blog of Google's Project Zero.How to run the test: either x86-32 or x86-64 , because it relies on x86's CLFLUSHinstruction for flushing cache lines.**Warning #1:*for protecting yourself, your property and data, and others from anyrisks caused by this code
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	 This code may cause unexpected andundesirable behavior to occur on your machine
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	 This code may notdetect the vulnerability on your machine.Be careful not to run this test on machines that contain importantdata
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	 On machines that are susceptible to the rowhammer problem, thistest could cause bit flips that crash the machine, or worse, cause bitflips in data that gets written back to disc.**Warning #2:*rowhammer problem, you may want to avoid using it as a multi-usersystem
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	 Bit flips caused by row hammering breach the CPU's memoryprotection
google-rowhammer-test	Program for testing for the DRAM "rowhammer" problem	 On a machine that is susceptible to the rowhammerproblem, one process can corrupt pages used by other processes or bythe kernel.
google-rowhammer-test	Mailing list	We invite people to post results from this test on the followingmailing list:A row hammering attempt involves picking two or more memory locationsand then accessing them, uncached, repeatedly
google-rowhammer-test	Mailing list	 If the locations arein different rows of DRAM but in the same bank, this will cause therows to be activated repeatedly
google-rowhammer-test	Mailing list	 It is these repeated row activationsthat can cause bit flips in adjacent rows.We use a probabilistic approach for picking memory locations: We cansimply pick random pairs of addresses, and retry repeatedly
google-rowhammer-test	Mailing list	 If amachine has 16 banks of DRAM, there should be a 1/16 chance that thetwo addresses chosen map to the same bank
google-rowhammer-test	Mailing list	  For example, somemachines that I've tested contain 2 DRAM modules with 8 banks each
google-rowhammer-test	Mailing list	This probabilistic approach means that the test doesn't need to knowhow the CPU's memory controller maps physical addresses to DRAM rowand column numbers, and it doesn't need to know the physical addressesof the memory it has allocated.The test allocates a large block of memory
google-rowhammer-test	Mailing list	 It repeatedly picks >2random addresses within the block, hammers them, and then checks theblock for bit flips
google-rowhammer-test	Mailing list	 If it sees a bit flip, it exits
google-rowhammer-test	Mailing list	 If it neversees a bit flip, it will run forever.
google-rpki-mgmt	limitations under the License.	== Summary ==Puppet configuration to support an RPKI publication server and associatedThis presumes there are multiple 'publication servers' ready to acceptrsync connections  rcynic connections  from the rest of the RPKI participants,and a single server storing the private key data away from public eyes
google-rpki-mgmt	limitations under the License.	Apuppet service contains configuration, and there are one or more syslogThe rpki-mgmt puppet module is automatically pulled from GitHub once a day.== RPKI setup ==The RPKI services are managed by this configuration/system are offered usingthe Dragon Research Labs reference platform
google-rpki-mgmt	limitations under the License.	This puppet configurationes doesnot  yet  install and manage the RPKI.net software
google-rpki-mgmt	limitations under the License.	It must be installed priorto deploying this puppet configuration
google-rpki-mgmt	limitations under the License.	A 'get going in 10 minutes' script isavailable here:The basic rpkid services, data locations and processes are:servers, run a script from cron to wrangle the publication data out to allpublication servers and move the rsyncd configuration to keep track of 'HEAD'for this data.Rsyncd will be managed by inetd/xinetd, so each client will see a clean andunchanging dataset to retrieve
google-rpki-mgmt	limitations under the License.	Rotation of that data off the disk will happenin a timely fashion as well.== Puppet config ==The basic systems configured in the provided site.pp.dist example are:publish-1.example.comAdditional publication or log servers can easily be added to the appropriatenode definitions in site.pp.dist.Several global variables that need to be defined:  $pupper_server  : puppet server to be configure on all nodesThere are 2 optional globals:  $ssh_client_range : an IP range used to restrict ssh access to all nodes
google-rpki-mgmt	limitations under the License.	 $ssh_unrestricted_port: a port to be allowed for any IP  e.g
google-rpki-mgmt	limitations under the License.	a secondaryAt the bottom of the site.pp.dist is a common_config class which can be usedto add any additional puppet config to be included for all nodes
google-rpki-mgmt	limitations under the License.	e.g.adding users and or additional packages.== Configuration Script ==A shell script, generate-rpki-mgmt-config.sh, is included to help in creatingpuppet configuration based on user input.Here is an example run of the script which sets upfor the github repo and performan an initial pull of the repo.You entered  /var/lib/rpki-mgmt 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?You entered  master 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?You entered  rpki-mgmt 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?: 10.11.12.0/24You entered  10.11.12.0/24 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?: puppet.example.comYou entered  puppet.example.com 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?: rpki-ca.example.comYou entered  rpki-ca.example.com 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?  enter one item per line; blank line to end, q to quit
google-rpki-mgmt	limitations under the License.	 : log-1.us.example.com: log-2.us.example.comYou entered  log-1.us.example.com log-2.us.example.com 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?  enter one item per line; blank line to end, q to quit
google-rpki-mgmt	limitations under the License.	 : rpki-pub-1.us.example.com: rpki-pub-2.us.example.comYou entered  rpki-pub-1.us.example.com rpki-pub-2.us.example.com 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?: Example RPKI Publication Service  US You entered  Example RPKI Publication Service  US  
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?Base directory for rpki-mgmt git repo : /var/lib/rpki-mgmtGit branch to trackUNIX Group for rpki-mgmt directoryIP range for ssh access to all servers: 10.11.12.0/24Host name of pupper serverHost name of RPKI CA/RP serverHost name s  of syslog-ng server s    : log-1.us.example.com log-2.us.example.comHost name s  of RPKI publication server s : rpki-pub-1.us.example.com rpki-pub-2.us.example.comrsync banner for publication server s : Example RPKI Publication Service  US Is this correct  Y/n ?remote: Counting objects: 736, done.remote: Compressing objects: 100%  53/53 , done.remote: Total 736  delta 20 , reused 0  delta 0 , pack-reused 677Receiving objects: 100%  736/736 , 101.24 KiB, done.Resolving deltas: 100%  356/356 , done
google-rpki-mgmt	limitations under the License.	 or: euYou entered  eu 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?You entered   
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?You entered   
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?  enter one item per line; blank line to end, q to quit
google-rpki-mgmt	limitations under the License.	 : log-1.eu.example.com: log-2.eu.example.comYou entered  log-1.eu.example.com log-2.eu.example.com 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?  enter one item per line; blank line to end, q to quit
google-rpki-mgmt	limitations under the License.	 : rpki-pub-1.eu.example.com: rpki-pub-2.eu.example.comYou entered  rpki-pub-1.eu.example.com rpki-pub-2.eu.example.com 
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?: Example RPKI Publication Service  EU You entered  Example RPKI Publication Service  EU  
google-rpki-mgmt	limitations under the License.	Is this correct  Y/n ?Host name of pupper serverHost name of RPKI CA/RP serverHost name s  of syslog-ng server s    : log-1.eu.example.com log-2.eu.example.comHost name s  of RPKI publication server s : rpki-pub-1.eu.example.com rpki-pub-2.eu.example.comrsync banner for publication server s : Example RPKI Publication Service  EU Is this correct  Y/n ?  or
google-rspirv	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.-------------The current implementation supports SPIR-V 1.3  Revision 1 .Multiple crates are published from this project:| :------------: | :-------: | :------: || rspirv| spirv\_headers |  ! Crate  img-crate-headers   crate-headers  |  ! Documentation  img-doc-headers   doc-headers  |In total rspirv APIs contains:of the source code using Cargo  build scripts  codegen .Please see the links to docs.rs for detailed documentation.------I plan to implement several functionalities:The SPIR-V binary module parser is almost feature complete; the only feature that I am aware of  missing is 64-bit selectors in OpSwitch.-----This project uses associated constants, which became available in the stable channelsince  1.20  rust-1.20 
google-rspirv	Disclaimer	So to compile with a compiler from the stable channel,please make sure that the version is >= 1.--------Building a SPIR-V module, assembling it, parsing it, and then disassembling it:extern crate rspirv;extern crate spirv_headers as spirv;use rspirv::binary::Assemble;use rspirv::binary::Disassemble;fn main   {-------------This project is licensed under the  Apache 2  LICENSE  license
google-rspirv	Disclaimer	Please see CONTRIBUTING  CONTRIBUTING.md  before contributing.
google-rspirv	Authors	This project is initialized and mainly developed by Lei Zhang  @antiagainst  me  
google-rspirv	Authors	img-crate-rspirv :  img-doc-rspirv :  crate-rspirv :  doc-rspirv :  img-crate-headers :  img-doc-headers :  crate-headers :  doc-headers :  spirv :  vulkan :  opengl :  opencl :  me :  json-grammar :  spirv-tools :  doc-mr :  doc-builder :  doc-parser :  doc-grammar :  doc-binary :  rust-1.20 : 
google-rtc-video-quality	Measuring Video Codec Performance	_This is not an official Google product._! Example graph of SSIM-Y over multiple bitrates  example-ssim-y.png ! Example graph of per-frame SSIM-Y inside a single clip  example-frame-ssim-y.png This project contains a couple of scripts that can be used to generate qualitymetrics and graphs for different video codecs, encoders and settings.Quality metrics can be generated for .y4m as well as .yuv raw I420 videofiles
google-rtc-video-quality	Measuring Video Codec Performance	.yuv files require the special format clip.WIDTH_HEIGHT.yuv:FPS sincewidth, height and fps metadata are not available in this containerless format.A set of industry-standard clips that can be used are available at Xiph.org Video Test Media  aka
google-rtc-video-quality	Measuring Video Codec Performance	"derf's
google-rtc-video-quality	Dependencies	To build pinned versions of dependencies, comparison tools and libvpx run:This requires git and build dependencies for libvpx that are not listed here.See build instructions for libvpx for build dependencies.To use .y4m files as input  instead of .yuv , mediainfo and ffmpeg areboth required  to extract metadata and convert to .yuv 
google-rtc-video-quality	Dependencies	They can either bebuilt and installed from source or likely by running  or similar depending ondistribution :
google-rtc-video-quality	Encoders	After building dependencies with ./setup.sh libvpx encoders are available.Additional encoders have to be fetched and built by using their correspondingsetup scripts.libvpx-rt:vp8 and libvpx-rt:vp9 use libvpx encoders with settings as closeas possible to settings used by Chromium's  WebRTC _TODO pbos : Add reasonable non-realtime settings for aom-good._
google-rtc-video-quality	libyami	To build pinned versions of libyami, VA-API and required utils run:Using libyami encoders  yami:vp8, yami:vp9  requires VA-API hardwareencoding support that's at least available on newer Intel chipsets
google-rtc-video-quality	libyami	Hardwareencoding support can be probed for with vainfo.
google-rtc-video-quality	aomedia	To build pinned versions of  aomedia  utils run:This permits encoding and evaluating quality for the AV1 video codec by runningthe encoder pair aom-good:av1
google-rtc-video-quality	aomedia	This runs a runs aomenc with --goodconfigured as a 2-pass non-realtime encoding
google-rtc-video-quality	aomedia	This is significantly slower thanrealtime targets but provides better quality._There's currently no realtime target for AV1 encoding as the codec isn'tconsidered realtime ready at the point of writing
google-rtc-video-quality	aomedia	When it is, aom-rt shouldbe added and runs could then be reasonably compared to other realtime encodersand codecs._
google-rtc-video-quality	OpenH264	To build pinned versions of OpenH264, run:OpenH264 is a single-pass encoder used in WebRTC both in Chrome and Firefox.This adds the openh264:h264 which runs h264enc with settings that areintended to be close to WebRTC's implementation.
google-rtc-video-quality	Generating Data	To generate graph data  after building and installing dependencies , see:Example usage:This will generate libvpx-rt.txt with an array of Python dictionaries withmetrics used later to build graphs
google-rtc-video-quality	Generating Data	This part takes a long time  may take hoursor even days depending on clips, encoders and configurations  as multiple clipsare encoded using various settings
google-rtc-video-quality	Generating Data	Make sure to back up this file after runningor risk running the whole thing all over again.To preserve encoded files, supply the --encoded-file-dir argument.
google-rtc-video-quality	VMAF	Graph data can be optionally supplemented with VMAF  metrics
google-rtc-video-quality	VMAF	To build a pinned version ofVMAF, run:This requires several additional dependencies that are not listed here.See build instructions for VMAF for build dependencies.To enable the creation of VMAF metrics, supply the generate_data.py.
google-rtc-video-quality	System Binaries	To use system versions of binaries  either installed or otherwise available inyour PATH variable , supply --use-system-path to generate_data.py
google-rtc-video-quality	System Binaries	Thiswill fall back to locally-compiled binaries  but warn  if the encoder commandsare not available in PATH.
google-rtc-video-quality	Dumping Encoder Commands	For debugging and reproducing  if you're working on encoders  it can be usefulto know which encoder command produced a certain data point.To dump the commands used to generate data instead of running them, supply--dump-commands to generate_data.py.
google-rtc-video-quality	Generating Graphs	To generate graphs from existing graph data run:This will generate several graph image files under OUT_DIR from data filesgenerated using generate_data.py, where each clip and temporal/spatialconfiguration are grouped together to generate graphs comparing differentencoders and layer performances for separate SSIM, AvgPSNR and GlbPSNRmetrics
google-rtc-video-quality	Generating Graphs	Multiple encoders and codecs are placed in the same graphs to enable acomparison between them.The script also generates graphs for encode time used
google-rtc-video-quality	Generating Graphs	For speed tests it'srecommended to use a SSD or similar, along with a single worker instance tominimize the impact that competing processes and disk/network drive performancehas on time spent encoding._The scripts make heavy use of temporary filespace
google-rtc-video-quality	Generating Graphs	Every worker instance usesdisk space rougly equal to a few copies of the original raw video file that isusually huge to begin with
google-rtc-video-quality	Generating Graphs	To solve or mitigate issues where disk space runsout during graph-data generation, either reduce the amount of workers used with--workers or use another temporary directory  with more space available  bychanging the TMPDIR environment variable._
google-rtc-video-quality	Adding or Updating Encoder Implementations	Adding support for additional encoders are encouraged
google-rtc-video-quality	Adding or Updating Encoder Implementations	This requires adding anentry under generate_data.py which handles the new encoder, optionallyincluding support for spatial/temporal configurations.Any improvements upstream to encoder implementations have to be pulled in byupdating pinned revision hashes in corresponding setup/build scripts.
google-rttcp	rttcp: A Tool To Debug The Performance of a Network Link Using TCP	Copyright 2017 Google Inc.This is not an official Google product.
google-rttcp	Introduction	rttcp is a tool to analyze the performance of a network link from a packettrace containing TCP traffic.The main use case is to provide some characterization of the performanceof a link using a tcp performance test  speedtest 
google-rttcp	Introduction	Assume you have anetwork whose performance you want to debug  e.g
google-rttcp	Introduction	it includes a radiolink 
google-rttcp	Introduction	You get a client to access a speedtest service  e.g
google-rttcp	Introduction	the Google Fiber Speedtest  This isvery handy, as any device with a browser can do
google-rttcp	Introduction	You run your HTMLspeedtest, and get some numbers
google-rttcp	Introduction	You also capture the trace at anypoint in the path between your device and the speedtest server.While measuring the performance of a connection by using tcp trafficpresents some issues  it depends on the exact parameters of tcp, likecongestion control, etc
google-rttcp	Introduction	, we can get an idea of how the link isbehaving by checking how the packets go back and forth.
google-rttcp	Discussion	rttcp provides 2 analysis modes, namely "flow" and "packet".the "flow" mode provides a per-flow performance analysis
google-rttcp	Discussion	Inparticular, it provides 4 graphs:the "packet" mode provides an analysis of per-packet RTT data
google-rttcp	Discussion	Wemeasure a TCP segment RTT as the difference between the timestamp ofthe TCP segment, and the timestamp of the first ACK packet that ACKsthe highest SEQ number of the TCP segment.The idea is that the first ACK that acknowledges a full segment isthe first instant where we can be sure that the segment has beenreceived
google-rttcp	Discussion	We remove any duplicate data segments to avoid biasing thestatistics with the latency of lost packets.This mode, in fact, measures the time for  a  the  data  segment toreach the receiver,  b  the time for the receiver tcp stack to receiveit and generate an ACK, and  c  the time for the  pure  ACK to reachthe capturing point
google-rttcp	Discussion	This provides a nice measurement of theround-trip time performance of the download path from the capturingIn particular, the "packet" mode provides 4 graphs  also known as"deltas" :  function of the timestamp of the TCP segment
google-rttcp	Discussion	 delta2: delta2 is similar to delta1, but instead of using the ACK  and SEQ numbers, it uses the TSval and TSecr of the   tcp timestamp option   delta3: delta3 tries to calculate the one-way latency of traffic  by estimating the offset and HZ of the sender
google-rttcp	Discussion	 delta4: delta4 measures the inter-packet latency in tcp trains
google-rttcp	Discussion	 It defines a train as a set of packets separated no more than a  constant  we use 2 msec for this, as this is the hystart_ack_delta  constant in linux/net/ipv4/tcp_cubic.c .delta1 and delta2 both measure the time for a segment to go from thecapture point to the client and back
google-rttcp	Discussion	delta3 measures the time fromthe client to the capture point.As the data segments can flow in both directions, we provide forseparation of the forward and reverse paths, which are typicallydifferent
google-rttcp	Discussion	We also provide a boxplot of the distribution of thevalues, plus the basic statistics.
google-rttcp	Operation	rttcp.py is a vanilla python file
google-rttcp	Operation	It uses tshark  a CLI version of wireshark  to print some selected fields in thepacket trace
google-rttcp	Operation	It then uses a combination of numpy, pandas, and matplotlibto analyze and graph the results.To get to know the options of the tool, run:usage: rttcp.py  -h   -d   --quiet   -v   --tshark TSHARK   -i INPUT-FILE rttcp flow aggregator.positional arguments:  {help,analyze,plot}optional arguments:  -h, --help  -d, --debug  --quiet  -v, --version  --tshark TSHARK  -i INPUT-FILE, --input INPUT-FILE  -o OUTPUT-FILE, --output OUTPUT-FILE  --type ANALYSIS_TYPE  set the analysis type  flow, packet   --src-reverse SRC-REVERSETo run the "flow" analysis:Figure 2 shows an example of "flow" analysis result.To run the "packet" analysis:Figure 3 shows an example of "packet" analysis result.
google-rttcp	References	but oriented to analyzing a trace composed of multiple connections,instead of performing per-connection analysis.
google-rust-shell	Rust shell 	This is not an officially supported Google productRust shell is a helper library for std::process::Command to write shellscript like tasks in rust
google-rust-shell	Rust shell 	The library only works with unix-like operation
google-rust-shell	Run command	run! macro creates a ShellCommand instance which you can run by run  
google-rust-shell	macro_use  extern crate shell;	use std::process::Stdio;use std::io::Read;// Access std::process::Command.let mut shell_command = cmd! "echo OK" ;  let mut command = &mut shell_command.command;  command.stdout Stdio::piped   ;// Access std::process::Child.let shell_child = shell_command.spawn  .unwrap  ;  let mut lock = shell_child.0.write  .unwrap  ;  let mut child = &mut lock.as_mut  .unwrap  .child;  let mut str = String::new  ;  child.stdout.as_mut  .unwrap  .read_to_string &mut str ;shell_child.wait  .unwrap  ;
google-rust-shell	ShellResult	The return value of ShellCommand#run   is ShellResult which is Ok _ only when the command successfully runs and its execution code is 0, so youcan use ? operator to check if the command successfully exits or not.
google-rust-shell	Output string	ShellCommand has a shorthand to obtain stdout as UTF8 string.
google-rust-shell	Spawn	ShellCommand has spawn   method which runs the command asynchronously andreturns ShellChild.
google-rust-shell	Thread	If you would like to run a sequence of commands asynchronously,shell::spawn creates a thread as well as std::thread::spawn but itreturns ShellHandle wrapping std::thread::JoinHandle.ShellHandle#signal   is used to send a signal to processes running on thethread
google-rust-shell	Thread	 It also stops launching a new process by ShellComamnd::run   onthat thread.
google-rust-shell	Signal handling	trap_signal_and_wait_children   starts watching SIGINT and SIGTERM, andwaits all child processes before exiting the process when receiving thesesignals
google-rust-shell	Signal handling	The function needs to be called before launching any new thread.std::process::Child
google-rust-shell	Signal handling	Both underlaying objects are accessible via public
google-rust-shell	License	Apatch 2 License
google-rustcxx	rustcxx: Using C++ from Rust made easy	rustcxx is a tool allowing C++ to be used from a Rust project easily.It works by allowing snippets of C++ to be included within a Rust function,and vice-versa.
google-rustcxx	#! plugin rustcxx_plugin  	cxx_inline! {let x: u32 = 5;let square = unsafe { cxx!  x: u32  -> u32 {}  };See  the provided example  example/main.rs  for more details.
google-rustcxx	Usage	rustcxx requires a nightly version of the Rust compiler.Add to your toml package build = "build.rs" dependencies.rustcxx_plugin git = ""branch = "unstable" build-dependencies.rustcxx_codegen git = ""branch = "unstable"and create a build.rs file containing the following:extern crate rustcxx_codegen;fn main   {
google-rustcxx	Authors	The main author is Paul Liétar.
google-rustcxx	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-rustcxx	Contributions	Please see CONTRIBUTING.md  CONTRIBUTING.md  for more details.
google-rustcxx	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.
google-rysim	Directories	Contains sequential C++ implementation.Contains sequential and Actor based Erlang implementations.Contains sequential, thread based, and Actor based Javapython/Contains utility scripts for running the experiments.Various bits of code used from other sources by this project.
google-s2geometry	S2 Geometry Library	  
google-s2geometry	Overview	This is a package for manipulating geometric shapes
google-s2geometry	Overview	Unlike many geometrylibraries, S2 is primarily designed to work with _spherical geometry_, i.e.,shapes drawn on a sphere rather than on a planar 2D map
google-s2geometry	Overview	This makes itespecially suitable for working with geographic data.If you want to learn more about the library, start by reading the overview  and  quick startdocument  then read theintroduction to the  basic types S2 documentation can be found on  s2geometry.io 
google-s2geometry	Requirements for End Users	On Ubuntu, all of these can be installed via apt-get:On macOS, use  MacPorts  or Homebrew   For MacPorts:1.8.0  unpack,and substituteThorough testing has only been done on Ubuntu 14.04.3 and macOS 10.
google-s2geometry	Build and Install	You may either download the source as a ZIP archive, or  clone the gitrepository 
google-s2geometry	Via ZIP archive	Download  ZIP file From the appropriate directory depending on how you got the source:Disable building of shared libraries with -DBUILD_SHARED_LIBS=OFF.
google-s2geometry	Python	If you want the Python interface, you will also need:Expect to see some warnings if you build with swig 2.
google-s2geometry	Disclaimer	This is not an official Google product.
google-safe-html-types	Safe HTML Types for Java	This is the Java version of the  safe HTML types library which allows safe-by-construction of web applications by introducingtypes with safe contracts for snippets of content in web languages.See  release-checklist.md  for instructions on how to push to github andmaven central.
google-safebrowsing	Reference Implementation for the Usage of Google Safe Browsing APIs  v4 	The sbserver program creates a proxy local server to check URLs and a URLredirector to redirect users to a warning page for unsafe URLs
google-safebrowsing	Reference Implementation for the Usage of Google Safe Browsing APIs  v4 	The sblookupprogram is a command line service that can also be used to check URLs.This **README.md*safebrowsing Go package
google-safebrowsing	Reference Implementation for the Usage of Google Safe Browsing APIs  v4 	It can be used out-of-the-box
google-safebrowsing	Reference Implementation for the Usage of Google Safe Browsing APIs  v4 	The GoDoc and APIdocumentation provide more details on fine tuning the parameters if desired.
google-safebrowsing	Setup	To use the safebrowsing Go package you must obtain an *API key Google Developer Console  For moreinformation, see the *Get Started
google-safebrowsing	How to Build	To download and install from the source, run the following command:Add that to your $PATH for convenience:The sbserver server binary runs a Safe Browsing API lookup proxy that allowsusers to check URLs via a simple JSON API
google-safebrowsing	How to Build	The server also runs an URLredirector to show an interstitial for anything marked unsafe
google-safebrowsing	How to Build	The interstitialshows warnings recommended by Safe Browsing.Once the Go environment is setup, run the following command with your API		go get github.com/google/safebrowsing/cmd/sbserver	sbserver -apikey $APIKEY		With the default settings this will start a local server at **127.0.0.1:8080**
google-safebrowsing	How to Build	Load the proxy server redirector in any web browser
google-safebrowsing	How to Build	Try these URLs:		127.0.0.1:8080/r?url=	127.0.0.1:8080/r?url=	127.0.0.1:8080/r?url=	127.0.0.1:8080/r?url=	To use the local proxy server to check a URL, send a POST request with thefollowing JSON body:	json	{		"threatInfo": {		}	}		Refer to the  Google Safe Browsing APIs  v4  
google-safebrowsing	Command-Line Lookup	The sblookup command-line binary is another example of how the Go SafeBrowsing library can be used to protect users from unsafe URLs
google-safebrowsing	Command-Line Lookup	Thiscommand-line tool filters unsafe URLs piped via STDIN
google-safebrowsing	Command-Line Lookup	Example usage:To perform an end-to-end test on the package with the Safe Browsing backend,run the following command:
google-samba-documents-provider	Overview	This is an Android app that extends the built in File Manager to support connecting to SMBfile shares.This app is built on top of Samba 4.5.
google-samba-documents-provider	Prerequisite	Android SDK and NDK r15b or above are required to build this app
google-samba-documents-provider	Prerequisite	Android Studio is highlyThis build guide is only tested on Ubuntu
google-samba-documents-provider	Prerequisite	Changes to make it build on other platforms are
google-samba-documents-provider	Build Steps	Download and unarchive Samba 4.5.1  source code  samba-source .Change directory to the root of Samba source code.Create a git repository.Run git apply /sambapatch.diff.Modify configure.sh to change $NDK to point to your NDK folder.Uncomment corresponding flags in configure.sh to compile for different architecture.Run compile.sh to compile libsmbclient.so.Run install.sh /app/src/main/jniLibs/.Change directory to SambaDocumentsProvider source code.Run mv app/src/main/jniLibs//includes app/src/main/cpp/samba_includes.Change directory to the root of Samba source code and run make distclean.Repeat step 6-12 for all desired ABI's.Make sure to change app's build.gradle to include only ABI's that Samba was builtCompile SambaDocumentsProvider.
google-samba-documents-provider	Discussion	Please go to our  Google group  discussion  to discuss any issues
google-samba-documents-provider	Discussion	samba-source :  discussion : 
google-sanitizers	sanitizers	This project is the home for Sanitizers: AddressSanitizer, MemorySanitizer, ThreadSanitizer, LeakSanitizer
google-sanitizers	sanitizers	The actual code resides in the  LLVM  repository.Here we keep extended  documentation  ../../wiki ,  bugs  ../../issues  and some helper code
google-sanitizers	sanitizers	Wiki documentation for our tools:
google-santa-tracker-android	About	 Google Santa Tracker app for Android  play-store  is an educational and entertaining tradition that brings joy to millions of children  and children at heart  across the world over the December holiday period
google-santa-tracker-android	About	The app is a companion to the  Google Santa Tracker  santa-web  website   repository here  showcasing unique platform capabilities like Android Wear watchfaces, device notifications and more.! Analytics 
google-santa-tracker-android	Features	First up, Santa Tracker is powered by  Firebase  firebase , so you'll need to enable iton your Google account over at the  Firebase console  fire-console 
google-santa-tracker-android	Features	Once you're in theconsole, follow these steps:Alternatively, import the source code into Android Studio  File, Import Project .Note: You'll need Android SDK version 24, build tools 24.0.0, and the Android Support Library tocompile the project
google-santa-tracker-android	Features	If you're unsure about this, use Android Studio and tick the appropriate boxesin the SDK Manager.
google-santa-tracker-android	License	All image and audio files  including *.png, *.jpg, *.svg, *.mp3, *.wavand *.ogg  are licensed under the CC-BY-NC license
google-santa-tracker-android	License	All other files arelicensed under the Apache 2 license
google-santa-tracker-android	License	See the LICENSE file for details
google-santa-tracker-android	License	play-store :  santa-web :  firebase :  fire-console : 
google-santa-tracker-web	Changes	In the 2016 version of Santa Tracker, some featured changes include-Santa Tracker supports Chrome, Firefox, and Edge; it also supports IE11, Safari 9+ and Chromium-based browsers  Opera, Samsung etc  at m44 or above.
google-santa-tracker-web	Prerequisites	You'll need npm, bower  use npm install -g bower if it's missing  and Java available on your system.
google-santa-tracker-web	Setup	Clone project, then from within the repo:
google-santa-tracker-web	Build and run	Build and run with gulp serve.This will serve from the root directory and recompile JavaScript or CSS on watched changes.The first build might take some time  ~10-20m , as it compiles every scene.You can load scenes  even while locked  via their ID, e.g
google-santa-tracker-web	Build and run	at /#codeboogie.Alternatively, unlock houses  in dev  by calling santaApp.unlockAllHouses  .If you'd like to serve another way, then you can build all development dependencies with gulp.
google-santa-tracker-web	Serve production build	First, build for prod and set a baseurl for static assets:Serve prod:Separately, serve the static resources:Open 
google-santa-tracker-web	Release	Use gulp dist --pretty to build.This performs additional steps, such as vulcanizing code and internationalization.Serve from ./dist_pretty.
google-santa-tracker-web	Scenes	Santa Tracker is comprised shared code along with many individual scenes: e.g., village, tracker etc.
google-santa-tracker-web	Relevant Paths	Scenes are referenced in a few locations-  This is also used as the reference for the HTML fanout, creating a HTML file per scene, per language
google-santa-tracker-web	Relevant Paths	 a 475x282 1x image: images/scenes/sceneName.pngThere are two optional locations-All image and audio files  including *.png, *.jpg, *.svg, *.mp3, *.wav and *.ogg  are licensed under the CC-BY-NC license
google-santa-tracker-web	Relevant Paths	All other files are licensed under the Apache 2 license
google-santa-tracker-web	Relevant Paths	See the LICENSE file for details.
google-santa	For other build/install/run options, run rake without any arguments	rake build:debugNote: the Xcode project is setup to use any installed "Mac Developer" certificateand for security-reasons parts of Santa will not operate properly if not signed.For more details on building see the  building.md  document.Building with CMake
google-santa	General steps	Install Xcode and the command line toolsInstall CMake using homebrewClone the santa source code repositorySet the signing keyCreate a build folder and configure the projectRun makegit clone mkdir buildcd buildexport CODESIGN_IDENTITY=XXXcmake ../santamake -j sysctl -n hw.ncpuThe CODESIGN_IDENTITY parameter can also be passed directly to CMake: cmake -DCODESIGN_IDENTITY=XXX /path/to/source/codeKext SigningKernel extensions on macOS 10.9 and later must be signed using an Apple-providedDeveloper ID certificate with a kernel extension flag
google-santa	General steps	Without it, the only wayto load an extension is to enable kext-dev-mode or disable SIP, depending on theOS version.There are two possible solutions for this, for distribution purposes:1  Use a  pre-built, pre-signed version of the kext that we supply
google-santa	General steps	Each time changes are made to the kext code we willupdate the pre-built version that you can make use of
google-santa	General steps	This doesn't prevent youfrom making changes to the non-kext parts of Santa and distributing those.If you make changes to the kext and make a pull request, we can merge them inand distribute a new version of the pre-signed kext.2  Apply for your own  kext signing certificate Apple will only grant this for broad distribution within an organization, theywon't issue them just for testing purposes.============Patches to this project are very much welcome
google-santa	General steps	Please see the  CONTRIBUTING ==========This is **not*
google-scene_lab	Overview	Scene Lab is a library that allows game developers who are using Fun PropulsionLabs technologies for their games to lay out objects in the game world andchange their properties, all within the game itself.Go to our  landing page    to browse our documentation and see some examples.
google-scene_lab	Features	This initial release of Scene Lab is focused on letting you perform certain coretasks needed for editing a game world:
google-scene_lab	Downloading	The library is written in portable C++ and has been tested on the followingsource using:  git clone --recursive 
google-scene_lab	Dependencies	Scene Lab depends on the following libraries:In order to use Scene Lab to lay out your scene, you must use CORGI andits included  component library    for your in-game objects
google-scene_lab	Dependencies	Your objects shoulduse the following components:EntityFactory, which uses a prototype-based system for instantiating entities,and ensure that you have included the EditOptionsComponent and associateddata in your code.Additionally, if you have any custom components, you must implement theirExportRawData functions if you want the user to be able to edit an object'sproperties from those components.
google-scene_lab	Notes	For application on Google Play that integrate this tool, usage is tracked
google-scene_lab	Notes	 Thistracking is done automatically using the embedded version string kSceneLabVersionString , and helps us continue to optimize it
google-scene_lab	Notes	 Aside fromconsuming a few extra bytes in your application binary, it shouldn't affect yourapplication at all
google-scene_lab	Notes	 We use this information to let us know if Scene Lab isuseful and if we should continue to invest in it
google-scene_lab	Notes	Since this is open source, youare free to remove the version string but we would appreciate if you would leaveit in.
google-scene_lab	Contributing	To contribute to this project see  CONTRIBUTING   
google-scene_lab	Contributing	  Breadboard :   CONTRIBUTING :   FlatBuffers :   FPLBase :   landing page :   OS X :   Scene Lab Issues Tracker :   Windows : 
google-schemaorg-java	Schema.org Client Library for Java	The Schema.org Client Library for Java is a library for creating  schema.org  entities.The entities can be easily serialized and deserialized with  JSON-LD format by using the JSON-LD serializer in the library.Note that it is based on a 2016 release snapshot of Schema.org, and is not currently actively being developed
google-schemaorg-java	Schema.org Client Library for Java	If you are interested to see updates  e.g
google-schemaorg-java	Schema.org Client Library for Java	for Schema.org 3.4 or later , please comment in  Issue #7 
google-schemaorg-java	Library Highlights	The library has the following highlights:
google-schemaorg-java	Limitations	Below is a simple example of creating schema.org  Thing object, serialize it into JSON-LD format and deserialize JSON-LD back to a Thing object.Some important usage recommendations are given below:
google-schemaorg-java	Package Structure	The Java Classes are organized into the following pakcages:
google-schemaorg-java	Builders	In the Java library, every schema.org type has a corresponding Java interfacewith the same name as the schema.org type
google-schemaorg-java	Builders	The Java interfaces are designed withthe  Builder Pattern  Developersdon't need to know any details about implementation of these interfaces, becauseall the operations on the object will be performed through the interface.CoreFactory and GoogFactory classes provide static factory methods thatreturn a Builder object for a specific schema.org type
google-schemaorg-java	Builders	In the builderinterfaces, there are add PropertyName  methods for each property which couldbe set in the corresponding schema.org type
google-schemaorg-java	Builders	Multiple values can be added to aproperty as documented by schema.org
google-schemaorg-java	Builders	The build   method should be called tocreate an immutable concrete instance of that type
google-schemaorg-java	Builders	A get PropertyName Listmethod is defined for each property
google-schemaorg-java	Builders	The get PropertyName List method willreturn an  ImmutableList containing all the values for the specific property
google-schemaorg-java	Builders	In order to add any customproperty into any schema.org type, the addProperty and getProperty methodsare defined in the interface for each schema.org type.
google-schemaorg-java	DataType	 DataType  is defined in the packagecom.google.schemaorg.core.datatype
google-schemaorg-java	DataType	To create a primitive DataType object, thestatic method of   in each type should be used.For example:
google-schemaorg-java	Enumeration	Subtypes of  Enumeration  are handled slightlydifferently
google-schemaorg-java	Enumeration	For each Enumeration subtype in schema.org, a Java interface iscreated which provides accessor methods for the properties of that type
google-schemaorg-java	Enumeration	Thename of the interface is the same name as the schema.org type
google-schemaorg-java	Enumeration	In addition, aJava Enum class is also created to hold the enum values of that schema.orgEnumeration type
google-schemaorg-java	Enumeration	The name of the Enum class is type name with Enum appended.For example,  ActionStatusType  is a subtypeof  Enumeration  in schema.org
google-schemaorg-java	Enumeration	It has thefollowing values:enum values:All the schema.org type builders also support setting the values for JSON-LDkeywords
google-schemaorg-java	Enumeration	Following methods are defined in the builder interface:
google-schemaorg-java	Serialization	class also has an overloaded convenience method that takes the builder classitself as shown below:serialize List objects .
google-schemaorg-java	Deserialization	JsonLdSerializer serializer = new JsonLdSerializer true /String jsonLd =try {  }} catch  JsonLdSyntaxException e  {  // Errors related to JSON-LD format and schema.org terms in JSON-LD} catch  JsonIOException e  {  // Errors related to JSON formatLimitations of current JSON-LD deserialization are given below:Future versions of this client library may remove these limitations.
google-schemaorg-java	Dependencies	This library depends on following public libraries:repositories {dependencies {
google-schism	Schism	Schism is an experimental self-hosting compiler from a subset of R6RS Scheme toThis is not an officially supported Google product.Development so far has focused on features necessary forself-hosting
google-schism	Schism	The compiler itself is written in, and compiles, a verysmall subset of Scheme
google-schism	Schism	Now that self-hosting has been achieved,development can shift towards supporting a more complete subset ofScheme
google-schism	Schism	Just to be clear, by subset we mean that all programssupported by Schism are also legal R6RS Scheme programs and they willhave the same behavior when run under Schism or an R6RS-compliantBesides just being fun, one of the goals of this project is to explore differentways to use WebAssembly
google-schism	Schism	This includes implementing garbage collection, possiblyusing the WebAssembly GC proposal, dynamic linking and code generation, etc.Chez Scheme was used to bootstrap, but development no longer relies on anexisting Scheme implementation and can instead run purely based on snapshotschecked into the repository.As mentioned, the goal has been to prioritize features needed for selfhosting
google-schism	Schism	Here are some of the current restrictions:See the docs directory for more information about how variousfeatures are implemented.
google-schism	Current Status and Next Steps	The compiler is self-hosting! Now the goal is to make a more completelanguage
google-schism	Current Status and Next Steps	Some of the big missing features are:it easier to implement them.
google-schism	Testing	We currently use a very simple testing protocol
google-schism	Testing	The do-test
google-schism	Testing	This function can do whatever it wants, but it must return a valueother than #f to pass.To run all the tests, do ./run-tests.sh.
google-schism	The Playground	This repository includes a very simple playground.html, which gives alightweight way to play around with the compiler
google-schism	The Playground	The best way to use it is tostart up a web server  python -m SimpleHTTPServer should work  and point yourbrowser at the page
google-schism	The Playground	Be warned, there is almost no error checking right now, sostrange things can happen.
google-schism	Development	The compiler code all lives in schism/compiler.ss
google-schism	Development	There is a small JavaScriptruntime in rt/rt.mjs
google-schism	Development	The goal is to keep as much code as possible in Scheme,but the runtime is needed to interact with the rest of the world
google-schism	Development	In the future,the runtime should also handle dynamic module loading.We have a staged build system
google-schism	Development	Stage0 is the compiler snapshot, stored inschism-stage0.wasm
google-schism	Development	Stage1 is generated by compiling schism/compiler.ss withthe Stage0 compiler, Stage2 by compiling with the Stage1 compiler, and Stage3 bycompiling with the Stage2 compiler
google-schism	Development	Stage3 should be equal to the Stage2compiler, and currently we only generate it to verify this is the case.To add a new feature, the usual flow is to start by adding a small test thatuses it
google-schism	Development	This test will probably fail at least the Stage0 compiler
google-schism	Development	Once thefeature is implemented, then the Stage1 and Stage2 compilers should pass thetest
google-schism	Development	Note that you cannot use the new feature in the compiler until it works instageOnce this happens, you should make a new snapshot using mksnapshot.sh.
google-science-journal-arduino	Building the firmware	This project uses  Platform IO Please refer to  Build Guide  guide 
google-science-journal-arduino	Contributing	Please read our  guidelines for contributors  contributing .
google-science-journal-arduino	License	Open Science Journal is licensed under the  Apache 2 license  license .
google-science-journal-arduino	More	Science Journal is brought to you by  Making & Science  making-science , an initiative by Google
google-science-journal-arduino	More	Open Science Journal is not an official Google product
google-science-journal-arduino	More	play-store :  contributing :  license :  making-science :  guide : 
google-science-journal	Features	Download the source, go into the OpenScienceJournal directory and run:Alternatively, import the source code in OpenScienceJournal into Android Studio  File, Import Project .Note: You'll need Android SDK version 23, build tools 23.0.3, and the Android Support Library tocompile the project
google-science-journal	Features	If you're unsure about this, use Android Studio and tick the appropriate boxesin the SDK Manager.The  OpenScienceJournal README contains details about the organization of the source code, and the relationship of this published sourceto the  published app  play-store .
google-science-journal	Release names	We have fun choosing names for our releases
google-science-journal	Release names	 Read the  stories  releasenames .
google-science-journal	Contributing	Please read our  guidelines for contributors  contributing .
google-science-journal	License	Open Science Journal is licensed under the  Apache 2 license  license .
google-science-journal	More	Science Journal is brought to you by  Making & Science  making-science , an initiative by Google
google-science-journal	More	Open Science Journal is not an official Google product
google-science-journal	More	play-store :  firmware-github : contributing :  releasenames :  license :  making-science : 
google-securemessage	Summary	This is a **portable crypto library***secure by design**, for use as a black-box building block in cryptographicprotocols
google-securemessage	Summary	 Security and portability are emphasized over efficient  compact encodings, but keeping the crypto overhead reasonably minimal is still arequirement
google-securemessage	Summary	The API and implementation should encourage the use of bestpractices, and reduce the likelihood of common protocol design errors.
google-securemessage	Overview	Existing cryptographic libraries available in most languages typically exposeraw crypto primitives  e.g., block ciphers with modes of operation, HMACs,digital signatures  that are often applied incorrectly in protocol design.While these libraries are "standards compliant", they do little or nothing toguide the protocol designer to produce secure protocol designs
google-securemessage	Overview	Worse still,they leave ample room for implementations to introduce subtle security bugssuch as timing attacks.The SecureMessage library leverages Google's protobuffer technology to providea simple and portable encoding for public keys and signed/encrypted data
google-securemessage	Overview	Theexposed API consists of two main classes, and two supporting classes.The main classes are:  decryption, and sanity checking in a secure fashionThe supporting classes are:  reject maliciously crafted inputs  e.g., EC public keys that are not on the  curve 
google-securemessage	Overview	Also assists with key generation
google-securemessage	Overview	 in the case of HKDF, providing clients of the library with access a portable  API for that primitive too, since it is not commonly available .In all cases, exposed APIs are carefully thought out, in order to encouragesafe use and prevent unsafe use
google-securemessage	Overview	For example, the SecureMessageParser API willnot return the original input data unless the signature on it has been verifiedfirst
google-securemessage	Overview	It also requires the caller to specify exactly which signature algorithmis expected to be used, to prevent callers from accidentally consuming messagessent using any other  potentially deprecated / insecure  signature algorithms.Currently supported signature algorithms are:The basic API for SecureMessage consists of two classes, one of which createsSecureMessages, whereas the other parses them
google-securemessage	Overview	 There are two basic types ofSecureMessage which these classes manipulate:  may be either a digital signature, or a MAC
google-securemessage	Overview	 are taken to ensure that the original signature cannot be stripped off of the  encrypted data and replaced by another signature from a different signer
google-securemessage	Overview	Note that we use the term "signature" in a generic sense, to refer to eitherdigital signatures  using asymmetric keys  or Message Authentication Codes using symmetric keys 
google-securemessage	Overview	Currently, the encryption component of signcryptedmessages only supports symmetric key encryption schemes, but this may change inthe future.Each SecureMessage consists of two primary components: a header and a body.The header describes the structure of the SecureMessage as well as providing aconvenient location for metadata related to the body
google-securemessage	Overview	The body of theSecureMessage will contain the primary payload
google-securemessage	Overview	Rather than using the protobufAPIs to retrieve these components from a SecureMessage, the SecureMessageParsermust be used
google-securemessage	Overview	The header component is always sent in the clear, and can beextracted from the SecureMessage by calling SecureMessageParser'sgetUnverifiedHeader   method without the use of any cryptographic keys
google-securemessage	Overview	Thus,it is possible to use the header contents to determine which key s  must beused to verify  and possibly decrypt  the body
google-securemessage	Overview	 In order to retrieve the bodycomponent, an appropriate call must be made to SecureMessageParser'sparseSignedCleartextMessage   or parseSigncryptedMessage   method, depending onwhich of the two message types was sent.To provide better support for building cryptographic protocols, we also providea utility class called PublicKeyProtoUtil that assists with encoding andparsing public keys in a simple wire format, as well as generating new keypairs
google-securemessage	Overview	In particular, this class can be used to dramatically simplifyDiffie-Hellman key exchanges.
google-securemessage	Caveats	There is a some excess overhead incurred for using this library, as compared toa more "direct" implementation of almost any of the offered functionality
google-securemessage	Caveats	Theexcess overhead is the price being paid for simplicity and robustness, both inthe API and in the implementation
google-securemessage	Caveats	If saving every CPU cycle or every bit ofbandwidth is of crucial importance to you, do not use this library  forexample, it would not make for a good SSL replacement for high volume traffic .To get a sense for magnitude of the SecureMessage overhead, a symmetric keybased HMAC SHA-256 and AES-256 CBC mode authenticated encryption incurs amaximum of about 80 bytes of overhead with SecureMessage, as opposed to amaximum of about 64 bytes of overhead using a direct implementation of the sameEncryption without signature is intentionally unsupported
google-securemessage	Caveats	Historically,offering encryption-only APIs has lead to a plethora of mistakes in protocoldesign and implementation, since it is frequently assumed that encrypted datacannot be tampered with  but this is not the case in practice .Support for public key encryption is not yet available, although it may beadded in the future
google-securemessage	Caveats	Instead, we recommend to design protocols that use EC Diffie-Hellman key exchanges, and then used the exchanged symmetric key forencryption
google-securemessage	Caveats	For instance, this approach can offer forward secrecy, andincreased efficiency when multiple messages are concerned
google-securemessage	Caveats	 Note that it iseasy to authenticate the Diffie-Hellman keys using a signature-onlySecureMessage wrapping with a public key signature scheme.
google-securemessage	Compilation and Use	See language specific implementation directories
google-seesaw	Seesaw v2	 ! GoDoc  Note: This is not an official Google product.
google-seesaw	About	Seesaw v2 is a Linux Virtual Server  LVS  based load balancing platform.It is capable of providing basic load balancing for servers that are on thesame network, through to advanced load balancing functionality such as anycast,Direct Server Return  DSR , support for multiple VLANs and centralisedAbove all, it is designed to be reliable and easy to maintain.
google-seesaw	Requirements	A Seesaw v2 load balancing cluster requires two Seesaw nodes physical machines or virtual instances
google-seesaw	Requirements	Each node must have two networkinterfaces four interfaces should be connected to the same layer 2 network.
google-seesaw	Building	Seesaw v2 is developed in Go and depends on several Go packages: libnl  and a compile time dependency onthe Go protobuf compiler.On a Debian/Ubuntu style system, you should be able to prepare for buildingby running:If your distro has a go version before 1.5, you may need to fetch a newerrelease from After setting GOPATH to an appropriate location  for example ~/go :Ensure that ${GOPATH}/bin is in your ${PATH} and in the seesaw directory:If you wish to regenerate the protobuf code, the protobuf compiler and Goprotobuf compiler generator are also needed:The protobuf code can then be regenerated with:
google-seesaw	Installing	After make install has run successfully, there should be a number ofbinaries in ${GOPATH}/bin with a seesaw_ prefix
google-seesaw	Installing	Install these to theappropriate locations:The setcap binary can be found in the libcap2-bin package on Debian/Ubuntu.
google-seesaw	Configuring	Each node needs a /etc/seesaw/seesaw.cfg configuration file, which providesinformation about the node and who its peer is
google-seesaw	Configuring	Additionally, each loadbalancing cluster needs a cluster configuration, which is in the form of atext-based protobuf An example seesaw.cfg file can be found in etc/seesaw/seesaw.cfg.example  etc/seesaw/seesaw.cfg.example  seesaw.cfg provides the following:master
google-seesaw	Configuring	This address needs to be allocated within the same netblock as boththe node IP address and peer IP address.An example cluster.pb file can be found in etc/seesaw/cluster.pb.example  etc/seesaw/cluster.pb.example  cluster.pb contains a seesaw_vip entry and two node entries
google-seesaw	Configuring	For eachservice that you want to load balance, a separate vserver entry isneeded, with one or more vserver_entry sections  one per port/proto pair ,one or more backends and one or more healthchecks
google-seesaw	Configuring	Further informationis available in the protobuf definition  pb/config/config.proto  pb/config/config.proto .On an upstart based system, running restart seesaw_watchdog will start  orrestart  the watchdog process, which will in turn start the other components.
google-seesaw	Anycast	Seesaw v2 provides full support for anycast VIPs an anycast VIP when it becomes available and will withdraw the anycast VIP ifit becomes unavailable
google-seesaw	Anycast	For this to work the Quagga BGP daemon needs to beinstalled and configured, with the BGP peers accepting host-specific routesthat are advertised from the Seesaw nodes within the anycast range  currentlyhardcoded as 192.168.255.0/24 .
google-seesaw	Command Line	Once initial configuration has been performed and the Seesaw components arerunning, the state of the Seesaw can be viewed and controlled via the Seesawcommand line interface
google-seesaw	Command Line	Running seesaw  assuming /usr/bin is in your path will give you an interactive prompt commands
google-seesaw	Command Line	A quick summary:A Seesaw should have five components that are running under the watchdog process table should show processes for:provided by the watchdog
google-seesaw	Command Line	If any of the processes are not running, check thecorresponding logs in /var/log/seesaw  e.g
google-seesaw	Command Line	seesaw_engine.{log,INFO} .
google-segment	Package Segment	This is a go library for general start/end segment manipulation, such asUnion, Intersect, and SetDiff
google-segment	Package Segment	All start/end types are int64.Build this package with bazel build //....This is not an official Google product.
google-sentencepiece	SentencePiece	   ! Build status     ! GitHub Issues   ! PyPI version   ! Contributions welcome   CONTRIBUTING.md  ! License  SentencePiece is an unsupervised text tokenizer and detokenizer mainly forNeural Network-based text generation systems where the vocabulary sizeis predetermined prior to the neural model training
google-sentencepiece	SentencePiece	SentencePiece implements**subword units***unigram language model*with the extension of direct training from raw sentences
google-sentencepiece	SentencePiece	SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.**This is not an official Google product.**
google-sentencepiece	Technical highlights	|Feature|SentencePiece| subword-nmt | WordPiece ||Supported algorithm|BPE, unigram, char, word|BPE|BPE*||OSS?|Yes|Yes|Google internal||Subword regularization| Yes  #subword-regularization |No|No||Python Library  pip | Yes  python/README.md |No|N/A||C++ Library| Yes  doc/api.md |No|N/A||Pre-segmentation required?| No  #whitespace-is-treated-as-a-basic-symbol |Yes|Yes||Customizable normalization  e.g., NFKC | Yes  doc/normalization.md |No|N/A||Direct id generation| Yes  #end-to-end-example |No|N/A|Note that BPE algorithm used in WordPiece is slightly different from the original BPE.
google-sentencepiece	What is SentencePiece?	SentencePiece is a re-implementation of **sub-word units**, an effective way to alleviate the open vocabulary  problems in neural machine translation
google-sentencepiece	What is SentencePiece?	SentencePiece supports two segmentation algorithms, **byte-pair-encoding  BPE *
google-sentencepiece	The number of unique tokens is predetermined	Neural Machine Translation models typically operate with a fixedvocabulary
google-sentencepiece	The number of unique tokens is predetermined	Unlike most unsupervised word segmentation algorithms, whichassume an infinite vocabulary, SentencePiece trains the segmentation model suchthat the final vocabulary size is fixed, e.g., 8k, 16k, or 32k.Note that SentencePices specifies the final vocabulary size for training, which is different from  subword-nmt  that uses the number of merge operations.The number of merge operations is a BPE-specific parameter and not applicable to other segmentation algorithms, including unigram, word and character.
google-sentencepiece	Trains from raw sentences	Previous sub-word implementations assume that the input sentences are pre-tokenized
google-sentencepiece	Trains from raw sentences	This constraint was required for efficient training, but makes the preprocessing complicated as we have to run language dependent tokenizers in advance.The implementation of SentencePiece is fast enough to train the model from raw sentences
google-sentencepiece	Trains from raw sentences	This is useful for training the tokenizer and detokenizer for Chinese, Japanese and Korean where no explicit spaces exist between words.
google-sentencepiece	Whitespace is treated as a basic symbol	The first step of Natural Language processing is text tokenization
google-sentencepiece	Whitespace is treated as a basic symbol	Forexample, a standard English tokenizer would segment the text "Hello world." into thefollowing three tokens.>  Hello   World   
google-sentencepiece	Whitespace is treated as a basic symbol	One observation is that the original input and tokenized sequence are **NOTreversibly convertible**
google-sentencepiece	Whitespace is treated as a basic symbol	For instance, the information that is no space between“World” and “.” is dropped from the tokenized sequence, since e.g., Tokenize “World.”  == Tokenize “World .” SentencePiece treats the input text just as a sequence of Unicode characters
google-sentencepiece	Whitespace is treated as a basic symbol	Whitespace is also handled as a normal symbol
google-sentencepiece	Whitespace is treated as a basic symbol	To handle the whitespace as a basic token explicitly, SentencePiece first escapes the whitespace with a meta symbol "▁"  U+2581  as follows.> Hello▁World.Then, this text is segmented into small pieces, for example:>  Hello   ▁Wor   ld   
google-sentencepiece	Whitespace is treated as a basic symbol	Since the whitespace is preserved in the segmented text, we can detokenize the text without any ambiguities.Note that we cannot apply the same lossless conversions when splitting thesentence with standard word segmenters, since they treat the whitespace as aspecial symbol
google-sentencepiece	Whitespace is treated as a basic symbol	Tokenized sequences do not preserve the necessary information to restore the original sentence.Subword regularization   Kudo
google-sentencepiece	Whitespace is treated as a basic symbol	  is a simple regularization methodthat virtually augments training data with on-the-fly subword sampling, which helps to improve the accuracy as well as robustness of NMT models.To enable subword regularization, you would like to integrate SentencePiece library   C++  doc/api.md#sampling-subword-regularization / Python  python/README.md   into the NMT system to sample one segmentation for each parameter update, which is different from the standard off-line data preparations
google-sentencepiece	Whitespace is treated as a basic symbol	Here's the example of  Python library  python/README.md 
google-sentencepiece	Whitespace is treated as a basic symbol	You can find that 'New York' is segmented differently on each SampleEncode call
google-sentencepiece	Whitespace is treated as a basic symbol	The details of sampling parameters are found in  sentencepiece_processor.h  src/sentencepiece_processor.h .
google-sentencepiece	Python module	SentencePiece provides Python wrapper that supports both SentencePiece training and segmentation.You can install Python binary package of SentencePiece with.
google-sentencepiece	C++  from source 	The following tools and libraries are required to build SentencePiece:The name of the protobuf library is different between ubuntu distros
google-sentencepiece	C++  from source 	Please enter appropriate command for your Ubuntu version.On ubuntu 14.04 LTS  Trusty Tahr :On ubuntu 16.04 LTS  Xenial Xerus :On ubuntu 17.10  Artful Aardvark  and Later:On OSX, you can use brew:If want to use self-prepared protobuf library, setup below environment variables before build:
google-sentencepiece	Build and Install SentencePiece	% sudo update_dyld_shared_cache
google-sentencepiece	Train SentencePiece Model	  the input with Unicode NFKC
google-sentencepiece	Train SentencePiece Model	You can pass a comma-separated list of files.Use --help flag to display all parameters for training.
google-sentencepiece	Encode raw text into sentence pieces/ids	Use SentencePiece supports nbest segmentation and segmentation sampling with 
google-sentencepiece	End-to-End Example	% spm_train --input=data/botchan.txt --model_prefix=m --vocab_size=1000unigram_model_trainer.cc 494  LOG INFO  Starts training with :input: "../data/botchan.txt"..
google-sentencepiece	End-to-End Example	unigram_model_trainer.cc 529  LOG INFO  EM sub_iter=1 size=1100 obj=10.4973 num_tokens=37630 num_tokens/piece=34.2091trainer_interface.cc 272  LOG INFO  Saving model: m.modeltrainer_interface.cc 281  LOG INFO  Saving vocabs: m.vocab% echo "I saw a girl with a telescope." | spm_encode --model=m.model▁I ▁saw ▁a ▁girl ▁with ▁a ▁ te le s c o pe .% echo "I saw a girl with a telescope." | spm_encode --model=m.model --output_format=id9 459 11 939 44 11 4 142 82 8 28 21 132 6% echo "9 459 11 939 44 11 4 142 82 8 28 21 132 6" | spm_decode --model=m.model --input_format=idI saw a girl with a telescope.You can find that the original input sentence is restored from the vocabulary id sequence.
google-sentencepiece	Export vocabulary list	 stores a list of vocabulary and emission log probabilities
google-sentencepiece	Export vocabulary list	The vocabulary id corresponds to the line number in this file.
google-sentencepiece	Redefine special meta tokens	  By default, SentencePiece uses Unknown  &lt;unk&gt; , BOS  &lt;s&gt;  and EOS  &lt;/s&gt;  tokens which have the ids of 0, 1, and 2 respectively
google-sentencepiece	Redefine special meta tokens	We can redefine this mapping in the training phase as follows.If you want to assign another special tokens, please see  Use custom symbols  doc/special_symbols.md .
google-sentencepiece	Vocabulary restriction	spm_encode accepts a --vocabulary and a --vocabulary_threshold option so that spm_encode will only produce symbols which also appear in the vocabulary  with at least some frequency 
google-sentencepiece	Vocabulary restriction	The background of this feature is decribed in  subword-nmt page The usage is basically the same as that of subword-nmt
google-sentencepiece	Vocabulary restriction	Assming that L1 and L2 are the two languages  source/target languages , train the shared spm model, and get resulting vocabulary for each:Then segment train/test corpus with 
google-serialization.dart	General serialization for Dart objects.	  Save and restore objects flexibly.This can serialize and de-serialize objects to multiple differentformats
google-serialization.dart	General serialization for Dart objects.	It is most useful if you have Dart on both ends, ratherthan needing to communicate with an external system
google-serialization.dart	General serialization for Dart objects.	It can handlecycles, inheritance, getters and setters, private or final fields setvia constructors, objectsserialized in different ways at different times, and other complexoptions
google-serialization.dart	General serialization for Dart objects.	It can handle serializing acyclic objects with only publicfields to a simple JSON format, but might be more heavyweight than isnecessary if that's the only requirement.This has no privileged access to object representations, so objectsare accessed and created according to their public APIs
google-serialization.dart	General serialization for Dart objects.	As a result,serializations from older versions where the internal representationhas changed can still be read as long as the public API is still available.The way an object's state is read and written is defined bySerializationRules
google-serialization.dart	General serialization for Dart objects.	These can be implemented in various ways
google-serialization.dart	General serialization for Dart objects.	Theeasiest to use is using mirrors to find the members
google-serialization.dart	General serialization for Dart objects.	Rules can also behand-written or, for relatively simple classes, generated using a
google-serialization.dart	Usage	Import eitherdepending on whether or not you want the mirrored rules
google-serialization.dart	Usage	These aremore convenient, but cause increased code size in dartj2s.To use the transformer, include something in the pubspec likeThen, set up the generated rules in a Serialization instance, and then callwrite  
google-serialization.dart	Usage	The serialization rules will be named asthe name of the model file with _serialization_rules appended to it,so in the case of stuff.dart, stuff_serialization_rules.dart, inthe same directory as the original.Normally you won't ever see these files, because thetransformer creates it on the fly and it is sent directly to pub serveor to dart2js without ever being written to disk.To see the generated code, run pub build in debug mode, e.g.if there is a program in the package's bin directory to run somethingusing these files, thenwould generate the code for that, and also log whichfiles were generated, in the formIt's also possible to run the transformer's code outside of thetransformer, which is helpful for debugging or to use the code in adifferent way
google-serialization.dart	Usage	See the test/transformer/generate_standalone.dart' foran example of that.The bin directory code would look something like.and on the client, do something likeAlternatively, if using the mirrored rules, just tell theserialization which classes might be serialized.For more concrete examples, see the pubspec.yaml for this package, and thetest/transformer directory.
google-serialization.dart	Requests and bugs	Please file feature requests and bugs via the GitHub Issue Tracker  issues 
google-serialization.dart	Requests and bugs	This is licensed under the same license as Dart  LICENSE 
google-serialization.dart	Disclaimer	This is not an official Google project
google-serialization.dart	Disclaimer	issues :  LICENSE : 
google-service-worker-detector	💻 💬 Description	This extension detects if a website registers a Service Worker by reading the navigator.serviceWorker.controller property Note: this is not an official Google product.
google-service-worker-detector	🖥 🔫 Screenshots	! Screenshot Service Worker ! Screenshot Manifest ! Screenshot Cache Storage 
google-service-worker-detector	🔧 🛍 Installation	Install the Service Worker Detector extension for your favorite browser:The extension represents Service Workers with construction worker emoji The extension icon randomly features the female or the male construction worker.
google-service-worker-detector	📄 💼 License	Copyright 2017 Google Inc
google-service-worker-detector	📄 💼 License	All rights reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License at  Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-service_worker.dart	service_worker	An implementation of the basic Service Worker protocol.Important note: Does not actually work at all yet.
google-service_worker.dart	Usage	A simple usage example:
google-service_worker.dart	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-service_worker.dart	Features and bugs	tracker : 
google-sg2im	sg2im	This is the code for the paper**Image Generation from Scene Graphs*Justin Johnson,Agrim Gupta,Li Fei-FeiPresented at  CVPR 2018 Please note that this is not an officially supported Google product.A **scene graph*Below we show some example scene graphs along with images generated from those scene graphs using our model
google-sg2im	sg2im	By modifying the input scene graph we can exercise fine-grained control over the objects in the generated image
google-sg2im	sg2im	                             If you find this code useful in your research then please cite
google-sg2im	Model	The input scene graph is processed with a *graph convolution network  
google-sg2im	Setup	All code was developed and tested on Ubuntu 16.04 with Python 3.5 and PyTorch 0.You can setup a virtual environment to run the code like this:You can download pretrained models by running the script bash scripts/download_models.sh
google-sg2im	Setup	This will download the following models, and will require about 355 MB of disk space:
google-sg2im	Running Models	You can use the script scripts/run_model.py to easily run any of the pretrained models on new scene graphs using a simple human-readable JSON format
google-sg2im	Running Models	For example you can replicate the sheep images above like this:We provide JSON files and pretrained models allowing you to recreate all images from Figures 5 and 6 from the paper.
google-sg2im	 Optional : GraphViz	This script can also draw images for the scene graphs themselves using  GraphViz  to enable this option just add the flag --draw_scene_graphs 1 and the scene graph images will also be saved in the output directory
google-sg2im	 Optional : GraphViz	For this option to work you must install GraphViz; on Ubuntu 16.04 you can simply run sudo apt-get install graphviz.
google-sg2im	Training new models	Instructions for training new models can be  found here  TRAINING.md .
google-shaderc-rs	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.-----This library uses  build.rs  build/build.rs  to automatically check outand compile a copy of native C++ shaderc and link to the generated artifacts,which requires git, cmake, and python existing in the PATH.To turn off this feature, specify --no-default-features when building.But then you will need to place a copy of the shaderc_combined library on Windows  or the shaderc_shared library  on Linux and macOS  to a locationthat is scanned by the linker  e.g., the deps directory within the targetdirectory .First add to your Cargo.toml:shaderc provides the  Compiler  doc-compiler  interface to compile GLSL/HLSLsource code into SPIR-V binary modules or assembly code
google-shaderc-rs	Disclaimer	It can also assembleSPIR-V assembly into binary module
google-shaderc-rs	Disclaimer	Default compilation behavior can beadjusted using  CompileOptions  doc-options 
google-shaderc-rs	Disclaimer	Successful results are kept in CompilationArtifact  doc-artifact s.Please see ! Documentation  for detailed documentation.-------Compile a shader into SPIR-V binary module and assembly text:use shaderc;let source = "#version 310 es\n void EP   {}";let mut compiler = shaderc::Compiler::new  .unwrap  ;let mut options = shaderc::CompileOptions::new  .unwrap  ;options.add_macro_definition "EP", Some "main"  ;let binary_result = compiler.compile_into_spirv assert_eq! Some &0x07230203 , binary_result.as_binary  .first   ;let text_result = compiler.compile_into_spirv_assembly assert! text_result.as_text  .starts_with "; SPIR-V\n"  ;-------------This project is licensed under the  Apache 2  LICENSE  license
google-shaderc-rs	Disclaimer	Please see CONTRIBUTING  CONTRIBUTING.md  before contributing.
google-shaderc-rs	Authors	This project is initialized and mainly developed by Lei Zhang  @antiagainst  me  
google-shaderc-rs	Authors	shaderc :  doc-compiler :  doc-options :  doc-artifact :  me : 
google-shaderc	Shaderc	   "Linux and Mac Build Status"  ! Windows Build status   "Windows Build Status"   Latest Build Status by Google:A collection of tools, libraries and tests for shader compilation.At the moment it includes:and  SPIRV-Tools  spirv-tools 
google-shaderc	Shaderc	 Shaderc aims toto provide:
google-shaderc	Status	Shaderc has maintained backward compatibility for quite some time, and wedon't anticipate any breaking changes.Ongoing enhancements are described in the  CHANGES  CHANGES  file.Shaderc has been shipping in the Android NDK  since version r12b
google-shaderc	Status	The NDK build uses sources from Those repos are downstream from GitHub
google-shaderc	Status	For licensing terms, please see the  LICENSE  LICENSE  file
google-shaderc	Status	 If interested incontributing to this project, please see  CONTRIBUTING.md  CONTRIBUTING.md .This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google
google-shaderc	Status	 That may change if Shaderc gainscontributions from others
google-shaderc	Status	 See the  CONTRIBUTING.md  CONTRIBUTING.md  filefor more information
google-shaderc	Status	See also the  AUTHORS  AUTHORS  and CONTRIBUTORS  CONTRIBUTORS  files.
google-shaderc	File organization	Sometimes a change updates both Shaderc and glslang
google-shaderc	File organization	 In that case theglslang change will appear in  google/glslang  google-glslang before it appears upstream in  KhronosGroup/glslang  khr-glslang We intend to upstream all changes to glslang
google-shaderc	File organization	We maintain the separatecopy only to stage those changes for review, and to provide something forShaderc to build against in the meantime
google-shaderc	File organization	 Please see DEVELOPMENT.howto.md  DEVELOPMENT.howto.md  for more details.Shaderc depends on  SPIRV-Tools  spirv-tools  for assembling, disassembling,and transforming SPIR-V binaries.Shaderc depends on the  Google Test testing framework.In the following sections, $SOURCE_DIR is the directory you intend to cloneShaderc into.
google-shaderc	Getting and building Shaderc	artifacts built by  Appveyor  appveyor  for the top of the tree of the masterbranch under the "Artifacts" tab of a certain job.1  Check out the source code:branch of the repository contains a known_good.json file describing a set of repo URLs and specific commits that have beentested together
google-shaderc	Getting and building Shaderc	 This information is updated periodically, and typicallymatches the latest update of these sources in the development branchof the Android NDK.The known-good branch also contains a update_shaderc.py script that will read the JSON file and checkout those specific commits for you.2  Ensure you have the requisite tools -3  Decide where to place the build output
google-shaderc	Getting and building Shaderc	In the following steps, we'll call it4a  Build  and test  with Ninja on Linux or Windows: Skip building threaded unit tests due to Googletest bug 606 the $BUILD_DIR/glslc/ directory, as well as a libshaderc library somewhereunder the $BUILD_DIR/libshaderc/ directory.The default behavior on MSVC is to link with the static CRT
google-shaderc	Getting and building Shaderc	If you would liketo change this behavior -DSHADERC_ENABLE_SHARED_CRT may be passed on thecmake configure line.See  the libshaderc README  libshaderc/README.md  for more on using the libraryAPI in your project.
google-shaderc	Tools you'll need	For building, testing, and profiling Shaderc, the following tools should beinstalled regardless of your OS:On Linux, if cross compiling to Windows:On Windows, the following tools should be installed and available on your path:Optionally, the following tools may be installed on any OS:Please make sure you have the Docker engine installed  on your machine.To create a Docker image containing Shaderc command line tools, issue thefollowing command in /usr/local internally, and a data volume mounted at /code.Assume  is shaderc/shaderc from now on.To invoke a tool from the above created image in a Docker container:the shaders you want to manipulate and run different kinds of tools viaan interactive shell in the container:We track bugs using GitHub - the project's GitHub page 
google-shaderc	Test coverage	On Linux, you can obtain test coverage as follows:
google-shaderc	Bindings	Bindings are maintained by third parties, may contain contentoffered under a different license, and may reference or containolder versions of Shaderc and its dependencies
google-shaderc	Bindings	google-glslang :  spirv-tools :  pyshaderc :  shaderc-rs :  appveyor : 
google-shaka-packager	Getting Shaka Packager	There are several ways you can get Shaka Packager
google-shaka-packager	Getting Shaka Packager	  here   for details.
google-shaka-packager	Useful Links	If you have improvements or fixes, we would love to have your contributions.See  for
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	Shaka Player is an open-source JavaScript library for adaptive media
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	 It playsadaptive media formats  such as  DASH    and  HLS     in a browser, withoutusing plugins or Flash
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	 Instead, Shaka Player uses the open web standards MediaSource Extensions    and  Encrypted Media Extensions   .Shaka Player also supports  offline storage and playback    of media using IndexedDB   
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	 Content can be stored on any browser
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	 Storage of licensesdepends on browser support.Our main goal is to make it as easy as possible to stream adaptive bitratevideo and audio using modern browser technologies
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	We try to keep the librarylight, simple, and free from third-party dependencies
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	Everything you need tobuild and deploy is in the sources
google-shaka-player	! Shaka Player  docs/shaka-player-logo.png 	DASH :  HLS :  MediaSource Extensions :  Encrypted Media Extensions :  IndexedDB :  offline storage and playback :|:---------:|:--------:|:-------:|:-------:|:-------:|:--:|:------:|:---:||Firefox¹   |**Y*|IE ≤ 10|IE 11|Opera¹|Chromecast²| |Tizen TV³  | 
google-shaka-player	Manifest format support matrix	|Format|Video On-Demand|Live |Event|In-Progress Recording||DASH  |**Y*|HLS   |**Y*You can also create a  manifest parser plugin    to support custom manifest formats
google-shaka-player	Manifest format support matrix	manifest parser plugin :DASH features supported:HLS features supported:
google-shaka-player	DRM support matrix	|Browser   |Widevine  |PlayReady|FairPlay |ClearKey⁷ ||Chrome¹   |**Y*|Firefox²  |**Y*|IE 11⁴|Opera|Tizen TV  |**Y*Other DRM systems should work out of the box if they are interoperable and compliant to the EME spec.Shaka Player supports: text display plugin    for customer rendering to go beyond browser-supported cueing data :  text display plugin : 
google-shaka-player	Important Links ##	If you have improvements or fixes, we would love to have your contributions.Please read CONTRIBUTING.md for more information on the process we would likecontributors to follow.
google-shaka-player	FAQ ##	For general help and before filing any bugs, please read the FAQ  docs/tutorials/faq.md .
google-shell-encryption	Introduction	This project is a library for fully-homomorphic symmetric-key encryption
google-shell-encryption	Introduction	Ituses Ring Learning with Errors  RLWE -based encryption to make it possible toboth add and multiply encrypted data
google-shell-encryption	Introduction	It uses modulus-switching to enablearbitrary-depth homomorphic encryption  provided sufficiently large parametersare set 
google-shell-encryption	Introduction	RLWE is also believed to be secure in the face of quantum computers.This library is designed to be compact and readable
google-shell-encryption	Introduction	The library includes just1500 lines of heavily-commented source  700 lines of source, 600 lines ofcomments and 200 blank lines  and 900 lines of unit tests.We intend this project to be both a useful experimental library and acomprehensible tool for learning about and extending RLWE.Discussion group: **THIS IS NOT AN OFFICIAL GOOGLE PRODUCT**
google-shell-encryption	Fully Homomorphic Encryption	Fully homomorphic encryption is a form of encryption that makes it possible toperform arbitrary computation on encrypted data.For example, suppose that Alice creates a secret key *sencrypt the numbers *2*{3}s*
google-shell-encryption	Fully Homomorphic Encryption	In an *additively homomorphicdoes not know the numbers inside the ciphertexts  could add the ciphertextstogether, generating the message *{5}s5 , or multiply the ciphertexts together, generating the messageresulting message remain hidden to Bob
google-shell-encryption	Fully Homomorphic Encryption	When he gives this result back to Alice,however, she can decrypt it to reveal the result of the computation.When an encryption scheme is both additively and multiplicatively homomorphic,it is said to be *fully homomorphic*.Homomorphic encryption has a vast number of applications
google-shell-encryption	Fully Homomorphic Encryption	As in the exampleabove, Alice can securely offload computation to another entity without worryingthat doing so will reveal any of her private information
google-shell-encryption	Fully Homomorphic Encryption	Among many otherapplications, it enables *private information retrievalcan serve user requests without learning which pieces of data the usersrequested
google-shell-encryption	Fully Homomorphic Encryption	 For more information on PIR, see  XPIR: Private InformationRetrieval for Everyone 
google-shell-encryption	Ring Learning with Errors	The homomorphic encryption scheme that this library implements is based off ofthe Ring Learning with Errors problem
google-shell-encryption	Ring Learning with Errors	The security of this system derives fromthe conjectured difficulty of finding the shortest vector in a lattice
google-shell-encryption	Ring Learning with Errors	Thisdocument does not delve into the mathematical underpinnings of these proofs ofThe cryptosystem implemented in this library is from  Fully HomomorphicEncryption from Ring-LWE and Security for Key DependentMessages The cryptosystem works as follows:
google-shell-encryption	Preliminaries	Each object in the cryptosystems, including keys, messages, and ciphertexts, aremade of polynomials
google-shell-encryption	Preliminaries	Each of these polynomials has degree *n-1*, where *npower of In other words, each of these polynomials has *nEach of the coefficients of these polynomials is an integer  mod *q* , where *qwe do so  mod *xn+1* .We also need a modulus *tof bits of plaintext information we are able to fit into each coefficient of aciphertext polynomial
google-shell-encryption	Preliminaries	The importance of *tFinally, we need two other components: a Gaussian distribution *Yand standard deviation *w*, where *wimportance of this distribution will become apparent soon.
google-shell-encryption	Key Generation	A secret key *sdistribution *Y*.
google-shell-encryption	Encryption	A message *mcoefficients, each of which is smaller than *t*.To encrypt *mfrom the ciphertext.The ciphertext consists of two polynomials
google-shell-encryption	Encryption	The first polynomial*c0 = as + m + et*
google-shell-encryption	Encryption	The second polynomial *c1 = -a*
google-shell-encryption	Encryption	Theproducts between polynomials are computed using polynomial multiplications  mod*xn+1* .
google-shell-encryption	Decryption	Given a ciphertext * c0, c1 *, the ciphertext is decryptedby computing *mwas already  mod *t* .
google-shell-encryption	Homomorphic Addition	To add two ciphertexts, simply add them component-wise
google-shell-encryption	Homomorphic Addition	If we added theciphertexts * c0x, c1x c1y *, we would get the ciphertext * c0x + c0y,c1x + c1y ext + ays + my + eyt,-ax  mx - ax + ay  *.If we let *az*ex + ey*, the resulting ciphertext is * azs +mz + ezt, -az *, which is just anotherciphertext encrypting the sum of the original messages.
google-shell-encryption	Homomorphic Absorbtion	We can multiply a ciphertext containing the message *mpolynomial *pmultiply the components of the ciphertext by *p*: * cxp,c1p containing the message *mpchanged to *ap*.
google-shell-encryption	Homomorphic Multiplication	Adding homomorphic multiplication to this library requires small tweaks to theaforementioned operations.To multiply two ciphertexts * c0x, c1x * c0y, c1y *, compute their cross product:* c0xc0y, c1xc0y +c0xc1y, c1xc1y *.Notice that the resulting ciphertext has three components, not the usual two.This is perfectly acceptable and all the aforementioned operations will work asbefore with small modifications:
google-shell-encryption	Error Growth	Observe that, after each homomorphic operation, the error in the resultingciphertext grows
google-shell-encryption	Error Growth	When adding, it grows additively, where in absorption andmultiplication it grows exponentially
google-shell-encryption	Error Growth	When the largest coefficient ofpolynomial that results from taking the inner product of the ciphertext vector* c0, c1, ..
google-shell-encryption	Error Growth	* s0, s1, ..
google-shell-encryption	Error Growth	up and decryption will fail.As you choose the parameters for your particular application, you will need totrace the growth of the sum of the error and the message carefully.One way of managing error is to set a larger modulus
google-shell-encryption	Error Growth	Setting a larger modulusmust be done with care, however
google-shell-encryption	Error Growth	Security of RLWE derives partly from the ratioof modulus to error
google-shell-encryption	Error Growth	If the modulus increases in size, so must the standarddeviation of the error distirbution.
google-shell-encryption	Modulus Switching	Modulus switching is a strategy to slow the rate of error growth when performingmany levels of homomorphic multiplications
google-shell-encryption	Modulus Switching	The explanation and implementationof this technique in this library derives from  Fully Homomorphic Encryptionwithout Bootstrapping Modulus switching takes a ciphertext converts a ciphertext from a larger modulusto a smaller modulus
google-shell-encryption	Modulus Switching	Specifically, when converting from modulus *q*r*, each coefficient of the ciphertext *kqdivided by *q*, and rounded to the nearest integer, producing *kr*.This value is then shifted up or down the minimum amount to ensure thatciphertext will decrypt properly
google-shell-encryption	Modulus Switching	When modulus switching, the error will scalewith the shift in the modulus, keeping the modulus-to-error ratio constant.To understand the benefit of modulus switching, consider the following example.Suppose four ciphertexts initially each have error *e*
google-shell-encryption	Modulus Switching	After homomorphicallymultiplying them in pairs, we will have two ciphertexts each with error*O e2 *
google-shell-encryption	Modulus Switching	When multiplying those two ciphertexts, the resulting errorwill be *O e4 *
google-shell-encryption	Modulus Switching	In other words, when multiplying ciphertextstogether, the exponent of the error will grow exponentially.Modulus switching offers a way to reduce the complexity of the error growth.After computing two ciphertexts each with error *x2*, we shift frommodulus *q*x*
google-shell-encryption	Modulus Switching	The modulus-to-error ratio is the same as before
google-shell-encryption	Modulus Switching	Were we to convert backto modulus *q*, the error would return to its original value
google-shell-encryption	Modulus Switching	When we multiplythese ciphertexts again, the overall error will be *x2Were we to convert back to the original modulus, the overall error would be*x3*, dramatically smaller than without modulus switching.This library has the ability to perform modulus switching.
google-shell-encryption	This Library	This library consists of four major components that form a RLWE stack.
google-shell-encryption	Montgomery Integers	This library is implemented in montgomery.h
google-shell-encryption	Montgomery Integers	At the lowest level is a librarythat represents modular integers in Montgomery form, which speeds up therepeated use of the modulo operator
google-shell-encryption	Montgomery Integers	This library supports 64-bit integers,meaning that it can support a modulus of up to 30-bits
google-shell-encryption	Montgomery Integers	For larger modulussizes, the higher levels of the stack can be parameterized with a different type such as a BigInteger 
google-shell-encryption	Montgomery Integers	Montgomery integers require several parameters inaddition to the modulus to perform the modular operations efficiently
google-shell-encryption	Montgomery Integers	Thesevalues have been chosen for several common moduli in constants.h.
google-shell-encryption	NTT Polynomial	This library is implemented in ntt_polynomial.h
google-shell-encryption	NTT Polynomial	We store all polynomials inNTT  Number-Theoretic Transformation  form
google-shell-encryption	NTT Polynomial	A polynomial multiplication onstandard polynomials can be computed with a coefficient-wise product on the samepolynomials in NTT form, reducing the complexity of the operation from*O n2 
google-shell-encryption	NTT Parameters	This library is implemented in ntt_parameters
google-shell-encryption	NTT Parameters	cc|h 
google-shell-encryption	NTT Parameters	Converting to and fromNTT form requires special parameters that this file generates
google-shell-encryption	NTT Parameters	In productioncode, these parameters should be generated ahead of time for the chosen valuesof *q
google-shell-encryption	Symmetric Encryption.	This library is implemented in symmetric_encryption.h
google-shell-encryption	Symmetric Encryption.	This library implementsall of the cryptographic operations described earlier in ths document
google-shell-encryption	Symmetric Encryption.	Itoperates on polynomials in NTT form.
google-shell-encryption	Dependencies	This library requires the following external dependencies:
google-shell-encryption	Acknowledgements	Although this library was written independently, the organization and several ofthe optimizations present in this library were drawn from the code underlyingthe New Hope RLWE key exchange protocol
google-shell-encryption	Acknowledgements	This library benefited greatly fromboth the  New Hope paper  and  New Hopecodebase  We also thank JonathanFrankle, who led the development of this library during an internship at Google.
google-shenzhen-go	"SHENZHEN GO"  working title 	    ! license  SHENZHEN GO  working title  is an **experimental*inspired by programming puzzle games such as TIS-100 and SHENZHEN I/O.SHENZHEN GO provides a UI for editing a "graph," where the nodes are goroutines and the arrows are channel reads and writes
google-shenzhen-go	"SHENZHEN GO"  working title 	 This is analogousto multiple "microcontrollers" communicating electrically in a circuit
google-shenzhen-go	"SHENZHEN GO"  working title 	It can also convert a graph into pure Go source code, which can be compiled and run, or used as a library in a regular Go program
google-shenzhen-go	"SHENZHEN GO"  working title 	SHENZHEN GO was unveiled  at the  linux.conf.au 2017 Open Source & Games Miniconf Read more at ! Example Graph  example_graph2.png 
google-shenzhen-go	Versions	There are currently TWO versions of Shenzhen Go
google-shenzhen-go	Versions	The original Graphviz-based prototype is "v0", and mostly works, but I'm not working on it anymore
google-shenzhen-go	Versions	The second version, "v1", is not quite ready yet, so for now it lives in the "dev" directory
google-shenzhen-go	Versions	But I'm working on it.
google-shenzhen-go	Getting started	See the getting-started guides at 
google-shenzhen-go	...for the impatient gopher	Choose one of:
google-shenzhen-go	Notes	This is not an official Google product.This is an experimental project no support.For discussions, there is  a Google Group  and  a Slack channel 
google-shenzhen-go	v1 / dev	The dev version wouldn't be nearly as good as it is without the following:The prototype  v0  relies heavily on Graphviz to function, but does not bundle or vendor any Graphviz components.
google-shipshape-demo	Shipshape sample repository	A repository with a sampling of code that shipshape will find defects on
google-shipshape-demo	Shipshape sample repository	Pleasesee github.com/google/shipshape.Locations where the analyses should find defects are already marked.This code is not intended to be run.This is not an official Google product.
google-shipshape	Overview of Shipshape #	  Shipshape is a static program analysis platform that allows custom analyzers toplug in through a common interface
google-shipshape	Overview of Shipshape #	Shipshape is packaged in a docker image.When that image is run, a Shipshape analyzer service starts up and processesanalysis requests
google-shipshape	Overview of Shipshape #	Structured analysis results are generated
google-shipshape	Overview of Shipshape #	Shipshape can berun as a command-line interface, or as a Jenkins plugin
google-shipshape	Overview of Shipshape #	The requirements to runare that you are running Linux with docker installed and the source code you wantto analyze available on disk.The source code for Shipshape is located in the "shipshape" directory.Third-party libraries used by Shipshape are all in the "third_party" directory.
google-shipshape	Download and Run Shipshape	Shipshape has been tested on Ubuntu  >=14.04  and Debian unstable, but should work on other Linux distributions.Shipshape requires  Docker  to run
google-shipshape	Download and Run Shipshape	Install instructions for Linux  shipshape/docs/linux-setup.md 
google-shipshape	Download and Run Shipshape	Install instructions for GCE  shipshape/docs/gce-setup.md .Once you've installed it, running is easy!For examples for how to use it,  see our documentation  shipshape/docs/run-cli.md .
google-shipshape	Building from source	Shipshape uses the  Bazel build tool  Once you have Docker and Bazel installed, you can build Shipshape with:The binary will be saved in bazel-bin/shipshape/cli/shipshape.
google-shipshape	Analyzers	The following analyzers are bundled with Shipshape:The following analyzers were contributed by external developers:See our  documentation  shipshape/docs/add-an-analyzer.md  on how to create more analyzers of your own.We also have  a complete example  shipshape/androidlint_analyzer/README.md .
google-shipshape	Contributing to shipshape	To contribute to shipshape, first  read our contribution guidelines  CONTRIBUTING.md  and thenmake sure you can  build and run shipshape from source  shipshape/docs/dev-setup.md .
google-shipshape	Running the Jenkins Plugin #	Instructions are located in shipshape/jenkins_plugin/README.md.
google-shipshape	Package Structure of Shipshape #	  go_dispatcher
google-shipshape	Package Structure of Shipshape #	The canonical simplest analyzer is in analyzers/postmessage  Shipshape analyzer service, using libraries from the service package  on a specified directory, and outputs analysis results  build off of javac  are services that implement the rpcs listed in the ShipshapeService interface  in proto/shipshape_rpc.proto
google-shipshape	Package Structure of Shipshape #	Analyzers produce structured output in the form  of Note messages, defined in proto/note.proto  go_dispatcher -  shipshape -  driver -  config -  locally on test input, useful when developing new analyzer services  slices, execing docker commands, or writing tests
google-signet	Signet	  Homepage  AuthorBob Aman  CopyrightCopyright © 2010 Google, Inc
google-signet	Signet	 LicenseApache 2.0 ! Gem Version    
google-signet	Description	Signet is an OAuth 1.0 / OAuth 2.0 implementation.
google-signet	Initialize the client	gem install signetBe sure  is in your gem sources.
google-simian	Overview	**Note 1: OS X 10.6, 10.7, 10.8 support dropped  22 April 2016 ****Note 2: Simian now supports Munki2 categories!**Simian is an enterprise-class Mac OS X software deployment solution hosted on Google App Engine  why  App Engine  ../../wiki/AppEngineAtAGlance ? 
google-simian	Overview	It scales to any enterprise fleet size automatically, and offers a future proof client extended from the active  Munki open-source project Because the Simian server is live code, not a static file server, it offers unique benefits over a typical Munki+Apache deployment:
google-simian	Getting Started	Please refer to the  Wiki documentation  ../../wiki/AdminSetup  for instructions on how to download, configure, build, and deploy Simian.For screenshots and an overview of Simian features, please see the  SimianAtAGlance wiki  ../../wiki/SimianAtAGlance .
google-simian	License	   here   You can find out more about the license, atIf you have any issue or question which isn't covered in the Wiki documentation, we recommend you search and then post to the  simian-discuss@googlegroups.com Google Group If your question is sensitive in nature, feel free to reach direct to the engineering team at simian-eng@googlegroups.com.Finally, if you'd like to stay aware of future Simian news, please subscribe to  simian-announce@googlegroups.com Google Group 
google-simple-reinforcement-learning	Simple Reinforcement Learning	This demonstrates reinforcement learning
google-simple-reinforcement-learning	Simple Reinforcement Learning	Specifically, ituses  Q-learning to move a player  @  around a fixed maze and avoid traps  ^  while gettingtreasure  $  as fast as possible.Add the directory containing srl to PYTHONPATH
google-simple-reinforcement-learning	Simple Reinforcement Learning	Then there are threeways to run the grid.py program:srl/grid.py --interactive  --random : Use the arrow keys to walksrl/grid.py --q  --random : An &epsilon;-greedy Q-learnersrl/all_tests.py: Run the unit tests.Here are some ideas in ways to extend grid.py
google-simple-reinforcement-learning	Simple Reinforcement Learning	These are increasingly difficult.Some early steps may be useful for later steps
google-simple-reinforcement-learning	Simple Reinforcement Learning	 simulation loop and the display so that you can simulate faster
google-simple-reinforcement-learning	Simple Reinforcement Learning	 the HumanPlayer to permit a learner to learn by observing a human play
google-simple-reinforcement-learning	Simple Reinforcement Learning	 approximator such as a neural network
google-simple-reinforcement-learning	Simple Reinforcement Learning	The QTable memorizes the  fixed map; with multiple maps you will need to feed the maze as  input to the neural network so it can "see" the map instead of  memorizing it
google-simple-reinforcement-learning	Simple Reinforcement Learning	 coordinates with a certain heading and velocity  and actions  acceleration and  turning
google-simple-reinforcement-learning	Simple Reinforcement Learning	 How will you relate states to each other in a continuous space?
google-sketch2ae	 Sketch2AE  5ae3a8a1 	 Sketch  66b609ab  layers may now be imported into  After Effects  56a59ddd  without redrawing everything in Illustrator
google-sketch2ae	 Sketch2AE  5ae3a8a1 	Avoid the startling realization that you have to repeat the whole import process because forgot to split one element out onto its own layer or that type has to be converted into live text as an additional process per layer.Quickly export selected layers or a whole artboard from Sketch with with type metrics, transform data, images, symbol hierarchy and grouping intact
google-sketch2ae	 Sketch2AE  5ae3a8a1 	It's kind of better than the native Illustrator => AE import
google-sketch2ae	 Sketch2AE  5ae3a8a1 	Hooray.> This is not an official Google product
google-sketch2ae	 Sketch2AE  5ae3a8a1 	Motion designers at Google just kinda like it a lot
google-sketch2ae	 Sketch2AE  5ae3a8a1 	Built by  Adam Plouff  8638464d 
google-sketch2ae	 Sketch2AE  5ae3a8a1 	  66b609ab :  "Sketch App"   56a59ddd :  "After Effects"   bodymovin :  "BodyMovin"   lottie :  "Lottie"Installation and usage at: 
google-sketch2ae	Changes	Apache 2.0
google-skicka	skicka	Utility for working with files and folders stored on Google Drive.Note: skicka is not an official Google product!
google-skicka	Intro	skicka makes it easy to copy files to and from Google Drive and to work withfiles stored on Google Drive.For example, skicka upload ~/Pictures /Pictures copies the entirecontents of the local ~/Pictures directory to a folder Pictures inGoogle Drive
google-skicka	Intro	If you then run skicka download /Pictures ~/Pictures2,then the contents of your ~/Pictures2 directory will match the contentsof ~/Pictures.More generally, skicka makes it easy to list the files in Google Drivefolders, compute the space used by Drive folders, and copy files betweenyour computer to Google Drive
google-skicka	Intro	 If you'd like to encrypt your files beforeuploading them, skicka supports AES-256 encryption.
google-skicka	What skicka is not	skicka is not a general solution for automatically synchronizing filesstored in Google Drive across multiple machines
google-skicka	What skicka is not	In particular, it doesn'thave logic to reconcile concurrent changes to the same file on differentFurthermore, although skicka has been robust in usage so far and hasno known data corruption bugs, it should for now be treated as "alpha"software
google-skicka	What skicka is not	 Bug reports are welcome.
google-skicka	Getting Started	You must have a  Go  compiler installed.Download and build skicka: go get github.com/google/skickaEither copy the skicka executable in $GOPATH/bin to a directory inRun skicka init to create a skeleton ~/.skicka.config file
google-skicka	Getting Started	VariousAuthorize skicka to access your Google Drive files: run skicka ls,After skicka is authorized, it will download and locally cacheIf you're going store encrypted files in Google Drive, create anTry it out: run skicka ls -l /
google-skicka	Getting Started	A list of the files and foldersJoin the  mailing list 
google-skicka	Usage	For a general overview of skicka's commands, run skicka help.To copy a local directory hierarchy to Google Drive, use the uploadcommand
google-skicka	Usage	 As the upload progresses, skicka periodically reports howmuch data has been uploaded and how much time has elapsed.above in "Getting Started" and then use the SKICKA_PASSPHRASE environment variable; thus, you might use:download
google-skicka	Usage	As the download progresses, status is periodically reported:Drive
google-skicka	Usage	For example, after uploading your ~/Pictures directory, you mightand the local modification time that the file on Google Drive is syncedto
google-skicka	Usage	The file permissions are based on the permissions of the file when itwas uploaded to Google Drive
google-skicka	Usage	For even more detail, ls -ll can be used, which also prints the MD5checksums of the files on Google Drive
google-skicka	Usage	The contents of a single file can be downloaded using cat:command, the -p option can be specified to indicate that the intermediatedirectories in the path should be created .Drive folder can be reported by du:in Google Drive:use the -s command-line option to rm
google-skicka	Usage	 To remove a folder andeverything inside it, use -r.Finally, there is a fsck command that checks the file system on GoogleDrive for problems and verifies that the local cache of file metadata isin-sync with the files stored on Drive.
google-skicka	Can skicka work with Google Drive files that it didn't create itself?	Yes
google-skicka	Can skicka work with Google Drive files that it didn't create itself?	 The only limitations are that regular Google Drive files don't storethe Unix permissions or the local modification of the original file when itwas uploaded
google-skicka	Can skicka work with Google Drive files that it didn't create itself?	 Therefore, in this case skicka download uses 644permissions for files it creates and 755 permissions for directories.
google-skicka	skicka ls -l indicates that a file has world-readable permissions on Google Drive; does this mean anyone can access it?	No
google-skicka	skicka ls -l indicates that a file has world-readable permissions on Google Drive; does this mean anyone can access it?	 Those permissions are only used to set the local file permissions whenthe file is downloaded with skicka download
google-skicka	skicka ls -l indicates that a file has world-readable permissions on Google Drive; does this mean anyone can access it?	The access permissions forthe files stored on Drive are handled with Drive's regular mechanisms.
google-skicka	How can I speed up uploads?	There's a fixed per-file overhead for each file uploaded to Google Drivethat limits skicka to creating roughly five files a second; if files arerelatively small, this overhead will be more of a limit than the time spenttransferring the contents of the files.If the uploaded files don't need to be accessed individually, creating atar or zip archive of them before uploading may help in this case.
google-skicka	I occasionally see "operation timed out" or "broken pipe" errors when uploading; what's going on?	A variety of transient errors can happen when using RESTful APIs like theGoogle Drive API
google-skicka	I occasionally see "operation timed out" or "broken pipe" errors when uploading; what's going on?	 When these errors are encountered, skicka makes a numberof attempts to retry the operation before giving up.It may be that skicka should make more attempts before giving up or that there arebetter error handling strategies; one trade-off is that if there is aserious error  like the internet connection is lost , then it's useful forthe user to know this sooner rather than later.If you do see these errors, re-run the operation you were performing; anyfiles that weren't transferred the first time should be taken care of witha second run.
google-skicka	Does skicka support rate-limited uploads and downloads?	Yes
google-skicka	Does skicka support rate-limited uploads and downloads?	By default, skicka doesn't try to limit its bandwidth usage
google-skicka	Does skicka support rate-limited uploads and downloads?	 However,if you add a line  download  section of your .skicka.config file, you can specify amaximum number of bytes per second to transfer for uploads or downloads,If this line isn't present  or has a value of zero , then bandwidth won'tbe limited.
google-skicka	Can an http proxy be used with skicka?	Yes--just set the HTTP_PROXY environment variable appropriately.
google-skicka	"skicka"?!?	Swedish, "to send".
google-skicka	How files are stored in Google Drive	When a directory hierarchy is uploaded, Google Drive file is created foreach local file and a Google Drive folder is created for each localdirectory
google-skicka	How files are stored in Google Drive	skicka stores the time the local copy file was last modified inthe "modifiedDate" Google Drive File resource
google-skicka	How files are stored in Google Drive	 The Unix file permissionsof the file or directory are stored in using a custom "Permissions" fileproperty, stored as a string with the octal file permissions.See the discussion of encryption below for details about how encryptedfiles are represented.
google-skicka	Synchronization algorithm	When deciding if a local file needs to be uploaded to Google Drive,skicka performs the following checks.If there is no corresponding file on Drive, the local file will be uploaded.Otherwise, if there is a corresponding file on Drive and the sizes of the filesare different, the local file will be uploaded.Otherwise, if the local file's modification time is after the modification time ofthe file the last time it was synced to Drive, then an MD5 checksum of thefile contents is computed
google-skicka	Synchronization algorithm	If this checksum differs from the checksum ofthe file stored on Google Drive, the file will be uploaded
google-skicka	Synchronization algorithm	 Thus, iftouch is run on a file to update its modification time but thefile's contents aren't modified, skicka won't unnecessarily re-uploadthe file
google-skicka	Synchronization algorithm	Note that skicka trusts that file modification times are meaningful: if afile's contents are modified leaving the file size is unchanged and if themodification time is set to be in the past, then skicka won't compute anMD5 checksum and won't know that the file should be uploaded
google-skicka	Synchronization algorithm	To overridethis behavior, run skicka upload with the -ignore-times flag; if thisflag is provided, then the MD5 checksum check in the third step will beapplied regardless of the file modification time.Note also that this algorithm is an algorithm to efficiently mirror thecontents of a set of local files on Google Drive; it's not a generalbidirectional synchronization algorithm
google-skicka	Synchronization algorithm	 For example, if a file ismodified both on Drive and on the local filesystem, a skicka upload runwill clobber the file contents on Drive
google-skicka	Synchronization algorithm	In other words, the assumption isthat the source directory hierarchy is by definition the canonical one andthe destination directory's role is to perfectly reflect the source.When downloading from Google Drive, skicka follows the same generalapproach: only files that don't yet exist, have different sizes, ordifferent MD5 checksums from the corresponding local file will bedownloaded
google-skicka	Synchronization algorithm	The -ignore-times option can also be used to bypass the filemodification time check and to force a comparison of file contents todecide whether to download.
google-skicka	Encryption	If the -encrypt flag is provided to the upload command, skicka willencrypt the contents of each file before uploading it to Google Drive.Conversely, the download and cat commands transparently decryptencrypted files when downloading them  if the encryption key and passphraseare available! Encryption requires both an encryption key and a passphrase; yourpassphrase should be stored in the SKICKA_PASSPHRASE environmentvariable
google-skicka	Encryption	 To generate an encryption key, run skicka genkey
google-skicka	Encryption	For example:encryption key; to save your key, edit your ~/.skicka.config file and addthe printed text to the  encryption  section of the file
google-skicka	Encryption	 You can nowupload and encrypt files:data is lost forever.*this information.skicka only encrypts file contents: it doesn't encrypt filenames or hidefile sizes, for example
google-skicka	Encryption	 If this is problematic for your usage, you shouldprobably use tar or zip to put the files you want to encrypt into asingle file before uploading it.
google-skicka	Key generation and storage	When skicka genkey is executed, an encryption key is generated asskicka generates a random 32-byte salt using Go's rand.Reader  which returnscryptographically secure pseudo-random numbers
google-skicka	Key generation and storage	The hex-encoded salt isprinted out, and should be recorded in the encrypted-key-iv configuration file field.The encryption key from #4 is encrypted using the initialization vectorfrom #5, using the second 32 bytes of the hash computed in #2 as theencryption key
google-skicka	Key generation and storage	 The result should be copied to the encrypted-key fieldof the config file.Upon subsequent runs of skicka, the salt is loaded from the config fileso that PBKDF2 can be used as in #2 above to hash the user's passphrase
google-skicka	Key generation and storage	Ifthe first 32 bytes of the passphrase hash match the stored bytes, then thesecond 32 bytes of the hash and the stored IV are used to decrypt theencrypted encryption key.Given the encryption key, when a file is to be encrypted before beinguploaded to Google Drive, skicka uses the key along with a fresh16-byte initialization vector for each file to encrypt the file usingAES- The initialization vector is prepended to the file contentsbefore upload
google-skicka	Key generation and storage	 Thus, encrypted files are 16 bytes larger on Google Drivethan they are locally
google-skicka	Key generation and storage	The initialization vector is also stored hex-encoded as a Google Drive fileProperty with the name "IV"
google-skicka	Key generation and storage	We store the initialization vector redundantlyso that if one downloads the encrypted file contents, it's possible todecrypt the file using the file contents  and the key!   alone
google-skicka	Key generation and storage	Conversely,also having the IV available in a property makes it possible to encrypt thecontents of a local version of a file without needing to download any ofthe contents of the corresponding file from Google Drive.
google-skylark	Skylark in Go	This is the home of the _Skylark in Go_ project.Skylark in Go is an interpreter for Skylark, implemented in Go.Skylark is a dialect of Python intended for use as a configuration language.Like Python, it is an untyped dynamic language with high-level datatypes, first-class functions with lexical scope, and garbage collection.Unlike CPython, independent Skylark threads execute in parallel, soSkylark workloads scale well on parallel machines.Skylark is a small and simple language with a familiar and highlyreadable syntax
google-skylark	Skylark in Go	You can use it as an expressive notation forstructured data, defining functions to eliminate repetition, or youcan use it to add scripting capabilities to an existing application.A Skylark interpreter is typically embedded within a largerapplication, and the application may define additional domain-specificfunctions and data types beyond those provided by the core language.For example, Skylark was originally developed for the Bazel build tool Bazel uses Skylark as the notation both for its BUILD files  likeMakefiles, these declare the executables, libraries, and tests in adirectory  and for  its macrolanguage through which Bazel is extended with custom logic to support newlanguages and compilers.
google-skylark	Documentation	Build the code:coins = {  'dime': 10,  'nickel': 5,  'penny': 1,  'quarter': 25,print 'By name:\t' + ', '.join sorted coins.keys     print 'By value:\t' + ', '.join sorted coins.keys  , key=coins.get   By name:	dime, nickel, penny, quarterBy value:	penny, nickel, dime, quarterInteract with the read-eval-print loop  REPL :
google-skylark	Contributing	We welcome submissions but please let us know what you're working onif you want to change or add to the Skylark repository.Before undertaking to write something new for the Skylark project,please file an issue or claim an existing issue.All significant changes to the language or to the interpreter's GoAPI must be discussed before they can be accepted.This gives all participants a chance to validate the design and toavoid duplication of effort.Despite some differences, the Go implementation of Skylark strives tomatch the behavior of the Java implementation used by Bazel.For that reason, proposals to change the language itself shouldgenerally be directed to the Bazel team, not to the maintainers ofthis project.Only once there is consensus that a language change is desirable mayits Go implementation proceed.We use GitHub pull requests for contributions.Please complete Google's contributor license agreement  CLA  beforesending your first change to the project
google-skylark	Contributing	 If you are the copyrightholder, you will need to agree to the individual contributor license agreement which can be completed online.If your organization is the copyright holder, the organization willneed to agree to the  corporate contributor license agreement If the copyright holder for your contribution has already completedthe agreement in connection with another Google open source project,it does not need to be completed again.
google-skylark	Stability	We reserve the right to make breaking language and API changes at thisstage in the project, although we will endeavor to keep them to a minimum.Once the project has its long-term name  see below  and location, andthe Bazel team has finalized the version 1 language specification,we will be more rigorous with interface stability.
google-skylark	Credits	Skylark was designed and implemented in Java byUlf Adams,Lukács Berki,Jon Brandvein,John Field,Laurent Le Brun,Dmitry Lomov,Damien Martin-Guillerez,Vladimir Moskva, andFlorian Weikert,standing on the shoulders of the Python community.The Go implementation was written by Alan Donovan and Jay Conrod;its scanner was derived from one written by Russ Cox.
google-skylark	Legal	Skylark in Go is Copyright  c  2017 The Bazel Authors.All rights reserved.It is provided under a 3-clause BSD license: LICENSE The name "Skylark" is a code name of the Bazel project.We plan to rename the language before the end of 2017 to reflect itsapplicability to projects unrelated to Bazel.Skylark in Go is not an official Google product.
google-sling	SLING 	  SLING is a parser for annotating text with frame semantic annotations
google-sling	SLING 	It istrained on an annotated corpus using  Tensorflow and  Dragnn The parser is a general transition-based frame semantic parser usingbi-directional LSTMs for input encoding and a Transition Based Recurrent Unit TBRU  for output decoding
google-sling	SLING 	It is a jointly trained model using only the texttokens as input and the transition system has been designed to output framegraphs directly without any intervening symbolic representation.! SLING neural network architecture
google-sling	SLING 	 ./doc/report/network.svg The SLING framework includes an efficient and scalable frame storeimplementation as well as a neural network JIT compiler for fast parsing atA more detailed description of the SLING parser can be found in this paper:This is SEMPAR, the first generation of the SLING parser
google-sling	SLING 	We have started to work on CASPAR, the second generation of the parser, which can be found  here 
google-sling	Trying out the parser	If you just want to try out the parser on a pre-trained model, you can installthe wheel with pip and download a pre-trained parser model
google-sling	Trying out the parser	On a Linux machinewith Python 2.7 you can install a pre-built wheel:import slingparser = sling.Parser "sempar.flow" text = raw_input "text: " doc = parser.parse text print doc.frame.data pretty=True for m in doc.mentions:  print "mention", doc.phrase m.begin, m.end 
google-sling	Installation	First, make sure that the repository is cloned with --recursive, so that youget all the submodules.distribution of Tensorflow, so this needs to be installed
google-sling	Installation	The installed versionof protocol buffers needs to match the version used by Tensorflow
google-sling	Installation	Finally,SLING uses  Bazel  as the build system, so you need toinstall Bazel in order to build the SLING parser.Operating system: LinuxLanguages: C++ 11  GCC 4 and above , Python 2.7, assemblerCPU: Intel x64 or compatibleBuild system: BazelYou can test your installation by building a few important targets.includes, try the following:Training a new model consists of preparing the commons store and the trainingdata, specifying various options and hyperparameters in the training script,and tracking results as training progresses
google-sling	Installation	These are described below in
google-sling	Data preparation	The first step consists of preparing the commons store  also called global store 
google-sling	Data preparation	This has frame andschema definitions for all types and roles of interest, e.g./saft/person or /pb/love-01 or /pb/arg0
google-sling	Data preparation	In order to build the commons storefor the OntoNotes-based parser you need to checkout PropBank in a directoryparallel to the SLING directory:Next, write a converter to convert documents in your existing format to SLING documents  sling/nlp/document/document.h 
google-sling	Data preparation	A SLING document is just adocument frame of type /s/document
google-sling	Data preparation	An example of such a frame in textual encodingcan be seen below
google-sling	Data preparation	It is best to create one SLING document per input sentence.For writing your converter or getting a better hold of the concepts of frames and store in SLING, you can have a look at detailed deep dive on frames and stores  here  sling/frame/README.md .The SLING  Document class  sling/nlp/document/document.h also has methods to incrementally make such document frames, e.g.Store global;// Read global store from a file via LoadStore  .// Lookup handles in advance.Handle h_person = global.Lookup "/saft/person" ;Handle h_love01 = global.Lookup "/pb/love-01" ;Handle h_arg0 = global.Lookup "/pb/arg0" ;Handle h_arg1 = global.Lookup "/pb/arg1" ;// Prepare the document.Store store &global ;Document doc &store ;  // empty document// Add token information.doc.SetText "John loves Mary" ;doc.AddToken 0, 4, "John", 0 ;doc.AddToken 5, 10, "loves", 1 ;doc.AddToken 11, 15, "Mary", 1 ;// Create frames that will eventually be evoked.Builder b1 &store ;b1.AddIsA h_person ;Frame john_frame = b1.Create  ;Builder b2 &store ;b2.AddIsA h_person ;Frame mary_frame = b2.Create  ;Builder b3 &store ;b3.AddIsA h_love01 ;b3.Add h_arg0, john_frame ;b3.Add h_arg1, mary_frame ;Frame love_frame = b3.Create  ;
google-sling	Add spans and evoke frames from them.	doc.AddSpan 0, 1 ->Evoke john_frame ;doc.AddSpan 1, 2 ->Evoke love_frame ;doc.AddSpan 2, 3 ->Evoke mary_frame ;doc.Update  ;string encoded = Encode doc.top   ;// Write 'encoded' to a zip stream or a file.Use the converter to create the following corpora:+ Training corpus of annotated SLING documents.+ Dev corpus of annotated SLING documents
google-sling	Add spans and evoke frames from them.	 per document, and the file for a document is just its encoded document  frame
google-sling	Add spans and evoke frames from them.	An alternate format is to have a folder with one file per  document
google-sling	Add spans and evoke frames from them.	More formats can be added by modifying the reader code here  and  here 
google-sling	Specify training options and hyperparameters:	Once the commons store and the corpora have been built, you are ready for traininga model
google-sling	Specify training options and hyperparameters:	For this, use the supplied  training script  sling/nlp/parser/tools/train.sh .The script provides various commandline arguments
google-sling	Specify training options and hyperparameters:	The ones that specifythe input data are:+ --commons: File path of the commons store built in the previous step.+ --train: Path to the training corpus built in the previous step.+ --dev: Path to the annotated dev corpus built in the previous step.+ --output or --output_dir: Output folder where checkpoints, master spec,  temporary files, and the final model will be saved.Then we have the various training options and hyperparameters:+ --oov_features: Whether fallback lexical features should be used in the LSTMs.+ --word_embeddings: Empty, or path to pretrained word embeddings in   Mikolov's word2vec format   If supplied, these are used to initialize the embeddings for word features.+ --word_embeddings_dim: Dimensionality of embeddings for word features
google-sling	Specify training options and hyperparameters:	 Should be the same as the pretrained embeddings, if they are supplied.+ --batch: Batch size used during training.+ --report_every: Checkpoint interval.+ --train_steps: Number of training steps.+ --method: Optimization method to use  e.g
google-sling	Specify training options and hyperparameters:	adam or momentum , along  with auxiliary arguments like --adam_beta1, --adam_beta2, --adam_eps.+ --dropout_keep_rate: Probability of keeping after dropout during  training , so --dropout_keep_rate=1.0 means nothing is dropped.+ --learning_rate: Learning rate.+ --decay: Decay steps.+ --grad_clip_norm: Max norm beyond which gradients will be clipped.+ --moving_average: Whether or not to use exponential moving average.+ --seed, --seed2: Randomization seeds used for initializing embedding matrices.The script comes with reasonable defaults for the hyperparameters fortraining a semantic parser model, but it would be a good idea to hardcodeyour favorite arguments  directly in thescript to avoid supplying them again and again on the commandline.
google-sling	Run the training script	To test your training setup, you can kick off a small training run:This training run should be over in 10-20 minutes, and should checkpoint andevaluate after every 500 steps
google-sling	Run the training script	For a full-training run, we suggest increasingthe number of steps to something like 100,000 and decreasing the checkpointfrequency to something like every 2000-5000 steps.As training proceeds, the training script produces a lot of usefuldiagnostic information, which we describe below
google-sling	Run the training script	 The table and its summary are dumped in $OUTPUT_FOLDER/{table,  table.summary}, and this path is logged by the script in its output
google-sling	Run the training script	 For example, here is the action table summary for the  semantic parsing model included in this release:    ===================================================  Action Type || Unique Arg Combinations || Raw Count  ===================================================  ===================================================      completely specifies the configuration of the two LSTMs and the feed forward  unit, including the features used by each component, and the dimensions of  the various embeddings
google-sling	Run the training script	 then you would have to modify the  MasterSpec generation code   and add any new feature definitions  here   and/or  here  Recall however that  --word_embeddings_dim, --pretrained_embeddings, and --oov_features  allow you to do some of this directly from the commandline
google-sling	Run the training script	 being dumped at $OUTPUT_FOLDER/master_spec as a textualized protocol  buffer, so you can visually check whether the configuration looks good or not
google-sling	Run the training script	 will finish here
google-sling	Run the training script	This is useful for first ascertaining that the spec and  action table look right, particularly while debugging or running a new  training setup for the first time
google-sling	Run the training script	 that it's creating a log directory for running  Tensorboard   Wrote events  incl
google-sling	Run the training script	graph  for Tensorboard to folder: /my/output/folder/tensorboard  The graph can be viewed via  tensorboard --logdir=/my/output/folder/tensorboard  then navigating to  and clicking on 'GRAPHS'    training, particularly the evaluation metrics at various checkpoints
google-sling	Run the training script	 It also allows you to view the Tensorflow graph used for training
google-sling	Run the training script	 shell  INFO:tensorflow:Initial cost at step 0: 2.949682  INFO:tensorflow:cost at step 100: 1.218417  INFO:tensorflow:cost at step 200: 0.991216  INFO:tensorflow:cost at step 300: 0.838045      After every checkpoint interval  specified via --report_every ,  it will save the model and evaluate it on the dev corpus
google-sling	Run the training script	 The evaluation runs a  graph matching algorithm  sling/nlp/parser/trainer/frame-evaluation.h   that outputs various metrics from aligning the gold frame graph  vs the test frame graph
google-sling	Run the training script	If you are looking for a single number to  quantify your model, then we suggest using **SLOT_F1**, which aggregates across  frame type and role accuracies  i.e
google-sling	Run the training script	both node and edge alignment scores 
google-sling	Run the training script	 it with an extrinsic evaluation, then just replace the binary   here  with your evaluation binary
google-sling	Run the training script	 different training options without really wanting to change the spec,  or the action table, or any lexical resources
google-sling	Run the training script	For this, use the  --train_only commandline argument
google-sling	Run the training script	This will initiate training from  the Tensorflow graph generation step, and will use the pre-generated spec  etc
google-sling	Run the training script	from the same output folder.We have made a synthetic training and evaluation corpus available for trying out the parser
google-sling	Parsing	The trained parser model is stored in a  Myelin  sling/myelin/README.md  flow file,e.g
google-sling	Parsing	sempar.flow
google-sling	Parsing	It contains all the information needed for parsing text:A pre-trained model can be download from  here The model can be loaded and initialized in the following way:
google-sling	#include "sling/nlp/parser/parser.h"	// Load parser model.sling::Store commons;sling::nlp::Parser parser;parser.Load &commons, "/tmp/sempar.flow" ;commons.Freeze  ;// Create document tokenizer.sling::nlp::DocumentTokenizer tokenizer;In order to parse some text, it first needs to be tokenized
google-sling	#include "sling/nlp/parser/parser.h"	The document withtext, tokens, and frames is stored in a local document frame store.// Create frame store for document.sling::Store store &commons ;sling::nlp::Document document &store ;// Tokenize text.string text = "John hit the ball with a bat.";tokenizer.Tokenize &document, text ;// Parse document.parser.Parse &document ;document.Update  ;// Output document annotations.std::cout << sling::ToText document.top  , 2 ;
google-sling	Annotation Tools	SLING comes with utility tools for annotating a corpus of documents with framesusing a parser model, benchmarking this annotation process, and optionallyevaluating the annotated frames against supplied gold frames.We provide two such tools - tf-parse  sling/nlp/parser/tools/tf-parse.py  Python script, and a  Myelin-basedparser tool  sling/nlp/parser/tools/parse.cc .Given the same trained parser model, both these tools should producethe same annotated frames and evaluation numbers
google-sling	Annotation Tools	However the Myelin-basedparser is significantly faster than Tensorflow-based tf-parse   3x-10x in ourexperiments 
google-sling	Myelin-based parser tool	This tool takes the following commandline arguments:
google-sling	Tensorflow-based parser tool	An alternative to running the Myelin-based parsing tool is to run the tf-parsePython script that executes the annotation part of the Tensorflow graph over theinput documents
google-sling	Tensorflow-based parser tool	It takes the following arguments:Sample Usage:
google-sling	Credits	Original authors of the code in this package include:
google-slowfs	#SlowFS	SlowFS is a FUSE filesystem written in Go to simulate physical media for testingpurposes
google-slowfs	#SlowFS	SlowFS works by mirroring a backing directory to another directory,and then making accesses to files in that directory take a specified amountof time
google-slowfs	#SlowFS	SlowFS can model things like seek time, throughput, sequential / nonFor addition details, run SlowFS with the help flag:  slowfs --helpThis is not an official Google product.
google-slowfs	##Basic Usage	Example invocation:  slowfs --backing-dir=my-backing-dir --mount-dir=my-mount-dir
google-slowfs	##Configuration Files	You can specify an optional configuration file listing configurations in JSON,and then pass that as an argument.Example invocation:  slowfs --backing-dir=my-backing-dir --mount-dir=my-mount-dir \
google-slowfs	###Overriding Values	You can also override any option through the corresponding command line flag.For example, if you would like to change seek time:  slowfs --backing-dir=my-backing-dir --mount-dir=my-mount-dir \
google-snappy-start	snappy-start: Tool for process startup snapshots	snappy-start is a tool which takes a snapshot of a Linux program's processstate after it has started up
google-snappy-start	snappy-start: Tool for process startup snapshots	 It allows multiple instances of the programto be quickly launched from the snapshot.This has two potential benefits:
google-snappy-start	Usage	First, build the tool by running make.sh  which also runs some tests .To create a snapshot:syscall, such as getpid  .Currently, the snapshot data is written to hard-coded files out_info containing register state and a list of memory mappings  and out_pages data to restore using mmap   .The idea for this tool comes from Kenton Varda, who proposed using a"record/replay" approach, using ptrace   to monitor syscalls so thatthey can later be replayed.
google-souper	Requirements	Souper should work on any reasonably modern Linux or OS X machine.You will need a reasonably modern compiler toolchain
google-souper	Requirements	LLVM has instructionson how to get one for Linux:You will also need CMake to build Souper and its dependencies.To run Souper over a bitcode file, you will need an SMT solver
google-souper	Requirements	Soupercan use Z3, Boolector, CVC4, or STP
google-souper	Requirements	We recommend ZIf you have Go installed, you will also need the Redigo Redis client:
google-souper	Building Souper	Download and build dependencies:Run CMake from a build directory:Run 'make' from the build directory.Optionally run 'make check' to run Souper's test suite
google-souper	Building Souper	To run the test suiteNote that GCC 4.8 and earlier have a bug in handling multiline stringliterals
google-souper	Building Souper	You should build Souper using GCC 4.9+ or Clang.
google-souper	Using Souper	After following the above instructions, you will have a Souperexecutable in /path/to/souper-build/souper and a Clang executable in/path/to/souper/third_party/llvm/$buildtype/bin/clang
google-souper	Using Souper	 You can use theClang executable to create an LLVM bitcode file like this:Once you have a bitcode file you can invoke Souper with the path to thebitcode file as a command line argument
google-souper	Using Souper	You will also need one of theseflags to tell Souper where the SMT solver executable is:Souper will extract SMT queries from the bitcode file and pass them toa solver
google-souper	Using Souper	Unsatisfiable queries  which represent missed optimizationopportunities  will cause Souper to print its internal representationof the optimizable expression along with the shorter expression thatrefines the original one.Alternatively, you may immediately let Souper modify the bitcode and letit apply the missed optimization opportunities by using the Souper llvm optpass
google-souper	Using Souper	When loaded the pass will automatically register itself to run afterLLVM's regular peephole optimizations.For example:Or to run the pass on its own:Or use the drop-in compiler replacements sclang and sclang++:Compilation using Souper can be sped up by caching queries
google-souper	Using Souper	By default, Souperuses a non-persistent RAM-based cache
google-souper	Using Souper	The -souper-external-cache flag causesSouper to cache its queries in a Redis database
google-souper	Using Souper	For this to work, Redis >=1.2.0 must be installed on the machine where you are running Souper and a Redisserver must be listening on the default port  6379 .sclang uses external caching by default since this often gives a substantialspeedup for large compilations
google-souper	Using Souper	This behavior may be disabled by setting theSOUPER_NO_EXTERNAL_CACHE environment variable
google-souper	Using Souper	Souper's Redis cache does not yethave any support for versioning; you should stop Redis and delete its dump fileany time Souper is upgraded.
google-souper	Disclaimer	Please note that although some of the authors are employed by Google, thisis not an official Google product.
google-source_transformer.dart	source_transformer	_NOTE: This project is **not***This package is currently in development**Not to be confused with source_transformer is a library for building and applyingmodifications to existing files, primarily .dart source files, and tocommit the results of those changes.Example uses:import 'package:source_transformer/source_transformer.dart';main List paths  async {  await runTransformer const DeduplicateDirectives  , paths ;
google-spatial-media	Spatial Media	A collection of specifications and tools for 360&deg; video and spatial audio, including:
google-spline	Disclaimers	**This is not an official Google product.**
google-sprockets	Sprockets     ! LICENSE   LICENSE 	*Last updated at 2016-11-30*
google-sprockets	Disclaimer	Sprockets is a framework for conformance testing based on state transitions.To run conformance tests, Sprockets users should provide:test_driver.py is the main program made of Python to run conformance tests specified by users with a test manifest, STL files, and python libraries.
google-sprockets	2.Environment Setup	To run test_driver.py, extra python packages below are necessary:
google-sprockets	2.Options	usage: test_driver.py  -h   -a MANIFEST_ARGS   -d  manifestpositional arguments:  manifestoptional arguments:  -h, --help  -a MANIFEST_ARGS, --manifest-args MANIFEST_ARGS  -d, --debug
google-sprockets	Test Manifest	The **test manifest*
google-sprockets	3.Example manifest	example.test:  'stl_files':     ,   ,  },
google-sprockets	3.stl_files	The ‘stl_files’ field must be a list of strings naming the STL files that include the transitions to be tested
google-sprockets	3.stl_files	The filenames here should be relative to the manifest .test file
google-sprockets	3.stl_files	In the example above,  example.test  example/example.test  and  example_base.stl  example/example_base.stl  are in the same directory.
google-sprockets	3.roles	The ‘roles’ field must be list of dicts
google-sprockets	3.roles	Each dict element in the list describes one role
google-sprockets	3.roles	These are the roles described in the stl_files listed in the ‘stl_files’ field
google-sprockets	3.roles	In the above example,  example_base.stl  example/example_base.stl  contains the following:example.stl:module example;role rReceiver {  string ipAddress;  string transportId;...This gets transformed intoThe ‘role’ key maps to the ‘module:rRoleName’, which in this case is ‘example::rReceiver’.The remaining key: value pairs map to the fields of the role as described in the STL file.
google-sprockets	3.constants	The ‘constants’ field must be a dictionary
google-sprockets	3.constants	Each entry in the dictionary defines a declared constant described in the stl_files listed in the ‘stl_files’ field
google-sprockets	3.constants	In the above example,  example_base.stl  example/example_base.stl  contains the following:example_base.stl:module example;const string kHelloWorld;This value gets defined in the manifest here:
google-sprockets	3.test	The ‘test’ field must be a list of strings naming the roles to be tested
google-sprockets	3.test	Each entry in the test list must correspond to a ‘role’ value in the ‘roles’ list.
google-sprockets	3.Substituting Parameters	Values can be substituted from the command line by passing a space separated list of = pairs to the --manifest-args option of test\_driver.py
google-sprockets	3.Substituting Parameters	The manifest .test file will then replace any occurence of parameter_example.test:}This is exactly equivalent to running with the following manifest:parameter_example_with_substitues.test:}
google-squidwarden	Squidwarden	Frontend to managaging ACLs for the Squid proxy.Copyright 2016 Google Inc
google-squidwarden	Squidwarden	All Rights Reserved.Apache 2.0 license.This is NOT a Google product.Contact: thomas@habets.se / habets@google.com
google-squidwarden	Install	TODO: This procedure is untested.
google-squidwarden	TODO: Not all of these settings may be needed.	http_port 3128via offforwarded_for delete
google-squidwarden	error_directory /etc/squid3/myerrors	acl success_hier hier_code HIER_DIRECTacl failure_hier hier_code HIER_NONEaccess_log daemon:/var/log/squid3/access.log squid failure_hierexternal_acl_type ext ttl=10 concurrency=2 %PROTO %SRC %METHOD %URI /usr/local/bin/proxyacl -db=/var/spool/squid3/proxyacl.sqlite -log=/var/log/squid3/proxyacl.log -block_log=/var/log/squid3/proxyacl.blocklogacl ext_acl external exthttp_access allow ext_aclvisible_hostname my.proxy.hostname.here.example.com
google-squidwarden	Default suffix.	http_access deny allThen point browser to  the UI  and get started.
google-squidwarden	Run UI via nginx	It can be a good idea to run through a real web server such as nginx,so that you don't have to remember which port it runs on
google-squidwarden	Run UI via nginx	It also makesit easier to set up TLS.FastCGI is nice, but doesn't support websockets
google-squidwarden	Run UI via nginx	When -fcgi issupplied, squidwarden will therefore not use websockets.
google-sshkey-audit	sshkey-audit	This is not an official Google product.
google-sshkey-audit	Example	ssh-rsa AAAAAhuteonhuneo… my-awesome-laptopssh-rsa AAAAhtuhsotiesi…  carol@my-desktopssh-rsa AAAAhtuhutnuheo…  corp@work-laptopssh-rsa AAAAhtuhuueoueo…  my-manager@their-work-laptopworklaptops my-awesome-laptop corp@work-laptopbob@foo.example.comirc@my-irc.shelladmin@my-router.lan:/etc/dropbear/authorized_keys @home  carol@my-desktop  my-awesome-laptop  corp@work-laptop  my-awesome-laptop  my-manager@their-work-laptop  carol@my-desktop  corp@work-laptop  my-awesome-laptop  carol@my-desktop  corp@work-laptop  my-awesome-laptop  carol@my-desktop  my-awesome-laptop … tool logs in to all accounts and checks that this is correct …  … tool logs in to all accounts and adds any missing keys  …  … tool logs in to all accounts and deletes any extraneous keys  … Adding the carol@my-desktop.lan can sometimes be useful to ssh localhost.
google-ssl_logger	ssl_logger	Decrypts and logs a process's SSL traffic.The functionality offered by *ssl_logger
google-ssl_logger	Basic Usage	python ssl_logger.py  -pcap    -verbose  
google-ssl_logger	Full Example	geffner@ubuntu:~geffner@ubuntu:~geffner@ubuntu:~ 2  98962Press Ctrl+C to stop logging.geffner@ubuntu:~SSL Session: 1820201001719DF42ECCA1D289C3D32E0AA0454B50E8AF00E8A65B0108F209A8 SSL_write  100.97.20.44:45836 --> 93.184.216.34:44300000000: 0ASSL Session: 1820201001719DF42ECCA1D289C3D32E0AA0454B50E8AF00E8A65B0108F209A8 SSL_read  93.184.216.34:443 --> 100.97.20.44:4583600000000: 48 54 54 50 2F 31 2E 30  20 32 30 30 20 4F 4B 0D  HTTP/1.0 200 OK.00000010: 0A 41 63 63 65 70 74 2D  52 61 6E 67 65 73 3A 20  .Accept-Ranges: 00000020: 62 79 74 65 73 0D 0A 43  61 63 68 65 2D 43 6F 6E  bytes..Cache-Con00000030: 74 72 6F 6C 3A 20 6D 61  78 2D 61 67 65 3D 36 30  trol: max-age=6000000040: 34 38 30 30 0D 0A 43 6F  6E 74 65 6E 74 2D 54 79  4800..Content-Ty00000050: 70 65 3A 20 74 65 78 74  2F 68 74 6D 6C 0D 0A 44  pe: text/html..D00000060: 61 74 65 3A 20 54 68 75  2C 20 32 32 20 4A 75 6E  ate: Thu, 22 Jun00000070: 20 32 30 31 37 20 31 35  3A 31 36 3A 35 32 20 47   2017 15:16:52 G00000080: 4D 54 0D 0A 45 74 61 67  3A 20 22 33 35 39 36 37  MT..Etag: "3596700000090: 30 36 35 31 22 0D 0A 45  78 70 69 72 65 73 3A 20  0651"..Expires: 000000A0: 54 68 75 2C 20 32 39 20  4A 75 6E 20 32 30 31 37  Thu, 29 Jun 2017000000B0: 20 31 35 3A 31 36 3A 35  32 20 47 4D 54 0D 0A 4C   15:16:52 GMT..L000000C0: 61 73 74 2D 4D 6F 64 69  66 69 65 64 3A 20 46 72  ast-Modified: Fr000000D0: 69 2C 20 30 39 20 41 75  67 20 32 30 31 33 20 32  i, 09 Aug 2013 2000000E0: 33 3A 35 34 3A 33 35 20  47 4D 54 0D 0A 53 65 72  3:54:35 GMT..Ser000000F0: 76 65 72 3A 20 45 43 53  20 28 72 68 76 2F 38 31  ver: ECS  rhv/8100000100: 38 46 29 0D 0A 56 61 72  79 3A 20 41 63 63 65 70  8F ..Vary: Accep00000110: 74 2D 45 6E 63 6F 64 69  6E 67 0D 0A 58 2D 43 61  t-Encoding..X-Ca00000120: 63 68 65 3A 20 48 49 54  0D 0A 43 6F 6E 74 65 6E  che: HIT..Conten00000130: 74 2D 4C 65 6E 67 74 68  3A 20 31 32 37 30 0D 0A  t-Length: 00000140: 43 6F 6E 6E 65 63 74 69  6F 6E 3A 20 63 6C 6F 73  Connection: clos00000150: 65 0D 0A 0D 0ASSL Session: 1820201001719DF42ECCA1D289C3D32E0AA0454B50E8AF00E8A65B0108F209A8 SSL_read  93.184.216.34:443 --> 100.97.20.44:4583600000000: 3C 21 64 6F 63 74 79 70  65 20 68 74 6D 6C 3E 0A  .00000010: 3C 68 74 6D 6C 3E 0A 3C  68 65 61 64 3E 0A 20 20  .
google-ssl_logger	Full Example	 00000020: 20 20 3C 74 69 74 6C 65  3E 45 78 61 6D 70 6C 6500000030: 20 44 6F 6D 61 69 6E 3C  2F 74 69 74 6C 65 3E 0A   Domain.00000040: 0A 20 20 20 20 3C 6D 65  74 61 20 63 68 61 72 73  .00000050: 65 74 3D 22 75 74 66 2D  38 22 20 2F 3E 0A 20 20  et="utf-8" />
google-ssl_logger	Full Example	 00000060: 20 20 3C 6D 65 74 61 20  68 74 74 70 2D 65 71 7500000070: 69 76 3D 22 43 6F 6E 74  65 6E 74 2D 74 79 70 65  iv="Content-type00000080: 22 20 63 6F 6E 74 65 6E  74 3D 22 74 65 78 74 2F  " content="text/00000090: 68 74 6D 6C 3B 20 63 68  61 72 73 65 74 3D 75 74  html; charset=ut000000A0: 66 2D 38 22 20 2F 3E 0A  20 20 20 20 3C 6D 65 74  f-8" />.000000B0: 61 20 6E 61 6D 65 3D 22  76 69 65 77 70 6F 72 74  a name="viewport000000C0: 22 20 63 6F 6E 74 65 6E  74 3D 22 77 69 64 74 68  " content="width000000D0: 3D 64 65 76 69 63 65 2D  77 69 64 74 68 2C 20 69  =device-width, i000000E0: 6E 69 74 69 61 6C 2D 73  63 61 6C 65 3D 31 22 20  nitial-scale=1" 000000F0: 2F 3E 0A 20 20 20 20 3C  73 74 79 6C 65 20 74 79  />.00000100: 70 65 3D 22 74 65 78 74  2F 63 73 73 22 3E 0A 20  pe="text/css">
google-ssl_logger	Full Example	00000110: 20 20 20 62 6F 64 79 20  7B 0A 20 20 20 20 20 2000000120: 20 20 62 61 63 6B 67 72  6F 75 6E 64 2D 63 6F 6C00000130: 6F 72 3A 20 23 66 30 66  30 66 32 3B 0A 20 20 20  or: #f0f0f2;.00000150: 20 20 20 20 20 20 20 20  70 61 64 64 69 6E 67 3A00000160: 20 30 3B 0A 20 20 20 20  20 20 20 20 66 6F 6E 74   0;.00000170: 2D 66 61 6D 69 6C 79 3A  20 22 4F 70 65 6E 20 53  -family: "Open S00000180: 61 6E 73 22 2C 20 22 48  65 6C 76 65 74 69 63 61  ans", "Helvetica00000190: 20 4E 65 75 65 22 2C 20  48 65 6C 76 65 74 69 63   Neue", Helvetic000001A0: 61 2C 20 41 72 69 61 6C  2C 20 73 61 6E 73 2D 73  a, Arial, sans-s000001B0: 65 72 69 66 3B 0A 20 20  20 20 20 20 20 20 0A 20  erif;.000001C0: 20 20 20 7D 0A 20 20 20  20 64 69 76 20 7B 0A 20000001D0: 20 20 20 20 20 20 20 77  69 64 74 68 3A 20 36 30000001E0: 30 70 78 3B 0A 20 20 20  20 20 20 20 20 6D 61 72  0px;.000001F0: 67 69 6E 3A 20 35 65 6D  20 61 75 74 6F 3B 0A 20  gin: 5em auto;
google-ssl_logger	Full Example	00000200: 20 20 20 20 20 20 20 70  61 64 64 69 6E 67 3A 2000000210: 35 30 70 78 3B 0A 20 20  20 20 20 20 20 20 62 61  50px;.00000220: 63 6B 67 72 6F 75 6E 64  2D 63 6F 6C 6F 72 3A 20  ckground-color: 00000230: 23 66 66 66 3B 0A 20 20  20 20 20 20 20 20 62 6F  #fff;.00000240: 72 64 65 72 2D 72 61 64  69 75 73 3A 20 31 65 6D  rder-radius: 1em00000250: 3B 0A 20 20 20 20 7D 0A  20 20 20 20 61 3A 6C 69  ;.00000260: 6E 6B 2C 20 61 3A 76 69  73 69 74 65 64 20 7B 0A  nk, a:visited {.00000270: 20 20 20 20 20 20 20 20  63 6F 6C 6F 72 3A 20 2300000280: 33 38 34 38 38 66 3B 0A  20 20 20 20 20 20 20 20  38488f;.000002A0: 20 6E 6F 6E 65 3B 0A 20  20 20 20 7D 0A 20 20 20   none;.000002B0: 20 40 6D 65 64 69 61 20  28 6D 61 78 2D 77 69 64   @media  max-wid000002C0: 74 68 3A 20 37 30 30 70  78 29 20 7B 0A 20 20 20  th: 700px  {.000002E0: 20 20 20 20 20 20 20 20  62 61 63 6B 67 72 6F 75000002F0: 6E 64 2D 63 6F 6C 6F 72  3A 20 23 66 66 66 3B 0A  nd-color: #fff;.00000300: 20 20 20 20 20 20 20 20  7D 0A 20 20 20 20 20 2000000310: 20 20 64 69 76 20 7B 0A  20 20 20 20 20 20 20 2000000320: 20 20 20 20 77 69 64 74  68 3A 20 61 75 74 6F 3B00000330: 0A 20 20 20 20 20 20 20  20 20 20 20 20 6D 61 72  .00000340: 67 69 6E 3A 20 30 20 61  75 74 6F 3B 0A 20 20 20  gin: 0 auto;.00000370: 20 20 20 20 20 20 20 70  61 64 64 69 6E 67 3A 2000000380: 31 65 6D 3B 0A 20 20 20  20 20 20 20 20 7D 0A 20  1em;.00000390: 20 20 20 7D 0A 20 20 20  20 3C 2F 73 74 79 6C 65000003A0: 3E 20 20 20 20 0A 3C 2F  68 65 61 64 3E 0A 0A 3C  >000003B0: 62 6F 64 79 3E 0A 3C 64  69 76 3E 0A 20 20 20 20  body>..000003D0: 69 6E 3C 2F 68 31 3E 0A  20 20 20 20 3C 70 3E 54  in.000003E0: 68 69 73 20 64 6F 6D 61  69 6E 20 69 73 20 65 73  his domain is es000003F0: 74 61 62 6C 69 73 68 65  64 20 74 6F 20 62 65 20  tablished to be SSL Session: 1820201001719DF42ECCA1D289C3D32E0AA0454B50E8AF00E8A65B0108F209A8 SSL_read  93.184.216.34:443 --> 100.97.20.44:4583600000000: 75 73 65 64 20 66 6F 72  20 69 6C 6C 75 73 74 72  used for illustr00000010: 61 74 69 76 65 20 65 78  61 6D 70 6C 65 73 20 69  ative examples i00000020: 6E 20 64 6F 63 75 6D 65  6E 74 73 2E 20 59 6F 75  n documents
google-ssl_logger	Full Example	You00000030: 20 6D 61 79 20 75 73 65  20 74 68 69 73 0A 20 20   may use this
google-ssl_logger	Full Example	 00000040: 20 20 64 6F 6D 61 69 6E  20 69 6E 20 65 78 61 6D00000050: 70 6C 65 73 20 77 69 74  68 6F 75 74 20 70 72 69  ples without pri00000060: 6F 72 20 63 6F 6F 72 64  69 6E 61 74 69 6F 6E 20  or coordination 00000070: 6F 72 20 61 73 6B 69 6E  67 20 66 6F 72 20 70 65  or asking for pe00000080: 72 6D 69 73 73 69 6F 6E  2E 3C 2F 70 3E 0A 20 20  rmission.
google-ssl_logger	Full Example	 00000090: 20 20 3C 70 3E 3C 61 20  68 72 65 66 3D 22 68 74000000A0: 74 70 3A 2F 2F 77 77 77  2E 69 61 6E 61 2E 6F 72  tp://www.iana.or000000B0: 67 2F 64 6F 6D 61 69 6E  73 2F 65 78 61 6D 70 6C  g/domains/exampl000000C0: 65 22 3E 4D 6F 72 65 20  69 6E 66 6F 72 6D 61 74  e">More informat000000D0: 69 6F 6E 2E 2E 2E 3C 2F  61 3E 3C 2F 70 3E 0A 3C  ion......</000000F0: 68 74 6D 6C 3E 0A
google-ssl_logger	Dependencies	This program uses the  frida  framework to perform code injection.Frida can be installed as follows: sudo pip install frida
google-ssl_logger	TODO	This is not an official Google product.
google-startup-os	StartupOS	 ! Gitter   ! CircleCI  > Examples for Google's Open Source stack and deployment to the cloud.The main technologies in the stack are:Try cloning the repo in Google Cloud Shell and look at the tutorials: ! Open in Cloud Shell  
google-startup-os	Supported languages	Protos, gRPC and Bazel are polyglot
google-startup-os	Supported languages	The examples in this repo are mostly in Java and Typescript, but there's support for many other languages:There are several useful tools in the  tools section 
google-startup-os	How to use StartupOS	You can treat StartupOS as a "developer image" with a pre-built setup and associated tools.You can either:Install  Bazel  That's it!
google-startup-os	Build & Test	A monorepo is a software development approach where all code is stored in a single repository.StartupOS doesn't require you to work with a monorepo, but some things, such as sharing a proto file across front-end and backend, are easier to do in a monorepo.Some good reads about the monorepo approach:You're welcome to contribute and in doing so, learn these technologies.You can have a look at the issues list, or at the project  milestones  docs/milestones.md .
google-statechart	C++ StateChart Library	StateCharts   Harel, 1987   ref1  is a visual formalism for declarativedescription of complex interactive systems.It extends the conventional state machine formalism with Hierarchy, Concurrencyand Communication
google-statechart	C++ StateChart Library	SCXML  is a W3C standard based on StaeCharts.This is a C++ library that implements the SCXML specification
google-statechart	C++ StateChart Library	Instead of XML, aStateChart is represented as a StateChart protobuf.
google-statechart	Features	Many features from the SCXML standard have been implemented.Here's an example of a StateChart that describes a Microwave.! Microwave StateChart  statechart/example/microwave_statechart.svg "Microwave StateChart" You can see  //statechart/example/microwave_example_main.cc  statechart/example/microwave_example_main.cc for details on how to specify such a StateChart as a StateChart proto and how to use it in code.
google-statechart	Usage	To build the library you'll need bazel
google-statechart	Usage	You can download and install it from  here 
google-statechart	Download/Clone the repo.	git clone cd statechart
google-statechart	Build the library	bazel build //statechart/...
google-statechart	Run unit tests	bazel test //statechart/...
google-statechart	Run the Microwave example	bazel run //statechart/example:microwave_example_main -
google-statechart	Disclaimer	This is not an officially supported Google product.
google-statechart	References	Science of Computer Programming
google-statechart	References	Link  Link 
google-stenographer	Query Language ###	A user requests packets from stenographer by specifying them with a very simplequery language
google-stenographer	Query Language ###	 This language is a simple subset of BPF, and includes the**NOTE**: Relative times must be measured in integer values of hours or minutesas demonstrated above.Primitives can be combined with and/&& and with or/||, which have equalprecendence and evaluate left-to-right
google-stenographer	Query Language ###	 Parens can also be used to group.
google-stenographer	Stenoread CLI ###	The *stenoreadand presenting them in a usable format to analysts
google-stenographer	Stenoread CLI ###	 It requests raw packetsfrom stenographer, then runs them through *tcpdumpfull-featured formatting/filtering experience
google-stenographer	Stenoread CLI ###	 The first argument to *stenoreadpassed to *tcpdump*
google-stenographer	Stenoread CLI ###	 For example:To download the source code, install Go locally, then run:depends on
google-stenographer	Stenoread CLI ###	 To build stenotype, go into the stenotype directory and run make.You may need to install the following Ubuntu packages  or their equivalents onother Linux distros :This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.This code is not intended  or used  to watch Google's users
google-stenographer	Stenoread CLI ###	 Its purposeis to increase security on our networks by augmenting our internal monitoring
google-stm32_bare_lib	STM32 Bare Library	System functions and example code for programming the "Blue Pill" STM32-compatible micro-controller boards.This is not an officially supported Google product.
google-stm32_bare_lib	Introduction	You can now buy "Blue Pill" development boards individually for less than $These devices have ARM Cortex M3 CPUs running at 72MHz, 20KB of SRAM, and 64KB of flash, and consume far less energy than standard ARM processors
google-stm32_bare_lib	Introduction	They offer an amazing amount of computing power for a cheap package that can be run on a battery for a long time
google-stm32_bare_lib	Introduction	They are perfect for prototyping running compute-intensive algorithms like machine learning on embedded systems.Unfortunately, though their price point makes them very accessible, there are other barriers to getting started with the boards
google-stm32_bare_lib	Introduction	They require separate hardware to program, and some basic wiring skills
google-stm32_bare_lib	Introduction	The system software that you need to do anything useful with them is also often proprietary and confusing
google-stm32_bare_lib	Introduction	This framework tackles all those problems by standardizing a work flow based on open software and hardware, providing step-by-step guides for the small amount of wiring needed, and offering self-contained system functions and examples in plain C.
google-stm32_bare_lib	What You Need	Before you get started, you'll need to have a few pieces of hardware available
google-stm32_bare_lib	What You Need	No soldering or tools are required though, you should be able to assemble everything you need by hand
google-stm32_bare_lib	What You Need	My thanks go to  Andy Selle  who pioneered the approach that I've documented below.These steps assume you have a Raspberry Pi 3 running a recent version of Raspbian
google-stm32_bare_lib	What You Need	There's nothing that I know definitely won't work on a Pi 2  or a Pi Zero/One with an adjustment to the OpenOCD scripts , but I've not tested any other combinations
google-stm32_bare_lib	What You Need	The approach I'm using came from  a great AdaFruit guide  which I recommend checking out for more background on what we're doing.The main piece of software we need to install is  OpenOCD  the Open On-Chip Debugger
google-stm32_bare_lib	What You Need	Despite its name, this tool also handles flashing micro-controller flash memory with new programs, as well as displaying debug information from the chip
google-stm32_bare_lib	What You Need	It does this through the Serial Wire Debug protocol, communicating through dedicated pins on the Blue Pill board.OpenOCD doesn't have a binary package for the Pi, but it is easy to compile
google-stm32_bare_lib	What You Need	To build it, run these commands in the terminal on your Pi:The four pins at the thin end of the Blue Pill board are dedicate to the SWD protocol, and need to be connected to the right pins on the Pi's header, which OpenOCD will then control to program the chip
google-stm32_bare_lib	What You Need	Here's a diagram showing how the wires should be attached between the Pi and the board:! Blue Pill Wiring This is based on the wiring recommended by the AdaFruit tutorial, where ground and power  3.3V  can be driven by any of the multiple pins on the Pi that supply them, SWDIO  the data pin  is on pin 24, and SWDCLK  the clock pin  is on pin I'm leaving the reset pin unconnected, since it's optional.! AdaFruit Diagram Here are some photos of my actual setup:! Blue Pill Wiring ! Pi Wiring ! Complete Picture of Wiring If you're using female-to-female jumper wires, you should be able to just push the connectors at each end onto the corresponding pins, and they should fit snugly with a small amount of force.There are also two yellow plastic jumper switches on the board
google-stm32_bare_lib	What You Need	Normally they will both in position furthest away from the SWD pins, and closest to the small USB port
google-stm32_bare_lib	What You Need	This is the recommended position for our workflow, but if they're in a different place when you get your board, you may need to move them back.Once you've wired in the ground and power  3.3v  connections, you should see a red LED on the board light up
google-stm32_bare_lib	What You Need	If it doesn't, check your wiring, or try another board in case there's a defect.
google-stm32_bare_lib	Building the Examples	Now you should be ready to build some example programs for the Blue Pill board
google-stm32_bare_lib	Building the Examples	To do this, you'll need to clone  ARM's CMSIS 5 micro-controller library  from GitHub and get this repository too
google-stm32_bare_lib	Building the Examples	You'll also need to install the cross-compilation toolchain for ARM.These are not quite like normal executables, they're just exact copies of the bytes that need to be copied into flash memory on the device
google-stm32_bare_lib	Building the Examples	They don't contain any debug symbols, and the very start of flash has to be a table of function pointers, so making sure that boot.s is first in linking order is important
google-stm32_bare_lib	Building the Examples	You don't need to worry about that for these examples, because the makefile takes care of all that, but once you start building your own programs you'll need to be careful.
google-stm32_bare_lib	Testing OpenOCD	Once you've got this library's repository from GitHub, you can start testing your wiring connection
google-stm32_bare_lib	Testing OpenOCD	There are a lot of settings you need to pass to OpenOCD to make a successful link, so to make things easier these are included in  opened.cfg  in the root of the source tree
google-stm32_bare_lib	Testing OpenOCD	To try out OpenOCD, run:
google-stm32_bare_lib	Running Examples	With OpenOCD running in one terminal, open up a new window and type:Finally we need to restart the chip again, at which point it should try to execute the program we've just uploaded to flash
google-stm32_bare_lib	Running Examples	We do this with the plain reset command, which with no arguments restarts the chip and begins execution.
google-stm32_bare_lib	Debug Output	Blinking LEDs is fun, but to be at all productive on complex programs we need to be able to easily pass information back to the host computer for debugging purposes
google-stm32_bare_lib	Debug Output	The  Hello World example  shows how to use  DebugLog    to do this
google-stm32_bare_lib	Debug Output	To run it, execute these commands in the OpenOCD command console:The DebugLog   function can take several hundred milliseconds to execute, since it has to call back to the host machine, so it shouldn't be used in performance-critical code, but it is handy when you're trying to track down issues.
google-stm32_bare_lib	Debugging with GDB	The standard Gnu debugger gdb works reasonably well with this setup
google-stm32_bare_lib	Debugging with GDB	To install it, run:For example, recompile and load the binary to the device againAnd interrupt it...Inspect variables...Inspect the stack...If you want to create your own programs using this framework, you should start off by copying one of the examples and expanding it
google-stm32_bare_lib	Debugging with GDB	You'll need to:Device manufacturers typically also release a header file that defines registers for peripherals that are not standard across all particular CPUs but that exist only on their boards
google-stm32_bare_lib	Debugging with GDB	Since Blue Pill SoCs are STM32-compatible, these would normally be in something like stm32f*.h, but this is only available as part of proprietary products from ST
google-stm32_bare_lib	Debugging with GDB	Instead, the  core_stm32.h  header includes a few of the most commonly-used device registers, as defined by  ST's reference guide to the processor  
google-stm32_bare_lib	Debugging with GDB	These definitions are used to set up and control the LEDs for example.
google-stm32_bare_lib	Further Reading	Looking through the  examples folder  should give you some ideas on the sort of things that are possible
google-stm32_bare_lib	Further Reading	STM32duino  has a wealth of information on Blue Pill boards, and the name even comes from  a thread on their forums  Thomas Trebisky has some fantastic examples  of bare-metal STM32 programming, and I've found them very useful to reference as I've been working on this
google-stm32_bare_lib	Further Reading	David Welch has also made available great sample code  for the STM Reference Manual  
google-strabo	Strabo	Strabo is a system designed to make it easy to run fast, scalable, and potentially complex geospatial analyses over your data
google-strabo	Strabo	It allows simple expressions likeMore complex queries are also possible, for instance:Strabo is a wrapper around  PostGIS  a widely used and well tested set of extensions to PostgreSQL that provide spatial indices, joins, querying, and shapefile operations
google-strabo	Strabo	It is implemented in Elixir and runs on the BEAM VM, so the server is fault tolerant and queries automatically make use of all available cores if possible
google-strabo	Strabo	Strabo currently comes with a Python-based query language, but client libraries for other languages are planned in the future
google-strabo	Strabo	Strabo is still in the very early stages of development, and is definitely not recommended for production usage.Server InstallationInstall  Vagrant  and  VirtualBox  If you are running Ubuntu, make sure you install Vagrant directly from their website, as the version in the Ubuntu repos is out of date.Clone this repo
google-strabo	Strabo	cd into it and run vagrant up
google-strabo	Strabo	This step will take a while.Once the Vagrant box has been downloaded, installed and provisioned; type vagrant ssh  from within the Strabo directory .At the vagrant prompt, run run_migrations to install dependencies and run all schema migrations.Once migrations are complete, run start_server to start the Strabo server.You can run tests with run_tests.Now you can visit localhost:4001 from your browser
google-strabo	Strabo	If it displays a "Welcome to Phoenix" page; you are good to go!Client InstallationThis repository includes a Python client library designed to interact with the Strabo server
google-strabo	Strabo	To install it, cd into this repository and run-------Support for downloading geographic shapefiles from the US Census Bureau  and other data sources , importing into Strabo, and using them in queries like my_location.get_containing_polygon 'us_counties_2014' 
google-strabo	Strabo	This is almost complete.Swap current Enum.map implementation for a parallel one that uses all available cores.Allow calculation of road distance using TIGER/LINE or OSM data.API to allow real-time upload of location data  for instance, from a mobile app 
google-strabo	Strabo	This is pretty much complete but needs to be cleaned up and documented.Allow saving a kernel  i.e
google-strabo	Strabo	a Strabo query with parameters  to the database, and exposing said kernel as an API endpoint
google-strabo	Strabo	This is nearly complete on the backend  there is a kernels table, and queries with parameters are supported , but it needs to be finished and documented.Legal notes
google-streaming_hdp	Streaming HD Previews.	**Disclaimer: This is not an official Google product.**This implements a proxy that cloud-renders pages and streams the state of theDOM back to the client.
google-streamy-dart	This package is deprecated	Consider the following alternatives:Streamy was a JSON RPC framework for applications written using  Dart programming language  It generated a Dart client library from a  Google API Discovery  file.
google-streetview-publish-client-libraries	Client libraries for the Google Street View Publish API	The  Street View Publish API allows your application to publish 360 photos to Google Maps, along with imagemetadata that specifies the position, orientation, and connectivity of eachphoto
google-streetview-publish-client-libraries	Client libraries for the Google Street View Publish API	With this API, any app can offer an interface for positioning,connecting, and uploading user-generated Street View images.This library provides code to call this API from several languages including Java, JavaScript, and python.Please see the  documentation for code samples and details.
google-streetview-publish-client-libraries	Python	To install the Python library, please see the Python package index for gapic-google-maps-streetview\_publish 
google-streetview-publish-client-libraries	Java	To install the Java library, please see the Central Repository for the java-streetview-publish artifact under the com.google.streetview.publish GroupId.
google-streetview-publish-client-libraries	JavaScript	To install the JavaScript library, please see the instructions for streetview-publish-client-libraries-v1 
google-stumblybot	StumblyBot	This is a very hacky test project to integrate Marty Robot, Google Assistant SDKand DialogFlow.**This is not an officially supported Google product.**
google-stumblybot	Hardware requirements	  device
google-stumblybot	Hardware requirements	 head.
google-stumblybot	Assistant SDK	You can install Assistant SDK on the same Raspberry Pi, connect speaker andmicrophone to it, and it will act as regular Google Assistant
google-stumblybot	Assistant SDK	This step isoptional
google-stumblybot	Assistant SDK	You can use any Assistant-enabled device to control your robot
google-stumblybot	Assistant SDK	GoogleHome, Android, iOS, smart TV, whatever.
google-stumblybot	Contacts	 
google-subcommands	subcommands #	 ! GoDoc    Subcommands is a Go package that implements a simple way for a single command tohave many subcommands, each of which takes arguments and so forth.This is not an official Google product.
google-subcommands	Usage ##	Set up a 'print' subcommand:import    "context"  "flag"  "fmt"  "os"  "strings" type printCmd struct {  capitalize boolfunc  *printCmd  Name   stringfunc  *printCmd  Synopsis   string { return "Print args to stdout." }func  *printCmd  Usage   string {  return func  p *printCmd  SetFlags f *flag.FlagSet  {  f.BoolVar &p.capitalize, "capitalize", false, "capitalize output" func  p *printCmd  Execute _ context.Context, f *flag.FlagSet, _ ...interface{}  subcommands.ExitStatus {  for _, arg := range f.Args   {  }  fmt.Println    return subcommands.ExitSuccessRegister using the default Commander, also use some built in subcommands,finally run Execute using ExitStatus as the exit code:func main   {  subcommands.Register subcommands.HelpCommand  , ""   subcommands.Register subcommands.FlagsCommand  , ""   subcommands.Register subcommands.CommandsCommand  , ""   subcommands.Register &printCmd{}, ""   ctx := context.Background    os.Exit int subcommands.Execute ctx   
google-subpar	Subpar	  Subpar is a utility for creating self-contained python executables
google-subpar	Subpar	 It isdesigned to work well with  Bazel 
google-subpar	Setup	par_binary   is a drop-in replacement for py_binary   in your BUILD filesthat also builds a self-contained, single-file executable for the application,with a .par file extension.To build the .par file associated with a par_binary name=myname  rule, dodirectories that py_binary   creates, but is independent of them.It can be copied to other directories or machines, and executeddirectly without needing the .runfiles directory
google-subpar	Setup	The body of the.par file contains all the srcs, deps, and data files listed.
google-subpar	Limitations:	Given a BUILD file with the following:load "@subpar//:subpar.bzl", "par_binary" par_binary  Run the following build command:compiled executable file:This is not an official Google product, it is just code that happensto be owned by Google.
google-supersonic	Copyright 2012 Google Inc. All Rights Reserved.	Installation instructions are provided in INSTALL.Basically ./config && make && make install .
google-support-tools	#Google Code Support Tools#	This project contains tools related to exporting data from Google Code.Google Code has been  turned down this repository is provided mostly for historical purposes
google-support-tools	#Google Code Support Tools#	For an archive ofprojects that were hosted on Google Code, see the Google Code Archive 
google-surveys	Introduction	This GitHub repository contains code samples for the Google Surveys API, built by the Surveys team @ Google
google-surveys	Introduction	Please note that this repository is not officially supported by Google.The Google Surveys team will do their best to keep the this repository up-to-date as the API evolves, but it's possible that at any given point the code stops working
google-surveys	Introduction	For this reason please treat the code as illustrative only
google-surveys	Introduction	Should you want to launch a production-quality service on the API please use the REST end-points directly.For more information on the Google Surveys API, check out the  Google Surveys API developer site To report an issue or request a feature, please  create a new issue  via Google’s Issue Tracker
google-surveys	Introduction	 For sales and product questions, please visit  Google Surveys support 
google-svcca	SVCCA for Deep Learning Dynamics and Interpretability	This repository contains the core code for implementing Canonical Correlation Analysis on deep neural network representations, which was used for the results in the paper: Maithra Raghu   Justin Gilmer   Jason Yosinski   Jascha Sohl-Dickstein   2017 
google-svcca	SVCCA for Deep Learning Dynamics and Interpretability	"SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability"  Neural Information Processing Systems  NIPS  
google-svcca	Dependencies	This code was written in Python 2.7 and relies on the numpy and pandas modules
google-svcca	Usage	The main function to compute CCA similarities between two representations is the get_cca_similarity function in  cca_core.py  cca_core.py 
google-svcca	Usage	This takes in two arrays of shape  num neurons1, num datapoints  ,  num neurons2, num_datapoints ,and outputs pairs of aligned directions, how well aligned they are, as well as coefficients to transform from the original neuron basis to the aligned directions.The  dft_ccas.py  dft_ccas.py  module builds on this functionality to work with convolutional networks
google-svcca	Usage	Convolutional layers have a more natural basis in terms of the number of channels, not raw neurons
google-svcca	Usage	Using some of the mathematical propertiesof the Discrete Fourier Transform, we have a computationally efficient method for comparing CCA similarity for convolutional layers
google-svcca	Usage	See Section 3 in the  paper  for more details
google-svcca	Usage	The fourier_ccas function in dft_ccas.py  dft_ccas.py  implements exactly this, taking the raw convolutional activations  num datapoints, height1, width1, num channels1 ,  num datapoints, height2, width2, num channels2 Note that according to the theory, we get an exact result if the datapoints used to _generate_  not train  the activations are translation invariant  any 2d translation of a datapoint x is also in the set of datapoints 
google-svcca	Usage	But even without this, we can get very good results  see Examples section .
google-svcca	Examples	In the paper, we apply this method to understand several aspects of neural network representations, and we give a couple of examples below.
google-swift-clang	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-clang	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-clang	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-clang	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-clang	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-clang	Code Reviews	All submissions, including submissions by project members, require review
google-swift-clang	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-clang	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-clang	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-cmark	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-cmark	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-cmark	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-cmark	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-cmark	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-cmark	Code Reviews	All submissions, including submissions by project members, require review
google-swift-cmark	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-cmark	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-cmark	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-compiler-rt	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-compiler-rt	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-compiler-rt	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-compiler-rt	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-compiler-rt	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-compiler-rt	Code Reviews	All submissions, including submissions by project members, require review
google-swift-compiler-rt	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-compiler-rt	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-compiler-rt	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-corelibs-foundation	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-corelibs-foundation	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-corelibs-foundation	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-corelibs-foundation	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-corelibs-foundation	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-corelibs-foundation	Code Reviews	All submissions, including submissions by project members, require review
google-swift-corelibs-foundation	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-corelibs-foundation	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-corelibs-foundation	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-corelibs-libdispatch	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-corelibs-libdispatch	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-corelibs-libdispatch	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-corelibs-libdispatch	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-corelibs-libdispatch	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-corelibs-libdispatch	Code Reviews	All submissions, including submissions by project members, require review
google-swift-corelibs-libdispatch	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-corelibs-libdispatch	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-corelibs-libdispatch	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-corelibs-xctest	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-corelibs-xctest	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-corelibs-xctest	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-corelibs-xctest	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-corelibs-xctest	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-corelibs-xctest	Code Reviews	All submissions, including submissions by project members, require review
google-swift-corelibs-xctest	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-corelibs-xctest	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-corelibs-xctest	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-integration-tests	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-integration-tests	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-integration-tests	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-integration-tests	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-integration-tests	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-integration-tests	Code Reviews	All submissions, including submissions by project members, require review
google-swift-integration-tests	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-integration-tests	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-integration-tests	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-jupyter	Swift-Jupyter	This is a Jupyter Kernel for Swift, intended to make it possible to use Jupyterwith the  Swift for TensorFlow  project.This kernel is currently very barebones and experimental.This kernel is implemented using LLDB's Python APIs.
google-swift-jupyter	Installation Instructions	Create a virtualenv and install jupyter in it.virtualenv venv
google-swift-jupyter	Installation Instructions	venv/bin/activatepip2 install jupyter # Must use python2, because LLDB doesn't support pythonOptionally  install SourceKitten   this enables codecompletion .Get a Swift toolchain
google-swift-jupyter	Installation Instructions	Here are a few options:
google-swift-jupyter	If you downloaded a prebuilt toolchain:	python register.py --sys-prefix --swift-toolchain 
google-swift-jupyter	If you built a toolchain from sources:	python register.py --sys-prefix --swift-toolchain 
google-swift-jupyter	If you are using an Xcode provided toolchain:	python register.py --sys-prefix --xcode-path Optionally add --sourcekitten  to the command if you installedSourceKitten
google-swift-jupyter	If you are using an Xcode provided toolchain:	This will give you code completion.Now run jupyter notebook, and it should have a Swift kernel.
google-swift-jupyter	Rich output	You can call Python libaries using  Swift's Python interop  to display richoutput in your Swift notebooks
google-swift-jupyter	Rich output	 Eventually, we'd like to support Swiftlibraries that produce rich output too!   system Python
google-swift-jupyter	Rich output	 Do not install them on the virtualenv from the Swift-Jupyter  installation instructions
google-swift-jupyter	Rich output	Swift's Python interop talks to your system  Python
google-swift-jupyter	Rich output	After taking care of the prerequisites, run%include "EnableIPythonDisplay.swift" in your Swift notebook
google-swift-jupyter	Rich output	Now you shouldbe able to display rich output! For example:let time = np.arange 0, 10, 0.01 let amplitude = np.exp -0.1 let position = amplitude plt.figure figsize:  15, 10  plt.plot time, position plt.plot time, amplitude plt.plot time, -amplitude plt.xlabel "time  s " plt.ylabel "position  m " plt.title "Oscillations" plt.show  ! Screenshot of running the above two snippets of code in Jupyter  ./screenshots/display_matplotlib.png  Swift's Python interop : 
google-swift-jupyter	%include directives	%include "" in your cell
google-swift-jupyter	%include directives	The kernel will preprocess your cell andreplace the %include directive with the contents of the file before sendingyour cell to the Swift interpreter
google-swift-jupyter	%include directives	must be relative to the directory containing swift_kernel.py.We'll probably add more search paths later.
google-swift-llbuild	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-llbuild	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-llbuild	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-llbuild	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-llbuild	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-llbuild	Code Reviews	All submissions, including submissions by project members, require review
google-swift-llbuild	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-llbuild	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-llbuild	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-lldb	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-lldb	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-lldb	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-lldb	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-lldb	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-lldb	Code Reviews	All submissions, including submissions by project members, require review
google-swift-lldb	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-lldb	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-lldb	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-llvm	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-llvm	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-llvm	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-llvm	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-llvm	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-llvm	Code Reviews	All submissions, including submissions by project members, require review
google-swift-llvm	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-llvm	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-llvm	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift-package-manager	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift-package-manager	Contributing	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift-package-manager	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift-package-manager	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift-package-manager	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift-package-manager	Code Reviews	All submissions, including submissions by project members, require review
google-swift-package-manager	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift-package-manager	Code Reviews	Consult GitHub Help for moreinformation on using pull requests.
google-swift-package-manager	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swift	Purpose	This repository exists to allow Googlers to collaborate and stage pull requestsagainst the official Swift repository.
google-swift	Swift for TensorFlow	We strongly encourage contributors to contribute directly to upstream wheneverpossible; contributions will be rejected if the project owners feel they aremore appropriate for a direct upstream contribution.If you would like to contribute to this repository, there are a few steps to
google-swift	Contributor License Agreement	Contributions to this project must be accompanied by a Contributor LicenseAgreement
google-swift	Contributor License Agreement	You  or your employer  retain the copyright to your contribution,this simply gives us permission to use and redistribute your contributions aspart of the project
google-swift	Contributor License Agreement	Head over to  to see yourcurrent agreements on file or to sign a new one.You generally only need to submit a CLA once, so if you‘ve already submitted one even if it was for a different project , you probably don’t need to do it
google-swift	Code Reviews	All submissions, including submissions by project members, require review
google-swift	Code Reviews	Weuse GitHub pull requests for this purpose
google-swift	Code Reviews	Consult GitHub Help  for more information on using pull
google-swift	Upstream Policies	All contributions to this repository are expected to go upstream; please makesure that your contribution follows all of the contribution policies from
google-swiftshader	SwiftShader	    ! Build status  SwiftShader is a high-performance CPU-based implementation of the OpenGL ES and Direct3D 9 graphics APIs12
google-swiftshader	SwiftShader	Its goal is to provide hardware independence for advanced 3D graphics.-----The SwiftShader libraries act as drop-in replacements for graphics drivers.On Windows, most applications can be made to use SwiftShader's DLLs by placing them in the same folder as the executable
google-swiftshader	SwiftShader	On Linux, the LD\_LIBRARY\_PATH environment variable or -rpath linker option can be used to direct applications to search for shared libraries in the indicated directory first.Prebuilt binaries can be found at: ------------See  CONTRIBUTING.txt  CONTRIBUTING.txt  for important contributing requirements.The canonical repository for SwiftShader is hosted at:All changes must be reviewed and approved in the  Gerrit  review tool at:Authenticate your account here:All changes require a  Change-ID  tag in the commit message
google-swiftshader	SwiftShader	A commit hook may be used to add this tag automatically, and can be found at: To clone the repository and install the commit hook in one go:Changes are uploaded to Gerrit by performing:Third-Party DependenciesThe  third_party  third_party/  directory contains projects which originated outside of SwiftShader: LLVM  third_party/LLVM/  contains an outdated and diverged copy of the  LLVM  compiler framework
google-swiftshader	SwiftShader	Until further notice, maintenance fixes can be made directly in the SwiftShader repository
google-swiftshader	SwiftShader	subzero  third_party/subzero/  contains a fork of the  Subzero  project
google-swiftshader	SwiftShader	It is part of Google Chrome's  Portable   Native Client  project
google-swiftshader	SwiftShader	Its authoritative source is at    The fork was made using  git-subtree  to include all of Subzero's history, and until further notice it should **not* llvm-subzero  third_party/llvm-subzero/  contains a minimized set of LLVM dependencies of the Subzero project
google-swiftshader	SwiftShader	PowerVR_SDK  third_party/PowerVR_SDK/  contains a subset of the  PowerVR Graphics Native SDK  for running several sample applications
google-swiftshader	SwiftShader	googletest  third_party/googletest/  contains the  Google Test  project, as a Git submodule
google-swiftshader	SwiftShader	It is used for running unit tests for Chromium, and Reactor unit tests
google-swiftshader	SwiftShader	Run git submodule update --init to obtain/update the code
google-swiftshader	SwiftShader	Any contributions should be made upstream.-------------See  docs/Index.md  docs/Index.md .-------Public mailing list:  swiftshader@googlegroups.com General bug tracker:  Chrome specific bugs: -------The SwiftShader project is licensed under the Apache License Version 2.You can find a copy of it in  LICENSE.txt  LICENSE.txt .Files in the third_party folder are subject to their respective license.Authors and ContributorsThe legal authors for copyright purposes are listed in  AUTHORS.txt  AUTHORS.txt 
google-swiftshader	SwiftShader	CONTRIBUTORS.txt  CONTRIBUTORS.txt  contains a list of names of individuals who have contributed to SwiftShader
google-swiftshader	SwiftShader	If you're not on the list, but you've signed the  Google CLA  and have contributed more than a formatting change, feel free to request to be added.----------Trademarks are the property of their respective owners.We do not claim official conformance with any graphics APIs at this moment.This is not an official Google product.
google-sync3k-client	sync3k-client	sync3k is an offline-first event-sourcing synchronization engine with optional end-to-end encryption.
google-sync3k-client	Installation	Install with npm:
google-sync3k-client	Usage	Currently, sync3k-client is offered as a redux store enhancer
google-sync3k-client	Usage	First, use sync3k store enhancer when creating a store:import { createStore, applyMiddleware, compose } from 'redux';import reducer from './reducers';import { enhancer } from 'sync3k-client';const store = createStore   reducer, // existing reducers for the application  compose     ;Then, dispatch an initializeSync message with websocket base url to sync3k-server, topic name, optional password for encryption  or empty string , and a boolean indicating whether to ask for encryption keys.Disclaimer: This is not an official Google product.
google-sync3k-server	Sync3k Server	sync3k-server is a lightweight websocket gateway to kafka
google-sync3k-server	Sync3k Server	The server accepts websocket path:Network binding, listening port and kafka bootstrap server can be configured through flags.
google-sync3k-server	Usage	Use sbt to run the server.sync3k-server includes  Dockerfile  Dockerfile  and  docker compose YAML  docker-compose.yml  that launches zookeeper, kafka and sync3k-server.To build the Docker image, first build an uber-jar with sbt assembly command:
google-synthesizer-io	Synthesizer IO	Hopefully, this will become a synthesizer written in Rust
google-synthesizer-io	Synthesizer IO	At the moment, it'sexperimental bits of technology toward that end.
google-synthesizer-io	Disclaimer	This is not an official Google product.
google-systemjs	Including the Loader	Download  es6-module-loader.js  and  traceur.js  from the  ES6-loader polyfill  and locate them in the same folder as system.js from this repo.Then include dist/system.js with a script tag in the page:
google-systemjs	Write and Load a Module	In the index.html page we can then load a module from the baseURL folder with:The module file at app/test.js will be loaded, its module format detected and any dependencies in turn loaded before returning the defined module.The entire loading class is implemented identically to the ES6 module specification, with the module format detection rules being the only addition.> _Note that when running locally, ensure you are running from a local server or a browser with local XHR requests enabled
google-systemjs	Write and Load a Module	If not you will get an error message._> _For Chrome on Mac, you can run it with: /Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --allow-file-access-from-files &> /dev/null &_> _In Firefox this requires navigating to about:config, entering security.fileuri.strict_origin_policy in the filter box and toggling the option to false._Working with Modules> Most of what is discussed in this section is simply the basics of using the new System loader
google-systemjs	Write and Load a Module	Only the extra module format support and plugin system is additional to this browser specification.Modules are dependency-managed JavaScript files
google-systemjs	Write and Load a Module	They are loaded by a **module name*Each module name directly corresponds to a JavaScript file URL, but without the .js extension, and with baseURL rules, mostly identical to RequireJS.The default baseURL rule is:  my/module -> resolve baseURL, 'my/module'  + '.js'
google-systemjs	Setting the baseURL	By default, the baseURL is set to the current page, but it can be changed with:The System loader comes with a paths configuration system
google-systemjs	Setting the baseURL	While not part of SystemJS, it is described here for completion._Note: The implementation is currently in discussion and not specified, thus it is subject to change._One can use the baseURL to reference library scripts like jquery, underscore etc.We then create a path for our local application scripts in their own separate folder, which can be set up with paths config:In this example, we can now write local application code in its own folder  app , without conflict with library code  js :
google-systemjs	Writing Modular Code	It is recommended to write modular code in either AMD or CommonJS
google-systemjs	Writing Modular Code	Both are equally supported by SystemJS, with the format detected automatically.For example, we can write modular CommonJS:javascript  exports.someMethod = function   {and load this with System.import 'app/module'  in the page.> Note: always use relative requires of the form ./ or ../ to reference modules in the same package
google-systemjs	Writing Modular Code	This is important within any package for modularity.
google-systemjs	Module Format Hints	The module format detection is well-tested over a large variety of libraries including complex UMD patterns
google-systemjs	Module Format Hints	It will detect in order ES6, AMD, then CommonJS and fall back to global modules.It is still impossible to write 100% accurate detection though.For this reason, it is also possible to write modules with the module format specified
google-systemjs	Module Format Hints	The module format is provided as a string, as the first line of code  excluding comments  in a file:It is recommended to use a format hint only in the few cases where the format detection would otherwise fail.
google-systemjs	Loading ES6 Modules	SystemJS is an ES6 module loader
google-systemjs	Loading ES6 Modules	It will detect and load ES6 modules, parsing them with Traceur dynamically
google-systemjs	Loading ES6 Modules	This allows for dynamic loading of ES6 without a build step, although a build step still needs to be run to transpile ES6 back to ES5 and AMD for production.A very simple example:For further examples of loading ES6 modules, see the  ES6 Module Loader polyfill documentation For examples of build workflows, see the  jspm CLI documentation 
google-systemjs	Automatic Global Detection	When no module format is detected, or when the "global" hint is present, modules are treated as global scripts.Any properties written to the global object  window, this, or the outer scope  will be detected and stored
google-systemjs	Automatic Global Detection	Then any dependencies of the global will have these properties rewritten before execution.In this way, global collissions are avoided
google-systemjs	Automatic Global Detection	Multiple versions of jQuery can run on the same page, for example.When only one new property is added to the global object, that is taken to be the global module.When many properties are written to the global object, the collection of those properties becomes the global module.This provides loading as expected in the majority of cases:The automatic detection handles most cases, but there are still scenarios where it is necessary to define the exported global name.To specify the exported name, provide an "export" string, directly beneath the "global" hint.javascript  "global";  "export MyGlobal.obj";  };Global modules can also specify dependencies using this same hint system.We write an "import" string, directly beneath the "global" hint.javascript  "global";  "import jquery";  "export $";  }
google-systemjs	AMD Compatibility Layer	As part of providing AMD support, SystemJS provides a small AMD compatibility layer, with the goal of supporting as much of the RequireJS test suite as possible to ensure functioning of existing AMD code.To create the requirejs and require globals as AMD globals, simply include the following  tag immediately after the inclusion of the System loader:_Note that AMD-style plugins are not supported._Map configuration works just like other module loaders, altering the module name at the normalization stage
google-systemjs	AMD Compatibility Layer	 System.map 'jquery'  = 'app/jquery@1.8.3';Map configuration also affects submodules:The order in which module format detection is performed, is provided by the System.formats
google-systemjs	AMD Compatibility Layer	The default value is  'amd', 'cjs', 'global' .To add a new module format, specify it in the System.formats array, and then provide a System.format rule for it.The format rule provides two functions   System.formats =  'amd', 'cjs', 'myformat', 'global' ;  }For further examples, see the internal AMD or CommonJS support implemented in this way here.Plugins can be created to handle alternative loading scenarios, including loading assets such as CSS or images, and providing custom transpilation scenarios.Plugins are indicated by ! syntax, which unlike RequireJS is appended at the end of the module name, not the beginning.The plugin name is just a module name itself, and if not specified, is assumed to be the extension name of the module.Supported Plugins:Note that the AMD compatibility layer could provide a mapping from AMD plugins into SystemJS plugins that provide the same functionality as associated SystemJS plugins.
google-systemjs	Creating Plugins	A plugin is just a set of overrides for the loader hooks of the ES6 module specification.The hooks plugins can override are locate, fetch and translate.Read more on the loader hooks at the  ES6 Module Loader polyfill page 
google-systemjs	Sample CoffeeScript Plugin	For example, we can write a CoffeeScript plugin with the following  CommonJS as an example, any module format works fine :javascript  var CoffeeScript = require 'coffeescript' ;  }By overriding the translate hook, we now support CoffeeScript loading with:A CSS plugin, on the other hand, would override the fetch hook:javascript  exports.fetch = function load  {  }Each loader hook can either return directly or return a thenable for the value.The other loader hooks are also treated identically to the specification.---
google-syzkaller	syzkaller 	    ! Go Report Card    ! License   LICENSE syzkaller is an unsupervised coverage-guided kernel fuzzer
google-syzkaller	syzkaller 	Linux kernel fuzzing has the most support, akaros, freebsd, fuchsia, netbsd, windows and gvisor are supported to varying degrees.The project mailing list is  syzkaller@googlegroups.com You can subscribe to it with a google account or by sending an email to syzkaller+subscribe@googlegroups.com
google-syzkaller	syzkaller 	List of found bugs  docs/found_bugs.md .
google-syzkaller	Documentation	Initially, syzkaller was developed with Linux kernel fuzzing in mind, but now it's being extended to support other OS kernels as well.Most of the documentation at this moment is related to the Linux kernel.For other OS kernels check:  Akaros  docs/akaros/README.md ,  FreeBSD  docs/freebsd.md ,  Fuchsia  docs/fuchsia.md ,  NetBSD  docs/netbsd.md ,  Windows  docs/windows.md ,  gVisor  docs/gvisor.md .This is not an official Google product.
google-talkback	Introduction	This repository contains sources for two Android accessibility services from Google:
google-talkback	Dependencies	To build TalkBack sources you will need:Download android sdk from <>Set ANDROID_HOME to the path of Android sdk folderOpen Android SDK manager and installTalkBack uses gradle as build system.Here are commands to build, install and test the project from command line:Assemble debug and release apks: ./gradlew assembleAssemble only debug apk: ./gradlew assembleDebugInstall debug apk on connected device: ./gradlew installDebugRun robolectric tests: ./gradlew test
google-talkback	Test App	This repository also includes a test app that you can use to:Test TalkBack's behavior against various standard widgets and interaction patterns.Explore source code for test cases to see the implementation of various TalkBack features.To build and install the app, do the following:Switch to the root directory of this repository.Change to the "tests" directory.To assemble debug and release apk: ./gradlew assembleTo build debug apk: ./gradlew assembleDebugThe apks will be located in the app/build/outputs/apk directory.
google-tamperchrome	How To Install *Tamper Chrome*	***Tamper Chrome**First Install the  *Tamper Chrome**Then Install the  *Tamper Chrome**Restart your browser.**
google-tamperchrome	Want to know how to use *Tamper Chrome*?	If you have any more questions feel free to post  to the group 
google-tamperchrome	How to open *Tamper Chrome*?	 **First of all, you need to open Google Chrome DevTools.** **After that, you will find a new tab called "Tamper" at the top-right side, and click on it.**
google-tamperchrome	How to use *Tamper Chrome*?	! Tamper Chrome *Tamper ChromeTo do so, simply click on the checkbox next to the tool's name, and this will mark the tool as active.! Active In the following section we explain how to use each tool.
google-tamperchrome	Block / Reroute Requests	This tool allows you to either **block*You can do that by simply changing the URL and clicking *Allow*.! Block You can also click on *Edit javascript
google-tamperchrome	Request Headers	While Block / Reroute requests is useful to tamper with a website, and cancel some requests, in many cases you might want to modify HTTP request headers.This tool will allow you to do just that.! Headers You can drop a header by clicking on the *Trash
google-tamperchrome	Response Headers	The response headers work exactly the same as the request headers
google-tamperchrome	Response Headers	It allows you to drop, modify or add new headers.! Response Very useful for dropping or modifying many security headers like Content-Security-Policy, X-Frame-Options, X-XSS-Protection, etcetera.
google-tamperchrome	Monitor PostMessages	Unlike the other tools, this tool is mostly only useful for monitoring websites that use the HTML5 postMessage API.When activated, it does the following:Another very cool feature of *Tamper ChromeWhen testing for XSS, you can use  as an HTML element, and *Tamper ChromeNote that you can also use  and , which also work as an attribute, and as a javascript variable.To trigger it, just use as your XSS payload tamperchrome as an attribute, tagname or javascript variable.! tcxss 
google-tamperchrome	Replay Requests  Experimental 	The last tool in *Tamper Chrome! replay 
google-tamperchrome	NOTE	This is not an official Google product.
google-tangent	Tangent 	   ! Join the chat at   Tangent is a new, free, and open-source Python library for automatic differentiation.! Autodiff Tool Space  docs/toolspace.png "Autodiff Tool Space" As a result, you can finally read your automatic derivative code just like the rest of your program
google-tangent	Tangent 	Tangent is useful to researchers and students who not only want to write their models in Python, but also read and debug automatically-generated derivative code without sacrificing speed and flexibility.Tangent works on a large and growing subset of Python, provides extra autodiff features other Python ML libraries don't have, has reasonable performance, and is compatible with TensorFlow and NumPy.This project is an experimental release, and is under active development
google-tangent	Tangent 	As we continue to build Tangent, and respond to feedback from the community, there might be API changes.
google-tangent	Usage	Note: An interactive notebook with all the code in this page can be found  here Tangent has a one-function API:If you want to print out derivatives at the time Tangent generates the derivative function:! Live Derivatives with Tangent  docs/sct-ad-live.gif "Live Derivatives with Tangent" 
google-tangent	Installation	The easiest way to install Tangent is to use pip.We'll have a conda package soon.
google-tangent	Automatic Differentiation	Under the hood, tangent.grad grabs the source code of the Python function you pass it  using inspect.getsource, which is available in the Python standard library , converts the source code into an abstract syntax tree  AST  using ast.parse  also built into the Python standard library , and walks the syntax tree in reverse order.Tangent has a library of recipes for the derivatives of basic arithmetic  +,-,/,**,* , pieces of syntax  ast.For, ast.If, ast.While  and TensorFlow Eager functions  tf.reduce_sum, tf.exp, tf.matmul, ..
google-tangent	Automatic Differentiation	 
google-tangent	Automatic Differentiation	For each piece of syntax it encounters  for example, c = a + b is a single AST node ast.Assign , tangent.grad looks up the matching backward-pass recipe, and adds it to the end of the derivative function.This reverse-order processing gives the technique its name: reverse-mode automatic differentiation.
google-tangent	TF Eager	Tangent supports differentiating functions that use TensorFlow Eager functions that are composed together.def f W,x :  h1 = tf.matmul x,W   h2 = tf.tanh h1   out = tf.reduce_sum h2   return outdfdW = tangent.grad f ! SCT on TF Eager  docs/sct-ad-tf.gif "SCT on TF Eager" 
google-tangent	Subroutines	When model code becomes long, using subroutines makes code more readable and reusable
google-tangent	Subroutines	Tangent handles taking derivatives of models that have user-defined functions.! SCT on Subroutines  docs/sct-ad-subroutine.gif "SCT on Subroutines" 
google-tangent	Control Flow	Tangent has recipes for auto-generating derivatives for code that contains if statements and loops:! SCT on Conditionals  docs/sct-ad-conditional.gif "SCT on Conditionals" You'll notice above that we have to modify the user's code to keep track of information that we will need in the backward pass
google-tangent	Control Flow	For instance, we need to save which branch of an if-statement was followed in the forward pass, so that we run the correct branch in the backward pass
google-tangent	Control Flow	We save this information from the forward pass by pushing it onto a stack, which we then pop off in the backward pass
google-tangent	Control Flow	This is an important data structure in ahead-of-time autodiff.For loops require a little more bookkeeping
google-tangent	Control Flow	Tangent has to save the number of iterations of the loop on the stack
google-tangent	Control Flow	Also, loops usually overwrite the values of variables inside the loop body
google-tangent	Control Flow	In order to generate a correct derivative, Tangent has to keep track of all of the overwritten values, and restore them in the backward pass in the correct order.! SCT on Loops  docs/sct-ad-loop.gif "SCT on Loops" 
google-tangent	Custom Gradients	Tangent uses Python's built-in machinery to introspect and transform the _abstract syntax tree_  AST  of parsed source code at runtime
google-tangent	Custom Gradients	For each piece of supported Python syntax, we have implemented a rule indicating how to rewrite an AST node into its backward pass equivalent, or "adjoint"
google-tangent	Custom Gradients	We have defined adjoints for function calls to NumPy and TF Eager methods, as well as larger pieces of syntax, such as if-statements and for-loops
google-tangent	Custom Gradients	The adjoints are stored in function definitions that serve as "templates", or code macros
google-tangent	Custom Gradients	Another alternative, which we found too cumbersome, would be to use a templating engine like  Mustache  and store adjoints as plain strings
google-tangent	Custom Gradients	Our templates also use a special syntax d x  to refer to the derivative of a variable x.While differentiating a function, if Tangent encounters a function call, it first checks if it has a gradient registered for that function
google-tangent	Custom Gradients	If not, it tries to get the function source, and generate a derivative ahead-of-time
google-tangent	Custom Gradients	But, it's easy to register your own gradients
google-tangent	Custom Gradients	Here's a toy example of defining the gradient of x^3.import tangentfrom tangent.grads import adjointdef cube x :  return x
google-tangent	is used in your containing function.	@adjoint cube def dcube result, x :  d x  = d result print tangent.grad f,verbose=1  The signature for the custom gradient of some functionThe first argument to the template is always the result of the function call, followed by the function arguments, in order.Tangent captures the variable names of the result and arguments, and then will use them to unquote the gradient template at the appropriate place in the backward pass.Check out an  example gradient definition of a NumPy function  and  of a TF eager function  Also,  see the docstring in grads.py for more info 
google-tangent	Debugging	Because Tangent auto-generates derivative code you can read, you can also easily debug your backward pass
google-tangent	Debugging	For instance, your NN might be outputting NaNs during training, and you want to find out where the NaNs are being generated in your model
google-tangent	Debugging	Just insert a breakpoint  e.g., pdb.set_trace    at the end of your forward pass.! SCT for Debugging  docs/sct-ad-debugging.png "SCT for Debugging" For large models, setting a breakpoint at the beginning of the backward pass and stepping through dozens of lines might be cumbersome
google-tangent	Debugging	Instead, you might want the breakpoint to be placed later in the derivative calculation
google-tangent	Debugging	Tangent lets you insert code directly into any location in the backward pass
google-tangent	Debugging	First, run from tangent import insert_grad_of, then add a with insert_grad_of block containing the code you'd like to insert into the backward pass.from tangent import insert_grad_ofdef f x :  ..
google-tangent	Debugging	 with insert_grad_of x  as dx:  ...! Ad Hoc Gradient Code  docs/sct-ad-insert_grad_of.gif "Ad Hoc Gradient Code" 
google-tangent	Derivative Surgery	You can use the insert_grad_of feature to do more than debugging and logging
google-tangent	Derivative Surgery	Some NN architectures benefit from tricks that directly manipulate the backward pass
google-tangent	Derivative Surgery	For example, recurrent neural networks  RNNs  suffer from the "exploding gradient" problem, where gradients grow exponentially
google-tangent	Derivative Surgery	This prevents the model from training properly
google-tangent	Derivative Surgery	A typical solution is to force the derivatives inside of an RNN to not exceed a certain value by directly clipping them
google-tangent	Derivative Surgery	We can implement this with insert_grad_of.def f params, x :  h = x  for i in range 5 :  return hdfdparams = tangent.grad f You can perform other backward-pass tricks with insert_grad_of, such as stop gradients  use a break in the inlined code to stop a for loop , or synthetic gradients  replace a derivative with a prediction from a neural network 
google-tangent	Derivative Surgery	This feature lets Tangent users easily debug their models, or quickly try out derivative tweaks in the backward pass.
google-tangent	Forward Mode	Reverse-mode autodiff, or backpropagation, generates efficient derivatives for the types of functions we use in machine learning, where there are usually many  perhaps millions  of input variables and only a single output  our loss 
google-tangent	Forward Mode	When the inverse is true, where there are many more outputs than inputs, reverse mode is not an efficient algorithm, as it has to be run as many times as there are output variables
google-tangent	Forward Mode	However, a less famous algorithm, forward-mode autodiff, only has to be run as many times as there are _input_ variables
google-tangent	Forward Mode	Tangent supports forward-mode autodiff.def f x :  a = x  c = a + b  return cforward_df = tangent.autodiff f, mode='forward' ! SCT Forward Mode  docs/sct-ad-forward.gif "SCT Forward Mode" 
google-tangent	Hessian-Vector Products	Although we won't dig into the technical details, forward-mode is very useful when combined with reverse-mode to calculate efficient higher-order derivatives, particularly for Hessian-vector products  HVP  of NNs
google-tangent	Hessian-Vector Products	This is useful in research applications, and usually very painful and slow to calculate
google-tangent	Hessian-Vector Products	Autograd has native forward-mode support, while TensorFlow has 3rd-party support.To take higher-order derivatives, you can use any combination of forwarddef f x :hvp = tangent.autodiff tangent.autodiff f,mode='reverse' ,mode='forward' 
google-tangent	Performance	Although we did not build Tangent for performance, it is competitive with major ML libraries
google-tangent	Performance	Because we are generating derivatives ahead-of-time, there is no interpretive overhead like there is with runtime autodiff libraries
google-tangent	Performance	We implemented a few compiler optimizations  dead code elimination, and constant folding , but we are still working on extra optimization passes to further increase performance.! Small Benchmark  docs/small-benchmark.png "Small Benchmark" 
google-tangent	Optimization	We are often interested in the gradients of only some of the arguments
google-tangent	Optimization	In thiscase, many of the adjoint calculation might be dead code
google-tangent	Optimization	In the optimizationpass this is removed
google-tangent	Optimization	We also perform limited constant folding and assignment propagation.
google-tangent	Known Limitations	Tangent is still an experiment, so expect some bugs
google-tangent	Known Limitations	If you report them to us on GitHub, we will do our best to fix them quickly.We are working to add support in Tangent for more aspects of the Python language  e.g., closures, inline function definitions, classes, more NumPy and TensorFlow functions 
google-tangent	Known Limitations	We also hope to add more advanced automatic differentiation and compiler functionality in the future, such as automatic trade-off between memory and compute  Griewank and Walther 2000; Gruslys et al., 2016 , more aggressive optimizations, and lambda lifting.Many of Python's advanced features are difficult to statically analyze or todefine sensible gradients of, so we restrict Python to a functional subset i.e
google-tangent	Known Limitations	no mutable objects .
google-tangent	Closures	Closures are currently not supported for the following reasons:  will resolve to the same function at each call.
google-tangent	Classes	Classes are not _currently_ supported, but are on our near-term roadmap.This will enable PyTorch/Chainer/TFEager-style class definitions of neural networks, and parameterized functions, like in TF Slim.
google-tangent	Team	Tangent is developed by Alex Wiltschko, Bart van Merrienboer and Dan Moldovan.
google-tarpc	tarpc: Tim & Adam's RPC lib	     ! Software License   LICENSE  ! Latest Version   ! Join the chat at   *Disclaimer*: This is not an official Google product.tarpc is an RPC framework for rust with a focus on ease of use
google-tarpc	tarpc: Tim & Adam's RPC lib	Defining aservice can be done in just a few lines of code, and most of the boilerplate ofwriting a server is taken care of for you
google-tarpc	tarpc: Tim & Adam's RPC lib	Documentation 
google-tarpc	What is an RPC framework?	"RPC" stands for "Remote Procedure Call," a function call where the work ofproducing the return value is being done somewhere else
google-tarpc	What is an RPC framework?	When an rpc function isinvoked, behind the scenes the function contacts some other process somewhereand asks them to evaluate the function instead
google-tarpc	What is an RPC framework?	The original function thenreturns the value produced by the other process.RPC frameworks are a fundamental building block of most microservices-orientedarchitectures
google-tarpc	What is an RPC framework?	Two well-known ones are  gRPC  and Cap'n Proto tarpc differentiates itself from other RPC frameworks by defining the schema in code,rather than in a separate language such as .proto
google-tarpc	What is an RPC framework?	This means there's no separate compilationprocess, and no cognitive context switching between different languages
google-tarpc	What is an RPC framework?	Additionally, itworks with the community-backed library serde: any serde-serializable type can be used asarguments to tarpc fns.
google-tarpc	Usage	**NB**: *this example is for master
google-tarpc	Usage	Are you looking for other versions Add to your Cargo.toml dependencies:tarpc has two APIs: sync for blocking code and future for asynchronouscode
google-tarpc	Usage	Here's how to use the sync api.
google-tarpc	#! plugin tarpc_plugins  	extern crate futures;
google-tarpc	macro_use 	extern crate tarpc;extern crate tokio_core;use futures::Future;use tarpc::future::{client, server};use tarpc::future::client::ClientExt;use tarpc::tls;use tarpc::util::{FirstSocketAddr, Never};use tokio_core::reactor;use tarpc::native_tls::{Pkcs12, TlsAcceptor};service! {
google-tarpc	derive Clone  	struct HelloServer;impl FutureService for HelloServer {fn get_acceptor   -> TlsAcceptor {fn main   {
google-tarpc	Example: Futures	Here's the same service, implemented using futures.
google-tarpc	Example: Futures + TLS	By default, tarpc internally uses a  TcpStream  for communication between your clients andservers
google-tarpc	Example: Futures + TLS	However, TCP by itself has no encryption
google-tarpc	Example: Futures + TLS	As a result, your communication will be sent inthe clear
google-tarpc	Example: Futures + TLS	If you want your RPC communications to be encrypted, you can choose to use  TLS 
google-tarpc	Example: Futures + TLS	TLSoperates as an encryption layer on top of TCP
google-tarpc	Example: Futures + TLS	When using TLS, your communication will occur over a TlsStream 
google-tarpc	Example: Futures + TLS	You can add the ability to make TLS clients and servers by adding tarpcwith the tls feature flag enabled.When using TLS, some additional information is required
google-tarpc	Example: Futures + TLS	You will need to make  client::tls::Context structs; client::tls::Context requires a  TlsConnector 
google-tarpc	Example: Futures + TLS	The TlsAcceptor  and  TlsConnector  types are defined in the  native-tls 
google-tarpc	Example: Futures + TLS	tarpc re-exportsexternal TLS-related types in its native_tls module  tarpc::native_tls 
google-tarpc	Example: Futures + TLS	TLS :  TcpStream :  TlsStream :  TlsAcceptor :  TlsConnector :  native-tls : Both TLS streams and TCP streams are supported in the same binary when the tls feature is enabled.However, if you are working with both stream types, ensure that you use the TLS clients with TLSservers and TCP clients with TCP servers.
google-tarpc	Sync vs Futures	A single service! invocation generates code for both synchronous and future-based applications.It's up to the user whether they want to implement the sync API or the futures API
google-tarpc	Sync vs Futures	The sync API hasthe simplest programming model, at the cost of some overhead thread
google-tarpc	Sync vs Futures	The futures API is based on tokio and can run on any tokio-compatible executor
google-tarpc	Sync vs Futures	This mean aservice that implements the futures API for a tarpc service can run on a single thread, avoidingcontext switches and the memory overhead of having a thread per RPC.
google-tarpc	Errors	All generated tarpc RPC methods return either std::error::Error  if no error type is explicitly specified in the service! macro invocation
google-tarpc	Errors	Anerror type can be specified like so:use tarpc::util::Message;service! {tarpc::util::Message is just a wrapper around string that implements std::error::Error providedfor service implementations that don't require complex error handling
google-tarpc	Errors	The pipe is used as syntaxfor specifying the error type in a way that's agnostic of whether the service implementation issynchronous or future-based
google-tarpc	Errors	Note that in the simpler examples in the readme, no pipe is used, andthe macro automatically chooses tarpc::util::Never as the error type.The above declaration would produce the following synchronous service trait:trait FutureService {
google-tarpc	Documentation	Use cargo doc as you normally would to see the documentation created for allitems expanded by a service! invocation.
google-tarpc	Gaps/Potential Improvements  not necessarily actively being worked on 	To contribute to tarpc, please see  CONTRIBUTING  CONTRIBUTING.md .
google-tarpc	License	tarpc is distributed under the terms of the MIT license.See  LICENSE  LICENSE  for details.
google-tcp_killer	tcp_killer	Shuts down a TCP connection on Linux or macOS
google-tcp_killer	tcp_killer	Local and remote endpoint arguments can be copied from the output of 'netstat -lanW'.The functionality offered by *tcp_killer
google-tcp_killer	Basic Usage	python tcp_killer.py  -verbose   
google-tcp_killer	Full Example	geffner@ubuntu:~ 1  135578geffner@ubuntu:~ 2  135579Connection to localhost 12345 port  tcp/*  succeeded!geffner@ubuntu:~tcpgeffner@ubuntu:~TCP connection was successfully shutdown
google-tcp_killer	Full Example	1  2 +  Done
google-tcp_killer	lsof	This program uses  lsof  to find the process and socket file descriptor associated with a given TCP connection.lsof can be installed via your package management system  for example, sudo apt-get install lsof .
google-tcp_killer	frida	This program uses the  frida  framework to perform code injection.Frida can be installed as follows: sudo pip install frida
google-tcp_killer	Disclaimer	This is not an official Google product.
google-tcpauth	tcpauth	Copyright 2016 Google Inc
google-tcpauth	tcpauth	All Rights Reserved.tcpauth allows you to wrap TCP connections in RFC2386 MD5 signatures, to preventany attacker from talking to a server without first having the shared secret.This protects against any preauth attacks in the server application itself
google-tcpauth	tcpauth	Youcould compare it to port knocking, in that this could let you keep SSH open forconnections from all over the world, as long as they know the sharedsecret
google-tcpauth	tcpauth	Normal authentication would take place after connection, so it doesn'treduce security.Another benefit is that when MD5 signatures are turned on an attacker can'tspoof RST packets to kill your connection.
google-tcpauth	Installing	If building from git repo:Example of running an SSH server on port On the server:
google-tcpproxy	tcpproxy	For library usage, see For CLI usage, see 
google-teknowledge	Who/what is Teknowledge?	Teknowledge's mission is to create a introductory CS curriculum for text-based programming
google-teknowledge	Who/what is Teknowledge?	 This is not a Google product, but worked on as part of a Googler's 20% time
google-teknowledge	Who/what is Teknowledge?	The current curriculum is being developed targeting 7th-8th grade students in Pittsburgh, though we aim to share it as widely as it finds use.Learn more at  teknowledge.xyz 
google-teknowledge	Using Teknowledge's Curriculum	There are two curriculums in this repository.
google-teknowledge	Credits	Teknowledge started as a Carnegie Mellon student organization in early 2016, and has continued through the help of many organizations and people.
google-teknowledge	Curriculum Developers	Erik Pintar, Chris George, Amal Nanavati, Rudina Morina, Vikram Shanker, Claire Wang, Henry Nelson, Dominic Calkosz, Keerthana Gurushankar
google-teknowledge	Special Thanks	Mark Stehlik, David Kosbie
google-teknowledge	Thanks for Funding	Google,  Google IgniteCS  Carnegie Mellon University
google-templatekit	#TemplateKit	*This software is still in alpha
google-templatekit	#TemplateKit	Backward-incompatible changes willbe made without notice.*TemplateKit is a framework for iOS view programming
google-templatekit	#TemplateKit	Its goal is tobecome a default tool for implementing complex custom views withabstractions optimized for the most common cases.TemplateKit provides an intuitive and efficient DSL to perform commontasks in view programming such as view hierarchy construction, datapopulation, and layout
google-templatekit	#TemplateKit	View code written with TemplateKit is muchshorter and more readable than code written with the raw UIView API.For example, to implement a classic table view cell with an image onthe left and two stacked texts on the right like this:you would just write:These seven lines of template code in the block is enough to tell the framework toconstruct a view hierarchy with one UIImageView instance and two UILabel instances,populate them with runtime data, and lay out the view hierarchy with the specifiedmargin and paddings
google-templatekit	#TemplateKit	Even a very simple view like this would take several dozens oflines if it were implemented with the raw UIView API.Find examples in SampleApp/Templates.
google-templatekit	##Discussion Forum	This is not an official Google product.
google-tensorflow-tools	Decode data ####	const TensorFlowReaders = require 'tensorflow-tools' .readers;let metaData = ...;let indexData = ...;let dataData = ...;let checkpointReader = readers.getCheckpointReader  ;checkpointReader.decode   metaData, indexData, dataData .then    => {  console.log 'Happy checkpoint data', checkpointReader ;} ;
google-tensorflow-tools	Decode local files ####	const TensorFlowReaders = require 'tensorflow-tools' .readers;let checkpointReader = readers.getCheckpointReader  ;checkpointReader.decodeLocalFiles   '...model.ckpt' .then    => {  console.log 'Happy checkpoint data', checkpointReader ;} ;
google-tensorflow-tools	Decode remote files ####	const TensorFlowReaders = require 'tensorflow-tools' .readers;let checkpointReader = readers.getCheckpointReader  ;checkpointReader.decodeRemoteFiles   ' .then    => {  console.log 'Happy checkpoint data', checkpointReader ;} ;--------------------
google-terminal-app-function-keys	Terminal.app Function Keys	Mac OS X Terminal.app profile which enables functional keys with modifiers.It's a known problem that a lot of proper keyboard shortcuts, like Shift-F2or Alt-PgUp do not work properly when used from Mac OS X Terminal.appI created this Terminal.app profile which enablesall the combinations of F1-F12, cursor keys, page up/downwith shift, alt and control.
google-terminal-app-function-keys	How to use?	Download Function Keys.terminal file and import it into Terminal Preferences|Profile| This may require Mac OS X Yosemite or later to be installed.In case you're using compact Apple keyboard:For some reason known shortcuts for linux terminals do not work properly
google-terminal-app-function-keys	How to use?	So, shortcuts likeControl-W could still be useful.
google-terminal-app-function-keys	Is it working at all?	There are some tricks as bare mac os bash abd byobu/tmux implement keyboard handling differently.For example: \0331;1P is recognised as F1 in byobu/tmux, but is not a validcombination in bash itself, as \033OP works for both.
google-terminal-app-function-keys	Full list of all bindings	You can do it by hand, if you don't want to use my files:
google-tern-closure	tern-closure	 tern-closure  tern-closure  is a plugin which adds support for  ClosureCompiler annotations  compiler  and the Closure type system to the JavaSriptcode intelligence system  Tern  tern .To use tern-closure, you need to  install  #installation  it and then configure  #configuration  Tern to load it.
google-tern-closure	Features	tern-closure adds the following features to your Tern installation:Understanding of types in JSDoc type annotations  similar to theUnderstanding of inheritance and interfaces with @extends andCompletion and go-to-definition support for type names in JSDoc comments andAutomatic loading of the definitions for types, so that you get completion
google-tern-closure	 Installation	Currently, tern-closure only works with the NodeJS  Tern Server  tern-server ,and not within a browser.
google-tern-closure	Short version	After installing Tern according the setup instructions of your desired  editorplugin  tern-editor , go to the place where the  Tern package  tern-npm  wasinstalled  or the  Tern repo  tern-repo  was cloned  and runSee  INSTALL.md  INSTALL.md  for instructions tailored to each editor.
google-tern-closure	 Configuration	In order for Tern to load the tern-closure plugin once it is installed, you mustinclude .tern-project in your project's root directory, or .tern-config in your homeYou must also explicitly disable the default doc_comment plugin, which willinterfere with tern-closure.Here is a minimal example .tern-project configuration file:
google-tern-closure	"Project directory" and .tern-project vs .tern-config	Tern looks for .tern-config is loaded instead, and *the working directory of the Tern serverprocess is used as the "project directory"*.Since Tern and tern-closure  including finders like  grep  #grep   use the"project directory" as the base for all relative paths, you should either use.tern-project or be careful about where you start your Tern server  or, whereyour editor plugin starts your Tern server .
google-tern-closure	Options	You can set the following options in the closure section of your Ternconfiguration file:
google-tern-closure	 Finders 	tern-closure uses "finders" to find the files providing Closure names viagoog.provide
google-tern-closure	 Finders 	Finders allow tern-closure to load and interpret the filesproviding names required via goog.require or referenced in JSDoc type stringsso it better understands the context of a given file.The finder section of the options object for closure in your .tern-projectfile specifies what finder implementation you want to use, and what options youwant to pass to the finder
google-tern-closure	 Finders 	By default, no finder is used, and files are notautomatically loaded
google-tern-closure	 Finders 	Currently, only one finder implementation is included withtern-closure,  grep  #grep .*Common finder options:*
google-tern-closure	 grep	This is a basic finder which uses the grep command-line utility  or findstrin Windows  to search for goog.provide statements at startup and create a mapof Closure names to providing files.Here is an example .tern-project file using the grep finder:You can easily use a finder not included in this repository, or implement yourown
google-tern-closure	 grep	This allows you to search for names in different ways, on demand, and touse existing indexes of your codebase.Given a finder name name, tern-closure first looks in its own lib/finderdirectory, then attempts to load name using require  , so a third-partyfinder module can be installed as an npm package.A finder module must implement a simple interface:Please note that while tern-closure is in a 0.X.X release, the finder API maybe subject to breaking changes.
google-tern-closure	Bug reports and feature requests	Please file bug reports and feature requests as issues on the  issuespage  tern-closure-issues  of the tern-closure repository.
google-tern-closure	Contributing	Pull requests to tern-closure are welcome
google-tern-closure	Contributing	Please see the CONTRIBUTING.md  CONTRIBUTING.md  file for requirements and guidelines.Disclaimer: tern-closure is not an official Google product, and is maintained ona best-effort basis
google-tern-closure	Contributing	compiler :  doc_comment :  npm :  tern-closure-issues :  tern-closure :  tern-config :  tern-editor :  tern-npm :  tern-repo :  tern-server :  tern : 
google-testimony	Configuration ###	On creation, sockets are configured based on the /etc/testimony.confconfiguration file, which lists all sockets to be created
google-testimony	Configuration ###	 Each socket containsthese configuration options:
google-testimony	Wire Protocol ###	Testimony uses an extremely simple wire protocol for establishing clientconnections and passing memory regions back and forth.Most values are passed as TLV, in the form:bytes long
google-testimony	Wire Protocol ###	 The type will always have its highest-order bit set, todifferentiate between a TLV and a block index.Post-connection, most communication is 4-byte block indexes passed backand forth
google-testimony	Wire Protocol ###	 At any time post-connection, either the server or client maysend arbitrary TLV values across the wire..
google-testimony	Wire Protocol ###	the other side should handlethem if it knows how and ignore them if it doesn't.The server sends a block index to the client when that block isavailable to process  and it references the block internally 
google-testimony	Wire Protocol ###	 The clientreturns the block index to the server when it's done processing it, and theserver unrefs that block
google-testimony	Wire Protocol ###	 When a block has no more references, it is returnedto the kernel to be refilled with packets.
google-text2text	Preapre the config file wrt the model you wish to run and put it in the	ls -Rtext2text  WORKSPACEbatch_reader  beam_search.py  BUILD  config  data  data.py  decode.py  __init__.py  library.py  main.py  metrics.py  model  README.mdcopynet_batcher.py  __init__.py  vocab_batcher.pycfg_copynet.py  cfg_seq2seq.py  cfg_bow2seq.py __init__.py copynet.py  __init__.py  seq2seq.py  bow2seq.pydata  data_convert_example.py  text_data  vocabbazel build -c opt --copt=-mavx --config=cuda text2text:main
google-text2text	Run the training.	bazel-bin/text2text/main \
google-text2text	Run the eval. Try to avoid running on the same machine as training.	bazel-bin/text2text/main \
google-text2text	Run the decode. Run it when the model is mostly converged.	bazel-bin/text2text/main \  --mode=decode \--config="config_file_name" determines the config file from the config dir  in which the model you wish to run, paths to data, and hyperparameters of the model are specified
google-text2text	Run the decode. Run it when the model is mostly converged.	There are sample config files for each models in config directory
google-text2text	Run the decode. Run it when the model is mostly converged.	The output of the code and summaries will be written to a text2text/config_file_name directory.
google-tflow2	tflow2	tflow2 is an in memory netflow version 9 and IPFIX analyzer.It is designed for fast arbitrary queries.*This software is currently not maintained in this repo
google-tflow2	tflow2	Check out
google-tflow2	Usage	Quick install with go get -u github.com/google/tflow2and go build github.com/google/tflow2or download a pre-built binary from the releases page The release binaries have an additional command, tflow2 -version,which reports the release version.Once you start the main binary it will start reading netflow version 9 packetson port 2055 UDP and IPFIX packets on port 4739 on all interfaces.For user interaction it starts a webserver on port 4444 TCP on all interfaces
google-tflow2	Usage	The webinterface allows you to run queries against the collected data.Start time and router are mandatory criteria
google-tflow2	Usage	If you don't provide any ofthese you will always receive an empty result.
google-tflow2	Command line arguments	  flows to disk
google-tflow2	Command line arguments	Default is false
google-tflow2	Command line arguments	 with prefix and autonomous system information
google-tflow2	Command line arguments	This is useful in case your  routers exported netflow data is lacking these
google-tflow2	Command line arguments	This is the case for example  if you use the ipt-NETFLOW on Linux
google-tflow2	Command line arguments	 The protocol needs to be named like this: "nf_x_y_z_a" with x_y_z_a being the  source IP address of flow packets, e.g
google-tflow2	Command line arguments	nf_185_66_194_0  database
google-tflow2	Command line arguments	 the moment
google-tflow2	Command line arguments	3 will dump every single received netflow packet on the screen
google-tflow2	Command line arguments	 will run out of memory
google-tflow2	Command line arguments	Experience shows that 500k flows need about 50G of RAM
google-tflow2	Command line arguments	 This is needed for suggestions in the web interface
google-tflow2	Command line arguments	 in case you use sampling.-v value-vmodule value
google-tflow2	Limitations	This software currently only supports receiving netflow packets over IPvPlease be aware this software is not platform indipendent
google-tflow2	Limitations	It will only workon little endian machines  such as x86 
google-tflow2	License	 c  Google, Licensed under  Apache-2  LICENSE  license.This is not an official Google product.
google-tie	Technical Interview Exercises     ! Code Coverage  	Technical Interview Exercises  TIE  is a lightweight open-source tool aimed athelping students learn key concepts, principles, and coding patterns that areimportant in software engineering
google-tie	Technical Interview Exercises     ! Code Coverage  	TIE allows users to write code to solvetechnical coding challenges and receive real time insightful and guidingThe project is currently in early Beta
google-tie	Technical Interview Exercises     ! Code Coverage  	This means that content and features arelimited
google-tie	Technical Interview Exercises     ! Code Coverage  	We plan to add more content and features as we develop towards version
google-tie	User setup	From  click on the green "Clone or download"button then click "Download ZIP"Unzip the zip fileOpen the file client/question.html in a web browserUse the coding window on the right to code a solution and click "I think I'mdone" if you think you have answer  repeat until you solve the question To stop the TIE application, simply close the browser windowTo remove TIE from your computer, delete the downloaded files from steps 1and 2
google-tie	Disclaimer	This is not an official Google product
google-tie	Disclaimer	TIE is provided "as is" and withoutwarranty  refer to the TIE LICENSE file for details .
google-tiger	Acknowledge	Tiger is highly inspired by Dagger, Kudos to those great guys.
google-tiger	Challenge	If you find a faster DI framework, let me know
google-tiger	Challenge	I will drop the title as long as it is proved.
google-tiger	Why Tiger?	It is the fastest! Not faster, but the fastest! I have tried it on a big project with ~200 modules
google-tiger	Why Tiger?	While it takes hundreds of milliseconds to instantiate dagger components, on the same hardware, it only takes a few milliseconds to instantiate Tiger injectors.Minimal amount of code to write therefore easy to maintain, if you need to maintain it at all
google-tiger	Why Tiger?	You don't need to write components like in Dagger
google-tiger	Why Tiger?	You don't need to split a module into several modules one for each scope that used by bindings provided by the module
google-tiger	Why Tiger?	You will feel it is some easy to change the scope of a binding
google-tiger	Why Tiger?	Just change it
google-tiger	Why Tiger?	Way to go, isn’t it?
google-tiger	Build up your knowledge	If you are here, you must already be familiar with DI Dependency Injection  and its advantage
google-tiger	Build up your knowledge	Otherwise  wiki  will be your friend.DI has been evolving for long time in the different form
google-tiger	Build up your knowledge	But the concept is not really changed much
google-tiger	Build up your knowledge	This document will not repeat these concepts
google-tiger	Build up your knowledge	If you find some concept not explained, google it
google-tiger	Build up your knowledge	Also Guice probably has explained those concept very well.
google-tiger	Integration	Tiger is an annotation process
google-tiger	Integration	Therefore just build the jar and use it the way that annotation processors are supposed to be used
google-tiger	Integration	All environment should work
google-tiger	Integration	The sample uses gradle.
google-tiger	How?	Before diving into details, it will be helpful, very helpful, to understand the intended usage of tiger
google-tiger	How?	Tiger is designed to let the machine do as much as possible and let human do as little as possible
google-tiger	How?	It requires minimal information from the developer
google-tiger	How?	From these information, scoped injectors are generated
google-tiger	How?	Application can instances these injectors and use them to inject classes
google-tiger	How?	To achieve this, tiger has distilled the information needed to generate injectors
google-tiger	How?	Here are they, with related annotation.
google-tiger	Scopes	Usually application has at least one scope, singleton
google-tiger	Scopes	Even if there is no scoped binding, it is harmless to have a singleton scope
google-tiger	Scopes	Therefore, tiger requires there always be a scope tree
google-tiger	Scopes	The root is usually singleton, but not necessary
google-tiger	Scopes	Details will be shown later in the sample
google-tiger	Scopes	Tiger generates one injector class for each scope.
google-tiger	@tiger.ScopeDependency	It specifies the dependencies between scopes
google-tiger	@tiger.ScopeDependency	All the dependency information form a scope tree.
google-tiger	@dagger.Module	It provides binding information through @Provides annotated methods with optional scope
google-tiger	@dagger.Module	Now 2016/08/10   we just reuse dagger.Module
google-tiger	@dagger.Module	In future, dagger.Module will be copied into tiger.Module so that tiger does not need to depend on dagger.
google-tiger	@javax.inject.Inject on ctor	It provides binding information with optional scope.
google-tiger	@tiger.MembersInjector with mandatory scope	It specifies interfaces which includes class that has fields or methods to be injected
google-tiger	@tiger.MembersInjector with mandatory scope	Injectors will implement all these interfaces.
google-tiger	@javax.inject.Inject on fields, methods	It specifies the injection points from which injector fans out when injecting an object.
google-tiger	@tiger.PackageForGenerated	The package for the generated injectors.
google-tiger	@tiger.ScopedComponentNames	It specify the names of the injectors.
google-tiger	@Module, @Inject and @MembersInjector are naturally scattered around the code. For the others, i.e., @ScopeDependency, @PackageForGenerated, @ScopedComponentNames and @GenerationTriggerAnnotation, we suggest to put them into a dedicated java file as the central configuration information for the app.	Here is the depicted code the sample with some modification  java@PackageForGenerated "sample" public class Scopes {Here is how ApplicationInjector is instantiated and used.
google-tiger	For Dagger users	As you can see, Tiger reuses annotations from dagger like dagger.Module, dagger.Provides, etc
google-tiger	For Dagger users	You can find the javadoc  here  We are not going to repeat them here
google-tiger	For Dagger users	Of course, Component and Subcomponent is not needed any longer
google-tiger	For Dagger users	Producer related stuff is also irrelevant to injection
google-tiger	For Dagger users	There is one nice feature from Tiger
google-tiger	For Dagger users	You don't need to split modules according to different scopes
google-tiger	For Dagger users	Yes, you can put bindings of different scopes into one module
google-tiger	For Dagger users	This way you have less modules
google-tiger	For Dagger users	And, if you want to change the scope of a binding, just change it, easy.
google-tiger	Tip	Inspecting the generate code will help you
google-tiger	Tip	If you want more, there is source code.Enjoy injection!
google-tiger	Group	 fastesttiger@googlegroups.com 
google-timesketch	Timesketch	   ! Version   ! Tweet  Timesketch is an open source tool for collaborative forensic timeline analysis
google-timesketch	Timesketch	Using sketches you and your collaborators can easily organize your timelines and analyze them all at the same time
google-timesketch	Timesketch	 Add meaning to your raw data with rich annotations, comments, tags and stars.! alt text  "Timesketch" 
google-timesketch	Obligatory Fine Print	This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-tink	Tink	----------------------------------------------------------------------------------------! Kokoro Ubuntu  | ! Kokoro macOS 
google-tink	Introduction	Using crypto in your application  shouldn't haveto feel like juggling chainsaws in the dark
google-tink	Introduction	Tink is a crypto library written by agroup of cryptographers and security engineers at Google
google-tink	Introduction	It was born out ofour extensive experience working with Google's product teams,  fixingweaknesses in implementations  andproviding simple APIs that can be used safely without needing a cryptoTink provides secure APIs that are easy to use correctly and hard er  to misuse.It reduces common crypto pitfalls with user-centered design, carefulimplementation and code reviews, and extensive testing
google-tink	Introduction	At Google, Tink isalready being used to secure data of many products such as AdMob, Google Pay,Google Assistant, Firebase, the Android Search App, etc.
google-tink	Getting started	 Bazel  then build, runand play with the  hello worldexamples Tink performs cryptographic tasks via so-called  primitives  docs/PRIMITIVES.md ,each of which is defined via a corresponding interface that specifies thefunctionality of the primitive
google-tink	Getting started	For example, _symmetric key encryption_ isoffered via an  _AEAD-primitive_  Authenticated Encryption with AssociatedData   docs/PRIMITIVES.md#authenticated-encryption-with-associated-data , thatsupports two operations:Before implementations of primitives can be used, they must be registered atruntime with Tink, so that Tink "knows" the desired implementations
google-tink	Getting started	Here's howyou can register all implementations of all primitives in Tink:After implementations of primitives have been registered, the basic use of Tinkproceeds in three steps: Load or generate the cryptographic key material  a Keyset in Tink terms 
google-tink	Getting started	Use the key material to get an instance of the chosen primitive
google-tink	Getting started	Use that primitive to accomplish the cryptographic task.Here is how these steps would look like when encrypting or decrypting with anAEAD primitive in Java:
google-tink	Learn More	If you want to contribute, please read  CONTRIBUTING  docs/CONTRIBUTING.md and send us pull requests
google-tink	Learn More	You can also report bugs or file feature requests.If you'd like to talk to the developers or get notified about major productupdates, you may want to subscribe to our  mailinglist  To join, simply sendan empty email to tink-users+subscribe@googlegroups.com.
google-tink	Maintainers	Tink is maintained by  A-Z :
google-tmppy	Example	As an example, let's write a metafunction  aka type trait class  add_pointer_multiple such that:However this syntax is quite verbose and not very readable
google-tmppy	Example	For more complex metafunctions this becomes a significant issue, leading to more bugs and more effort when debugging or maintaining the code.Some C++ metaprogramming libraries  notably Boost's MPL library  can be used to reduce the verbosity, however that comes at the price of slower compile times.Using TMPPy, the above can be written as:And this TMPPy code can then be compiled to C++ code equivalent to the metafunction above  without the overhead of e.g
google-tmppy	Example	MPL .For more information on TMPPy, see  the wiki 
google-tmppy	License	TMPPy is released under the Apache 2.0 license
google-tmppy	License	See the LICENSE file for details.This is not an official Google product.
google-todo-tracks	TODO Tracks	  TODO Tracks is a tool to let users get a handle on the various TODOs they ortheir teammate have added over time
google-todo-tracks	TODO Tracks	This allows people to track progress byexamining the TODOs remaining.The tool examines all the branches in a git repo  local and remote , finds the TODOsin the different revisions, and presents them to the user
google-todo-tracks	TODO Tracks	Use cases:This is not an official Google product.
google-todo-tracks	Prerequisites	Building requires the Go tools and GNU Make
google-todo-tracks	Prerequisites	Running the built binary requires the git command line tool.
google-todo-tracks	Building the source code	First checkout the code from the git repo:Build the binary:And then launch it:The tracker requires that it be started in a directory that contains at least one git repo, and it shows the TODOs from every git repo under that directory.The UI for the tracker is a webserver which defaults to listening on port To use a different port, pass it as an argument to the "--port" flag:For more details about the supported command line flags, pass in the "--help" flag.
google-todo-tracks	Running in Google Compute Engine	We provide a pre-built binary and config files for deploying the tool to a GCE VMusing Google Deployment Manager.Assuming you already have the gcloud preview commands installed, run the following steps:
google-traceout	traceout	  This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-traceur-compiler	What is Traceur?	Traceur is a JavaScript.next-to-JavaScript-of-today compiler that allows you touse features from the future **today**
google-traceur-compiler	What is Traceur?	Traceur supports ES6 as well as some experimental ES.next features.Traceur's goal is to inform the designof new JavaScript features which are only valuable if they allow you to writebetter code
google-traceur-compiler	What is Traceur?	Traceur allows you to try out new and proposed language features today, helping you say what you mean in your code while informing the standards process.JavaScript's evolution needs your input
google-traceur-compiler	What is Traceur?	Try  out thenew language features
google-traceur-compiler	What is Traceur?	Tell us how they work for you and what's still causing you to use more boilerplate and"design patterns" than you prefer.
google-traceur-compiler	What now? What can Traceur do for me?	Read the Getting Started page to get up and running
google-traceur-compiler	What now? What can Traceur do for me?	You can use some language features right now andeven try it out in your browser here Just type in some code and see what Traceur produces
google-traceur-compiler	What now? What can Traceur do for me?	For an idea of what isavailable and what we have in the pipeline, see the Language Features The JSConf 2011 presentation of Traceur describes the goals of the project andwhat it can do today
google-traceur-compiler	What now? What can Traceur do for me?	Some documentation is on the wiki on this site.Extra demos are in the source repository.We also presented Traceur at NodeConf The video isavailable on  YouTube Questions, suggestions, and comments can be directed to the discussion group 
google-tracing-framework	Setup	See  building  for instructions and testing  for information on running the various tests.
google-tracing-framework	Quickstart	Just want the extension as fast as possible?
google-tracing-framework	License	All code except dependencies under third_party/ is licensed under the permissive BSD license
google-tracing-framework	License	Feel free to fork/rip/etc and use as you wish!
google-tracing-framework	Contributing	Have a fix or feature? Submit a pull request Note that we do keep to the  style_guide so please check it out first!As this is a Google project, you *must Google Contributor License Agreement  before we can accept anycode
google-tracing-framework	Contributing	It takes only a second and basically just says you won't sue us or claimcopyright of your submitted code.
google-transitfeed	transitfeed	Provides a library to help you parse, validate, and generate  General Transit Feed Spec  GTFS   feed files
google-transitfeed	transitfeed	 See INSTALL for installation instructions.For the latest documentation, see:
google-translation-cards	Translation Cards	 Translation Cards  is an Android app that makes it really easy to record and play back translated words and phrases.Translation Cards is an in-development tool designed to make it easy for those communicating with someone who speaks another language, providing ready access to pre-recorded translated content just by tapping a card on the screen
google-translation-cards	Translation Cards	This app comes with an initial set of translated and recorded content, oriented towards the medical field
google-translation-cards	Translation Cards	As a user of Translation Cards, you’re also able record their own translations for additional words and phrases.The need for this tool was born out of  field research  done for the European migrant crisis, where field workers lacked a ready way to provide instructions in a foreign language, which Translation Cards seeks to address.
google-trillian-examples	Trillian examples	This repository contains example applications built on top of Trillian   , showing that it's possible to applyTransparency concepts to problems other than Certificates Currently the examples here are:These examples are not supported per-se, but the Trillian team will likely tryto help where possible
google-trillian-examples	Trillian examples	 You can contact them via the channels listed under Trillian : 
google-trillian	MySQL Setup	To run Trillian's integration tests you need to have an instance of MySQLrunning and configured to:database like so:the  MySQL maximum connection count Trillian includes an integration test suite to confirm basic end-to-endfunctionality, which can be run with:Working on the CodeDevelopers who want to make changes to the Trillian codebase need someadditional dependencies and tools, described in the following sections
google-trillian	MySQL Setup	 The Travis configuration  .travis.yml  for the codebase is also useful referencefor the required tools and scripts, as it may be more up-to-date than this
google-trillian	Rebuilding Generated Code	Some of the Trillian Go code is autogenerated from other files:Re-generating mock or protobuffer files is only needed if you're changingthe original files; if you do, you'll need to install the prerequisites:and run the following:The Trillian codebase includes a couple of external projects under the master branch and the current stable release 
google-trillian	Rebuilding Generated Code	 These external codebases areincluded as Git subtrees To update the code in one of these subtrees, perform steps like:The  scripts/presubmit.sh  scripts/presubmit.sh  script runs various toolsand tests over the codebase.
google-trillian	Install gometalinter and all linters	go get -u github.com/alecthomas/gometalintergometalinter --install
google-trillian	Or just run the linters alone:	gometalinter --config=gometalinter.json ./...------
google-trillian	Design Overview	Trillian is primarily implemented as a gRPC service this service receives get/set requests over gRPC and retrieves the correspondingMerkle tree data from a separate storage layer  currently using MySQL , ensuringthat the cryptographic properties of the tree are preserved along the way.The Trillian service is multi-tenanted &ndash; a single Trillian installationcan support multiple Merkle trees in parallel, distinguished by their TreeId&ndash; and operates in one of two modes:proofs of inclusion/consistency are available for data items added to the
google-trillian	Personalities	The Trillian service expects to be paired with additional code that is specificto the particular application of the transparent store; this is known as aThe primary purpose of a personality is to implement **admission criteria*the store, so that only particular types of data are added to the store
google-trillian	Personalities	Forexample, a certificate transparency log only accepts data items that are validcertificates; a "CT Log" personality would police this, so that the Trillianservice can process all incoming data blindly.A personality may also perform **canonicalization*convert equivalent formulations of the same underlying data to a singlecanonical format, avoiding needless duplication
google-trillian	Personalities	  For example, keys inJSON dictionaries could be sorted, or Unicode string data could be normalised
google-trillian	Personalities	The per-application personality is also responsible for providing anexternally-visible interface, typically over HTTP S .Note that a personality may need to implement its own data store,separate from Trillian
google-trillian	Personalities	 In particular, if the personality does notcompletely trust Trillian, it needs to store the various things thatTrillian signs in order to be able to detect problems  and so thepersonality effectively also acts as a monitor for Trillian .
google-trillian	Map Mode	Trillian in Map mode can be thought of as providing a key:value store, togetherwith cryptographic transparency guarantees for that data.When running in Map mode, Trillian provides a straightforward gRPC API with thefollowing available operations: Documentation may be out-of-date; please check the protocol buffer message definitions  trillian_map_api.proto  for the definitive current map API
google-trillian	Map Mode	Each SetLeaves request includes a batch of updates to the Map; once all ofthese updates have been applied, the Map has a new **revision**, with a new treehead for that revision
google-trillian	Map Mode	 To allow historical queries, the API allows queriesof the Map as of a particular revision.TODO: add description of per-personality MappersTODO: add description of distribution: how many instances run, how distributed,how synchronized  master election , mention use of transactions as a fallback in case of errors in master election .! Map components  docs/MapDesign.png 
google-trillian	Log Mode	When running in Log mode, Trillian provides a gRPC API whose operations aresimilar to those available for Certificate Transparency logs cf
google-trillian	Log Mode	 RFC 6962  These include:In Log mode, Trillian includes an additional Signer component; this componentperiodically processes pending queued items and adds them to the Merkle tree,creating a new signed tree head as a result.! Log components  docs/LogDesign.png TODO: add description of distribution: how many instances run, how distributed etc.
google-trillian	Logged Map	As it currently stands, it is not possible to reliably monitor or audit aTrillian Map instance; key:value pairs can be modified and subsequently resetwithout anyone noticing.A future plan to deal with this is to create a *Logged Map*, which combines aTrillian Map with a Trillian Log so that all published revisions of the Maphave their signed tree head data appended to the corresponding Map.Use Cases
google-trillian	Certificate Transparency Log	The most obvious application for Trillian in Log mode is to provide acertificate transparency  RFC 6962  Log
google-trillian	Certificate Transparency Log	 To do this, the CT Log personalityneeds to include all of the certificate-specific processing &ndash; inparticular, checking that an item that has been suggested for inclusion isindeed a valid certificate that chains to an accepted root.
google-trillian	Verifiable Log-Derived Map	One useful application for Trillian in Map mode is to provide a verifiablelog-derived map  VLDM , as described in the Verifiable Data Structures  docs/VerifiableDataStructures.pdf  white paper which uses the term 'log-backed map' 
google-trillian	Verifiable Log-Derived Map	 To do this, a VLDM personality wouldmonitor the additions of entries to a Log, potentially external, and would writesome kind of corresponding key:value data to a Trillian Map.Clients of the VLDM are then able to verify that the entries in the Map they areshown are also seen by anyone auditing the Log for correct operation, which inturn allows the client to trust the key/value pairs returned by the Map.A concrete example of this might be a VLDM that monitors a certificatetransparency Log and builds a corresponding Map from domain names to the set ofcertificates associated with that domain.The following table summarizes properties of data structures laid in the Verifiable Data Structures  docs/VerifiableDataStructures.pdf  white paper.“Efficiently” means that a client can and should perform this validationthemselves
google-trillian	Verifiable Log-Derived Map	 “Full audit” means that to validate correctly, a client would needto download the entire dataset, and is something that in practice we expect asmall number of dedicated auditors to perform, rather than being done by each| ---------------------------------------| Prove inclusion of value| Prove non-inclusion of value| Retrieve provable value for key| Retrieve provable current value for key  |  Impractical| Prove append-only| Enumerate all entries| Prove correct operation| Enable detection of split-view
google-truth	What is Truth?	Truth makes your  test assertions  and  failure messages  more readable
google-truth	What is Truth?	Similar  comparison  to  AssertJ , it  natively supports  known_types  many JDKand  Guava  types, and it is  extensible  extension  to others.Truth is owned and maintained by the  Guava  team
google-truth	What is Truth?	It is used from the majorityof the tests in Google’s own codebase.Read more at  the main website  test assertions :  failure messages :  comparison :  AssertJ :  known_types :  extension :  Guava :  gh-pages-shield :  gh-pages-link :  travis-shield :  travis-link :  maven-shield :  maven-link :  stackoverflow-shield :  stackoverflow-link : 
google-ts-bridge	Time Series Bridge  ts-bridge 	Time Series Bridge is a tool that can be used to import metrics from onemonitoring system to another
google-ts-bridge	Time Series Bridge  ts-bridge 	It regularly runs a specific query againsta source monitoring system  currently only Datadog  and writes result into thedestination system  currently only Stackdriver .ts-bridge is an App Engine Standard app written in Go.
google-ts-bridge	Quick Start	  Add it into $PATH
google-ts-bridge	Quick Start	 cd app/ && goapp deploy -application $APP_ID -version live
google-ts-bridge	Datadog	To import a metric from Datadog, ts-bridge regularly runs a configured queryagainst the  Datadog QueryAPI Metrics imported from Datadog are defined in the datadog_metrics section ofthe configuration file  app/metrics.yaml 
google-ts-bridge	Datadog	The following parameters need tobe specified for each metric:  stackdriver_destinations section of the configuration file.All parameters are required.Please keep in mind the following details about Datadog API:  the whole organization
google-ts-bridge	Datadog	Even if ts-bridge is the only user of the Query API,  it still means you can only import 5 metrics if you are querying every minute   which is the default 
google-ts-bridge	Datadog	The limit can be raised
google-ts-bridge	Datadog	 as part of your query, Datadog will return a single point per each rollup  interval
google-ts-bridge	Datadog	If rollup interval is longer than the importing period of  ts-bridge, some import operations will fetch 0 new points
google-ts-bridge	Datadog	For example, if  your query is producing a 10-minute ratio    xxx.rollup sum, 600  / yyy.rollup sum, 600   and you are using the default  importing period  1 minute , ts-bridge will still issue the query every  minute, however Datadog will only return a single point once every 10 minutes
google-ts-bridge	Datadog	 interval 
google-ts-bridge	Datadog	Please keep in mind that Datadog might return more than 1 point  per minute, and all points will be written to Stackdriver, even though  Stackdriver does not allow querying with  alignment period  
google-ts-bridge	Stackdriver	Imported metrics can be written to multiple destination Stackdriver projects,even though in practice we expect a single instance of Time Series Bridge towrite to a single project  usually matching the GCP project where thets-bridge is running .Stackdriver destinations are listed in the stackdriver_destinationssection of the configuration file
google-ts-bridge	Stackdriver	The following parameters can be specifiedfor each destination:  ts-bridge is running will be used.If you are using ts-bridge to write metrics to a different Stackdriver projectthan the one it's running in, you will need to grant roles/monitoring.editorIAM permission to the service account used by the ts-bridge App Engine app toallow it to read and write Stackdriver metrics.
google-ts-bridge	Importing period	Time Series Bridge attempts to import all configured metrics regularly
google-ts-bridge	Importing period	Thisis driven by the  App Engine Cron Service   which isconfigured in app/cron.yaml
google-ts-bridge	Importing period	By default metrics are imported every minute.
google-ts-bridge	Global settings	Some other settings can be set globally as App Engine environment variables viathe env_variables section of app/app.yaml
google-ts-bridge	Global settings	 points are found
google-ts-bridge	Global settings	This interval should be kept reasonably short to  avoid fetching too much data from Stackdriver on each update
google-ts-bridge	Global settings	 than this, and a subsequent update will be triggered again
google-ts-bridge	Global settings	 context of a single incoming HTTP request, and setting this value too high  might result in the App Engine instance running out of RAM.You can use --env_var flag to override these environment variables whilerunning the app via dev_appserver.py.
google-ts-bridge	Status Web Page	If ENABLE_STATUS_PAGE environment variable is set to 'yes', the index page ofthe App Engine app shows a list of configured metrics along with import statusfor each metric
google-ts-bridge	Status Web Page	This might be useful for debugging, however is disabled bydefault to avoid publicly exposing a list of configured metrics  App Engine HTTPendpoints are publicly available by default .If you choose to leave the status page enabled, we recommend configuring Identity-Aware Proxy  IAP  for the Cloud project where ts-bridge is running
google-ts-bridge	Status Web Page	You can use IAP torestrict access to ts-bridge by a specific Google group or a list ofGoogle accounts.
google-ts-bridge	Monitoring	Time Series Bridge uses  OpenCensus  to report severalmetrics to Stackdriver:  you might need to increase UPDATE_PARALLELISM or UPDATE_TIMEOUT
google-ts-bridge	Monitoring	 data.All metrics are reported as Stackdriver custom metrics and have names prefixed by
google-ts-bridge	Development	  Add it into $PATHIf you'd like to contribute a patch, please see contribution guidelines in
google-ts-bridge	Support	This is not an officially supported Google product.
google-ts-style	gts 	 ! NPM Version  npm-image   npm-url  ! CircleCI  circle-image   circle-url   david-image   david-url   david-dev-image   david-dev-url  ! Known Vulnerabilities  snyk-image   snyk-url  ! codecov  codecov-image   codecov-url  gts  npm-url  is Google's TypeScript style guide, and the configuration for our formatter, linter, and automatic code fixer
google-ts-style	gts 	No lint rules to edit, no configuration to update, no more bike shedding over syntax
google-ts-style	gts 	To borrow from  standardjs  standardjs-url :Made with ❤️ by the Google Node.js team.
google-ts-style	Getting Started	If you're already using npm@5.3+  bundled with Node 8.3+ , run:Still on an older version of npm? We got ya! In a directory with your package.json run:When you run the npx gts init command, it's going to do a few things for you:The commands above will all run in the scope of the current folder
google-ts-style	Getting Started	 Some commands can be run on individual files:See  LICENSE.md  LICENSE.md > ***NOTE: This is not an official Google product.*** circle-image :  circle-url :  clang-format-url :  codecov-image :  codecov-url :  david-dev-image :  david-dev-url :  david-image :  david-url :  npm-image :  npm-url :  snyk-image :  snyk-url :  standardjs-url :  tslint-url : 
google-tsviewdb	Table Of Contents	--------
google-tsviewdb	Time-series of Time-series	Time-series of time-series can be produced by periodically run experiments each of which contain multiple iterations
google-tsviewdb	Time-series of Time-series	 TSViewDB stores the data points associated with these multiple iterations, and also automatically calculate various summary statistics over them  mean, min, max, 50th percentile, etc
google-tsviewdb	Time-series of Time-series	.! Time-series of Time-series  docs/ts_of_ts.png "Time-series of Time-series" 
google-tsviewdb	Interactive Graphs	TSViewDB provides a UI which quickly shows you what's in your data
google-tsviewdb	Interactive Graphs	 You have ready access to interactive graphs for summary statistics  aggregates , for iteration points, and for histograms of iteration points
google-tsviewdb	Interactive Graphs	 Common functionality is either a mouseover, click, or click and drag away
google-tsviewdb	Interactive Graphs	 Graphs are zoomable and auto-resizing.! TSViewDB Screenshot  docs/screenshot.png "TSViewDB Screenshot" 
google-tsviewdb	Regression Detection	TSViewDB can optionally determine if a regression has occurred in non-cyclic data for any of the read result data it returns
google-tsviewdb	Regression Detection	 The regression function works over noisy, non-cyclic data and returns the precise regressing segments  which may also be graphed 
google-tsviewdb	Regression Detection	 This facilitates setting up daily regression alert emails and analysis systems.
google-tsviewdb	Easy Horizontal Infrastructure Scaling	TSViewDB's current Apache Cassandra backend can be scaled simply by adding nodes, and is  known to handle significant write traffic   The TSViewDB server itself can be replicated behind a load balancer
google-tsviewdb	Easy Horizontal Infrastructure Scaling	 It includes an in-process, cluster-aware cache server which allows latencies for read hits to be low  --------------------Download executable:Quick Start1\
google-tsviewdb	Easy Horizontal Infrastructure Scaling	Register a new data source: "testdir/testsubdir/testdata"2\
google-tsviewdb	Easy Horizontal Infrastructure Scaling	Upload some data to it.Result should be something like:Additional Documentation----------
google-tuneup.dart	tuneup.dart	A command-line tool to manipulate and inspect your Dart projects
google-tuneup.dart	tuneup.dart	 
google-tuneup.dart	Installing	To install, run:
google-tuneup.dart	Running	Run tuneup --help  or pub global run tuneup --help  to see a list of available commands.from the root of your project.
google-tuneup.dart	Filing Issues	Please file reports on the  GitHub Issue Tracker 
google-tuneup.dart	Disclaimer	This is not an official Google product.
google-turbine	Turbine	Turbine is a header compiler for Java.
google-turbinia	Summary	Turbinia is an open-source framework for deploying, managing, and running distributed forensic workloads
google-turbinia	Summary	 It is intended to automate running of common forensic processing tools  i.e
google-turbinia	Summary	Plaso, TSK, strings, etc  to help with processing evidence in the Cloud, scaling the processing of large amounts of evidence, and decreasing response time by parallelizing processing where possible.
google-turbinia	How it works	Turbinia is composed of different components for the client, server and the workers
google-turbinia	How it works	 These components can be run in the Cloud, on local machines, or as a hybrid of both
google-turbinia	How it works	 The Turbinia client makes requests to process evidence to the Turbinia server
google-turbinia	How it works	 The Turbinia server creates logical jobs from these incoming user requests, which creates and schedules forensic processing tasks to be run by the workers
google-turbinia	How it works	 The evidence to be processed will be split up by the jobs when possible, and many tasks can be created in order to process the evidence in parallel
google-turbinia	How it works	 One or more workers run continuously to process tasks from the server
google-turbinia	How it works	 Any new evidence created or discovered by the tasks will be fed back into Turbinia for further processing.Communication from the client to the server is currently done with either Google Cloud PubSub or  Kombu  messaging
google-turbinia	How it works	 The worker implementation can use either  PSQ   a Google Cloud PubSub Task Queue  or  Celery  for task scheduling.More information on Turbinia and how it works can be  found here  docs/how-it-works.md .
google-turbinia	Status	Turbinia is currently in Alpha release.
google-turbinia	Installation	There is an  rough installation guide here  docs/install.md .
google-turbinia	Usage	The basic steps to get things running after the initial installation and configuration are: usage: turbiniactl  -h   -q   -v   -d   -a   -f   -o OUTPUT_DIR   -L LOG_FILE optional arguments:  -h, --help  -q, --quiet  -v, --verbose  -d, --debug  -a, --all_fields  -f, --force_evidence  Force evidence processing request in potentially  -o OUTPUT_DIR, --output_dir OUTPUT_DIR  -L LOG_FILE, --log_file LOG_FILE  -r REQUEST_ID, --request_id REQUEST_ID  -S, --server  -C, --use_celery  -V, --version  -D, --dump_json  -F FILTER_PATTERNS_FILE, --filter_patterns_file FILTER_PATTERNS_FILE  -j JOBS_WHITELIST, --jobs_whitelist JOBS_WHITELIST  -J JOBS_BLACKLIST, --jobs_blacklist JOBS_BLACKLIST  -p POLL_INTERVAL, --poll_interval POLL_INTERVAL  -w, --wait  The commands for processing the evidence types of rawdisk and directory specify information about evidence that Turbinia should process
google-turbinia	Usage	By default, when adding new evidence to be processed, turbiniactl will act as a client and send a request to the configured Turbinia server, otherwise if usage: turbiniactl rawdisk  -h  -l LOCAL_PATH  -s SOURCE   -n NAME optional arguments:  -h, --help  -l LOCAL_PATH, --local_path LOCAL_PATH  -s SOURCE, --source SOURCE  -n NAME, --name NAME  Descriptive name of the evidence
google-turbinia	Other documentation	This is not an official Google product  experimental or otherwise , it is just code that happens to be owned by Google.
google-u2f-ref-code	Reference code for U2F specifications	This code implements the FIDO U2F specifications being developed at  This code is intended as a reference and resourcefor developers who are interested in exploring U2F
google-u2f-ref-code	Reference code for U2F specifications	 The code consists of thefollowing components:
google-u2f-ref-code	Java U2F implementation	This code can verify U2F registrations and signatures
google-u2f-ref-code	Java U2F implementation	A web application builtto accept U2F 2nd factor is built on top of a code base such as this
google-u2f-ref-code	Java U2F implementation	The codebase includes a trivial web application so the user can experiment withregistration and signatures  also see the sample web app below .
google-u2f-ref-code	A virtual  software  U2F device	This is a Java implementation of a U2F device
google-u2f-ref-code	A virtual  software  U2F device	It generates registration andsignature statements and is meant for testing against your serverimplementation
google-u2f-ref-code	A virtual  software  U2F device	A physical U2F device will generate similar statements.
google-u2f-ref-code	A sample web app that uses U2F	This is a sample application built on the Google App Engine web platform whichdemonstrates a possible UX for  user interaction with U2F in a web page
google-u2f-ref-code	A sample web app that uses U2F	 Thesample application is deployed and available live at The underlying U2F capability is provided by theJava U2F implementation
google-u2f-ref-code	A sample web app that uses U2F	 A developer can take the core ideas from here andintegrate U2F into a web application on their own favorite web app platform.
google-u2f-ref-code	A U2F extension for the Chrome browser	This extension brings U2F capability to the Chrome browser
google-u2f-ref-code	A U2F extension for the Chrome browser	A web applicationis able to access USB U2F devices using the U2F API provided by this extension.The extension is  available from the Chrome store  webstore  for direct use.The source is available in u2f-chrome-extension for experimentation, see the extension README  u2f-chrome-extension/README.md  for details
google-u2f-ref-code	A U2F extension for the Chrome browser	webstore :USB device since the virtual device *does nottime
google-u2f-ref-code	A U2F extension for the Chrome browser	You can visit  to find FIDO U2F compliant devicesavailable for sale.
google-u2f-ref-code	Getting started	u2f-ref-code is a self contained java project that includes a basic web serverand includes packages for all crypto, utilities, etc
google-u2f-ref-code	Getting started	 It does *notin a container or application server like Tomcat
google-u2f-ref-code	Getting started	 To run the demo server, runthe main class in com.google.u2f.tools.httpserver.U2fHttpServerTo compile and run the server in Eclipse, import the Maven project into yourworkspace
google-u2f-ref-code	Getting started	You may need to fix the classpath if your version of JDK isdifferent  this has been tested with Java 1.7 
google-u2f-ref-code	Getting started	 The simple demo web server isin com.google.u2f.tools.httpserver.U2fHttpServer.java and runs on portRun this class as a regular Java application  right click, select *Runinstalled in Chrome in order for the demo app to talk to your U2F token.To run directly with Maven, run mvn compile exec:java from the u2f-ref-code
google-u2f-ref-code	U2F-GAE-Demo	The u2f-gae-demo project is a sample application built on the Google App Engineweb platform which demonstrates a possible UX for user interaction with U2F in aweb page.To start the development server with Maven, run mvn appengine:devserver
google-u2f-ref-code	U2F-GAE-Demo	Thiswill run the server locally at .As above, if importing the Maven project into Eclipse you might have to adjustJDK versions, App Engine SDK version, etc
google-u2f-ref-code	U2F-GAE-Demo	Once everything compiles, you can runthe App Engine server locally and point Google Chrome at .The built-in support for U2F in Google Chrome only works on HTTPS sites
google-u2f-ref-code	U2F-GAE-Demo	 To testthe app on , which uses HTTP, you need to do one of the
google-u2f-ref-code	Option 1: Use the extension from the webstore	   u2f-api.js   to
google-u2f-ref-code	Option 2: Use the built-in chrome support	You can deploy this App Engine app to your own domain by changing the applicationname in u2f-gae-demo/war/WEB-INF/appengine-web.xml.
google-ubntools	ubntools	Copyright 2017 Google Inc.This is not a google product.Tools to do fun things with ubiquity gear.
google-ubntools	Generate SSH key	Try a one-time upload by uploading 
google-ubntools	Set up regular data uploads	On the AP, run:Make sure files are being uploaded to the server every 10 minutes
google-ubntools	Set up regular data uploads	If it alllooks good then the AP setup is done
google-ubntools	Set up regular data uploads	At least until it reboots.
google-ubntools	On server: Create database	There are premade views  do \d and then SELECT but you can query more raw data too.
google-uiimage-additions	UIImage Additions	A collection of miscellaneous utility methods for UIImage for memory-efficientimage transformations.
google-uiimage-additions	CocoaPods	Add the following to your Podfile:
google-uiimage-additions	Carthage	Add the following to your Cartfile:
google-uiimage-additions	Import	Import the umbrella header as:
google-uniflow-polymer	UniFlow for Polymer 2.x	Set of mixins to enable uni-directional data flow in Polymer application.*This library was developed as part of internal project at Google and isn't directly affiliated with the Polymer project  although Polymer team has provided some good feedback on UniFlow implementation .*
google-uniflow-polymer	History & Overview	When you start working on a new Polymer application, it's easy to start and build the first few elements, and make them communicate via events and data binding, so everything looks nice and rosy
google-uniflow-polymer	History & Overview	However, as the number and complexity of elements grows, it becomes increasingly difficult to manage relationships between them, trace where/when the data changes happened, and debug the problems
google-uniflow-polymer	History & Overview	So this project started as an attempt by our team at Google to find a good way to architect large Polymer application
google-uniflow-polymer	History & Overview	Inspired by React's community Flux  and, later, Redux  architecture, we implemented a unidirectional data flow pattern  data down, events up  for Polymer
google-uniflow-polymer	History & Overview	We found that when using UniFlow application code becomes more streamlined  e.g
google-uniflow-polymer	History & Overview	it is clear what the responsibilities of each element are  and much easier to manage; the code has fewer bugs, and debugging is a lot more efficient
google-uniflow-polymer	History & Overview	Adding new functionality no longer exponentially increases complexity.This project was also inspired by Backbone Marionette
google-uniflow-polymer	History & Overview	Backbone.js back in the days of its glory was a great library that provided a nice set of building blocks for building JavaScript applications
google-uniflow-polymer	History & Overview	However, it left much of the application design, architecture and scalability to the developer, including memory management, view management, and more
google-uniflow-polymer	History & Overview	Marionette brought an application architecture to Backbone, along with built in view management and memory management
google-uniflow-polymer	History & Overview	It was designed to be a lightweight and flexible library of tools that sits on top of Backbone, providing the framework for building a scalable application
google-uniflow-polymer	History & Overview	Uniflow strives to achieve similar goal for Polymer
google-uniflow-polymer	History & Overview	We feel that Polymer, and web components in general, is a great concept that takes interoperability and encapsulation in Web development to the next level
google-uniflow-polymer	History & Overview	But it lacked the patterns for building large and complex applications, and this is the void we expect UniFlow to fill
google-uniflow-polymer	History & Overview	It is still in beta, so breaking changes may be happening before the first release
google-uniflow-polymer	History & Overview	However, we believe that abstractions implemented in the library can be useful for Polymer community, so we encourage people to try, fork, ask questions, send  comments, and submit pull requests.
google-uniflow-polymer	Applicability	This library implements the architectural pattern called 'unidirectional data flow'
google-uniflow-polymer	Applicability	It works best if application logic involves complicated data management, when multiple elements need to have access to or modify the same data
google-uniflow-polymer	Applicability	Even though the pattern can be implemented just using built-in Polymer concepts, such as custom events and data binding, the UniFlow library provides a useful set of tools and abstractions, and helps to structure application code.
google-uniflow-polymer	Implementation	UniFlow is implemented as a set of mixins that developers apply to their elements
google-uniflow-polymer	Implementation	It is assumed that each application has a singleton application element that maintains state of entire application
google-uniflow-polymer	Implementation	Each element that needs access to the data is bound, directly or indirectly, to sub-tree of application state tree
google-uniflow-polymer	Implementation	Two way data binding is never used to send data up, from child to parent, so only parent elements send data to children using one way data binding
google-uniflow-polymer	Implementation	Child elements, in turn, send the events  emit actions  responding to user actions, indicating that the data may need to be modified
google-uniflow-polymer	Implementation	Special non-visual elements called action dispatchers mutate the data, then all elements listening to the data changes render new data
google-uniflow-polymer	Action Dispatcher	Use UniFlow.ActionDispatcher for non-visual elements that process actions emitted by visualelements
google-uniflow-polymer	Action Dispatcher	Action dispatchers usually placed at the application level
google-uniflow-polymer	Action Dispatcher	Each action dispatcherelement gets a chance to process the action in the order the elements are present in theDOM tree
google-uniflow-polymer	Action Dispatcher	It is important that action dispatcher elements get two-way data binding toapplication state as follows:Action dispatcher elements can include nested action dispatchers, so you can have ahierarchical organization of action dispatchers.
google-uniflow-polymer	HTML:	class MyElement extends UniFlow.StateAware Polymer.Element  {  }customElements.define MyElement.is, MyElement ;When above element is declared as follows:
google-uniflow-polymer	JavaScript:	class MyApp extends UniFlow.ApplicationState Polymer.Element  {  }customElements.define MayApp.is, MyApp ;In the example above,  will receive notification of any changes to the state,as if it was declared as follows:the value of state.someElement.propertyA, and receive all notification of the property changewhenever the corresponding data in state tree changes
google-uniflow-polymer	JavaScript:	This essentially translates to followingown state, it is considered their private state and no other elements will be notified of those
google-uniflow-polymer	Action Emitter	Whenever element needs to emit an action, this mixin should be used
google-uniflow-polymer	Action Emitter	Action object must always include type property.
google-uniflow-polymer	Application State	Assign this mixin to your main application element
google-uniflow-polymer	Application State	It provides globalstate and functionality to maintain individual elements states
google-uniflow-polymer	Application State	This mixinis responsible for notifying all state-aware elements about their statechanges  provided those elements have statePath property defined .Only one element in the application is supposed to have this mixin.
google-uniflow-polymer	List View	This mixin used by elements that need to render multiple models backedby 'list' array
google-uniflow-polymer	List View	You may want to use ModelView to render individualmodels in the list
google-uniflow-polymer	List View	The mixin supports element selection by setting predefined$selected property on list elements.
google-uniflow-polymer	Model View	Element rendering data represented by a single object  model  in theapplication state should use ModelView mixin
google-uniflow-polymer	Model View	Model View is a powerfulconcept that encapsulates model data  likely the data received from theserver and to be persisted to the server if modified as a result of useractions , status  validity of the data, flag that data was modified,notifications for the user, etc
google-uniflow-polymer	Model View	Auxiliary data supplied by actiondispatchers and needed for display purposes or element's logicshould be defined as element’s properties
google-uniflow-polymer	Model View	Same applies to datacreated/modified by the element but not intended to be persisted.If StateAware mixin is used along with ModelView, you can take advantageof statePath property that indicates path to the element's state in theapplication state tree
google-uniflow-polymer	Model View	Whenever any data is mutated by action dispatchersat statePath or below, the element will receive notification of itsproperties' change  even if there is no explicit binding for thoseproperties 
google-uniflow-polymer	Model View	See UniFlow.StateAware for more details and example.ModelView mixin defines some properties that are intended to be overriddenin the elements:+ validation property allows to specify validation rulesthat will be applied when validateModel   method is called
google-uniflow-polymer	Model View	As a result ofthis method validation status will be updated to indicate result for eachmodel field that has validation rule associated with it.+ saveAction property indicates which action should be emitted whensaveModel method is called to perform save of the model.+ getMessage should be overridden with the function returning messagestring for given error code  to translate validation error code to message 
google-uniflow-polymer	State Aware	 Key mixin that must be assigned to all elements that need to access application state and/or have access to the application element
google-uniflow-polymer	State Aware	The element is notified of any changes to application's state, as well as all its properties when they're modified by state mutator elements
google-uniflow-polymer	State Aware	state-path property must be used to identify path to element's state in application state tree.
google-uniflow-polymer	State Mutator	Some non-visual elements, like action dispatchers, need to modify applicationstate, in which case they should have this mixin assigned
google-uniflow-polymer	State Mutator	Implements stateare only supposed to exist at the application level.
google-unigem-objective-c	Unigem	This repository contains **Unicode Gems**, a Mac app, an iOS app,and an iOS keyboard that makes it easy for you to use interestingtypefaces in contexts that don't allow fonted text.As an iOS app, you get an iPhone UI, an iPad UI, and iPad split view support.Apple, in iOS 11, dramatically extended the character styles that you can get in theirimplementation of Unicode.Some examples:𝐓𝐡𝐞 𝐪𝐮𝐢𝐜𝐤 𝐛𝐫𝐨𝐰𝐧 𝐟𝐨𝐱 𝐣𝐮𝐦𝐩𝐞𝐝 𝐨𝐯𝐞𝐫 𝐭𝐡𝐞 𝐥𝐚𝐳𝐲 𝐝𝐨𝐠𝐬.𝕋𝕙𝕖 𝕢𝕦𝕚𝕔𝕜 𝕓𝕣𝕠𝕨𝕟 𝕗𝕠𝕩 𝕛𝕦𝕞𝕡𝕖𝕕 𝕠𝕧𝕖𝕣 𝕥𝕙𝕖 𝕝𝕒𝕫𝕪 𝕕𝕠𝕘𝕤.🄽🄾🅆 🄸🅂 🅃🄷🄴 🅃🄸🄼🄴 🄵🄾🅁 🄰🄻🄻 🄶🄾🄾🄳 🄼🄴🄽 🅃🄾 🄲🄾🄼🄴 🅃🄾 🅃🄷🄴 🄰🄸🄳 🄾🄵 🅃🄷🄴🄸🅁 🄿🄰🅁🅃🅈.𝙉𝙤𝙬 𝙞𝙨 𝙩𝙝𝙚 𝙩𝙞𝙢𝙚 𝙛𝙤𝙧 𝙖𝙡𝙡 𝙜𝙤𝙤𝙙 𝙢𝙚𝙣 𝙩𝙤 𝙘𝙤𝙢𝙚 𝙩𝙤 𝙩𝙝𝙚 𝙖𝙞𝙙 𝙤𝙛 𝙩𝙝𝙚𝙞𝙧 𝙥𝙖𝙧𝙩𝙮.𝒥𝒶𝒸𝓀𝒹𝒶𝓌𝓈 𝓁ℴ𝓋ℯ 𝓂𝓎 𝒷𝒾ℊ 𝓈𝓅𝒽𝒾𝓃𝓍 ℴ𝒻 𝓆𝓊𝒶𝓇𝓉𝓏.𝔍𝔞𝔠𝔨𝔡𝔞𝔴𝔰 𝔩𝔬𝔳𝔢 𝔪𝔶 𝔟𝔦𝔤 𝔰𝔭𝔥𝔦𝔫𝔵 𝔬𝔣 𝔮𝔲𝔞𝔯𝔱𝔷.¿ʇɐɥʇ ɟo ʞuᴉɥʇ I ʇ,upᴉp ʎɥʍ ʍoNThese unicode tricks only work for the English alphabet, and some will translate to uppercaseif that is all that mode has.Sample Mac screenshot:! Sample Mac screenshot  Art/MacSample.png Sample iPhone screenshot:! Sample iPhone screenshot  Art/iPhoneSample.png This is not an officially supported Google product.
google-unigem-objective-c	Using:	Select a mode and start typing
google-unigem-objective-c	Using:	Copy from the result line into another app or use the customkeyboard to type directly into another app.
google-unigem-objective-c	Caveat:	Since your text is mapped to unusual unicode values, it won't be indexed correctly by search engines
google-unigem-objective-c	Caveat:	If you care,you should repeat the text as ordinary characters in the body of your message.
google-unigem-objective-c	Building	1  Start by editing account.xcconfig
google-unigem-objective-c	Building	It currently says:change that to your bundle prefix: the one on your developer account
google-unigem-objective-c	Building	Example:2  With the project 'Unigem' selected in Xcode's File Navigator, select each of the three targets and fix up the signing for your developer account
google-unigem-objective-c	Building	If you don't do this then you'll only able to run the Mac app, and the iOS ones in the simulator.2.a  In the Unigem target's General section check the checkbox to turn on automatic signing and select your team.2.b  Do the same for the 'keys' target2.c  and again for the unigem target3  Now you'll be able to select each of the three targets and use Xcode's Run command to run them.4  On the iOS device, you enable a custom keyboard in Settings > General > Keyboard > Keyboards > Add New Keyboard.PRODUCT_VERSION is a build setting defined at the project level that affects all three targets.None of the three versions of Unigem store or send your data.
google-unigem-objective-c	See also:	Macintosh Unicode  Character Viewer  Part of OS X.Click on a character to enter it in the current text edit box
google-unigem-objective-c	See also:	Zalgo Text  Stacking punctuation to make your text look likesomething out of a Lovecraft horror novel.
google-unimorph	Abstract	Which languages convey the most information in a given amount of space? This isa question often asked of linguists, especially by engineers who often have someinformation theoretic measure of "information" in mind, but rarely defineexactly how they would measure that information
google-unimorph	Abstract	The question is, in factremarkably hard to answer, and many linguists consider it unanswerable
google-unimorph	Abstract	But itis a question that seems as if it ought to have an answer
google-unimorph	Abstract	If one had a databaseof close translations between a set of typologically diverse languages, withdetailed marking of morphosyntactic and morphosemantic features, one could hopeto quantify the differences between how these different languages conveyinformation
google-unimorph	Abstract	Since no appropriate database exists we decided to constructone
google-unimorph	Abstract	The purpose of this paper is to present our work on the database, alongwith some preliminary results
google-unimorph	Abstract	We plan to release the dataset once complete.
google-unimorph	Per the paper	Our data are taken from a few domains of interest to Google including drivingdirections and answers generated from structured data for Google Now™
google-unimorph	Per the paper	 Notethat no Google user data is included in our data collection
google-unimorph	Per the paper	  Obviously suchexamples are but a subset of the ways in which language is used to communicate:The reason for picking data from this circumscribed set of domains is that forpart of the data at least, the text corresponds to, and in a real applicationwould be automatically generated from, data in a defined format  see below foran example 
google-unimorph	Per the paper	Therefore the basic intended meaning of a message is to a largeextent given, thus obviating the need to do semantic annotation
google-unimorph	Per the paper	By producingparallel target sentences in various languages, and making sure that thetranslations are as close as possible, while still being stylistically andsocially acceptable, we can be minimize differences in information content thatmight arise for irrelevant reasons, such as liberal choices of wording taken bythe translators
google-unimorph	Per the paper	We are therefore focusing as much as possible on what thelanguages must convey, rather than one what they may convey.Our initial dataset consists of 85 sentences from a mix of domains for thefollowing languages: English, French, Italian, German, Russian, Arabic, Koreanand Mandarin Chinese
google-unimorph	Per the paper	These languages were chosen from among languages for whichwe have very good resources, to be somewhat typologically balanced, representinglanguages of the “isolating” or quasi-isolating type  English, Mandarin ,“inflectional”  French, Italian, German, Russian, Arabic  and “agglutinative”’ Korean 
google-unimorph	Per the paper	We are also interested in languages with rich case systems  German,Russian, Korean , gender systems  French, Italian, German, Russian, Arabic ,anda variety of language families — four in this case.2 For the current dataset,translators were given the English original in a spreadsheet, and were given thefollowing instructions:This is a request for natural sounding and socially appropriate translationswhich should be inserted directly into the provided spreadsheet in the columnfor your language
google-unimorph	Per the paper	 Important: There is no character restriction for thesetranslations
google-unimorph	Per the paper	However, we want translations that are succinct as possible,natural sounding, and socially appropriate.
google-upb	μpb 	    μpb is a small protobuf implementation written in C.API and ABI are both subject to change!  Please do not distributeas a shared library for this reason  for now at least .
google-upb	Building the core libraries	The core libraries are pure C99 and have no dependencies.This will create a separate C library for each core libraryin lib/
google-upb	Building the core libraries	 They are built separately to help your binariesslim, so you don't need to link in things you neither wantor need.Other useful targets:
google-upb	C and C++ API	The public C/C++ API is defined by all of the .h files inupb/ except .int.h files  which are internal-only .
google-upb	Lua bindings	Lua bindings provide μpb's functionality to Lua programs.The bindings target Lua 5.1, Lua 5.2, LuaJIT, and  soon  Lua 5.To build the Lua bindings, the Lua libraries must be installed
google-upb	Lua bindings	 Oncethey are installed, run:Note that if the Lua headers are not in a standard place, you mayneed to pass custom flags:To test the Lua bindings:
google-upb	Contact	Author: Josh Haberman   jhaberman@gmail.com  mailto:jhaberman@gmail.com , haberman@google.com  mailto:haberman@google.com  
google-upvote	Features	  
google-upvote	Setup	See the  docs page  docs/setup.md  for full instructions.
google-upvote	Docs	We are current working hard to get Upvote ready for external contributions.However, at this time, we do not have the necessary approvals to do so.In the meantime, please feel free to file GitHub issues or post in our GoogleGroup,  upvote-discuss with any comments, bugs, or feature requests.
google-upvote	Contributors	Core Contributors:  Chief  Matthew Special thanks to  Danny  Haru   Maxim And to the Santa team:  Russell  Tom   Ed  Phillip 
google-upvote	Disclaimer	This is not an official Google product.
google-uri.dart	UriPattern	UriPattern is an interface for classes that match and parse URIs, much like the  Pattern  pattern  is for Strings
google-uri.dart	UriPattern	It defines the methods bool matches Uri uri  and UriMatch match Uri uri 
google-uri.dart	UriPattern	pattern : 
google-uri.dart	UriMatch	UriMatch is the result of UriPattern.match  
google-uri.dart	UriMatch	It contains the parameters parsed out of a URI and the "rest" of the URI left over after parsing, which is useful for parsing a single URI with multiple relative URI patterns that form a hierarchy.
google-uri.dart	UriTemplate	UriTemplate is an implementation of  RFC 6570 URI Templates  rfc6570 
google-uri.dart	UriTemplate	URI Templates are useful for generating URIs from data
google-uri.dart	UriTemplate	UriTemplates are created from a template string, and then expanded with data to generate a URI:URI templates are strings made up of fixed and variable parts
google-uri.dart	UriTemplate	The variable parts are described with _expressions_, which are places within single curly-braces: { and }.Expressions consist of an optional _operator_ and a comma-separated list of _variable_specifications_
google-uri.dart	UriTemplate	Variable specifications consist of a variable name and an optional _modifier_
google-uri.dart	UriTemplate	The operator applies to the whole expression and controls how reserved characters are expanded, the prefix and separator, if any, applied to the expansion, and whether to expand the variable as a key/value pair
google-uri.dart	UriTemplate	Modifiers apply to each variable in the expression and allow truncating the value, or "exploding" list and maps into multiple key/value pairs.
google-uri.dart	Examples	URI template expansions does more than simple variable replacement, it has facilities for generating paths, fragments, query strings and more
google-uri.dart	Examples	To control the expansion, expressions can use one of the supported operators:| Operator | Description| _none_   | Simple string expansion| +| #| .| /| ;| ?| &
google-uri.dart	Modifiers	Modifiers control | Modifier | Description| _none_   | Default expansion| :_n_
google-uri.dart	UriParser	UriParser parses URIs according to a UriTemplate, extracting paramaters based on the variables defined in the template.Since URI Templates are not designed to be parsable, only a restricted subset of templates can be used for parsing.Parsable templates have the following restrictions over expandable templates:UriBuilder is mutable container of URI components for incrementally building Uris.
google-uribeacon	Project Status Update	We launched the UriBeacon project in 2014 to explore how to use BLE technology to share URLs
google-uribeacon	Project Status Update	 Since then, we’ve been thrilled about the community that has formed around UriBeacon, and with the contributors and partners who have worked with us to produce UriBeacon utilities, apps, prototypes, and production-ready beacons.We’ve also found that in addition to broadcasting URLs, there is much more that can be accomplished with an open beacon format.To that end, **UriBeacon is evolving to become part of the  Eddystone open beacon format Like UriBeacon, Eddystone supports broadcasting URLs in BTLE advertisement packets via its  Eddystone-URL  frame type
google-uribeacon	Project Status Update	 But unlike UriBeacon, Eddystone offers first class support for a variety of payload types
google-uribeacon	Project Status Update	 Eddystone provides much better support for unique IDs via its  Eddystone-UID  frame, provides telemetry information via its  Eddystone-TLM  frame, and it opens the door for more future innovation
google-uribeacon	Project Status Update	 Read the full  Protocol Specification There are some protocol changes to this new format, but this move should not impact much for the  Physical Web  project, which will support Eddystone-URL beacons.We look forward to continuing to work with you in the Eddystone-URL project!—The UriBeacon  and now Eddystone-URL  team
google-uribeacon	Old Repo Contents	If you’re looking for the old UriBeacon specification and code, you can find it tagged  here 
google-us-altgr-intl	US AltGr International Keyboard for Android	This package contains additional layout files for physical keyboards  i.e
google-us-altgr-intl	US AltGr International Keyboard for Android	USB,Bluetooth  to enable the "AltGr" variant of the US International keyboard layouton Android.These layouts are also known as "us altgr-intl" or "US Extended".
google-us-altgr-intl	The Layouts	The layouts are based on the existing English  US International  layouts, withthe following changes:In case of the Pixel C variant, the following additional changes were done:
google-us-altgr-intl	English  US AltGr International 	! Keyboard Layout Picture  images/keyboard_english_us_intl.png 
google-us-altgr-intl	English  US AltGr International; Pixel C 	! Keyboard Layout Picture  images/keyboard_dragon_english_us_intl.png 
google-us-altgr-intl	Compiling & Installing	keyboard layouts from this package
google-us-altgr-intl	Compiling & Installing	They will show up as layouts provided by"US AltGr International External Keyboard Layout".Pixel C users: to go back to using the layouts included with the device, run oneTo add a custom layout:Download one of the existing layout files fromEdit and rename the file as needed
google-us-altgr-intl	Compiling & Installing	Some ideas:Save it below res/raw/ in this repository.Duplicate and edit one of the existing entries belowDuplicate and edit one of the existing entries inCompile and install as above.
google-us-altgr-intl	Copyright	See the LICENSE file.
google-us-altgr-intl	Contributing	See the CONTRIBUTING.md file.
google-us-altgr-intl	Disclaimer	This is not an official Google product.
google-usbinfo	USBInfo	USBInfo provides Python developers a way to uniformly access informationabout USB endpoints on a system without the need to understand the finedetails of any one particular platform's implementation of USB
google-usbinfo	USBInfo	This isuseful in robotics and device automation and allows developers to writemore portable code.More information can be found in the documentation 
google-uuid	uuid ! build status 	The uuid package generates and inspects UUIDs based on RFC 4122 and DCE 1.1: Authentication and Security Services
google-uuid	uuid ! build status 	This package is based on the github.com/pborman/uuid package  previously namedcode.google.com/p/go-uuid 
google-uuid	uuid ! build status 	 It differs from these earlier packages in thata UUID is a 16 byte array rather than a byte slice
google-uuid	uuid ! build status 	 One loss due to thischange is the ability to represent an invalid UUID  vs a NIL UUID .
google-uuid	Install	go get github.com/google/uuid
google-uuid	Documentation 	 ! GoDoc  Full go doc style documentation for the package can be viewed online withoutinstalling this package by using the GoDoc site here: 
google-vae-seq	VAE-Seq	VAE-Seq is a library for modeling sequences of observations.
google-vae-seq	Background	One tool that's commonly used to model sequential data is theRecurrent Neural Network  RNN , or gated variations of it such as theLong Short-Term Memory cell or the Gated Recurrent Unit cell.RNNs in general are essentially trainable transition functions:Normal distributions for real-valued observations.The output of the RNN specifies the parameters of the observationdistribution  e.g
google-vae-seq	Background	the logits of a Categorical or the mean andvariance of a Normal 
google-vae-seq	Background	But the size of the RNN output and thenumber of parameters that we need don't necessarily match up
google-vae-seq	Background	To solvethis, we project output into the appropriate shape via a NeuralNetwork we'll call a decoder.And what about the input of the RNN? It can be empty, but we mightwant to include side information from the environment  e.g
google-vae-seq	Background	actionswhen modeling a game or a metronome when modelingmusic 
google-vae-seq	Background	Additionally, the observation from the previous step s  isalmost always an important feature to include
google-vae-seq	Background	Here, we'll use anotherNeural Network we'll call an encoder to summarize the observationinto a more digestible form.Together, these components specify a factored  by time step probability distribution that we can train in the usual way: bymaximizing the probability of the network weights given theobservations in your training data and your priors over thoseweights
google-vae-seq	Background	Once trained, you can use ancestral sampling to generate new
google-vae-seq	Motivation	This library allows you to express the type of model describedabove
google-vae-seq	Motivation	It handles the plumbing for you: you define the encoder, thedecoder, and the observation distribution
google-vae-seq	Motivation	The resulting model canbe trained on a Dataset of observation sequences, queried for theprobability of a given sequence, or queried to generate new sequences.But the model above also has a limitation: the family of observationdistributions we pick is the only source of non-determinism in themodel
google-vae-seq	Motivation	If it can't express the true distribution of observations, themodel won't be able to learn or generate the true range of observationsequences
google-vae-seq	Motivation	For example, consider a sequence of black/white images
google-vae-seq	Motivation	Ifwe pick the observation distribution to be a set of independentBernoulli distributions over pixel values, the first generated imagewould always look like a noisy average over images in the trainingset
google-vae-seq	Motivation	Subsequent images might get more creative since they areconditioned on a noisy input, but that depends on how images varybetween steps in the training data.The issue in the example above is that the observation distribution wepicked wasn't expressive enough: pixels in an image aren'tindependent
google-vae-seq	Motivation	One way to fix this is to design very expressiveobservation distributions that can model images
google-vae-seq	Motivation	Another way is tocondition the simple distribution on a latent variable to produce ahierarchical output distribution
google-vae-seq	Motivation	This latter type of model is knownas a Variational Auto encoder  VAE .There are different ways to incorporate latent variables in asequential model  see the supported architectures below  but thegeneral approach we take here is to view the RNN state as acollection of stochastic and deterministic variables.
google-vae-seq	Usage	To define a model, subclass ModelBase to define an encoder, adecoder, and the output distribution
google-vae-seq	Usage	The decoder and outputdistribution are packaged together into a DistModule  see: vaeseq/codec.py  vaeseq/codec.py  .The following model architectures are currently available  see: vaeseq/vae  vaeseq/vae  : see:  vaeseq/hparams.py  vaeseq/hparams.py  
google-vae-seq	Usage	You can select amongthe architectures above by setting the vae_type parameter.
google-vae-seq	Examples	When you build and install this library via python setup.py install,the following example programs are installed as well
google-vae-seq	Examples	See: vaeseq/examples  vaeseq/examples .
google-vae-seq	Text	A character-sequence model that can be used to generate nonsense textor to evaluate the probability that a given piece of text was writtenby a given author.To train on Andrej Karpathy's "Tiny Shakespeare" dataset:After training has completed, you can generate text:Or you can tell how likely a piece of text is to be Shakespearean:
google-vae-seq	MIDI	Similar to the text example above, but now modeling MIDI music specifically, piano rolls 
google-vae-seq	MIDI	Installed under vaeseq-midi
google-vae-seq	MIDI	Don'texpect it to sound great.
google-vae-seq	Play	An experiment modeling a game environment and using that to train anagent via policy gradient
google-vae-seq	Play	This example uses the OpenAI Gymmodule
google-vae-seq	Play	Installed under vaeseq-play.
google-vae-seq	Disclaimer	This is not an official Google product.
google-varstruct	Varstruct Overview	Varstruct creates struct-like types with runtime-computed array sizes.Varstruct is a header-only library -build config, just add varstruct.h and varstruct_internal.h to your includes.C-style struct definitions may have internal array fields; however, these fielddeclarations must specify the size of each array at compile time so that thecompiler may reserve enough space when computing the offset of each member andthe size of the struct.Unfortunately, many I/O protocols use headers with internal arrays whose size isspecified or computed based on other header fields
google-varstruct	Varstruct Overview	Therefore, code that parsesthese headers often has to perform error-prone manual pointer manipulation.Varstruct is a C++11 library that creates types that may contains internalarrays, and the sizes of these arrays may be passed in at runtime
google-varstruct	Varstruct Overview	Varstructthen computes offsets to each member, and can also read and modify fields whengiven an input pointer
google-varstruct	Varstruct Overview	Modification is performed via std::memcpy   to avoid memory alignment problemsthat would otherwise occur accessing misaligned fields -any padding of its own .You can run the tests by running the following in the repo root directory  youwill need Google Bazel installed :bazel test :varstruct_testSee the comments in varstruct.h for more information.Author: Caleb Raitto
google-varstruct	Disclaimer	This is not an official Google product.
google-vector_math.dart	vector_math	    
google-vector_math.dart	Introduction	A Vector math library for 2D and 3D applications.
google-vector_math.dart	Features	1\
google-vector_math.dart	Features	Add the following to your project's **pubspec.yaml*Read the  docs 
google-vector_math.dart	Examples	1\
google-vector_math.dart	Examples	Using the GLSL getter and setter syntax.import 'package:vector_math/vector_math.dart';void main   {  Vector3 x = new Vector3.zero  ; // Zero vector  Vector4 y = new Vector4.all 4.0 ; // Vector with 4.0 in all lanes  x.zyx = y.xzz; // Sets z,y,x the values in x,z,z2\
google-vector_math.dart	Examples	Transforming a vector.import 'dart:math';import 'package:vector_math/vector_math.dart';void main   {  // Rotation of PI/2 degrees around the Y axis followed by a  // translation of  5.0, 2.0, 3.0 
google-vector_math.dart	Examples	 Matrix4 T = new Matrix4.rotationY PI  Vector3 position = new Vector3 1.0, 1.0, 1.0 ;  // Transform position by T
google-vector_math.dart	Examples	 T.transform3 position ;3\
google-vector_math.dart	Examples	Invert a matriximport 'dart:math';import 'package:vector_math/vector_math.dart';void main   {  // Rotation of 90 degrees around the Y axis followed by a  // translation of  5.0, 2.0, 3.0 
google-vector_math.dart	Examples	 Matrix4 T = new Matrix4.rotationY PI  T.invert  ;  // Invert just the rotation in T
google-vector_math.dart	Examples	 T.invertRotation  ;4\
google-vector_math.dart	Examples	Rotate a vector using a quaternionimport 'dart:math';import 'package:vector_math/vector_math.dart';void main   {  // The X axis
google-vector_math.dart	Examples	 Vector3 axis = new Vector3 1.0, 0.0, 0.0 ;  // 90 degrees
google-vector_math.dart	Examples	 double angle = PI / 2.0;  // Quaternion encoding a 90 degree rotation along the X axis
google-vector_math.dart	Examples	 Quaternion q = new Quaternion.axisAngle axis, angle ;  // A point
google-vector_math.dart	Examples	 Vector3 point = new Vector3 1.0, 1.0, 1.0 ;  // Rotate point by q
google-vector_math.dart	Examples	 q.rotate point ;5\
google-vector_math.dart	Examples	Check if two axis aligned bounding boxes intersectimport 'package:vector_math/vector_math.dart';void main   {  // Define the first box with a minimum and a maximum
google-vector_math.dart	Examples	 Aabb2 aabbOne = new Aabb2.minMax new Vector2.zero  , new Vector2 4.0, 4.0  ;  // Define the second box  Aabb2 aabbTwo =  // Extend the second box to contain a point  aabbTwo.hullPoint new Vector2 3.0, 3.0  ;  // Check if the two boxes intersect, returns true in this case
google-vector_math.dart	Examples	 bool intersect = aabbOne.intersectsWithAabb2 aabbTwo ;6\
google-vector_math.dart	Examples	Check where a ray and a sphere intersectimport 'package:vector_math/vector_math.dart';void main   {  // Define a ray starting at the origin and going into positive x-direction
google-vector_math.dart	Examples	 Ray ray = new Ray.originDirection new Vector3.zero  , new Vector3 1.0, 0.0, 0.0  ;  // Defines a sphere with the center  5.0 0.0 0.0  and a radius of   Sphere sphere = new Sphere.centerRadius new Vector3 5.0, 0.0, 0.0 , 2.0 ;  // Checks if the ray intersect with the sphere and returns the distance of the  // intersection from the origin of the ray
google-vector_math.dart	Examples	Would return null if no intersection  // is found
google-vector_math.dart	Examples	 double distanceFromOrigin = ray.intersectsWithSphere sphere ;  // Evaluate the position of the intersection, in this case  3.0 0.0 0.0 
google-vector_math.dart	Examples	 Vector3 position = ray.at distanceFromOrigin ;7\
google-vector_math.dart	Examples	Work with colorsimport 'package:vector_math/vector_math.dart';void main   {  // Access a build-in color, colors are stored in 4-dimensional vectors
google-vector_math.dart	Examples	 Vector4 red = Colors.red;  Vector4 gray = new Vector4.zero  ;  // Convert the red color to a grayscaled color
google-vector_math.dart	Examples	 Colors.toGrayscale red, gray ;  // Parse a blue color from a hex string
google-vector_math.dart	Examples	 Vector4 blue = new Vector4.zero  ;  Colors.fromHexString '#0000FF', blue ;  // Convert the blue color from RGB to HSL
google-vector_math.dart	Examples	 Colors.rgbToHsl blue, blue ;  // Reduce the lightness of the color by 50%
google-vector_math.dart	Examples	 blue.z *= 0.5;  // Convert the HSL color back to RGB
google-vector_math.dart	Examples	 Colors.hslToRgb blue, blue ;
google-vector_math.dart	Development	To run test cases:
google-verilogpp	Verilogpp User Manual	 idle" and "write1 ->write1" are implicit.
google-verilogpp	OPTIONS	If the "--enum" option is specified on the first line of the FSM macro, then anenum is used to generate the state variables instead of a bitvector and a setof localparam declarations.
google-verilogpp	INST {#Macro_INST}	The INST macro creates an instance of the specified module
google-verilogpp	INST {#Macro_INST}	 The"specifications" text of the INST macro can be used to specify parameters,and to indicate how port names should be mapped onto signal names.Parameters can be specified for the instantiated block like this:Transformation of port names onto signal names occurs by applying aset of transformation rules onto the port name to produce the signalname that port should connect to.The simplest transformation simply maps a port to a signal, like this:Alternately, a regular expression substitution can be performed on theport name to produce the signal name:The INST macro is often used in conjunction with the AUTONET macro toautomatically generate correct net declarations for all nets mapped onto theports of INST-instantiated submodules
google-verilogpp	INST {#Macro_INST}	 Additionally, the AUTOINTERFACE macrocan be used to propagate unbound ports from INST-instantiated submodules to themodule interface.See also: the AUTONET, AUTOINTERFACE, and FORINST macros.
google-verilogpp	PERL {#Macro_PERL}	*DEPRECATED*: Use the EXEC macro instead.This macro is expanded by evaluating an embedded perl script.The STDOUT produced by the embedded perl script is the generatedverilog code
google-verilogpp	PERL {#Macro_PERL}	 Think of it like a "generate" statement on steroids.This macro improves code by providing a more maintainablealternative to the copy-paste-edit cycle.
google-verilogpp	REG {#Macro_REG}	*DEPRECATED*: Use a macro instead.This macro provides a concise way to instantiate registers in a consistentfashion
google-verilogpp	REG {#Macro_REG}	 Register mapping is specified using a simple RTL syntax:Alternately, conditional loading of registers can be specified:Clock and reset default to "clock" and "reset_n" respectively, but canbe overridden with the "clk:" and "rst:" directives.
google-verilogpp	STRUCT {#Macro_STRUCT}	*DEPRECATED*: This macro was useful when working with Verilog-2001 code,but modern code should use SystemVerilog struct constructs.The STRUCT macro is used to concatenate a series of signalsinto a data-structure like bus, by defining a set of macrosto simplify the assembly and disassembly of that bus.Each line is a data member, optionally prefixed by a word size
google-verilogpp	STRUCT {#Macro_STRUCT}	 Ifword size is omitted, the data member is assumed to be a single bit wide.By default, fields in the structure are concatenated in order so thatthe first element is the least-signficant part of the structure
google-verilogpp	STRUCT {#Macro_STRUCT}	 Ifthe reverse order is preferred, supply the "--reverse" option to themacro declaration, and the first item will be the most significant partof the structure.Options: if the "--reverse" option is supplied to the macro declarationline, the fields of the structure are produced in reverse order  ie
google-verilogpp	STRUCT {#Macro_STRUCT}	firstitem is the most signficiant part of the packed structure word .
google-verilogpp	TIEOUTPUTSTOZERO {#Macro_TIEOUTPUTSTOZERO}	This macro can be used to automatically tie all outputs of the currentmodule to zeroes, enabling quick creation of stub modules.For example:Expands to:
google-vim-codefmt	Supported File-types	Use :FormatLines to format a range of lines or use :FormatCode to formatthe entire buffer.
google-vim-codefmt	Usage example	This example uses  Vundle  whoseplugin-adding command is Plugin.to register formatters.
google-vim-codefmt	Autoformatting	Want to just sit back and let autoformat happen automatically? Add this to yourvimrc  or any subset :Most formatters have some options available that can be configured via Glaive You can get a quick view of all codefmt flags by executing :Glaive codefmt, orstart typing flag names and use tab completion
google-vim-codefmt	Autoformatting	See :help Glaive for usage
google-vim-codefmt	Installing formatters	Codefmt defines several built-in formatters
google-vim-codefmt	Installing formatters	The easiest way to see the list ofavailable formatters is via tab completion: Type :FormatCode  in vim.Formatters that apply to the current filetype will be listed first.To use a particular formatter, type :FormatCode FORMATTER-NAME
google-vim-codefmt	Installing formatters	This willeither format the current buffer using the selected formatter or show an errormessage with basic setup instructions for this formatter
google-vim-codefmt	Installing formatters	Normally you willtrigger formatters via key mappings and/or autocommand hooks
google-vim-codefmt	Installing formatters	Seevroom/main.vroom to learn more about formatting features, and seevroom/FORMATTER-NAME.vroom to learn more about usage for individual formatters.
google-vim-codefmt	Creating a New Formatter	Assume a filetype myft and a formatter called MyFormatter
google-vim-codefmt	Creating a New Formatter	Our detailedguide to creating a formatter  liveshere // TODO kashomon : Create a worked example formatter.
google-vim-codereview	Commands	Use :CodeReview {remoterepo} to view pull requests / pending changes betweenlocal and remote repo.
google-vim-codereview	Usage example	This example uses  Vundle  whoseplugin-adding command is Plugin.
google-vim-colorscheme-primary	A Vim color scheme based on Google's colors	! Light mode  /screenshots/light.png?raw=true ! Dark mode  /screenshots/dark.png?raw=true 
google-vim-colorscheme-primary	Installation	Install using your favorite plugin manager.To install using Vundle, add the following to your vimrc:To set Primary as your default color scheme, add these lines to your .vimrc:See doc/colorscheme-primary.txt for detailed instructions and additional
google-vim-colorscheme-primary	Happy Google-inspired coding!	it is just code that happens to be owned by Google.*
google-vim-coverage	Commands	Use :CoverageToggle to toggle coverage visibility for the current file.
google-vim-coverage	Installation	This example uses  Vundle  whoseplugin-adding command is Plugin.detecting installed libraries.
google-vim-coverage	Using coverage providers	The easiest way to see the list of available providers is via tab completion:Type :CoverageShow  in vim.To use a particular provider, type :CoverageShow PROVIDER-NAME
google-vim-coverage	Using coverage providers	This willeither show coverage in the current buffer using the selected provider or showan error message if provider is not available
google-vim-coverage	Using coverage providers	Normally you will triggerproviders via key mappings and/or autocommand hooks.vim-coverage currently defines one coverage provider, a coverage.py provider forpython
google-vim-coverage	Using coverage providers	See  for other plannedCoverage offers a lot of customization on colors and signs rendered for coveredand uncovered lines
google-vim-coverage	Using coverage providers	You can get a quick view of all coverage flags by executing:help Glaive for usage details.
google-vim-coverage	Defining custom providers	Any plugin wishing to be a coverage provider needs only to register itself usingMaktaba's registry feature, passing a dictionary of following format:
google-vim-glaive	Usage example	This example uses  Vundle.vim  whoseplugin-adding command is Plugin
google-vim-glaive	Usage example	Note that Vundle does not add plugins to theruntime path until vundle#end  , so Glaive commands must come after thisfunction call.We will use two plugins for demonstration:   maktaba set rtp+=~/.vim/bundle/Vundle.vimcall vundle#begin  " Add maktaba, glaive, and codefmt to the runtimepath."  Glaive must also be installed before it can be used
google-vim-glaive	Usage example	Plugin 'google/vim-maktaba'Plugin 'google/vim-glaive'Plugin 'google/vim-codefmt'vundle#end  filetype plugin indent on" Add helloworld to the runtime path
google-vim-glaive	Usage example	 Normally this would be done with another" Plugin command, but helloworld doesn't have a repository of its own
google-vim-glaive	Usage example	call maktaba#plugin#Install maktaba#path#Join  maktaba#Maktaba  .location,call glaive#Install  " Configure helloworld using glaive.Glaive helloworld plugin mappings  name='Bram'" Real world example: configure vim-codefmtGlaive codefmt google_java_executable='java -jar /path/to/google-java-format.jar'Now, Goodbye, Bram!
google-vim-glaive	Usage example	  Recall that  defaults to \
google-vim-jsonnet	vim-jsonnet	 Jsonnet  jsonnet  filetype plugin for Vim
google-vim-jsonnet	vim-jsonnet	jsonnet : ! A screenshot of Jsonnet syntax highlighting 
google-vim-jsonnet	Install	To install via Vim plugin managers:
google-vim-jsonnet	Vundle	For more info on Jsonnet:
google-vim-maktaba	Plugins Using Maktaba	Several vim plugins are already using maktaba As a user, you can generally expect these plugins to be configurable using Glaive  and be more well-behaved in terms ofthings like defining unwanted global mappings and variables and avoidingannoying side-effects like moving your cursor.Plugin authors should consider developing plugins using maktaba to simplifycode, support modular plugins with hassle-free dependency management, and avoidcommon pitfalls
google-vim-maktaba	Plugins Using Maktaba	If you've written a plugin using maktaba, please add it to thelist above and share feedback.
google-vim-maktaba	Further reading	In the vroom/ directory you'll find literate test files that walk you throughmaktaba features in depth
google-vim-maktaba	Further reading	vroom/main.vroom is a good place to start.In the examples/ directory you can find an example maktaba plugin to give youa feel for how maktaba plugins look.In the doc/ directory you'll find helpfiles for maktaba
google-vim-maktaba	Further reading	These are alsoavailable via :help maktaba if maktaba has been installed and helptags havebeen generated
google-vim-maktaba	Further reading	The help files document the maktaba API in its entirety.
google-vim-searchindex	vim-searchindex	This plugin shows how many times does a search pattern occur in the currentbuffer
google-vim-searchindex	vim-searchindex	After each search, it displays total number of matches, as well as theindex of a current match, in the command line:You can also press g/ to display search index for the last search term at thecurrent cursor position.That's it! The plugin is as simple and unobtrusive as possible
google-vim-searchindex	vim-searchindex	It works out ofthe box with all built-in search commands, and stays fast even on huge filesthanks to caching
google-vim-searchindex	vim-searchindex	For full documentation  including extensibility andconfiguration options , see :help searchindex.
google-vim-searchindex	Installation	If you don't have a preferred installation method, I recommendinstalling  pathogen.vim  andthen simply copy and paste:Once help tags have been generated, you can view the manual with:help searchindex.*Disclaimer: This is not an official Google product
google-vim-searchindex	Installation	It is just an open sourcecode that happens to be owned by Google.*
google-vim-selector	Installation	This example uses  Vundle  whoseplugin-adding command is Plugin.This is not an official Google product.
google-vim-syncopate	syncopate	 **Syn** tax  **cop** y-p **a** s **te** .
google-vim-syncopate	What's it for?	To make sharing beautiful code as frictionless as possible.Say you have a nicely syntax-highlighted buffer in vim.This plugin lets you open a browser tab with that buffer's contents, including the highlighting.If you copy-paste into a webmail window, a Google Doc, etc., the syntax highlighting stays intact.Best of all, it cleans up after itself: it won't clutter your directories with .html files.
google-vim-syncopate	How do I install it?	Depends on your plugin manager.Note that syncopate is a  maktaba  plugin, so you will need to install maktaba  if your plugin manager doesn't handle dependencies .If you want to configure the plugin, we strongly recommend installing  glaive  as well.Here are instructions for Vundle, the most popular plugin manager.Add the following lines between your call vundle#begin   and call vundle#end   lines." Dependency; required for vim-syncopate.Plugin google/vim-maktaba" Strongly recommended: easy configuration of maktaba plugins.Plugin google/vim-glaivePlugin google/vim-syncopateSyncopate is expected to work on any platform vim supports, but the defaultconfiguration may not work on your system and direct-to-clipboard support hasn'tbeen implemented for some platforms
google-vim-syncopate	How do I install it?	Contributions welcome!
google-vim-syncopate	xclip	Syncopate requires xclip to manipulate the clipboard
google-vim-syncopate	xclip	 In most cases,installing it from your package manager should just work.Arch Linux's official repository has an xclip  0.12.4  which is too old: itdoesn't support --target
google-vim-syncopate	xclip	Arch users should install xclip-svn from AUR:
google-vim-syncopate	Use the clipboard directly	Use the :SyncopateExportToClipboard command.It populates the clipboard with the contents of your buffer  or just part of it, if you're in visual mode , including highlighting.You can then paste your beautiful code into a compose window  such as Gmail .Of course, it's even better with a keymapping, which you can enable using Glaive:" This line needs to go anywhere after 'call vundle#end  '.call glaive#Install  " Enable keymappings.Glaive syncopate plugin mappings By default, syncopate's mappings all start with the prefix The following examples will assume you're using the default prefix, and that your    is ,.
google-vim-syncopate	Put it in a browser window	Alternatively, you can use the :SyncopateExportToBrowser command.It opens the HTML in a new browser tab, so you can select regions interactively.Syncopate automatically cleans up the HTML file after opening the tab.If you use :SyncopateExportToBrowser, be sure to copy with Ctrl-C  as opposed to mouse selection/middle-click ; otherwise, the highlighting will not be retained.
google-vim-syncopate	How do I configure it?	There are a variety of syncopate-specific options: whether to change the colorscheme, which browser to use, etc.See :help syncopate-config.For everything else, use the built-in options for the :TOhtml command: :help 2html.vim
google-vim-syncopate	How do I configure it?	Options are down below, starting at :help g:html_diff_one_file
google-vim-syncopate	How do I configure it?	For example, the following line will exclude line numbers from the output, even if you use them in vim:Mainly convenience.Under the hood, :SyncopateExportToClipboard will:Switch to the default colorscheme  it shows up better on white backgrounds .Create the HTML version of your vim buffer.Export it to the clipboard.Restore your colorscheme, and any other settings it needed to change.Simply running :TOhtml only does the second step.In particular, the third step is difficult to remember how to do.Without it, :TOhtml usually involves tiresome saving-and-subsequently-deleting of HTML files, and fiddling with a browser.
google-vimdoc	Block Directives	Block directives take up an entire line in the comment block
google-vimdoc	Block Directives	They look likeAvailable block directives include:The global directives  @stylized, @order, and @library  are all detected frominside a @section block  usually the Introduction section .
google-vimdoc	Inline Directives	Inline directives occur in the body of comment blocks
google-vimdoc	Inline Directives	Most take one argumentenclosed in parenthesis
google-vimdoc	Inline Directives	 are left off, stylized is used.
google-vimdoc	Other Metadata	Some metadata for your plugin is not configured via vimdoc directives, but comesfrom other sources.By default, the name for the plugin is the name of its top-level directory
google-vimdoc	Other Metadata	If addon-info.json file is present and contains an explicit "name" field, vimdoc will use thatplugin name instead
google-vimdoc	Other Metadata	This is important if the plugin lives in a directory with a"vim" prefix or suffix, such as "vim-dispatch"
google-vimdoc	Other Metadata	This plugin name will appear inthe helpfile header and determine the name of the helpfile itself.Vimdoc will also take the author and description values from the "author"and "description" fields in addon-info.json.------Vimdoc syntax is reminiscent of helpfile syntax.The generated helpfile for a plugin has the following structure:upon the comment blocks existing in the right places in the file
google-vimdoc	Other Metadata	You mayeliminate sections by omitting the comment blocks
google-vimdoc	Other Metadata	You may add custom sectionswith the @section directive.
google-vimdoc	Header	The header is a simple line or two following the vim helpfile style guide
google-vimdoc	Header	Itlooks something like:
google-vimdoc	Table of Contents	Of the formAnd so on for each section.
google-vimdoc	Introduction	The introductory comment block is used to populate this section.
google-vimdoc	Configuration	This section contains descriptions of all the flags and settings that wereannotated by vimdoc comment blocks.Any global let command with a doc comment will automatically be detected as aYou can use the @setting block directive to declare settings vimdoc doesn'tMaktaba flags with doc comments are also automatically recognized:
google-vimdoc	Commands	Contains a list of commands available to the user
google-vimdoc	Commands	Vimdoc understands -bang,-nargs, -range, -count, -register, and -buffer
google-vimdoc	Commands	 It ignores -bar
google-vimdoc	Commands	 It willparse out the arguments in the order that they are mentioned in the commentblock above the command and will generate a usage line for the command
google-vimdoc	Commands	Forexample, the following comment block:will generate the following usage line:You can override the usage line with the @usage command, which takes a list ofarguments
google-vimdoc	Commands	Any arguments that look like vim variable names  \I\i+  will beassumed to be parameters, and their required-ness will be inferred from thedocs
google-vimdoc	Commands	You can force required-ness by providing arguments that look like vimvariables wrapped in curly  required  or square  optional  brackets
google-vimdoc	Commands	Emptycurly brackets stand in for the remainder of the inferred required variables.Empty square brackets stand in for the remainder of the inferred optionalvariables
google-vimdoc	Commands	For example:For more advanced usage, you may use the @command directive
google-vimdoc	Commands	This is usefuleither when your command takes a non-standard argument list  like :substitute or when your command is not recognized by vimdoc  when you :execute 'command's:name .The @command directive takes one argument, which is the entire usage line
google-vimdoc	Commands	{}expands to all of the inferred required parameters,    to all of the inferredoptional parameters, and <> to the complete inferred command name with built-inflags included
google-vimdoc	Commands	For example:generates the usage line:An argument which may be given multiple times should be suffixed with anellipsis
google-vimdoc	Commands	For example, {arg...} documents an argument that may appear once ormore and  arg..
google-vimdoc	Commands	 denotes an argument that may appear zero or more times.Sometimes you want a command to have more than one usage
google-vimdoc	Commands	For that you may usemore than one usage directive
google-vimdoc	Commands	Example:This will generate two docs for the command: one for list, one for dicts
google-vimdoc	Commands	An@all directive denotes that the remainder of the block will be included in allusages
google-vimdoc	Commands	In the above example, the warning will be included in both the list andthe dict version of the command docs.
google-vimdoc	Dictionaries	Vimscript kinda-sorta supports object oriented programming via dictionarieswith functions attached
google-vimdoc	Dictionaries	 See :help Dictionary-function
google-vimdoc	Dictionaries	 Vimdoc helps yougroup these dictionaries and their methods in one place in the documentation.You may describe a dictionary object type using the @dict annotation ina comment block that is above a blank line
google-vimdoc	Dictionaries	Then you may annotate thedictionary functions with the @dict directive to have them grouped with thedictionary description
google-vimdoc	Dictionaries	 Such functions will not be listed in the functionssection
google-vimdoc	Functions	Function documentation is very similar to command documentation.The order of required parameters is inferred by looking at the functionThe order of optional parameters is inferred by the order they are mentioned inthe comment block
google-vimdoc	Functions	Use the @usage command as described in the Command sectionto correct the order of optional arguments.Functions may have multiple usages just like commands
google-vimdoc	Functions	Functions are notexposed in the help docs by default
google-vimdoc	Functions	Use @public to make them public by@function can be used to tell vimdoc about a non-obvious function  such as onecreated by :execute 
google-vimdoc	Functions	  , {}, and    expand as in @command.
google-virtualdesktops-extension	Browser Action Icon	The browser action icon is actually created via a  element
google-virtualdesktops-extension	Browser Action Icon	Thisallows rendering the desktop number on the icon on-the-fly without needing oneimage file per supported desktop.
google-virtualdesktops-extension	Moving Chrome Windows	To reposition an existing window, the chrome.windows  API isused
google-virtualdesktops-extension	Moving Chrome Windows	However, one can't just call chrome.windows.update   on an existingwindow and expect the position and size to "just work"! The problem is thatespecially on X11, the window manager will add window borders and title bars tothe Chrome-specified target window size
google-virtualdesktops-extension	Moving Chrome Windows	So to actually achieve the desiredposition, the following approach is taken:  requested the size change from the window manager, but before the window  manager actually performed the action! In fact, on X11, the window manager  can even silently ignore the request, so there is no safe way for Chrome to  just "wait till the window manager is done".Note that this will allow a window to overlap its neighboring window's borders.This is intentional to save some space on the screen
google-virtualdesktops-extension	Moving Chrome Windows	It should not be possiblefor a window to actually overlap into a neighboring window's content area.No Chrome permissions are required for this action.
google-virtualdesktops-extension	Extracting Tabs to New Windows	To turn an existing window into a tab, the currentWindow.There are some pitfalls here too, though:  special cases, we instead create the window without a size specification, and  move it into place using chrome.windows.update   as in the previous  section
google-virtualdesktops-extension	Extracting Tabs to New Windows	 pass throgh the tab's incognito property to the chrome.windows.create    call.No Chrome permissions are required for this action.
google-virtualdesktops-extension	Managing Virtual Desktops	There is currently no way in ChromeOS to manage virtual desktops a window ison
google-virtualdesktops-extension	Managing Virtual Desktops	So how can we possibly do this? Essentially using the same approach existing software  can use to provide thesame feature on Windows.Essentially, what this means is:Of course, there are pitfalls when doing this too:  switching away from its desktop
google-virtualdesktops-extension	Managing Virtual Desktops	 without specifying a target size, and then run a second round setting the  window positions
google-virtualdesktops-extension	Managing Virtual Desktops	 position and size is persisted into localStorage.No Chrome permissions are required for this action.-----------  not necessary
google-virtualdesktops-extension	Managing Virtual Desktops	 window is on  already and not just when releasing the keys like what happens on most X11  window managers
google-virtualdesktops-extension	Managing Virtual Desktops	 empty desktop would no longer allow you to switch to a non-empty one
google-virtualdesktops-extension	Managing Virtual Desktops	Thus  empty desktops will be skipped when switching between desktops, and closing  the last remaining Chrome window on a desktop will automatically switch to  another, non-empty, desktop.-------The code is released unser the Apache 2.0 license
google-virtualdesktops-extension	Managing Virtual Desktops	See the LICENSE file formore details.This project is not an official Google project
google-virtualdesktops-extension	Managing Virtual Desktops	It is not supported by Googleand Google specifically disclaims all warranties as to its quality,merchantability, or fitness for a particular purpose.
google-vk_callback_swapchain	Vulkan Callback Swapchain	Vulkan Callback Swapchain is a Vulkan layer This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google
google-vk_callback_swapchain	Vulkan Callback Swapchain	See the CONTRIBUTING.md  CONTRIBUTING.md  file for more information
google-vk_callback_swapchain	Vulkan Callback Swapchain	See also the AUTHORS  AUTHORS  and  CONTRIBUTORS  CONTRIBUTORS  files.If an application inserts this layer, either by explicitly enabling thislayer, or through environment variables, the default swapchain mechanism isreplaced
google-vk_callback_swapchain	Vulkan Callback Swapchain	All of the existing platform-specific swapchain and surface callsremain valid
google-vk_callback_swapchain	Vulkan Callback Swapchain	However instead of creating a swapchain thatrenders to the given native surface, a virtual swapchain will be created.The following calls are intercepted.It follows that a Valid native surface is not required.Any window/module/connection parameters are ignored
google-vk_callback_swapchain	Vulkan Callback Swapchain	This can be used forexample to allow an application that typically renders to a window tobe run without a window.The following method is additionally exported by the layer.This function allows the user to set a callback function to be called when aswapchain image has been scheduled for presentation
google-vk_callback_swapchain	Vulkan Callback Swapchain	The parametersto the provided callback are the originally supplied user_data, apointer to the bytes that would have been output, and the number of bytes
google-vk_callback_swapchain	Building	This project is a standard CMake project.Example using ninja.specified by setting the CMake variable VULKAN_INCLUDE_LOCATION.
google-vmregistry	VMRegistry	 ! Docker Repository on Quay  "Docker Repository on Quay"  **This is not an official Google product**VMRegistry is a simple GRPC-based API around libvirt that allows to query VMdetails and to manage VM state.You can find all the currently exposed APIs in proto/vmregistry.proto.
google-vmregistry	Accessing VMRegistry	VMRegistry auth is based on JWT as provided by  credstore  Consultcredstore documentation on how to generate a token.There's no RBAC at the moment, so anyone holding a valid token has full accessto the vmregistry, possibly meaning a transitive root access to the host nodevia libvirt.
google-vogon	Vogon: scalable customization of video campaigns	Vogon combines a video creative, a data table and a layout specification,generating a copy of the video creative combined with each line of the datatable according to the layout specification.The data can contain text and images
google-vogon	Vogon: scalable customization of video campaigns	The specification determines the timing,position and font definitions for each piece of text and image, referencingdata fields through their names
google-vogon	Vogon: scalable customization of video campaigns	Fixed text can also be used in the layoutThe generated videos are  optionally  uploaded to a Youtube channel, and a campaign specification file is generated to be imported in AdWords for Video,creating geo-targeted campaigns for each of the videos.This is not an official Google product.
google-vogon	Dependencies	In order to run Vogon, you need to have the following installed first:Vogon can upload videos to Youtube using the Youtube API and help you create AdWords for Video campaigns
google-vogon	Dependencies	In order to do that, you need to complete the steps below.Create a project in the  Google Developers Console   In the Console, create a new project with the "Create Project" button  Click "Enable an API" and activate the "Youtube Data V3" API  In "APIs and Auth -> Credentials", create a new Client ID for a installed application  Download the JSON file with the "Download JSON" button, and save it in the directory where you will run Vogon  together with your configuration, data and image files   The account that manages the Youtube channel and the AdWords account must both have Edit access to the project, which can be configured in the "Permissions" section of the ConsoleThe Youtube and AdWords accounts must be linked 
google-vogon	Configuration	Vogon configuration files are  JSON documents  Two samples are included with the source, a version for  Unix-like systems  and another for  Windows  You can use one of these as a starting point for your project.In most values, you can use variables to insert values from the input CSV
google-vogon	Configuration	For example, you can use the location name from the CSV to specify the geo-targeting for the campaigns.The syntax for variables is {{column name}}, where "column name" is the name in the CSV header
google-vogon	Configuration	For example, if your CSV looks like this:City | PriceSão Paulo | 48.900,00Curitiba | 49.900,00You can configure geo-targeting like this:"Location": "{{city}}"Column names are case-insensitive  e.g
google-vogon	Configuration	"City" and "city" both work .Vogon pre-defines some special variables that don't come from the CSV:{{$id}}: a sequential line number of the record in the CSV file  starting at 1, after the header 
google-vogon	Configuration	It can be useful to generate video files with unique names, for example.{{$video_id}}: After a video is uploaded to YouTube, this is the video ID
google-vogon	Configuration	It can be used for linking to the video
google-vogon	Configuration	The "Video Id" ad attribute in the output CSV is automatically set to this value.
google-vogon	Importing the Campaigns	Vogon will generate a CSV file that can be imported into AdWords for Video, containing all the new campaigns, ads and targeting for the generated videos
google-vogon	Importing the Campaigns	This file can be modified with a text editor or spreadsheet application  like LibreOffice or Excel , if necessary, or imported as is.If you want to insert ads into existing campaigns, you'll need to obtain the campaign ID
google-vogon	Importing the Campaigns	To do that, click the "Bulk Upload" button, choose the "Only Data" option and click "Download"
google-vogon	Importing the Campaigns	The generated file will contain the campaign ID numbers.
google-vogon	Reference	AdWords for Video bulk upload documentation: 
google-vogon	Location Codes	Location names need to be followed by their codes, which can be looked up in this page:  The prefix "47-" needs to be added to the code that you look up from the page.For example:If the codes are present, the names are not really important, as the system will use the code to look up the location
google-vogon	Location Codes	If the code is absent, the system will try to find the location by name, but this is unreliable and can lead to missing or incorrect locations.
google-voice-builder	Voice Builder	Voice Builder is an opensource text-to-speech  TTS  voice building tool thatfocuses on simplicity, flexibility, and collaboration
google-voice-builder	Voice Builder	Ourtool allows anyone with basic computer skills to run voice training experimentsand listen to the resulting synthesized voice.We hope that this tool will reduce the barrier for creating new voices andaccelerate TTS research, by making experimentation faster andinterdisciplinary collaboration easier
google-voice-builder	Voice Builder	We believe that our tool can helpimprove TTS research, especially for low-resourced languages,where more experimentations are often needed to get the most out of the limited
google-voice-builder	Prerequisites	Create a project on  Google Cloud Platform  GCP  Enable billing and request more quota for your projectInstall  Docker Go to  firebase.com  and import the project to firebase platformInstall gcloud cmd line tool by installing  CloudInstall  Node.js Install  firebase cmd line tool Enable all the following GCP services:		GCP will bring you to another page to set credentials for these
google-voice-builder	Prerequisites	Optional  Setup your own  custom data exporter 
google-voice-builder	Deployment	> If you have not completed all prerequisites, please do so before going further in the following steps.Clone this project to your current directory by:If you haven't logged in to your account via gcloud yet, please log in by:Also, if you haven't logged in to your account via firebase , please log in by:Open deploy.sh and edit the following variables:Create GCS buckets for Voice Builder to store each job dataDeploy cloud functions componentDeploy ui component
google-voice-builder	Create an example voice	At this step, you should have all components in place and can access the UI  at  VoiceBuilder initially provides you with two  example TTS engines   Festival   and  Merlin  and public data  from  language resources repo   yourself using our provided Festival engine by:  Access  and go to a create-voice form by clicking  You will see a form where you can choose different TTS engines and input  Click on "JOBS" tab
google-voice-builder	Create an example voice	Now, you should see a new job that you have just  After an hour, you should see "Completed Voice Model Deployment" under
google-voice-builder	 Optional  Using Custom Data Exporter	Data Exporter is another additional component you can add to the system.Normally, Voice Builder can work without Data Exporter
google-voice-builder	 Optional  Using Custom Data Exporter	Without it,Voice Builder would just use the input files as they are.However, in some cases you want to apply some conversion to your input filesbefore feeding them into TTS algorithms
google-voice-builder	 Optional  Using Custom Data Exporter	For example:can use to manipulate data before running the actual TTS algorithm
google-voice-builder	 Optional  Using Custom Data Exporter	Your customdata exporter will get a  Voice Specification containing file location, chosen TTS algorithm, tuning parameters, etc
google-voice-builder	 Optional  Using Custom Data Exporter	You can use these information tomanipulate/convert your data
google-voice-builder	 Optional  Using Custom Data Exporter	In the end, your data exporter should put allnecessary files into the designated job folder to trigger the actual TTS algorithm to run.Firstly, you need to give your data exporter access to GCS buckets.Open /deploy.sh and edit the following variables:Run command to give DATA_EXPORTER_SERVICE_ACCOUNT an ACL access to GCS bucketsOpen /config.js and add DATA_EXPORTER_API to the config as follows:Redeploy Voice Builder UI instance so that it now has a new config and knows  where to send Voice Specification info
google-voice-builder	 Optional  Using Custom Data Exporter	to your data exporterTry to create a new job! Voice Builder should now send a request to your DATA_EXPORTER_URL	with the created job's Voice Specification.
google-voice-builder	Voice Builder specification	VoiceBuildingSpecification is a JSON definition of the voice specification
google-voice-builder	Voice Builder specification	This specification is created by the Voice Builder backend when a user triggers a voice building request from the UI
google-voice-builder	Voice Builder specification	 It can be used by the data exporter  passed to the data exporter via its API  to convert files and by the TTS engine for its training parameters.id | Unique global job id.voice_name | User friendly voice name  e.g
google-voice-builder	Voice Builder specification	multi speaker voice .created_by | The name of the user who created the voice.job_folder | The path to the GCS job folder
google-voice-builder	Voice Builder specification	This is where all the data related to the job is store.lexicon_path | Path to the lexicon.phonology_path | Path to the phonology.wavs_path | Path to the wavs  should be a tar file .wavs_info_path | Path to the file containing mapping of wav name and prompts.sample_rate | Sample rate at which the voice should be built.tts_engine | Type of TTS engine to train the voice
google-voice-builder	Voice Builder specification	The value for this would be the engine_id from the selected TTS engine engine.json.engine_params | The additional parameters for tts engine.
google-voice-builder	EngineParam	-----------key | Parameter key.value | Value for the parameter key.
google-voice-builder	Path	-----------path | Path to the file.file_type | Format of the file.
google-voice-builder	Example	For example, if you set up your data exporter, when you create a voiceusing our predefined Festival engine, Voice Builder will send the requestbody similar to below to your data exporter
google-voice-builder	Example	Your data exporter then haveto pre-process data and put them in job_folder location which is gs://your-voice-builder-jobs/1 in this example .After all necessary files are placed in the folder, the actual voice buildingprocess will begin automatically as expected.
google-voice-iot-maker-demo	Google Actions + Particle Photon  via Dialogflow 	This maker-friendly tutorial is a great starting point for developers, students, and tinkerers of all types who want to integrate the  Google Home  with their IoT prototyping projects
google-voice-iot-maker-demo	Google Actions + Particle Photon  via Dialogflow 	You can use this app to control an LED by voice, thanks to the magic of  Google Assistant  and  Dialogflow  and an internet-connected  Particle Photon *Disclaimer*: This is not an official Google product.
google-voice-iot-maker-demo	What's included	This example ties together multiple technology platforms, so there are a few separate components included in this repo:
google-voice-iot-maker-demo	What you'll need	We’ll build our web app with Node.js, and will rely on some libraries to make life easier:You'll also need accounts with:If you've got all those  or similar services/devices  good to go, then we're ready to start!
google-voice-iot-maker-demo	Getting started	Assuming you have all the required devices and accounts as noted above, the first thing you'll want to do is to set up apps on the corresponding services so you can get your devices talking to each other.
google-voice-iot-maker-demo	Local setup	First, you'll need to clone this repo, and cd into the newly-created directory.You should see three directories  alongside some additional files :
google-voice-iot-maker-demo	Dialogflow	Using the Dialogflow account referenced above, you‘ll want to create a  Dialogflow agent  We'll be setting up a  webhook  to handle our triggers and send web requests to the Particle API.Create a new agent  or  click here  to begin 
google-voice-iot-maker-demo	Dialogflow	You can name it whatever you likeSelect *Create a new Google projectIn the Settings section  click on the gear icon next to your project name  and go to *Export and ImportYou've now imported the basic app shell — take a look at the new ledControl intent  viewable from the *IntentsHead over to the Integrations tab, and click *Google Assistant*.Scroll down to the bottom, and click *Update DraftClick on the *Google CloudClick on the *Actions on GoogleClick *Add*, and fill in the details of your project thereScroll down to the bottom, and click *Test Draft*You can now test out the conversational side of the app in one of two ways:However, if you’re following along step-by-step, it won't turn any lights on yet — we still have to set up the web service and the Photon app
google-voice-iot-maker-demo	Dialogflow	Onward then!
google-voice-iot-maker-demo	Google Cloud	Depending on which hosting environment you want to use, cd into either ./dialogflow-webhook/1-firebase-functions or ./dialogflow-webhook/2-app-engine, and continue the setup instructions in that directory's README.md file.
google-voice-iot-maker-demo	Particle	Make sure the Photon is correctly set up and connected
google-voice-iot-maker-demo	Particle	 If it’s not configured yet, follow the steps in the  Particle docs You can upload your code to your photon via the  Particle web editor  the  Particle Desktop IDE   based on Atom , or the  Particle command-line tools We'll be using the CLI for this example, which you can install thusly:To deploy via the command line, first make sure you’re logged in:You can find out the ID of your device by running:Then upload the code using that ID:The Photon should blink rapidly while the upload is in process, and when it's done  and calmly pulsing cyan , you're ready to go.You can make sure it all works by running the following from your terminal:If everything is configured properly, you should see something like the following:
google-voice-iot-maker-demo	Putting it all together	Once you’ve uploaded all the code and each service is configured, it’s time to give it all a try! You can confirm that everything went to plan by going to either your Assistant-enabled device or the  Google Actions simulator  asking to talk to your app  *"talk to  APP-NAME "* , and typing *"turn the light on"*
google-voice-iot-maker-demo	Putting it all together	If all goes well, your LED should turn on!
google-voice-iot-maker-demo	Further reading	This application is just a taste of what's possible — how far you take this framework is up to you!  Here are a few resources to help you continue on your journey:This demo was created by the Google Proto Studio team, including:
google-volley	Volley	Volley is an HTTP library that makes networking for Android apps easier and, mostimportantly, faster.For more information about Volley and how to use it, visit the  Android developer trainingpage 
google-voyager	Voyager	Voyager is a Chrome app designed to connect learners with educational,inspirational, and aspirational content from around the world.Voyager is designed to work on Chromebooks, and will evolve to be responsiveto other platforms
google-voyager	Voyager	When it comes to education, Voyager is meant to be astepping stone, not a final destination
google-voyager	Voyager	It is meant to excite and ignite whilepreparing learners to explore beyond Voyager’s boundaries.! Voyager screenshot 
google-voyager	Category Image Licenses	The following images are used under license:
google-vpn-reverse-tether	VPN-based USB "reverse tether"	Reverse tethering routes traffic from the device via host gateway over USB.This allows the Android device to access the network through the host withoutdepending on Wifi or Bluetooth.This method leverages VpnService API and **does not require root access**.
google-vpn-reverse-tether	ant	Get Android SDK and NDK
google-vpn-reverse-tether	ant	Using the SDK manager, get build tools.Build the native library:Build the apk and install it:Build the host-side forwarder:
google-vpn-reverse-tether	Eclipse	Get Android Development Tools and Android Native Development Tools.Import existing project into workspace and build.Build the host-side forwarder:
google-vpn-reverse-tether	Usage	Start the VPN service:Start the tunnel:When done, press Enter to stop the tether.
google-vpn-reverse-tether	License	See  LICENSE  LICENSE .
google-vroom	Vroom: Launch vim tests	! Vroom  /images/vroom_logo.png?raw=true _**Vroom is experimental.*haven't figured out how to work around
google-vroom	Vroom: Launch vim tests	We reserve the right to make backwardsincompatible changes in order to address these._Vroom is for testing vim.Let's say you're a vimscript author
google-vroom	Vroom: Launch vim tests	You want to test your new plugin
google-vroom	Vroom: Launch vim tests	You couldfind a nice vimscript test suite, but that only lets you test your vimscriptfunctions
google-vroom	Vroom: Launch vim tests	What you really want is a way to specify vim commands — actual inputkeys that that the user hits — and then verify vim's output.Enter vroom.The above vroom test opens vim, sends the keys iHello, world! and thenverifies that the contents of the current buffer is Hello, world!.Things can get much more complex than this, of course
google-vroom	Vroom: Launch vim tests	You need to be able tocheck the output of multiple buffers
google-vroom	Vroom: Launch vim tests	You need to check what messages yourfunctions echo
google-vroom	Vroom: Launch vim tests	You need to sandbox vim, capture its system commands, andrespond with dummy data
google-vroom	Vroom: Launch vim tests	And a few shortcuts would be nice.Never fear! Vroom has it all
google-vroom	Vroom: Launch vim tests	Check the examples for details and moredocumentation
google-vroom	Vroom: Launch vim tests	examples/basics.vroom is a good place to start.Run vroom -h to learn about vroom's configuration options.Did you accidentally set off a giant vroom test that's running too fast to halt?Never fear! Pop open another terminal and vroom --murder.Make sure the --servername flag matches with the vroom you're trying to kill.You may need to run reset in the terminal with the murdered vroom.See the Tips and Tricks page page for some strategies for getting the most out of vroom.
google-vroom	Installation	Note that Vroom requires a version of vim built with the +clientserveroption  run vim --version to check 
google-vroom	Installation	 See :help clientserver foradditional requirements.If you're on Ubuntu or Debian, you can install release packages  from GitHub.Otherwise, the easiest way to install vroom is to clone the vroom repositoryfrom GitHub, cd into the vroom directory, and runVim 7.4.384 and later have built-in syntax support for the vroom filetype
google-vroom	Installation	Youcan install the standalone ft-vroom plugin  for older versions of
google-vroom	Usage	Vroom is invoked from the command-line on .vroom files.
google-vroom	Vroom cheat sheet	Below is a table of the special symbols and conventions vroom recognizes
google-vroom	Vroom cheat sheet	Seethe files under  examples/  examples/  and in particular examples/basics.vroom  examples/basics.vroom  for explanations.| Symbol  | Description| ------|   >   | gt leader|   :   | colon leader|   %   | percent leader  | text|   |   &   | ampersand|   ~   | tilde leader|   |   | pipe leader|   !   | bang leader|   |   @   | at leaderSpecial controls: examples/directives.vroom  examples/directives.vroom  and examples/macros.vroom  examples/macros.vroom  for explanations.By default, vroom uses vim to execute vroom files
google-vroom	Vroom cheat sheet	You can instead invoke itwith the --neovim flag to execute vroom files inside neovim.To use it, you need to install the neovim-mode dependencies:You can configure your vim plugin's vroom files to be tested continuously in Travis CI Just create a .travis.yml file at the root of your repository
google-vroom	Vroom cheat sheet	The particularsmay vary for your plugin, but here's an example configuration:instructions are still being finalized
google-vroom	Vroom cheat sheet	Details coming soon.
google-vroom	Known issues	Vroom uses vim as a server
google-vroom	Known issues	Unfortunately, we don't yet have a reliable way todetect when vim has finished processing commands
google-vroom	Known issues	Vroom currently relies uponarbitrary delays
google-vroom	Known issues	As such, tests run more slowly than is necessary
google-vroom	Known issues	Furthermore,some lengthy commands in vroom tests require additional arbitrary delays inorder to make the tests pass.We're still looking for workarounds
google-vroom	Known issues	 If you, like us, wish vim had a saneclient/server architecture, consider supporting  neovim 
google-vsaq	Introduction	it's just code that happens to be owned by Google.VSAQ is an interactive questionnaire application
google-vsaq	Introduction	Its initial purpose wasto support security reviews by facilitating not only the collection ofinformation, but also the redisplay of collected data in templated form.At Google, questionnaires like the ones in this repository are used toassess the security programs of third parties
google-vsaq	Introduction	But the templates providedcan be used for a variety of purposes, including doing a self-assessmentof your own security program, or simply becoming familiar with issuesaffecting the security of web applications.To test the application without deploying it, go to e.g., *Assessment target*Assessment targetto export the answers.*Assessment targetfrom *assessment target*.
google-vsaq	Project Structure	---VSAQ includes an easy-to-use setup script called do.sh
google-vsaq	Project Structure	It supports thefollowing commands:To build VSAQ, run the following commands:./do.sh build
google-vsaq	Local Development Server	To run the VSAQ development server locally, use the run command:./do.sh runNote that the development app server uses a snapshot of the code, takenat the time you run it
google-vsaq	Local Development Server	If you make changes to the code, be sure to run theappropriate build command again and restart the dev server:
google-vsaq	Deployment	The open source version of VSAQ does not require a dedicated back end
google-vsaq	Deployment	This meansVSAQ can be hosted as a static application on any web server.To deploy VSAQ, complete the following steps:./do.sh build_prod — This will run a normal build, but will also removetest files.Copy the content of the build directory into any directory hosted on yourweb server.The questionnaire should now be available underhttps:// yourserver /vsaq.html?qpath=questionnaires/test_template.json---code to run on a back end
google-vsaq	Deployment	All operations are performed by vsaq_main.js in theAlthough this makes deployment very easy, you may want to run a customserver-side component for storing answers and mapping questionnairesto users
google-vsaq	Deployment	vsaq_main.js provides example code for submitting and loading questionnaireanswers to/from a back end:build/vsaq_binary.js.Closure Templates are compiled by the Closure Template Compilerand placed in build/templates/vsaq/static/questionnaire/templates.soy.js.The /questionnaires directory and parts of the /static directories arereplicated in build/.Changes to the JSON /questionnaires do not require redeployment of theapplication code, and can be done on the server if required.
google-vulkan_test_applications	Vulkan Test Applications	Vulkan Test Applications is a repository that contains several sets ofVulkan applications.The goals of this project are to maintain a repository of accessible testapplications for Vulkan tool developers to leverage, as well as exposeinteresting or non-obvious implications of the API.This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google
google-vulkan_test_applications	Vulkan Test Applications	See the CONTRIBUTING.md  CONTRIBUTING.md  file for more information
google-vulkan_test_applications	Vulkan Test Applications	See also the AUTHORS  AUTHORS  and  CONTRIBUTORS  CONTRIBUTORS  files.
google-vulkan_test_applications	Sample applications	These are a set of sample applications that either uses the API in a way that isinteresting for tools or use some functionality of the API that has not beenexposed to other samples.
google-vulkan_test_applications	GAPID command tests	These tests are designed to test the functionality of GAPID  for Vulkan
google-vulkan_test_applications	GAPID command tests	They can also beused to expose a variety of function call permutations for any layers
google-vulkan_test_applications	GAPID command tests	As agroup, they attempt to call all Vulkan functions with all permutations ofvalid inputs
google-vulkan_test_applications	GAPID command tests	See  gapid_tests  gapid_tests/README.md  for more information.
google-vulkan_test_applications	Checking out / Building	To clone:git clone --recursive path/to/this/repositoryThis will ensure that you have all of the dependencies checked out.To build for Windows.To build for Android.This assumes the Android ndk is installed in the default location ofIf it is installed elsewhere, useTo build only for 32-bit ARM platform.glslc is required to compile GLSL shaders to SPIR-V
google-vulkan_test_applications	Checking out / Building	If it is noton your path, its location should be specified through -DCMAKE_GLSL_COMPILER
google-vulkan_test_applications	Compilation Options	The only specific other compilation options control default behavior for allapplications
google-vulkan_test_applications	Compilation Options	See  entry  support/entry/README.md  for more informationon these flags.
google-vulkan_test_applications	Support Functionality	These should be checked out into third_party.
google-walt	WALT Latency Timer ##	 installed from Google Play or downloaded in the  releases section  the iOS app must be built from source.! WALT photo  docs/WALT_photo_audio_r07.jpg 
google-walt	Notes	  several minutes
google-walt	Notes	The workaround is to use the app to re-sync the  clocks
google-walt	Notes	Some, but not all tests in the app will sync the clocks when starting a measurement.
google-wasserstein-dist	wasserstein-dist 	wasserstein-dist is a tensorflow implementation of the Wasserstein  aka optimal transport  distance between a fixed set of data points and a probability distribution  from which one can sample 
google-wasserstein-dist	wasserstein-dist 	It can also be used to compute the distance between to points sets,but it is not optimized for this purpose
google-wasserstein-dist	wasserstein-dist 	The implementation follows the semi-dual Algorithms 2 in  Genevay Aude, Marco Cuturi, Gabriel Peyre, Francis Bach, "Stochastic Optimization for Large-scale Optimal Transport", NIPS 2016 
google-wasserstein-dist	wasserstein-dist 	This is not an official Google product.
google-wayback-machine-button	The Wayback Machine Button	This Chrome extension adds a Wayback Machine button to your browser toolbar.When you click it, it searches for the current tab in the Wayback Machine.This is not an official Google product.
google-wayback-machine-button	Icon	The Wayback Machine Button icon is the" library " icon by Kavya from the Noun Project 
google-wear-screeninfo	Wear-based WatchFace	This sample uses the Gradle build system
google-wear-screeninfo	Wear-based WatchFace	To build this project in releasemode with the embedded wearable APK, you will need to use"gradlew assembleRelease" or use Android Studio and the "Generate Signed APK"menu option.Patches are encouraged, and may be submitted by forking this project andsubmitting a pull request through GitHub
google-wear-screeninfo	Wear-based WatchFace	Please see CONTRIBUTING for more-------Copyright 2015 Google Inc
google-wear-screeninfo	Wear-based WatchFace	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-wear-sensors	Wear-based Activity	This sample uses the Gradle build system
google-wear-sensors	Wear-based Activity	To build this project in releasemode with the embedded wearable APK, you will need to use"gradlew assembleRelease" or use Android Studio and the "Generate Signed APK"menu option.Patches are encouraged, and may be submitted by forking this project andsubmitting a pull request through GitHub
google-wear-sensors	Wear-based Activity	Please see CONTRIBUTING for more-------Copyright 2015 Google Inc
google-wear-sensors	Wear-based Activity	All Rights Reserved.Licensed under the Apache License, Version 2.0  the "License" ;you may not use this file except in compliance with the License.You may obtain a copy of the License atdistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.
google-weasel	yummy-weasel	A simple frontend  App Engine app  that serves content from a GoogleCloud Storage  GCS  bucket, while allowing for:
google-weasel	design	The design is simple
google-weasel	design	Suppose you have a static website www.example.com,served directly from a GCS gs://www.example.com.A very simplified picture of the serving path can be shown as follows.Weasel enhancement consists of modifying the serving path to:A visitor requests the website page
google-weasel	design	Note that /index.html is now optional.Weasel fetches the object content from the original GCS bucket and cachesWeasel responds with the GCS object contents
google-weasel	design	Note that we can optionally
google-weasel	license	Apache License 2.This is not an official Google product.
google-web-activities	Web Activities JavaScript library	It’s a common task for a web page to open a different page  an iframe, a popup or a redirect  that will return its result back to the calling page
google-web-activities	Web Activities JavaScript library	The typical use cases include location picker, contact picker, payment form, social sign-in, and so on.While many platforms provide an easy and reliable APIs to accomplish this, Web platform does not
google-web-activities	Web Activities JavaScript library	The Web Activities library provides a common API to do this.
google-web-activities	Key concepts	The API provides two parts: a client  or port  and a host
google-web-activities	Key concepts	A host page implements the actual activity and a client page opens the host and waits for the result to be returned.
google-web-activities	Client API  ports 	These APIs are provided within the ActivityPorts class.A client page can open the activity as an iframe or a standalone page.To open the activity as an iframe:To open the activity as a standalone page  popup or redirect :// First setup callback, even if you are not yet starting an activity
google-web-activities	Client API  ports 	This// will ensure that you are always prepared to handle redirect results.ports.onResult resultId, port => {  port.acceptResult  .then result => {  } ;} ;// Open the activity.ports.open resultId, url, target, args, options ;For details options, see ActivityOpenOptionsDef type.
google-web-activities	Host API  hosts 	These APIs are provided within the ActivityHosts class.A host page implements the activity by connecting it to the client:activities.connectHost  .then host => {  // Check origin properties
google-web-activities	Host API  hosts 	 host.accept  ;  host.result result ;} ;
google-web-activities	Compiling Web Activities into your source	Include Web Activities as a  npm package In the npm package, you can either use the combined acitivities.js, or two separate activity-ports.js and activity-hosts.js based on whether you are implementing a client or a host.
google-web-activities	Using the precompiled binary in your project	Include  as a script on your page:  ..
google-web-activities	Using the precompiled binary in your project	 } ;Once the activities binary is loaded, you can use ports and hosts
google-web-activities	Using the precompiled binary in your project	For the actual APIs,see the  How to use this API  #how-to-use-this-api .
google-web-bsd-hunt	#Web Hunt	Port of the real-time multiplayer 2D maze war BSD game "Hunt" to GoogleApp Engine and modern web browsers
google-web-bsd-hunt	#Web Hunt	 Moderately complex multiplayer real-time web and mobile games requirea mix of stateless and stateful components to deal with managing gamestate, load balancing, scaling, matchmaking, statistics gathering,monitoring, analytics, and more.This project implements one such design and architecture for modernizingthe retro terminal based real-time multiplayer 1980's BSD game, "Hunt"and running in Google App Engine  GAE  Platform as a Service.It includes the entire client and server side applications, from theJavascript Single Page App running in a browser, to the statelessserving infrastructure running in the GAE StandardEnvironment, a stateful game engine in the GAE Flexible environment.Memcache, Datastore, Cloud Pub-Sub, Cron, and Metadata services areutilized as architectural components.
google-web-bsd-hunt	###Prerequisites	 
google-web-bsd-hunt	###Build and Deploy	create a new project
google-web-bsd-hunt	###Build and Deploy	     Make note of the name assigned to the new project.
google-web-starter-kit-extras	Web Starter Kit Extras	This repository contains optional additions to  Web Starter Kit  WSK   0  project, such as web server configurations, which, while useful, do not strictly belong in the main WSK repository.
google-web-starter-kit-extras	 Server Configs  server-configs 	Boilerplate configurations for various web servers to host WSK-based app.
google-web-starter-kit-extras	Contributing	Contributions, questions and comments are all welcome and encouraged
google-web-starter-kit-extras	Contributing	For code contributions to Web Starter Kit Extras, please see our  Contribution guide  CONTRIBUTING.md  before submitting a pull request
google-web-starter-kit-extras	Contributing	 WSK  0  related issues should be filed on the  main repo issue tracker  1 .
google-web-starter-kit-extras	License	Apache 2.0Copyright 2014 Google Inc 0 :  1 : 
google-web-starter-kit	Overview	 Web Starter Kit  is an opinionated boilerplate for web development
google-web-starter-kit	Overview	Tools for building a great experience across many devices and  performance oriented  #web-performance 
google-web-starter-kit	Overview	Helping you to stay productive following the best practices outlined in Google's  Web Fundamentals  A solid starting point for both professionals and newcomers to the industry.
google-web-starter-kit	Features	| Feature| Responsive boilerplate | A responsive boilerplate optimized for the multi-screen web
google-web-starter-kit	Features	Powered by  Material Design Lite   You're free to use either this or a completely clean-slate  via  basic.html | Sass support| Performance optimization| Code Linting| ES2015 via Babel 6.0| Built-in HTTP Server| Live Browser Reloading| Cross-device Synchronization| Offline support| PageSpeed Insights
google-web-starter-kit	Quickstart	 Download  the kit or clone this repository and build on what is included in the app directory.There are two HTML starting points, from which you can choose:Once you have verified that your system can run WSK, check out the  commands  docs/commands.md  available to get started.
google-web-starter-kit	Web Performance	Web Starter Kit strives to give you a high performance starting point out of the box
google-web-starter-kit	Web Performance	Our median Web Page Test  scores  for the default template have a  Speed Index  of ~1100  1000 is ideal  and a repeat-visit Speed Index of ~550 thanks to Service Worker precaching.
google-web-starter-kit	Browser Support	At present, we officially aim to support the last two versions of the following browsers:
google-web-starter-kit	Troubleshooting	If you find yourself running into issues during installation or running the tools, please check our  Troubleshooting  guide and then open an  issue  We would be happy to discuss how they can be solved.
google-web-starter-kit	A Boilerplate-only Option	If you would prefer not to use any of our tooling, delete the following files from the project: package.json, gulpfile.babel.js and .travis.yml
google-web-starter-kit	A Boilerplate-only Option	You can now safely use the boilerplate with an alternative build-system or no build-system at all if you choose.
google-web-starter-kit	Docs and Recipes	Web Starter Kit is inspired by  Mobile HTML5 Boilerplate  and Yeoman's  generator-gulp-webapp  having taken input from contributors to both projects during development
google-web-starter-kit	Docs and Recipes	Our  FAQs  attempt to answer commonly asked questions about the project.
google-web-starter-kit	Contributing	Contributions, questions and comments are all welcome and encouraged
google-web-starter-kit	Contributing	For code contributions to Web Starter Kit, please see our  Contribution guide  CONTRIBUTING.md  before submitting a pull request
google-web-starter-kit	Contributing	 Website  related issues should be filed on the  Web Fundamentals  issue tracker.
google-web-starter-kit	License	Apache 2.0  Copyright 2015 Google Inc
google-web_notifications.dart	web_notifications	  A package that implements the Notification API
google-web_notifications.dart	web_notifications	Somewhat of anexperiment in making new/experimental APIs available as packages,rather than having everything in dart:html.
google-web_notifications.dart	Usage	A simple usage example:import 'dart:html' hide Notification;import 'package:notification/notification.dart';main   async {  if  !Notification.supported  return;  await Notification.requestPermission  ;  new Notification "Hello world", body: "Have a nice day!" ;
google-web_notifications.dart	Features and bugs	Please file feature requests and bugs at the  issue tracker  tracker 
google-web_notifications.dart	Features and bugs	tracker : 
google-webauthndemo	WebAuthnDemo	An example Java Relying Party implementation of the  WebAuthnspecification 
google-webauthndemo	Install	The demo is written on top of Google App Engine
google-webauthndemo	Install	Runfor a local development server instance.
google-webdriver.dart	webdriver	   ! pub package  Provides WebDriver bindings for Dart
google-webdriver.dart	webdriver	These use the WebDriver JSON interface,and as such, require the use of the WebDriver remote server.
google-webdriver.dart	Installing	 Depend on it Install it Import it
google-webdriver.dart	Testing	Unfortunately using bazel with Dart libraries and Dart WebDriver is not yetsupported
google-webdriver.dart	Testing	We hope to add this at some point, but for now pub still works
google-webdriver.dart	Testing	As a consequence, running tests is a bit more complicated than we'd like:1  Launch a WebDriver binar ies .2  Run a test
google-webdriver.dart	Testing	All files suffixed with '_test.dart' are tests
google-webdriver.dart	Testing	 
google-webkit_inspection_protocol.dart	webkit_inspection_protocol.dart	   ! pub package  
google-webkit_inspection_protocol.dart	What is it?	The webkit_inspection_protocol package is a client of the Webkit InspectionProtocol  WIP 
google-webkit_inspection_protocol.dart	What is it?	It's used to talk to Chrome DevTools based debuggers.
google-webkit_inspection_protocol.dart	The protocol	Read more about the protocol  here 
google-webkit_inspection_protocol.dart	Disclaimer	This is not an official Google product.
google-webview-local-server	Overview	The purpose of this library is to enable hosting local content  such as assetsor resources  under an http s :// URL
google-webview-local-server	Overview	 The traditional way to access local resources is to use file:///android_assetor file://android_res/ URLs but using the file: scheme poses problems with  the Same-Origin policy  andmakes it problematic to reference local content from content loaded overa secure  https:  connection.
google-webview-local-server	Usage	Using the WebView-Local-Server requires the following steps:Create a WebViewLocalServer instance.Tell the server where to host the resources.Hook up the server in the shouldInterceptRequest method.Consider using the following settings in order to maximize security:
google-webview-local-server	Picking a domain.	One potential problem of hosting local resources on a http s :// URL is thatdoing so may conflict with a real website
google-webview-local-server	Picking a domain.	This means that local resourcesshould only be hosted on domains that the user has control of or which havebeen dedicated for this purpose
google-webview-local-server	Picking a domain.	 The androidplatform.net domain has been specifically reserved for thispurpose and you are free to use it.By default the hostResources.Should using a random subdomain be inconvenient for some reason it is possibleto use a fixed domain  like androidplatform.net or a domain you own .
google-webview-local-server	Disclaimer	This is not an official Google product  experimental or otherwise , it is justcode that happens to be owned by Google.
google-weighted-dict	WeightedDict	A "dictionary" for logarithmic time sampling of keys according to a probabilitydistribution defined by the keys'  normalized  values.
google-weighted-dict	Operations	The values in the weightedDict are assumed to be non-negative.The following operations are all worst case O log n  time:Example usage:Output should be:
google-where-am-i	Where am I? Complication for Wear OS	This is a simple app that shows a complication on the watchface which tells you the current addressyou are at according to your GPS
google-where-am-i	Where am I? Complication for Wear OS	It uses the Google Maps API to reverse-geocode your location todisplay a human-readable address.Useful for smartwatch users who are blind or vision-impaired who would like to get their bearingsquickly.
google-wicked-good-xpath	Wicked Good XPath	    ! npm version  
google-wicked-good-xpath	About	Wicked Good XPath is a Google-authored pure JavaScript implementation of the DOM Level 3 XPath specification
google-wicked-good-xpath	About	It enables XPath evaluation for HTML documents in every browser
google-wicked-good-xpath	About	We believe it to be the fastest XPath implementation available in JavaScript.
google-wicked-good-xpath	Instructions	Download the latest wgxpath.install.js file and include it on your webpage with a script tag
google-wicked-good-xpath	Instructions	For example:Then call wgxpath.install   from your JavaScript code, which will ensure document.evaluate, the XPath evaluation function, is defined on the window object
google-wicked-good-xpath	Instructions	To install the library on a different window, pass that window as an argument to the install function.We provide an NPM package at There's also another NPM package at To install via NPM or Bower, do
google-wicked-good-xpath	Building it Yourself	We use Gulp:You can also run src/compile.sh if you want to use different versions ofClosure Compiler / Closure Library.
google-wicked-good-xpath	History	Wicked Good XPath started as a Google Closure port of the JavaScript-XPath project by Cybozu Labs
google-wicked-good-xpath	History	At the time, JavaScript-XPath was the fastest JavaScript implementation of XPath available --While it was fast, the code fell out of maintenance  last update was in 2007  so bugs were tough to get fixed
google-wicked-good-xpath	History	Also, since it wasn't written in Google Closure, it was tricky for us Googlers to integrate into our JavaScript applications
google-wicked-good-xpath	History	A rewrite was necessary.However, we went beyond merely porting the library to Google Closure and fixing a couple bugs
google-wicked-good-xpath	History	We identified some significant additional performance improvements, such that our version runs about 30% faster than the original
google-wicked-good-xpath	History	On top of that, the Closure compiler was able to minify our code down to a mere 25K, 40% smaller than JavaScript-XPath's 42K  though it has grown a bit since 
google-wicked-good-xpath	History	Finally, the code is structured and documented in a way that we believe will make future maintenance quicker and easier.
google-winops	Overview	This repository contains various small tools, scripts, and libraries formanaging Windows computers in an enterprise environment.
google-winops	Contact	We have a public discussion list at google-winops@googlegroups.com 
google-winops	Disclaimer	This is not an official Google product.
google-woff2	Build & Run	This document documents how to run the compression reference code
google-woff2	Build & Run	At thiswriting, the code, while it is intended to produce a bytestream that can bereconstructed into a working font, the reference decompression code is notdone, and the exact format of that bytestream is subject to change.The build process depends on the g++ compiler.
google-woff2	Build	On a standard Unix-style environment:to build executables and libraries:Ensure the binaries from the build process are in your $PATH, then:WOFF Ultra Condensed file format: proposals and discussion of wire formatissues  PDF is in docs/ directory WIFF Ultra Condensed: more discussion of results and compression techniques.This tool was used to prepare the data in that document.
google-wuffs	Wrangling Untrusted File Formats Safely	  Formerly known asPuffs Parsing Untrusted File Formats Safely .Wuffs is a domain-specific language and library for wrangling untrusted fileformats safely
google-wuffs	Wrangling Untrusted File Formats Safely	Wrangling includes parsing, decoding and encoding
google-wuffs	Wrangling Untrusted File Formats Safely	Examples ofsuch file formats include images, audio, video, fonts and compressed archives.Unlike the C programming language, Wuffs is safe with respect to bufferoverflows, integer arithmetic overflows and null pointer dereferences
google-wuffs	Wrangling Untrusted File Formats Safely	The keydifference between Wuffs and other memory-safe languages is that all suchchecks are done at compile time, not at run time
google-wuffs	Wrangling Untrusted File Formats Safely	*If it compiles, it is safe*,with respect to those three bug classes.The aim is to produce software libraries that are as safe as Go or Rust,roughly speaking, but as fast as C, and that can be used anywhere C librariesare used
google-wuffs	Wrangling Untrusted File Formats Safely	This includes very large C/C++ products, such as popular web browsersand operating systems  using that term to include desktop and mobile userinterfaces, not just the kernel .The trade-off in aiming for both safety and speed is that Wuffs programs takelonger for a programmer to write, as they have to explicitly annotate theirprograms with proofs of safety
google-wuffs	Wrangling Untrusted File Formats Safely	A statement like y is not zero.Wuffs is not a general purpose programming language
google-wuffs	Wrangling Untrusted File Formats Safely	While technicallypossible, it is unlikely that a Wuffs compiler would be worth writing in Wuffs.
google-wuffs	What Does Wuffs Code Look Like?	The  std/lzw/decode_lzw.wuffs  ./std/lzw/decode_lzw.wuffs  file is a goodexample
google-wuffs	What Does Wuffs Code Look Like?	See the "Poking Around" section below for more guidance.
google-wuffs	What Does Compile Time Checking Look Like?	For example, making this one-line edit to the GIF codec leads to a compile timeerror
google-wuffs	What Does Compile Time Checking Look Like?	wuffs gen fails to generate the C code, i.e
google-wuffs	What Does Compile Time Checking Look Like?	fails to compile transpile  the Wuffs code to C code:diff --git a/std/lzw/decode_lzw.wuffs b/std/lzw/decode_lzw.wuffsindex f878c5e..f10dcee 100644+++ b/std/lzw/decode_lzw.wuffs@@ -98,7 +98,7 @@ pub func lzw_decoder.decode? dst ptr buf1, src ptr buf1, src_final bool    {correctly" tests then fail :diff --git a/std/lzw/decode_lzw.wuffs b/std/lzw/decode_lzw.wuffsindex f878c5e..b43443d 100644+++ b/std/lzw/decode_lzw.wuffs@@ -97,8 +97,8 @@ pub func lzw_decoder.decode? dst ptr buf1, src ptr buf1, src_final bool    {gen wrote:gen unchanged:  /home/n/go/src/github.com/google/wuffs/gen/h/gif.hgen unchanged:  /home/n/go/src/github.com/google/wuffs/gen/c/gif.cgen unchanged:  /home/n/go/src/github.com/google/wuffs/gen/h/gif.hgif/basic.cgif/gif.c  000000: dcdc dc00 00d9 f5f9 f6df dc5f 393a 3a3a  ..........._9:::  000010: 3a3b 618e c8e4 e4e4 e5e4 e600 00e4 bbbb  :;a............
google-wuffs	What Does Compile Time Checking Look Like?	 000020: eded 8f91 9191 9090 9090 9190 9192 9192  ...............
google-wuffs	What Does Compile Time Checking Look Like?	 000030: 9191 9292 9191 9293 93f0 f0f0 f1f1 f2f2  ................excerpts of got  above  versus want  below :  000000: dcdc dcdc dcd9 f5f9 f6df dc5f 393a 3a3a  ..........._9:::  000010: 3a3a 618e c8e4 e4e4 e5e4 e6e4 e4e4 bbbb  ::a............
google-wuffs	What Does Compile Time Checking Look Like?	 000020: eded 8f91 9191 9090 9090 9090 9191 9191  ...............
google-wuffs	What Does Compile Time Checking Look Like?	 000030: 9191 9191 9191 9193 93f0 f0f0 f1f1 f2f2  ...............
google-wuffs	What Does Compile Time Checking Look Like?	 000000: dcdc dc00 00d9 f5f9 f6df dc5f 393a 3a3a  ..........._9:::  000010: 3a3b 618e c8e4 e4e4 e5e4 e600 00e4 bbbb  :;a............
google-wuffs	What Does Compile Time Checking Look Like?	 000020: eded 8f91 9191 9090 9090 9190 9192 9192  ...............
google-wuffs	What Does Compile Time Checking Look Like?	 000030: 9191 9292 9191 9293 93f0 f0f0 f1f1 f2f2  ................excerpts of got  above  versus want  below :  000000: dcdc dcdc dcd9 f5f9 f6df dc5f 393a 3a3a  ..........._9:::  000010: 3a3a 618e c8e4 e4e4 e5e4 e6e4 e4e4 bbbb  ::a............
google-wuffs	What Does Compile Time Checking Look Like?	 000020: eded 8f91 9191 9090 9090 9090 9191 9191  ...............
google-wuffs	What Does Compile Time Checking Look Like?	 000030: 9191 9191 9191 9193 93f0 f0f0 f1f1 f2f2  ................wuffs-test-c: some tests failedwuffs test: some tests failed
google-wuffs	Background	Decoding untrusted data, such as images downloaded from across the web, have along history of security vulnerabilities
google-wuffs	Background	As of 2017, libpng is over 18 yearsold, and the  PNG specification is dated 2003  butthat well examined C library is still getting  CVE's published in2017 Sandboxing and fuzzing can mitigate the danger, but they are reactions to C'sfundamental unsafety
google-wuffs	Background	Newer programming languages remove entire classes ofpotential security bugs
google-wuffs	Background	Buffer overflows and null pointer dereferences areamongst the most well known.Less well known are integer overflow bugs
google-wuffs	Background	Offset-length pairs, defining asub-section of a file, are seen in many file formats, such as OpenType fontsand PDF documents
google-wuffs	Background	A conscientious C programmer might think to check that asection of a file or a buffer is within bounds by writing if  offset + length's memset function.If your C/C++ project is large, you might want both the .c files  adding eachto your build system  and the .h files
google-wuffs	Background	If your C/C++ project is small, youmight only need the .c files, not the .h files, as the .c files are designed tobe a  drop-in library For example, if you want a GIF decoder, you only need gif.c
google-wuffs	Background	See TODO for anexample
google-wuffs	Background	More complicated decoders might require multiple .c files modules
google-wuffs	Background	For example, the PNG codec  TODO  requires the deflate codec, but theyare separate files, since HTTP can use also deflate compression  also known asgzip or zlib, roughly speaking  without necessarily processing PNG images.
google-wuffs	Getting Deeper	If you want to modify the Wuffs standard library, or compile your own Wuffscode, you will need to do a little more work, and will have to install at leastthe Go toolchain in order to build the Wuffs tools
google-wuffs	Getting Deeper	To run the test suite, youmight also have to install C compilers like clang and gcc, as well as Clibraries  and their .h files  like libjpeg and libpng, as some tests comparethat Wuffs produces exactly the same output as these other libraries.Running go get -v github.com/google/wuffs/cmd/..
google-wuffs	Getting Deeper	will download and installthe Wuffs tools
google-wuffs	Getting Deeper	Change get to install to re-install those programs withoutdownloading, e.g
google-wuffs	Getting Deeper	after you've modified their source code, or after a manuallyissued git pull
google-wuffs	Getting Deeper	The Wuffs tools that you'll most often use are wuffsfmt analogous to clang-format, gofmt or rustfmt  and wuffs  roughlyanalogous to make, go or cargo .You should now be able to run wuffs test
google-wuffs	Getting Deeper	If all goes well, you should seesome output containing the word "PASS" multiple times.
google-wuffs	Poking Around	Feel free to edit the std/lzw/decode_lzw.wuffs file, which implements the GIFLZW decoder
google-wuffs	Poking Around	After editing, run wuffs gen std/gif or wuffs test std/gif tore-generate the C edition of the Wuffs standard library's GIF codec, andoptionally run its tests.Try deleting an assert statement and re-running wuffs gen
google-wuffs	Poking Around	The result shouldbe syntactically valid, but a compile error, as some bounds checks can nolonger be proven.Find the line wuffs gen should fail, as the computation can underflow.Similarly, replacing the line var n_bits u32 with var n_bits u32 = 10should fail, as an n_bits < 8 assertion, a pre-condition, a few lines furtherdown again cannot be proven.Similarly, changing the 4095 in var prev_code u32 ..4095  either higher orlower should fail.Try adding assert false at various places, which should obviously fail, butshould also cause wuffs gen to print what facts the compiler can prove atthat point
google-wuffs	Poking Around	This can be useful when debugging why Wuffs can't prove somethingyou think it should be able to.
google-wuffs	Running the Tests	If you've changed any of the tools  i.e
google-wuffs	Running the Tests	changed any .go code , re-run goinstall -v github.com/google/wuffs/cmd/..
google-wuffs	Running the Tests	and go testIf you've changed any of the libraries  i.e
google-wuffs	Running the Tests	changed any wuffs test or, ideally, wuffs test -mimic to also check that Wuffs' outputmimics  i.e
google-wuffs	Running the Tests	exactly matches  other libraries' output, such as giflib for GIF,libpng for PNG, etc.If your library change is an optimization, run wuffs bench or wuffs bench-mimic both before and after your change to quantify the improvement
google-wuffs	Running the Tests	Themimic benchmark numbers should't change if you're only changing .wuffs code,but seeing zero change in those numbers is a sanity check on any unrelatedsystem variance, such as software updates or virus checkers running in the
google-wuffs	Directory Layout	  mentioned above, Wuffs transpiles to C code, and Go is not necessarily  involved if all you want is to use the C edition of Wuffs
google-wuffs	Directory Layout	 Go and Rust code.default values" commit is an example of adding new Wuffs syntax and threadingthat all the way through to C code generation and testing.
google-wuffs	Documentation	Proof of concept
google-wuffs	Documentation	Version 0.1 at best
google-wuffs	Documentation	API and ABI aren't stabilized yet
google-wuffs	Documentation	Thereare plenty of tests to create, docs to write and TODOs to do
google-wuffs	Documentation	The compilerundoubtedly has bugs
google-wuffs	Documentation	Assertion checking needs more rigor, especially aroundside effects and aliasing, and being sufficiently well specified to allowalternative implementations
google-wuffs	Documentation	Lots of detail needs work, but the broadbrushstrokes are there.
google-wuffs	Discussion	The mailing list is at  
google-wuffs	Contributing	The  CONTRIBUTING.md  ./CONTRIBUTING.md  file contains instructions on how tofile the Contributor License Agreement before sending any pull requests  PRs .Of course, if you're new to the project, it's usually best to discuss anyproposals and reach consensus before sending your first PR.
google-wuffs	License	Apache See the LICENSE file for details.
google-wuffs	Disclaimer	This is not an official Google product, it is just code that happens to beowned by Google.Updated on June 
google-wwwbasic	WWWBasic	WWWBasic is an implementation of BASIC  Beginner's All-purpose SymbolicInstruction Code  designed to be easy to run on the Web.
google-wwwbasic	How to use WWWBasic	You can include WWWBasic directly in Web pages:It supports a range of features including:WWWBasic has a "Work-in-progress" test suite.It can be run with: ./run-tests.sh.
google-wwwbasic	Source Code Headers	Every file containing source code must include copyright and licenseinformation
google-wwwbasic	Source Code Headers	This includes any JS/CSS files that you might be serving out tobrowsers
google-wwwbasic	Source Code Headers	 This is to help well-intentioned people avoid accidental copying thatdoesn't comply with the license
google-wwwbasic	Source Code Headers	Apache header:
google-wycheproof	Project Wycheproof	*Project Wycheproof is named after Mount Wycheproof  the smallestmountain in the world
google-wycheproof	Project Wycheproof	The main motivation for the project is to have a goalthat is achievable
google-wycheproof	Project Wycheproof	The smaller the mountain the more likely it is to be able toclimb it.* TOC 
google-wycheproof	Introduction	Project Wycheproof tests crypto libraries against known attacks
google-wycheproof	Introduction	It is developedand maintained by members of Google Security Team, but it is not an officialGoogle product.At Google, we rely on many third party cryptographic software libraries.Unfortunately, in cryptography, subtle mistakes can have catastrophicconsequences, and we found that libraries fall into such implementationpitfalls much too often and for much too long
google-wycheproof	Introduction	Good implementation guidelines,however, are hard to come by: understanding how to implement cryptographysecurely requires digesting decades' worth of academic literature
google-wycheproof	Introduction	We recognizethat software engineers fix and prevent bugs with unit testing, and we foundthat cryptographic loopholes can be resolved by the same means.These observations have prompted us to develop Project Wycheproof, a collectionof unit tests that detect known weaknesses or check for expected behaviors ofsome cryptographic algorithm
google-wycheproof	Introduction	Project Wycheproof provides tests for mostcryptographic algorithms, including RSA, elliptic curve crypto andauthenticated encryption
google-wycheproof	Introduction	Our cryptographers have systematically surveyed theliterature and implemented most known attacks
google-wycheproof	Introduction	We have over 80 test cases whichhave uncovered more than  40 bugs  doc/bugs.md 
google-wycheproof	Introduction	Forexample, we found that we could recover the private key of widely-used DSA andECDHC implementations.While we are committed to develop as many attacks as possible, ProjectWycheproof is by no means complete
google-wycheproof	Introduction	Passing the tests does not imply that thelibrary is secure, it just means that it is not vulnerable to the attacks thatProject Wycheproof tests for
google-wycheproof	Introduction	Cryptographers are also constantly discoveringnew attacks
google-wycheproof	Introduction	Nevertheless, with Project Wycheproof developers and users now cancheck their libraries against a large number of known attacks, without havingto spend years reading academic papers or become cryptographers themselves.For more information on the goals and strategies of Project Wycheproof, pleasecheck out our  doc  doc/ .
google-wycheproof	Coverage	Project Wycheproof has tests for the most popular crypto algorithms, includingcryptographic interface
google-wycheproof	Coverage	This allowed us to test multiple providers with asingle test suite
google-wycheproof	Coverage	While this interface is somewhat low level, and should notbe used directly, we still apply a "defense in depth" argument and expect thatthe implementations are as robust as possible
google-wycheproof	Coverage	For example, we consider weakdefault values to be a significant security flaw
google-wycheproof	Coverage	We are converting as manytests into sets of test vectors to simplify porting the tests to otherlanguages
google-wycheproof	Coverage	We provide ready-to-use test runners for Java CryptographyArchitecture providers such as  Bouncy Castle  Spongy Castle  and the defaultproviders in  OpenJDK 
google-wycheproof	Usage	bazel test BouncyCastleAllTests_you change the WYCHEPROOF_BOUNCYCASTLE_JAR environment variable, run bazelclean to force a rebuild:refuse to run or its results might be incorrect if you are using some other JDK.If you downloaded your JDK from Oracle or  you're probablyusing Oracle JDK, which should be compatible with OpenJDK, thus the tests shouldrun correctly.Some tests take a very long time to finish
google-wycheproof	Usage	If you want to exclude them, useBouncyCastleTest, SpongyCastleTest or OpenJDKTest -slow tests  which are annotated with @SlowTest .Most test targets are failing, and each failure might be a security issue
google-wycheproof	Usage	Tolearn more about what a failed test means, you might want to check out  ourdocumentation  doc/bugs.md  or the comments on top of the corresponding testfunction and test class.
google-wycheproof	Hall of Bugs	Here are some of the notable vulnerabilities that are uncovered byProject Wycheproof:
google-wycheproof	Maintainers	Project Wycheproof is maintained by:If you want to contribute, please read  CONTRIBUTING  CONTRIBUTING.md  and sendus pull requests
google-wycheproof	Maintainers	You can also report bugs or request new tests.If you'd like to talk to our developers or get notified about major newtests, you may want to subscribe to our mailing list  Tojoin, simply send an empty mail to wycheproof-users+subscribe@googlegroups.com.
google-xctestrunner	XCTestRunner	A tool for running prebuilt iOS tests on iOS real device and simulator.
google-xctestrunner	Prerequisites	You can download the ios_test_runner.par binary in  release or build the ios_test_runner.par binary by bazel:
google-xctestrunner	Usage	xcodebuild command line tool or  bazel In overview, there are two sub-commands in the runner binary.after test finishes.See more details by running ios_test_runner.par -h in terminal.
google-xctestrunner	Notes	Disclaimer: This is not an official Google product.XCTestRunner uses Apple native tool xcodebuild, simctl to control iOSSimulator and launch tests on iOS devices.For testing, XCTestRunner injects app under test and test bundle file into adummy project
google-xctestrunner	Notes	Then the dummy project can be used xcodebuild test to runXCTest  not for XCUITest , or xcodebuild build-for-testing to generatexctestrun file for further testing.For iOS 7 real device testing, the latest supported Xcode version is 7.2.For iOS 7 simulator testing, latest supported Xcode version is 7.2.1 and latestsupported MacOS version is Yosemite  10.10.x .
google-xi-editor	Getting started	This repository is the core only
google-xi-editor	Getting started	You'll also need a front-end, from the list
google-xi-editor	Building the core	Xi targets 'recent stable Rust'
google-xi-editor	Building the core	We recommend installing via  rustup The current minimum supported version is 1.To build the xi editor from the root directory of this repo:protocol, but perhaps could be revitalized:experimental GL-based front-end in Rust.documentation at this point  on the protocol at frontend.md  If you're working on a front-end, feel free tosend a PR to add it to the above list.
google-xi-editor	Design decisions	Here are some of the design decisions, and motivation why they shouldcontribute to the above goals:  responsible for all potentially expensive editing operations
google-xi-editor	Design decisions	 On Mac, that’s Cocoa
google-xi-editor	Design decisions	 performance is possible in C++, but Rust offers a much more reliable, and  in many ways, higher level programming platform
google-xi-editor	Design decisions	 clients  thread with a snapshot of the current editor buffer  the persistent rope  data structure is copy-on-write so this operation is nearly free , which can  then proceed to write out to disk at its leisure, while the buffer is still  fully editable
google-xi-editor	Design decisions	 both more arcane and less powerful than “real” languages
google-xi-editor	Design decisions	The xi editor will  communicate with plugins through pipes, letting them be written in any  language, and making it easier to integrate with other systems such as  version control, deeper static analyzers of code, etc
google-xi-editor	Design decisions	 considered binary formats, but the actual improvement in performance would  be completely in the noise
google-xi-editor	Design decisions	Using JSON considerably lowers friction for  developing plug-ins, as it’s available out of the box for most modern  languages, and there are plenty of the libraries available for the other  ones.
google-xi-editor	Current status	This is still a project in its early stages
google-xi-editor	Current status	The Mac build has basic editingfunctionality  it was used to write this README , but looks very spare andis still missing essentials such as auto-indent
google-xi-editor	Current status	At the moment, it’s expectedthat its main community will be developers interested in hacking on a text
google-xi-editor	Authors	The main author is Raph Levien.
google-xi-editor	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-xi-editor	Contributions	Please see CONTRIBUTING.md  CONTRIBUTING.md  for more details.If you are interested in contributing but not sure where to start, there isan active IRC channel at #xi on irc.mozilla.org
google-xi-editor	Contributions	There is also a subreddit at /r/xi_editor 
google-xi-editor	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.
google-xi-mac	Requirements	and recommend installing through  rustup is the front-end, and the back-end  or core  is now in: xi-editor  Make sure to have that checked outas a subdirectory.
google-xi-mac	Troubleshooting	The most common cause of a failed build is an outdated version of rustup update stable.
google-xi-mac	Configuration	User settings are currently stored in files; the general preferences arelocated at ~/Library/Application Support/XiEditor/preferences.xiconfig.This file can be opened from File > Preferences  ⌘ + , .The default font for Xi is  Inconsolata  whichis bundled with the app.
google-xi-mac	Theme	A few theme files are bundled with the application
google-xi-mac	Theme	A theme can be selectedfrom the Debug > Theme menu
google-xi-mac	Theme	There is not yet a mechanism for includingcustom themes.
google-xi-mac	Authors	The main author is Raph Levien.
google-xi-mac	License	This project is licensed under the Apache 2  license  LICENSE 
google-xi-mac	License	The bundled fonts are under adifferent license, the Open Font License
google-xi-mac	License	See the  fonts  fonts  directory for the fonts and associated
google-xi-mac	Contributions	We gladly accept contributions via GitHub pull requests, as long as the authorhas signed the Google Contributor License
google-xi-mac	Contributions	Please see CONTRIBUTING.md  CONTRIBUTING.md  for more details.
google-xi-mac	Disclaimer	This is not an official Google product  experimental or otherwise , itis just code that happens to be owned by Google.
google-xi-win	Xi editor for Windows	This project is currently a seedling, which I am hopeful will growinto a useful front-end for  xi editor It makes some decisions which are fairly unusual for GUI softwarewritten in It targets winapi directly, rather than using atoolkit, and is written in Rust
google-xi-win	Xi editor for Windows	The main reason is so that we cantarget performance; winapi has api's for Direct2D rendering that mayenable significantly lower latency and smoother scrolling thanaccessible through a toolkit
google-xi-win	Xi editor for Windows	Part of the reason for taking on thisproject is to quantify the relative performance.Other important dimensions of performance are startup speed andexecutable size.Given the goals of this project and the  current  flux in the xiprotocol, I expect the focus of this project to be input and renderingpipelines, with less emphasis on features; it may be a while beforethis is really useful as an editor
google-xi-win	Xi editor for Windows	That said, I certainly welcomeany help in getting there sooner.
google-xi-win	Disclaimer	This is not an official Google product.
google-xi-win	Contributions	We gladly accept contributions via GitHub pull requests, as long asthe author has signed the Google Contributor License
google-xi-win	Contributions	Please see CONTRIBUTING.md  CONTRIBUTING.md  for more details.
google-xi-win	Authors	The main author is Raph Levien.
google-xpra-upstart	Upstart Xpra config	Missing upstart config for Xpra  screen for X 
google-xpra-upstart	Upstart Xpra config	Should work on Ubuntu 14.
google-xrtl	Developing	GDB may need the following commands run at startup to resolve some third partysource code
google-xrtl	Developing	Replace directories with your workspace location:
google-xrtl	Test Tags	Common tags that can be added to tests:
google-xsecurelock	About XSecureLock	XSecureLock is an X11 screen lock utility designed with the primary goal ofScreen lock utilities are widespread
google-xsecurelock	About XSecureLock	However, in the past they often hadsecurity issues regarding authentication bypass  a crashing screen locker wouldunlock the screen , information disclosure  notifications may appear on top ofthe screen saver , or sometimes even worse.In XSecureLock, security is achieved using a modular design to avoid the usualpitfalls of screen locking utility design on XDetails are available in the Security Design  #security-design  section.
google-xsecurelock	Requirements	The following packages need to be installed; their names depend on your Linuxdistribution of choice, but will be similar:NOTE: In these instructions, please replace SERVICE-NAME by the name of anappropriate and existing file in common-auth would work
google-xsecurelock	Requirements	This will be used as default and can be overriddenwith  XSECURELOCK_PAM_SERVICE  #options .Configuring a broken or missing SERVICE-NAME will render unlocking the screenimpossible! If this should happen to you, switch to another terminal Ctrl-Alt-F1 , log in there, and run: killall xsecurelock to force unlockingof the screen.Pick one of the  authentication modules  #authentication-modules  and one of the screen saver modules  #screen-saver-modules .Tell your desktop environment to run XSecureLock by using a command line such asone of the following:
google-xsecurelock	Automatic Locking	To automatically lock the screen after some time of inactivity, use xss-lock  as follows:the screen saver is active short time after wakeup!NOTE: When using xss-lock, it's recommended to not launch xsecurelockdirectly for manual locking, but to manually lock using xset s activate
google-xsecurelock	Automatic Locking	Thisensures that xss-lock knows about the locking state and won't try again, whichwould spam the X11 error log.WARNING: Never rely on automatic locking for security, for the followingAutomatic locking should merely be seen as a fallback for the case of the userforgetting to lock explicitly, and not as a security feature
google-xsecurelock	Automatic Locking	If you really wantto use this as a security feature, make sure to kill the session wheneverattempts to lock fail  in which case xsecurelock will return a non-zero exitstatus .
google-xsecurelock	xautolock	xautolock can be used instead of xss-lock as long as you do not care forsuspend events  like on laptops :Ideally, an environment integrating xsecurelock should provide the following Wait for one of the following events: Repeat.This is, of course precisely what xss-lock does, and handling As an alternative, we also support this way of integrating: Wait for one of the following events: Repeat.NOTE: When using dimmer, please set XSECURELOCK_DIM_TIME_MS and XSECURELOCK_WAIT_TIME_MS tomatch the time your dimming tool takes for dimming, and how long you want towait in dimmed state before locking.
google-xsecurelock	Options	Options to XSecureLock can be passed by environment variables:Additionally, command line arguments following a "--" argument will be executedvia execvp once locking is successful; this can be used to notify a callingprocess of successful locking.
google-xsecurelock	Authentication Modules	The following authentication modules are included:
google-xsecurelock	Writing Your Own Module	The screen saver module is a separate executable, whose name must start withsaver_ and be installed together with the included auth_ modules  defaultlocation: /usr/local/libexec/xsecurelock/helpers .
google-xsecurelock	Screen Saver Modules	The following screen saver modules are included:
google-xsecurelock	Security Design	In order to achieve maximum possible security against screen lock bypassexploits, the following measures are taken:
google-xsecurelock	Known Security Issues	Most these issues are inherent with X11 and can only really be fixed bymigrating to an alternative such as Wayland; some of the issues  in particularthe gamepad input issue  will probably persist even with Wayland.
google-xsecurelock	Forcing Grabs	As a workaround to the issue of another window already holding a grab, we offeran XSECURELOCK_FORCE_GRAB option.This adds a last measure attempt to force grabbing by iterating through allsubwindows of the root window, unmapping them  which closes down their grabs ,then taking the grab and mapping them again.This has the following known issues:
google-xsecurelock	License	The code is released unser the Apache 2.0 license
google-xsecurelock	License	See the LICENSE file for moreThis project is not an official Google project
google-xsecurelock	License	It is not supported by Googleand Google specifically disclaims all warranties as to its quality,merchantability, or fitness for a particular purpose.
google-yara-procdump-python	yara-procdump-python	A Python extension to wrap the Yara process memory access API.This is not an official Google product.
google-yaricv32	yaricv32	Yet Another RIsCV32 implementation of the  rv32ui  1  ISA
google-yaricv32	yaricv32	Testing can be done on the Lattice iCE40 family of FPGAs
google-yaricv32	yaricv32	The specific board used for development is:For anyone interested further information is available at:
google-yaricv32	Prerequisites	Ubuntu 17.10 although it should work on 16.04 as well
google-yaricv32	Prerequisites	All necessary tools can be installed via:The simulator can be invoked via:The repository containing the tests can be cloned along with the cross toolchain using the includedbuild script:The tests will be compiled and executed via:The firmware can be built using:Before flashing the FPGA board, the USB access permissions need a minor adjustment that will allow the tools towrite a bitstream on the device
google-yaricv32	Prerequisites	Create a new file at:Add this line inside:Make sure that the breakout board is connected to the host PC and configured for SRAMFlashing the bitstream on the FPGA can be done by invoking:The default program will currently calculate the fibonacci sequence of numbers.As mentioned before the 'OUT' instruction will transmit the register 'A' contents on the second UART port.The serial device will usually appear on the host as '/dev/ttyUSB1'
google-yaricv32	Prerequisites	The configuration used right now is: 1 :  2 :  3 :  4 :  5 :  6 : 
google-youtube-8m	YouTube-8M Tensorflow Starter Code	This repo contains starter code for training and evaluating machine learningmodels over the  YouTube-8M  dataset
google-youtube-8m	YouTube-8M Tensorflow Starter Code	This is the starter code for our  2nd Youtube8M Video Understanding Challenge on Kaggle  and part of the European Conference on Computer Vision  ECCV  2018 selected workshop session
google-youtube-8m	YouTube-8M Tensorflow Starter Code	The code gives an end-to-end working example for reading the dataset, training aTensorFlow model, and evaluating the performance of the model
google-youtube-8m	YouTube-8M Tensorflow Starter Code	Out of the box,you can train several  model architectures  #overview-of-models  over eitherframe-level or video-level features
google-youtube-8m	YouTube-8M Tensorflow Starter Code	The code can easily be extended to trainyour own custom-defined models.
google-youtube-8m	Requirements	This option requires you to have an appropriately configured Google CloudPlatform account
google-youtube-8m	Requirements	To create and configure your account, please make sure youfollow the instructions  here Please also verify that you have Python 2.7+ and Tensorflow 1.0.0 or higherinstalled by running the following commands:All gcloud commands should be done from the directory *immediately abovesource code
google-youtube-8m	Requirements	You should be able to see the source code directory if yourun 'ls'.As you are developing your own models, you will want to test themquickly to flush out simple problems without having to submit them to the cloud.You can use the gcloud beta ml local set of commands for that.Here is an example command line for video-level training:allow you to work offline
google-youtube-8m	Requirements	The command below will copy 10 out of the 4096training data files to the current directory.Once you download the files, you can point the job to them using the'train_data_pattern' argument  i.e
google-youtube-8m	Requirements	instead of pointing to the "gs://..."files, you point to the local files .Once your model is working locally, you can scale up on the Cloudwhich is described below.
google-youtube-8m	Video-level	mkdir -p ~/yt8m/v2/videocd ~/yt8m/v2/videocurl data.yt8m.org/download.py | shard=1,100 partition=2/video/train mirror=us pythoncurl data.yt8m.org/download.py | shard=1,100 partition=2/video/validate mirror=us pythoncurl data.yt8m.org/download.py | shard=1,100 partition=2/video/test mirror=us python
google-youtube-8m	Frame-level	mkdir -p ~/yt8m/v2/framecd ~/yt8m/v2/framecurl data.yt8m.org/download.py | shard=1,100 partition=2/frame/train mirror=us pythoncurl data.yt8m.org/download.py | shard=1,100 partition=2/frame/validate mirror=us pythoncurl data.yt8m.org/download.py | shard=1,100 partition=2/frame/test mirror=us pythonNote: this readme will assume the directory ~/yt8m for storing the dataset,code, and trained models
google-youtube-8m	Frame-level	However, you can use another directory path.Nonetheless, you might find it convenient to simlink that directory to ~/yt8mso that you can copy the commands from this page onto your terminal
google-youtube-8m	Frame-level	If you are located outside of North America, you should change the flag 'mirror' to 'eu' for Europe or 'asia' for Asia to speed up the transfer of the files.
google-youtube-8m	Try the starter code	Clone this git repo:
google-youtube-8m	Training on Video-Level Features	Note: Above binary runs "forever"  i.e
google-youtube-8m	Training on Video-Level Features	keeps watching for updated modelcheckpoint and re-runs evals 
google-youtube-8m	Training on Video-Level Features	To run once, pass flag If you are competing on Kaggle, you should do inference outputing a CSV  e.g.naming file as kaggle_solution.csv :then upload my_model.tgz to Kaggle via Team Model Upload
google-youtube-8m	Train Frame-level model	Train using Evaluate the modelProduce CSV  --output_model_tgz=my_model.tgz.
google-youtube-8m	Downloading the entire dataset	Now that you've downloaded a fraction and the code works, you are all set todownload the entire dataset and come up with the next best video classificationTo download the entire dataset, repeat the above download.py commands, droppingthe shard variable
google-youtube-8m	Downloading the entire dataset	You can download the video-level training set with:occupying 18GB of space
google-youtube-8m	Downloading the entire dataset	If you are located outside of North America, you shouldchange the flag 'mirror' to 'eu' for Europe or 'asia' for Asia to speed up thetransfer of the files.Change 'train' to 'validate'/'test' and re-run the command to download theother splits of the dataset
google-youtube-8m	Downloading the entire dataset	Change 'video' to 'frame' to download theframe-level features
google-youtube-8m	Downloading the entire dataset	The complete frame-level features take about 1.53TB ofspace
google-youtube-8m	Downloading the entire dataset	You can set the environment variable 'shard' to 'm,n' to download onlym/n-th of the data.
google-youtube-8m	Tensorboard	You can use Tensorboard to compare your frame-level or video-level models, like:We find it useful to keep the tensorboard instance always running, as we trainand evaluate different models.
google-youtube-8m	Training Details	The binaries --train_dir
google-youtube-8m	Training Details	The train.py outputs to --train_dir the  TensorFlow graph aswell as the model checkpoint, as the model is training
google-youtube-8m	Training Details	It will also output aJSON file, model_flags.json, which is used by evaluate.py and inference.pyto setup the model and know what type of data to feed  frame-level VSvideo-level, as determined by the flags passed to train.py .You can specify a model by using the --model flag
google-youtube-8m	Training Details	For example, you canutilize the LogisticModel  the default  by:to represent all of those files.By default, the training code will frequently write _checkpoint_ files  i.e.values of all trainable parameters, at the current training iteration 
google-youtube-8m	Training Details	Thesewill be written to the --train_dir
google-youtube-8m	Training Details	If you re-use a --train_dir, the trainerwill first restore the latest checkpoint written in that directory
google-youtube-8m	Training Details	This onlyworks if the architecture of the checkpoint matches the graph created by thetraining code
google-youtube-8m	Training Details	If you are in active development/debugging phase, consideradding --start_new_model flag to your run configuration.
google-youtube-8m	Evaluation and Inference	Here's how to evaluate a model on the validation dataset:name, the 'training' argument really just offers a cloud hostedpython/tensorflow service
google-youtube-8m	Evaluation and Inference	From the point of view of the Cloud Platform, thereis no distinction between our training and inference jobs
google-youtube-8m	Evaluation and Inference	The Cloud ML platformalso offers specialized functionality for prediction withTensorflow models, but discussing that is beyond the scope of this readme.Once these job starts executing you will see outputs similar to thefollowing for the evaluation code:You can browse the storage buckets you created on Google Cloud, for example, toaccess the trained models, prediction CSV files, etc
google-youtube-8m	Evaluation and Inference	by visiting the Google Cloud storage browser Alternatively, you can use the 'gsutil' command to download the files directly.For example, to download the output of the inference code from the previoussection to your local machine, run:to the 'gcloud' training command given above, and change 'video' in paths to'frame'
google-youtube-8m	Evaluation and Inference	Here is a sample command to kick-off a frame-level job:logistic model trained over the video-level features
google-youtube-8m	Evaluation and Inference	Please look at the'video_level_models.py' or 'frame_level_models.py' files to see how to implementyour own models.
google-youtube-8m	Using Frame-Level Features	Follow the same instructions as above, appending--frame_features=True --model=FrameLevelLogisticModel --feature_names="rgb"--feature_sizes="1024" for train.py and changing --train_dir.The models.py file to see how to implement your own models.
google-youtube-8m	Using Audio Features	The feature files  both Frame-Level and Video-Level  contain two sets offeatures: 1  visual and 2  audio
google-youtube-8m	Using Audio Features	The code defaults to using the visualfeatures only, but it is possible to use audio features instead of  or besides visual features
google-youtube-8m	Using Audio Features	To specify the  combination of  features to use you must set--feature_names and --feature_sizes flags
google-youtube-8m	Using Audio Features	The visual and audio features arecalled 'rgb' and 'audio' and have 1024 and 128 dimensions, respectively.The two flags take a comma-separated list of values in string
google-youtube-8m	Using Audio Features	For example, touse audio-visual Video-Level features the flags must be set as follows:lists provided to the two flags above match
google-youtube-8m	Using Audio Features	Also, the order must match whenrunning training, evaluation, or inference.
google-youtube-8m	Using GPUs	If your Tensorflow installation has GPU support, this code will make use of allof your compatible GPUs
google-youtube-8m	Using GPUs	You can verify your installation by runningwith the GPUs, whereas the CPU will be used primarily for the input and outputpipelines
google-youtube-8m	Using GPUs	If you have multiple GPUs, the current default behavior is to useonly one of them.
google-youtube-8m	Ground-Truth Label Files	We also provide CSV files containing the ground-truth label information of the'train' and 'validation' partitions of the dataset
google-youtube-8m	Ground-Truth Label Files	These files can bedownloaded using 'gsutil' command:ground-truth labels corresponding to that video
google-youtube-8m	Ground-Truth Label Files	For example, for a video withid 'VIDEO_ID' and two labels 'LABEL1' and 'LABEL2' we store the following line:
google-youtube-8m	Training on the Cloud over Video-Level Features	The following commands will train a model on Google Cloudover video-level features.containing the 'train.py' script and more generally the python package whichshould be deployed to the cloud worker
google-youtube-8m	Training on the Cloud over Video-Level Features	The module-name refers to the specificpython script which should be executed  in this case the train module .It may take several minutes before the job starts running on Google Cloud.When it starts you will see outputs like the following:model will continue to train indefinitely in the Cloud
google-youtube-8m	Training on the Cloud over Video-Level Features	Later, you can checkon its progress or halt the job by visiting the Google Cloud ML Jobs console You can train many jobs at once and use tensorboard to compare their performance  If you are using Google Cloud Shell, you can instead click the Web Preview buttonon the upper left corner of the Cloud Shell window and select "Preview on port 8080".This will bring up a new browser tab with the Tensorboard view.
google-youtube-8m	Using Larger Machine Types	Some complex frame-level models can take as long as a week to converge whenusing only one GPU
google-youtube-8m	Using Larger Machine Types	You can train these models more quickly by using morepowerful machine types which have additional GPUs
google-youtube-8m	Using Larger Machine Types	To use a configuration with4 GPUs, replace the argument to --config with youtube-8m/cloudml-4gpu.yaml.Be careful with this argument as it will also increase the rate you are chargedby a factor of 4 as well.
google-youtube-8m	Overview of Models	This sample code contains implementations of the models given in the YouTube-8M technical report 
google-youtube-8m	Create Your Own Dataset Files	You can create your dataset files from your own videos
google-youtube-8m	Create Your Own Dataset Files	Our feature extractor  ./feature_extractor  code creates tfrecordfiles, identical to our dataset files
google-youtube-8m	Create Your Own Dataset Files	You can use our starter code to train onthe tfrecord files output by the feature extractor
google-youtube-8m	Create Your Own Dataset Files	In addition, you canfine-tune your YouTube-8M models on your new dataset.
google-youtube-8m	Training without this Starter Code	You are welcome to use our dataset without using our starter code
google-youtube-8m	Training without this Starter Code	However, ifyou'd like to compete on Kaggle, then you must make sure that you are able toproduce a prediction CSV file, as well as a model .tgz file that match whatgets produced by our inference.py
google-youtube-8m	Training without this Starter Code	In particular, the  predictionsCSV file  must have two fields: Id,Labels where Id is stored as id in the each testexample and Labels is a space-delimited list of integer label IDs
google-youtube-8m	Training without this Starter Code	The .tgzmust contain these 4 files at minumum:   TensorFlow  MetaGraph To verify that you correctly generated the .tgz file, run it with
google-youtube-8m	About This Project	This project is meant help people quickly get started working with the YouTube-8M  dataset.This is not an official Google product.
google-ytstatistics-demo	ytstatistics-demo	Automatically exported from code.google.com/p/ytstatistics-demoThis project is intended for educational use
google-ytstatistics-demo	ytstatistics-demo	It demonstrates the use of the  YouTube GData API  the  Google Visualization API   GWT  and  App Engine  Using these technologies this application enables users to view statistics for a YouTube user's video stream.For learning purposes, the app is available in two versions:! screenshot  Click here to see a running demo of the app
google-ytstatistics-demo	ytstatistics-demo	 Except as otherwise  noted  the contents of this document are © Copyright 2011 Google, and licensed under the  Creative Commons Attribution 2.5 License 
google-zarathustra	What is Zarathustra?	The code in this repository is the core of Zarathustra, an experimental systemto detect web-inject malware by observing the changes injected in web pages.The paper included in the repository provides further details on thearchitecture and the goals of this code.
google-zarathustra	A note on code quality	By no means the code in this repository should be considered of "production" quality:while it passes unit tests, it was only meant to support the academic researchdetailed in the paper; it is being released manly as a support for future workin the field, because we should stop reinventing the wheel.
google-zazu	Zazu 	An unopinionated, scalable reporting application built on  Google Cloud Platform  and  Data Studio  for vendor-coop reporting.
google-zazu	What is Vendor-Coop?	Vendor-coop is a form of joint marketing where organizations pool together resources and expertise to acheive a joint goal
google-zazu	What is Vendor-Coop?	 In the classic case, consider a retailer that sells vacuum cleaners from a specific manufacturer
google-zazu	What is Vendor-Coop?	 The retailer and the manufacturer might pool together marketing budget, data and creative content to launch a joint marketing campaign to attract consumers to a retail location to purchase vacuums from the manufacturer 
google-zazu	What is Zazu?	Zazu is an open-source application that can be used as scalable infrastructure to help facilitate reporting between organizations
google-zazu	What is Zazu?	 In the case of the retailer and manufacturer, Zazu is an application that the retailer can deploy such that the retailer can share 1st party data directly to the manufacturer in a controlled, secure and private manner
google-zazu	What is Zazu?	 As an example, the retailer may choose to report impressions, store visits or revenue as a metric to the manufacturer to show the business results driven by the joint marketing campaign.
google-zazu	Dependencies	Zazu integrates several popular production reliable web, data and analytics technologies:Billing method available or already set up on the  Google Cloud Platform  GCP  Docker installed:  Instructions here Google Cloud SDK installed:  Instructions here 
google-zazu	Installation steps	Create a new project in  GCP APIs & Services > Dashboard > If not already enabled, enable the Big Query, Google+ API and Google Container Registry.Run cd /zazuAdd your key and certificate, .key and .crt for https under /zazu/encryption
google-zazu	Installation steps	For your key and certificate, talk to your admin.cd /zazu; docker build -t zazuimg .Push your Docker image to the Google Container Registry.Provision one static IP address for the application
google-zazu	Installation steps	Give it an appropriate name like **zazu-app**.
google-zazu	Support	This project is in alpha 
google-zooshi	Motivation	 Zooshi    serves as a demonstration of how to build cross-platformgames using a suite of open source game technologies fromFun Propulsion Labs at  Google    such as  Breadboard   , CORGI   ,  FlatBuffers   ,  FlatUI   ,  fplbase   ,  fplutil   , Motive   ,  Pindrop   ,  Scene Lab    and  WebP   
google-zooshi	Motivation	Zooshi    also demonstrates how to use the  Google Cardboard    API, whichis integrated into  fplbase   .
google-zooshi	Downloading	 Zooshi    can be downloaded from:**Important**:  Zooshi    uses submodules to reference other components itdepends upon, so download the source from  GitHub    using:~~~
google-zooshi	Documentation	See our documentation for how to  Build and Run Zooshi    and for a Programmer's Guide    that details the overall structure of the game and allof it's subsystems.To contribute the this project see  CONTRIBUTING   .For applications on Google Play that are derived from this application, usageis tracked.This tracking is done automatically using the embedded version string kVersion , and helps us continue to optimize it
google-zooshi	Documentation	Aside fromconsuming a few extra bytes in your application binary, it shouldn't affectyour application at all
google-zooshi	Documentation	We use this information to let us know if Zooshiis useful and if we should continue to invest in it
google-zooshi	Documentation	Since this is opensource, you are free to remove the version string but we would appreciate ifyou would leave it in
google-zooshi	Documentation	  Breadboard :   CORGI :   Flatbuffers :   fplbase :   GitHub :   Google :   Google Play :   Motive :   Pindrop :   Scene Lab :   Zooshi : 
